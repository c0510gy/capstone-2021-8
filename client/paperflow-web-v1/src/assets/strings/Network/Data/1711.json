{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "deep learning", "adversarial network", "graph"], ["recurrent neural network", "reinforcement learning", "transfer learning", "model", "machine learning", "embedding", "wireless network", "deep", "clustering", "generative adversarial network", "generative adversarial", "translation", "system", "challenge", "dialogue system", "deep reinforcement learning", "deep reinforcement", "generative model", "problem", "object detection", "detection", "object", "analysi", "datum", "machine translation", "neural machine translation", "neural machine", "recognition", "action recognition", "image", "framework", "algorithm", "approximation", "estimation", "pose estimation", "information", "video", "relational", "convolutional network", "classification", "application", "understanding", "game", "approach", "domain adaptation", "unsupervised domain adaptation", "unsupervised domain", "deep network", "communication", "resource allocation", "code", "speech recognition", "speech", "software", "complexity", "method", "word embedding", "language", "survey", "network embedding", "attack", "constraint", "massive mimo", "physical layer security", "physical layer", "distribution", "set", "prediction", "function", "bandit", "multi-armed bandit", "generation", "lower bound", "person re-identification", "segmentation", "channel", "design", "influence", "feature", "optimization", "training", "reading comprehension", "knowledge graph", "supervision", "social network", "signal", "question answering", "decomposition", "fast", "gan", "state", "medical image", "image retrieval", "agent", "extraction", "adversarial learning", "variational autoencoder", "case study", "reasoning", "genetic algorithm", "software development", "representation learning", "regression", "point cloud", "image segmentation", "study", "learning approach", "transfer", "deep convolutional", "program", "flow", "natural language", "proof", "explanation"], ["deep convolutional neural", "deep learning analysi", "learning analysi", "deep learning model", "learning model", "regularization of deep", "dropout", "graph clustering", "reinforcement", "machine learning algorithm", "learning algorithm", "monoid", "intersection", "networks for object", "video object", "deep generative model", "approximation algorithm", "median", "center", "architectures for deep", "first-person video", "fully convolutional network", "video classification", "synthesi", "question answering system", "localization", "language modeling", "high resolution", "motif", "cyclic", "cyclic code", "kernel", "rank", "recognition system", "software metric", "perspective", "deep generative", "hand pose estimation", "hand pose", "pose", "sentiment analysi", "adversarial attack", "efficient", "neural embedding", "layer security", "encoding", "abstract", "ordered", "image generation", "re-identification", "instance segmentation", "bound", "mimo channel", "filter", "extended version", "election", "dimensionality reduction", "answering", "visual question answering", "visual question", "question", "non-orthogonal multiple acces", "quantum", "content-based image retrieval", "deep representation", "autoencoder", "management system", "power control", "task-oriented dialogue system", "dataset", "machine type communication", "deep model", "deep learning approach", "machine learning approach", "style transfer", "deep convolutional autoencoder", "convolutional autoencoder", "classification using deep", "speech enhancement", "enhancement", "visual explanation", "extended abstract"], ["spectral dropout", "networks with spectral", "critical learning period", "classification with deep", "mapping diverse convolutional", "diverse convolutional neural", "toolflow for mapping", "free planar graph", "vertex partition", "free planar", "invariant encoding generative", "encoding generative adversarial", "data-driven dialogue system", "ethical challenge", "challenges in data-driven", "action branching architecture", "branching architecture", "game maturity model", "digital game maturity", "maturity model", "digital game", "invariant encoding", "jet tagging", "atlas experiment", "jet", "unified generative adversarial", "finite monoid", "intersection problem", "problem for finite", "video object detection", "characterize malware", "executables to detect", "detect and characterize", "dynamic analysi", "malware", "contextual cascading bandit", "cascading bandit", "clustering of contextual", "contextual cascading", "rgb-d datum", "detection from rgb-d", "frustum pointnet", "stochastic deep learning", "memristive network", "learning in memristive", "stochastic deep", "degeneracies and solution", "learning for machine", "unmanned ground vehicle", "recognition and manipulation", "vehicle for navigation", "unmanned ground", "hdr image", "reproduction of hdr", "gamut-mapping framework", "framework for color-accurate", "algorithms for ordered", "directed information", "estimation of directed", "directed", "multi-directional recurrent neural", "temporal data stream", "estimating missing datum", "streams using multi-directional", "multi-directional recurrent", "temporal relational reasoning", "reasoning in video", "relational reasoning", "counterfactual learning", "recurrent convolutional network", "recurrent convolutional", "shape inpainting", "dense volumetric pancrea", "networks for video", "classification by synthesi", "safer classification", "retrieval-based question answering", "modelling domain relationship", "systems in e-commerce", "domain relationship", "potential application", "understanding graph", "understanding map", "graph and understanding", "centroidal localization game", "centroidal localization", "localization game", "centroidal", "action branching", "challenges and approach", "code-switched datum", "modeling for code-switched", "adversarial feature augmentation", "feature augmentation", "augmentation for unsupervised", "color-accurate reproduction", "multimodal deep network", "high resolution urban", "resolution urban remote", "urban remote sensing", "motifs for optimized", "spatio-temporal motif", "optimized", "kernel and rank", "context neural machine", "document context neural", "memory network", "partially aligned corpus", "speech recognition system", "robust speech recognition", "recognition system based", "nonparametric independence testing", "nonparametric independence", "ecosystem perspective", "interactive complexity", "reliability of saliency", "saliency method", "reliability", "saliency", "method for object", "aligned corpus", "imagine and match", "improving textual-visual cross-modal", "textual-visual cross-modal retrieval", "exploiting temporal information", "temporal information", "pre-trained word embedding", "accuracy of pre-trained", "pre-trained word", "embeddings for sentiment", "interactive robot learning", "language and affordance", "learning of gesture", "robot learning", "interactive robot", "survey on network", "cooperative multi-agent planning", "multi-agent planning", "communication complexity", "efficient defense", "defenses against adversarial", "robust to adversarial", "interpretable neural embedding", "sparse interpretable neural", "stringent hardware constraint", "hardware constraint", "development under stringent", "stringent hardware", "agile method", "fine-grained action recognition", "diagnose and fix", "interpretable approach", "approach for fine-grained", "fine-grained action", "bdma massive mimo", "beamforming for physical", "grid flexibility support", "distribution market", "flexibility support", "ramping aggregator", "aggregator for grid", "fuzzy set", "closed-valued fuzzy set", "lattice embedding", "embeddings between type", "lattice", "student success prediction", "success prediction", "student succes", "prediction in mooc", "succes", "fully abstract", "sessions and function", "polymorphic session", "contextual gan", "generation from sketch", "sketch constraint", "constraint using contextual", "superpolynomial lower bound", "unambiguous automaton", "superpolynomial lower", "size of non-deterministic", "non-deterministic complement", "video captioning", "objects and interaction", "large-scale person re-identification", "quality estimation network", "region-based quality estimation", "quality estimation", "center of mas", "mass encoding", "encoding for instance", "distance to center", "data-driven dialogue", "bound for mimo", "gallager bound", "wireless fading channel", "vlsi design", "nonparametric equalizer", "equalizer for massive", "social influence", "elections through social", "controlling election", "controlling", "robust visual slam", "line feature", "visual slam", "slam with point", "point and line", "riemannian optimization", "generalized perspective", "reduction on grassmannian", "grassmannian via riemannian", "large minibatch sgd", "extremely large minibatch", "minibatch sgd", "large minibatch", "extremely large", "machine reading comprehension", "machine reading", "supervised language task", "neural skill transfer", "skill transfer", "knowledge graph embedding", "graph embedding", "structured knowledge graph", "multi-label zero-shot learning", "learning with structured", "thoracic disease identification", "limited supervision", "disease identification", "identification and localization", "localization with limited", "crowd signal", "detection in social", "networks via crowd", "fake news detection", "high-order attention model", "multiple access system", "uplink resource allocation", "enhanced uplink resource", "access system", "tensor decomposition", "intrinsic image decomposition", "self-supervised intrinsic image", "image decomposition", "intrinsic image", "optimization framework", "generic and fast", "generic", "fast and flexible", "fast reading comprehension", "entrepreneurship in america", "sad state", "state of entrepreneurship", "america", "learning deep representation", "representations of medical", "prosthetic agent", "capital for prosthetic", "communicative capital", "capital", "communicative", "prediction of website", "website fingerprint", "fingerprints with deep", "p-fp", "kernelized hashcode representation", "multi-domain adversarial learning", "learning for knowledge", "kbgan", "semantic topic embedding", "topic embedding model", "continuous semantic topic", "semantic topic", "content management system", "macedonian education", "computing and content", "content management", "efficient power control", "energy-delay efficient power", "efficient power", "control in wireles", "learning and reasoning", "algorithms for evolving", "evaluation function", "parallel genetic algorithm", "cryptanalysis of merkle-hellman", "merkle-hellman cipher", "security in bdma", "image understanding", "large-scale dataset", "deeper in image", "challenger", "matrix factorization perspective", "explicit matrix factorization", "enhancing network embedding", "auxiliary information", "discrete representation learning", "neural discrete representation", "discrete representation", "discrete", "audio representation learning", "regression for hand", "dense", "regression problem", "similarity group proposal", "point cloud instance", "cloud instance segmentation", "group proposal network", "similarity group", "unsupervised image segmentation", "fully unsupervised image", "model for fully", "fully unsupervised", "gan distribution", "study of covariate", "covariate shift", "shift in gan", "classification-based study", "efficient uncertainty quantification", "multiscale method", "approach for efficient", "generalized style transfer", "content for generalized", "generalized style", "separating style", "painter classification", "deeppainter", "learning deep", "relational theory", "semantics for relational", "adversarial feature", "similarity learning", "visual speech enhancement", "visual speech", "medical conversation", "resource analysi", "probabilistic program", "bounded expectation", "analysis for probabilistic", "expectation", "semi-automated signal surveying", "video enhancement", "task-oriented flow", "enhancement with task-oriented", "flow correlation tracking", "operational natural language", "natural language inference", "language inference model", "inference models enhanced", "neural natural language", "proof rule", "almost-sure termination", "rule for almost-sure", "termination", "rule", "deep visual explanation", "focus deep visual", "focus deep", "resizable mini-batch gradient", "mini-batch gradient descent", "gradient descent based", "resizable mini-batch", "mini-batch gradient"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 1]}, {"source": "learning", "target": "transfer learning", "depth": [0, 1]}, {"source": "learning", "target": "model", "depth": [0, 1]}, {"source": "learning", "target": "machine learning", "depth": [0, 1]}, {"source": "network", "target": "adversarial network", "depth": [0, 0]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "embedding", "depth": [0, 1]}, {"source": "network", "target": "wireless network", "depth": [0, 1]}, {"source": "network", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning analysi", "depth": [0, 2]}, {"source": "deep learning", "target": "learning analysi", "depth": [0, 2]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 2]}, {"source": "deep learning", "target": "learning model", "depth": [0, 2]}, {"source": "deep neural network", "target": "spectral dropout", "depth": [0, 3]}, {"source": "deep neural network", "target": "networks with spectral", "depth": [0, 3]}, {"source": "deep neural network", "target": "regularization of deep", "depth": [0, 2]}, {"source": "deep neural network", "target": "dropout", "depth": [0, 2]}, {"source": "deep neural network", "target": "critical learning period", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "classification with deep", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "mapping diverse convolutional", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "diverse convolutional neural", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "toolflow for mapping", "depth": [0, 3]}, {"source": "graph", "target": "graph clustering", "depth": [0, 2]}, {"source": "graph", "target": "clustering", "depth": [0, 1]}, {"source": "graph", "target": "free planar graph", "depth": [0, 3]}, {"source": "graph", "target": "vertex partition", "depth": [0, 3]}, {"source": "graph", "target": "free planar", "depth": [0, 3]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [0, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "adversarial network", "target": "translation", "depth": [0, 1]}, {"source": "adversarial network", "target": "invariant encoding generative", "depth": [0, 3]}, {"source": "adversarial network", "target": "encoding generative adversarial", "depth": [0, 3]}, {"source": "system", "target": "challenge", "depth": [1, 1]}, {"source": "system", "target": "dialogue system", "depth": [1, 1]}, {"source": "system", "target": "data-driven dialogue system", "depth": [1, 3]}, {"source": "system", "target": "ethical challenge", "depth": [1, 3]}, {"source": "system", "target": "challenges in data-driven", "depth": [1, 3]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [1, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [1, 2]}, {"source": "reinforcement learning", "target": "action branching architecture", "depth": [1, 3]}, {"source": "reinforcement learning", "target": "branching architecture", "depth": [1, 3]}, {"source": "model", "target": "generative model", "depth": [1, 1]}, {"source": "model", "target": "game maturity model", "depth": [1, 3]}, {"source": "model", "target": "digital game maturity", "depth": [1, 3]}, {"source": "model", "target": "maturity model", "depth": [1, 3]}, {"source": "model", "target": "digital game", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "translation", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "invariant encoding generative", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "encoding generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "invariant encoding", "depth": [1, 3]}, {"source": "machine learning", "target": "machine learning algorithm", "depth": [1, 2]}, {"source": "machine learning", "target": "jet tagging", "depth": [1, 3]}, {"source": "machine learning", "target": "atlas experiment", "depth": [1, 3]}, {"source": "machine learning", "target": "learning algorithm", "depth": [1, 2]}, {"source": "machine learning", "target": "jet", "depth": [1, 3]}, {"source": "generative adversarial", "target": "translation", "depth": [1, 1]}, {"source": "generative adversarial", "target": "invariant encoding generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "encoding generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "invariant encoding", "depth": [1, 3]}, {"source": "generative adversarial", "target": "unified generative adversarial", "depth": [1, 3]}, {"source": "problem", "target": "monoid", "depth": [1, 2]}, {"source": "problem", "target": "finite monoid", "depth": [1, 3]}, {"source": "problem", "target": "intersection problem", "depth": [1, 3]}, {"source": "problem", "target": "problem for finite", "depth": [1, 3]}, {"source": "problem", "target": "intersection", "depth": [1, 2]}, {"source": "object detection", "target": "detection", "depth": [1, 1]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "networks for object", "depth": [1, 2]}, {"source": "object detection", "target": "video object detection", "depth": [1, 3]}, {"source": "object detection", "target": "video object", "depth": [1, 2]}, {"source": "analysi", "target": "characterize malware", "depth": [1, 3]}, {"source": "analysi", "target": "executables to detect", "depth": [1, 3]}, {"source": "analysi", "target": "detect and characterize", "depth": [1, 3]}, {"source": "analysi", "target": "dynamic analysi", "depth": [1, 3]}, {"source": "analysi", "target": "malware", "depth": [1, 3]}, {"source": "clustering", "target": "graph clustering", "depth": [1, 2]}, {"source": "clustering", "target": "contextual cascading bandit", "depth": [1, 3]}, {"source": "clustering", "target": "cascading bandit", "depth": [1, 3]}, {"source": "clustering", "target": "clustering of contextual", "depth": [1, 3]}, {"source": "clustering", "target": "contextual cascading", "depth": [1, 3]}, {"source": "datum", "target": "rgb-d datum", "depth": [1, 3]}, {"source": "datum", "target": "detection from rgb-d", "depth": [1, 3]}, {"source": "datum", "target": "frustum pointnet", "depth": [1, 3]}, {"source": "datum", "target": "object", "depth": [1, 1]}, {"source": "datum", "target": "detection", "depth": [1, 1]}, {"source": "deep", "target": "stochastic deep learning", "depth": [1, 3]}, {"source": "deep", "target": "memristive network", "depth": [1, 3]}, {"source": "deep", "target": "learning in memristive", "depth": [1, 3]}, {"source": "deep", "target": "stochastic deep", "depth": [1, 3]}, {"source": "deep", "target": "deep generative model", "depth": [1, 2]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "translation", "depth": [1, 1]}, {"source": "machine translation", "target": "degeneracies and solution", "depth": [1, 3]}, {"source": "machine translation", "target": "learning for machine", "depth": [1, 3]}, {"source": "detection", "target": "object", "depth": [1, 1]}, {"source": "detection", "target": "networks for object", "depth": [1, 2]}, {"source": "detection", "target": "rgb-d datum", "depth": [1, 3]}, {"source": "detection", "target": "detection from rgb-d", "depth": [1, 3]}, {"source": "detection", "target": "frustum pointnet", "depth": [1, 3]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "unmanned ground vehicle", "depth": [1, 3]}, {"source": "recognition", "target": "recognition and manipulation", "depth": [1, 3]}, {"source": "recognition", "target": "vehicle for navigation", "depth": [1, 3]}, {"source": "recognition", "target": "unmanned ground", "depth": [1, 3]}, {"source": "image", "target": "framework", "depth": [1, 1]}, {"source": "image", "target": "hdr image", "depth": [1, 3]}, {"source": "image", "target": "reproduction of hdr", "depth": [1, 3]}, {"source": "image", "target": "gamut-mapping framework", "depth": [1, 3]}, {"source": "image", "target": "framework for color-accurate", "depth": [1, 3]}, {"source": "algorithm", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "algorithms for ordered", "depth": [1, 3]}, {"source": "algorithm", "target": "median", "depth": [1, 2]}, {"source": "algorithm", "target": "center", "depth": [1, 2]}, {"source": "algorithm", "target": "approximation", "depth": [1, 1]}, {"source": "estimation", "target": "pose estimation", "depth": [1, 1]}, {"source": "estimation", "target": "directed information", "depth": [1, 3]}, {"source": "estimation", "target": "estimation of directed", "depth": [1, 3]}, {"source": "estimation", "target": "information", "depth": [1, 1]}, {"source": "estimation", "target": "directed", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "action branching architecture", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "branching architecture", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "architectures for deep", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "multi-directional recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "temporal data stream", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "estimating missing datum", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "streams using multi-directional", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "multi-directional recurrent", "depth": [1, 3]}, {"source": "video", "target": "first-person video", "depth": [1, 2]}, {"source": "video", "target": "temporal relational reasoning", "depth": [1, 3]}, {"source": "video", "target": "reasoning in video", "depth": [1, 3]}, {"source": "video", "target": "relational reasoning", "depth": [1, 3]}, {"source": "video", "target": "relational", "depth": [1, 1]}, {"source": "translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "translation", "target": "neural machine", "depth": [1, 1]}, {"source": "translation", "target": "degeneracies and solution", "depth": [1, 3]}, {"source": "translation", "target": "learning for machine", "depth": [1, 3]}, {"source": "translation", "target": "counterfactual learning", "depth": [1, 3]}, {"source": "convolutional network", "target": "fully convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "recurrent convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "recurrent convolutional", "depth": [1, 3]}, {"source": "convolutional network", "target": "shape inpainting", "depth": [1, 3]}, {"source": "convolutional network", "target": "dense volumetric pancrea", "depth": [1, 3]}, {"source": "classification", "target": "video classification", "depth": [1, 2]}, {"source": "classification", "target": "networks for video", "depth": [1, 3]}, {"source": "classification", "target": "classification by synthesi", "depth": [1, 3]}, {"source": "classification", "target": "safer classification", "depth": [1, 3]}, {"source": "classification", "target": "synthesi", "depth": [1, 2]}, {"source": "transfer learning", "target": "retrieval-based question answering", "depth": [1, 3]}, {"source": "transfer learning", "target": "question answering system", "depth": [1, 2]}, {"source": "transfer learning", "target": "modelling domain relationship", "depth": [1, 3]}, {"source": "transfer learning", "target": "systems in e-commerce", "depth": [1, 3]}, {"source": "transfer learning", "target": "domain relationship", "depth": [1, 3]}, {"source": "application", "target": "potential application", "depth": [1, 3]}, {"source": "application", "target": "understanding graph", "depth": [1, 3]}, {"source": "application", "target": "understanding map", "depth": [1, 3]}, {"source": "application", "target": "graph and understanding", "depth": [1, 3]}, {"source": "application", "target": "understanding", "depth": [1, 1]}, {"source": "game", "target": "centroidal localization game", "depth": [1, 3]}, {"source": "game", "target": "centroidal localization", "depth": [1, 3]}, {"source": "game", "target": "localization game", "depth": [1, 3]}, {"source": "game", "target": "centroidal", "depth": [1, 3]}, {"source": "game", "target": "localization", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "reinforcement", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "action branching architecture", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "branching architecture", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "architectures for deep", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "action branching", "depth": [1, 3]}, {"source": "approach", "target": "challenges and approach", "depth": [1, 3]}, {"source": "approach", "target": "language modeling", "depth": [1, 2]}, {"source": "approach", "target": "code-switched datum", "depth": [1, 3]}, {"source": "approach", "target": "modeling for code-switched", "depth": [1, 3]}, {"source": "approach", "target": "challenge", "depth": [1, 1]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "adversarial feature augmentation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "feature augmentation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "augmentation for unsupervised", "depth": [1, 3]}, {"source": "framework", "target": "hdr image", "depth": [1, 3]}, {"source": "framework", "target": "reproduction of hdr", "depth": [1, 3]}, {"source": "framework", "target": "gamut-mapping framework", "depth": [1, 3]}, {"source": "framework", "target": "framework for color-accurate", "depth": [1, 3]}, {"source": "framework", "target": "color-accurate reproduction", "depth": [1, 3]}, {"source": "deep network", "target": "multimodal deep network", "depth": [1, 3]}, {"source": "deep network", "target": "high resolution urban", "depth": [1, 3]}, {"source": "deep network", "target": "resolution urban remote", "depth": [1, 3]}, {"source": "deep network", "target": "urban remote sensing", "depth": [1, 3]}, {"source": "deep network", "target": "high resolution", "depth": [1, 2]}, {"source": "communication", "target": "resource allocation", "depth": [1, 1]}, {"source": "communication", "target": "motifs for optimized", "depth": [1, 3]}, {"source": "communication", "target": "spatio-temporal motif", "depth": [1, 3]}, {"source": "communication", "target": "optimized", "depth": [1, 3]}, {"source": "communication", "target": "motif", "depth": [1, 2]}, {"source": "code", "target": "cyclic", "depth": [1, 2]}, {"source": "code", "target": "cyclic code", "depth": [1, 2]}, {"source": "code", "target": "kernel and rank", "depth": [1, 3]}, {"source": "code", "target": "kernel", "depth": [1, 2]}, {"source": "code", "target": "rank", "depth": [1, 2]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "context neural machine", "depth": [1, 3]}, {"source": "neural machine translation", "target": "document context neural", "depth": [1, 3]}, {"source": "neural machine translation", "target": "memory network", "depth": [1, 3]}, {"source": "neural machine translation", "target": "partially aligned corpus", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech recognition system", "depth": [1, 3]}, {"source": "speech recognition", "target": "recognition system", "depth": [1, 2]}, {"source": "speech recognition", "target": "robust speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "recognition system based", "depth": [1, 3]}, {"source": "information", "target": "directed information", "depth": [1, 3]}, {"source": "information", "target": "estimation of directed", "depth": [1, 3]}, {"source": "information", "target": "directed", "depth": [1, 3]}, {"source": "information", "target": "nonparametric independence testing", "depth": [1, 3]}, {"source": "information", "target": "nonparametric independence", "depth": [1, 3]}, {"source": "software", "target": "software metric", "depth": [1, 2]}, {"source": "software", "target": "ecosystem perspective", "depth": [1, 3]}, {"source": "software", "target": "interactive complexity", "depth": [1, 3]}, {"source": "software", "target": "complexity", "depth": [1, 1]}, {"source": "software", "target": "perspective", "depth": [1, 2]}, {"source": "method", "target": "reliability of saliency", "depth": [1, 3]}, {"source": "method", "target": "saliency method", "depth": [1, 3]}, {"source": "method", "target": "reliability", "depth": [1, 3]}, {"source": "method", "target": "saliency", "depth": [1, 3]}, {"source": "method", "target": "method for object", "depth": [1, 3]}, {"source": "neural machine", "target": "context neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "document context neural", "depth": [1, 3]}, {"source": "neural machine", "target": "memory network", "depth": [1, 3]}, {"source": "neural machine", "target": "partially aligned corpus", "depth": [1, 3]}, {"source": "neural machine", "target": "aligned corpus", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "generative model", "target": "imagine and match", "depth": [1, 3]}, {"source": "generative model", "target": "improving textual-visual cross-modal", "depth": [1, 3]}, {"source": "generative model", "target": "textual-visual cross-modal retrieval", "depth": [1, 3]}, {"source": "pose estimation", "target": "hand pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "hand pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "exploiting temporal information", "depth": [1, 3]}, {"source": "pose estimation", "target": "temporal information", "depth": [1, 3]}, {"source": "word embedding", "target": "pre-trained word embedding", "depth": [1, 3]}, {"source": "word embedding", "target": "sentiment analysi", "depth": [1, 2]}, {"source": "word embedding", "target": "accuracy of pre-trained", "depth": [1, 3]}, {"source": "word embedding", "target": "pre-trained word", "depth": [1, 3]}, {"source": "word embedding", "target": "embeddings for sentiment", "depth": [1, 3]}, {"source": "language", "target": "interactive robot learning", "depth": [1, 3]}, {"source": "language", "target": "language and affordance", "depth": [1, 3]}, {"source": "language", "target": "learning of gesture", "depth": [1, 3]}, {"source": "language", "target": "robot learning", "depth": [1, 3]}, {"source": "language", "target": "interactive robot", "depth": [1, 3]}, {"source": "survey", "target": "network embedding", "depth": [1, 1]}, {"source": "survey", "target": "survey on network", "depth": [1, 3]}, {"source": "survey", "target": "embedding", "depth": [1, 1]}, {"source": "survey", "target": "cooperative multi-agent planning", "depth": [1, 3]}, {"source": "survey", "target": "multi-agent planning", "depth": [1, 3]}, {"source": "complexity", "target": "software metric", "depth": [1, 2]}, {"source": "complexity", "target": "ecosystem perspective", "depth": [1, 3]}, {"source": "complexity", "target": "interactive complexity", "depth": [1, 3]}, {"source": "complexity", "target": "perspective", "depth": [1, 2]}, {"source": "complexity", "target": "communication complexity", "depth": [1, 3]}, {"source": "attack", "target": "adversarial attack", "depth": [1, 2]}, {"source": "attack", "target": "efficient defense", "depth": [1, 3]}, {"source": "attack", "target": "defenses against adversarial", "depth": [1, 3]}, {"source": "attack", "target": "robust to adversarial", "depth": [1, 3]}, {"source": "attack", "target": "efficient", "depth": [1, 2]}, {"source": "embedding", "target": "network embedding", "depth": [1, 1]}, {"source": "embedding", "target": "survey on network", "depth": [1, 3]}, {"source": "embedding", "target": "interpretable neural embedding", "depth": [1, 3]}, {"source": "embedding", "target": "sparse interpretable neural", "depth": [1, 3]}, {"source": "embedding", "target": "neural embedding", "depth": [1, 2]}, {"source": "constraint", "target": "stringent hardware constraint", "depth": [1, 3]}, {"source": "constraint", "target": "hardware constraint", "depth": [1, 3]}, {"source": "constraint", "target": "development under stringent", "depth": [1, 3]}, {"source": "constraint", "target": "stringent hardware", "depth": [1, 3]}, {"source": "constraint", "target": "agile method", "depth": [1, 3]}, {"source": "action recognition", "target": "fine-grained action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "diagnose and fix", "depth": [1, 3]}, {"source": "action recognition", "target": "interpretable approach", "depth": [1, 3]}, {"source": "action recognition", "target": "approach for fine-grained", "depth": [1, 3]}, {"source": "action recognition", "target": "fine-grained action", "depth": [1, 3]}, {"source": "massive mimo", "target": "bdma massive mimo", "depth": [1, 3]}, {"source": "massive mimo", "target": "physical layer security", "depth": [1, 1]}, {"source": "massive mimo", "target": "beamforming for physical", "depth": [1, 3]}, {"source": "massive mimo", "target": "physical layer", "depth": [1, 1]}, {"source": "massive mimo", "target": "layer security", "depth": [1, 2]}, {"source": "distribution", "target": "grid flexibility support", "depth": [1, 3]}, {"source": "distribution", "target": "distribution market", "depth": [1, 3]}, {"source": "distribution", "target": "flexibility support", "depth": [1, 3]}, {"source": "distribution", "target": "ramping aggregator", "depth": [1, 3]}, {"source": "distribution", "target": "aggregator for grid", "depth": [1, 3]}, {"source": "set", "target": "fuzzy set", "depth": [1, 3]}, {"source": "set", "target": "closed-valued fuzzy set", "depth": [1, 3]}, {"source": "set", "target": "lattice embedding", "depth": [1, 3]}, {"source": "set", "target": "embeddings between type", "depth": [1, 3]}, {"source": "set", "target": "lattice", "depth": [1, 3]}, {"source": "prediction", "target": "student success prediction", "depth": [1, 3]}, {"source": "prediction", "target": "success prediction", "depth": [1, 3]}, {"source": "prediction", "target": "student succes", "depth": [1, 3]}, {"source": "prediction", "target": "prediction in mooc", "depth": [1, 3]}, {"source": "prediction", "target": "succes", "depth": [1, 3]}, {"source": "function", "target": "fully abstract", "depth": [1, 3]}, {"source": "function", "target": "sessions and function", "depth": [1, 3]}, {"source": "function", "target": "polymorphic session", "depth": [1, 3]}, {"source": "function", "target": "encoding", "depth": [1, 2]}, {"source": "function", "target": "abstract", "depth": [1, 2]}, {"source": "bandit", "target": "multi-armed bandit", "depth": [1, 1]}, {"source": "bandit", "target": "contextual cascading bandit", "depth": [1, 3]}, {"source": "bandit", "target": "cascading bandit", "depth": [1, 3]}, {"source": "bandit", "target": "clustering of contextual", "depth": [1, 3]}, {"source": "bandit", "target": "contextual cascading", "depth": [1, 3]}, {"source": "approximation", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "approximation", "target": "median", "depth": [1, 2]}, {"source": "approximation", "target": "ordered", "depth": [1, 2]}, {"source": "approximation", "target": "algorithms for ordered", "depth": [1, 3]}, {"source": "approximation", "target": "center", "depth": [1, 2]}, {"source": "generation", "target": "contextual gan", "depth": [1, 3]}, {"source": "generation", "target": "generation from sketch", "depth": [1, 3]}, {"source": "generation", "target": "sketch constraint", "depth": [1, 3]}, {"source": "generation", "target": "constraint using contextual", "depth": [1, 3]}, {"source": "generation", "target": "image generation", "depth": [1, 2]}, {"source": "lower bound", "target": "superpolynomial lower bound", "depth": [1, 3]}, {"source": "lower bound", "target": "unambiguous automaton", "depth": [1, 3]}, {"source": "lower bound", "target": "superpolynomial lower", "depth": [1, 3]}, {"source": "lower bound", "target": "size of non-deterministic", "depth": [1, 3]}, {"source": "lower bound", "target": "non-deterministic complement", "depth": [1, 3]}, {"source": "object", "target": "rgb-d datum", "depth": [1, 3]}, {"source": "object", "target": "detection from rgb-d", "depth": [1, 3]}, {"source": "object", "target": "frustum pointnet", "depth": [1, 3]}, {"source": "object", "target": "video captioning", "depth": [1, 3]}, {"source": "object", "target": "objects and interaction", "depth": [1, 3]}, {"source": "person re-identification", "target": "re-identification", "depth": [1, 2]}, {"source": "person re-identification", "target": "large-scale person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "quality estimation network", "depth": [1, 3]}, {"source": "person re-identification", "target": "region-based quality estimation", "depth": [1, 3]}, {"source": "person re-identification", "target": "quality estimation", "depth": [1, 3]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 2]}, {"source": "segmentation", "target": "center of mas", "depth": [1, 3]}, {"source": "segmentation", "target": "mass encoding", "depth": [1, 3]}, {"source": "segmentation", "target": "encoding for instance", "depth": [1, 3]}, {"source": "segmentation", "target": "distance to center", "depth": [1, 3]}, {"source": "challenge", "target": "data-driven dialogue system", "depth": [1, 3]}, {"source": "challenge", "target": "dialogue system", "depth": [1, 1]}, {"source": "challenge", "target": "ethical challenge", "depth": [1, 3]}, {"source": "challenge", "target": "challenges in data-driven", "depth": [1, 3]}, {"source": "challenge", "target": "data-driven dialogue", "depth": [1, 3]}, {"source": "channel", "target": "bound", "depth": [1, 2]}, {"source": "channel", "target": "mimo channel", "depth": [1, 2]}, {"source": "channel", "target": "bound for mimo", "depth": [1, 3]}, {"source": "channel", "target": "gallager bound", "depth": [1, 3]}, {"source": "channel", "target": "wireless fading channel", "depth": [1, 3]}, {"source": "design", "target": "filter", "depth": [1, 2]}, {"source": "design", "target": "extended version", "depth": [1, 2]}, {"source": "design", "target": "vlsi design", "depth": [1, 3]}, {"source": "design", "target": "nonparametric equalizer", "depth": [1, 3]}, {"source": "design", "target": "equalizer for massive", "depth": [1, 3]}, {"source": "influence", "target": "social influence", "depth": [1, 3]}, {"source": "influence", "target": "elections through social", "depth": [1, 3]}, {"source": "influence", "target": "controlling election", "depth": [1, 3]}, {"source": "influence", "target": "election", "depth": [1, 2]}, {"source": "influence", "target": "controlling", "depth": [1, 3]}, {"source": "feature", "target": "robust visual slam", "depth": [1, 3]}, {"source": "feature", "target": "line feature", "depth": [1, 3]}, {"source": "feature", "target": "visual slam", "depth": [1, 3]}, {"source": "feature", "target": "slam with point", "depth": [1, 3]}, {"source": "feature", "target": "point and line", "depth": [1, 3]}, {"source": "optimization", "target": "riemannian optimization", "depth": [1, 3]}, {"source": "optimization", "target": "generalized perspective", "depth": [1, 3]}, {"source": "optimization", "target": "reduction on grassmannian", "depth": [1, 3]}, {"source": "optimization", "target": "grassmannian via riemannian", "depth": [1, 3]}, {"source": "optimization", "target": "dimensionality reduction", "depth": [1, 2]}, {"source": "training", "target": "large minibatch sgd", "depth": [1, 3]}, {"source": "training", "target": "extremely large minibatch", "depth": [1, 3]}, {"source": "training", "target": "minibatch sgd", "depth": [1, 3]}, {"source": "training", "target": "large minibatch", "depth": [1, 3]}, {"source": "training", "target": "extremely large", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading", "depth": [1, 3]}, {"source": "reading comprehension", "target": "supervised language task", "depth": [1, 3]}, {"source": "reading comprehension", "target": "neural skill transfer", "depth": [1, 3]}, {"source": "reading comprehension", "target": "skill transfer", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 3]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 3]}, {"source": "knowledge graph", "target": "structured knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "multi-label zero-shot learning", "depth": [1, 3]}, {"source": "knowledge graph", "target": "learning with structured", "depth": [1, 3]}, {"source": "supervision", "target": "thoracic disease identification", "depth": [1, 3]}, {"source": "supervision", "target": "limited supervision", "depth": [1, 3]}, {"source": "supervision", "target": "disease identification", "depth": [1, 3]}, {"source": "supervision", "target": "identification and localization", "depth": [1, 3]}, {"source": "supervision", "target": "localization with limited", "depth": [1, 3]}, {"source": "social network", "target": "crowd signal", "depth": [1, 3]}, {"source": "social network", "target": "detection in social", "depth": [1, 3]}, {"source": "social network", "target": "networks via crowd", "depth": [1, 3]}, {"source": "social network", "target": "fake news detection", "depth": [1, 3]}, {"source": "social network", "target": "signal", "depth": [1, 1]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question", "depth": [1, 2]}, {"source": "question answering", "target": "question", "depth": [1, 2]}, {"source": "question answering", "target": "high-order attention model", "depth": [1, 3]}, {"source": "resource allocation", "target": "multiple access system", "depth": [1, 3]}, {"source": "resource allocation", "target": "uplink resource allocation", "depth": [1, 3]}, {"source": "resource allocation", "target": "enhanced uplink resource", "depth": [1, 3]}, {"source": "resource allocation", "target": "non-orthogonal multiple acces", "depth": [1, 2]}, {"source": "resource allocation", "target": "access system", "depth": [1, 3]}, {"source": "decomposition", "target": "tensor decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "intrinsic image decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "self-supervised intrinsic image", "depth": [1, 3]}, {"source": "decomposition", "target": "image decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "intrinsic image", "depth": [1, 3]}, {"source": "fast", "target": "optimization framework", "depth": [1, 3]}, {"source": "fast", "target": "generic and fast", "depth": [1, 3]}, {"source": "fast", "target": "generic", "depth": [1, 3]}, {"source": "fast", "target": "fast and flexible", "depth": [1, 3]}, {"source": "fast", "target": "fast reading comprehension", "depth": [1, 3]}, {"source": "gan", "target": "contextual gan", "depth": [1, 3]}, {"source": "gan", "target": "generation from sketch", "depth": [1, 3]}, {"source": "gan", "target": "sketch constraint", "depth": [1, 3]}, {"source": "gan", "target": "constraint using contextual", "depth": [1, 3]}, {"source": "gan", "target": "image generation", "depth": [1, 2]}, {"source": "state", "target": "quantum", "depth": [1, 2]}, {"source": "state", "target": "entrepreneurship in america", "depth": [1, 3]}, {"source": "state", "target": "sad state", "depth": [1, 3]}, {"source": "state", "target": "state of entrepreneurship", "depth": [1, 3]}, {"source": "state", "target": "america", "depth": [1, 3]}, {"source": "medical image", "target": "learning deep representation", "depth": [1, 3]}, {"source": "medical image", "target": "content-based image retrieval", "depth": [1, 2]}, {"source": "medical image", "target": "image retrieval", "depth": [1, 1]}, {"source": "medical image", "target": "deep representation", "depth": [1, 2]}, {"source": "medical image", "target": "representations of medical", "depth": [1, 3]}, {"source": "agent", "target": "prosthetic agent", "depth": [1, 3]}, {"source": "agent", "target": "capital for prosthetic", "depth": [1, 3]}, {"source": "agent", "target": "communicative capital", "depth": [1, 3]}, {"source": "agent", "target": "capital", "depth": [1, 3]}, {"source": "agent", "target": "communicative", "depth": [1, 3]}, {"source": "extraction", "target": "prediction of website", "depth": [1, 3]}, {"source": "extraction", "target": "website fingerprint", "depth": [1, 3]}, {"source": "extraction", "target": "fingerprints with deep", "depth": [1, 3]}, {"source": "extraction", "target": "p-fp", "depth": [1, 3]}, {"source": "extraction", "target": "kernelized hashcode representation", "depth": [1, 3]}, {"source": "adversarial learning", "target": "multi-domain adversarial learning", "depth": [1, 3]}, {"source": "adversarial learning", "target": "knowledge graph embedding", "depth": [1, 3]}, {"source": "adversarial learning", "target": "graph embedding", "depth": [1, 3]}, {"source": "adversarial learning", "target": "learning for knowledge", "depth": [1, 3]}, {"source": "adversarial learning", "target": "kbgan", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "semantic topic embedding", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "topic embedding model", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "continuous semantic topic", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "semantic topic", "depth": [1, 3]}, {"source": "case study", "target": "content management system", "depth": [1, 3]}, {"source": "case study", "target": "management system", "depth": [1, 2]}, {"source": "case study", "target": "macedonian education", "depth": [1, 3]}, {"source": "case study", "target": "computing and content", "depth": [1, 3]}, {"source": "case study", "target": "content management", "depth": [1, 3]}, {"source": "wireless network", "target": "efficient power control", "depth": [1, 3]}, {"source": "wireless network", "target": "energy-delay efficient power", "depth": [1, 3]}, {"source": "wireless network", "target": "efficient power", "depth": [1, 3]}, {"source": "wireless network", "target": "power control", "depth": [1, 2]}, {"source": "wireless network", "target": "control in wireles", "depth": [1, 3]}, {"source": "reasoning", "target": "temporal relational reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "reasoning in video", "depth": [1, 3]}, {"source": "reasoning", "target": "relational reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "relational", "depth": [1, 1]}, {"source": "reasoning", "target": "learning and reasoning", "depth": [1, 3]}, {"source": "genetic algorithm", "target": "algorithms for evolving", "depth": [1, 3]}, {"source": "genetic algorithm", "target": "evaluation function", "depth": [1, 3]}, {"source": "genetic algorithm", "target": "parallel genetic algorithm", "depth": [1, 3]}, {"source": "genetic algorithm", "target": "cryptanalysis of merkle-hellman", "depth": [1, 3]}, {"source": "genetic algorithm", "target": "merkle-hellman cipher", "depth": [1, 3]}, {"source": "physical layer security", "target": "physical layer", "depth": [1, 1]}, {"source": "physical layer security", "target": "layer security", "depth": [1, 2]}, {"source": "physical layer security", "target": "bdma massive mimo", "depth": [1, 3]}, {"source": "physical layer security", "target": "beamforming for physical", "depth": [1, 3]}, {"source": "physical layer security", "target": "security in bdma", "depth": [1, 3]}, {"source": "software development", "target": "stringent hardware constraint", "depth": [1, 3]}, {"source": "software development", "target": "hardware constraint", "depth": [1, 3]}, {"source": "software development", "target": "development under stringent", "depth": [1, 3]}, {"source": "software development", "target": "stringent hardware", "depth": [1, 3]}, {"source": "software development", "target": "agile method", "depth": [1, 3]}, {"source": "dialogue system", "target": "task-oriented dialogue system", "depth": [1, 2]}, {"source": "dialogue system", "target": "data-driven dialogue system", "depth": [1, 3]}, {"source": "dialogue system", "target": "ethical challenge", "depth": [1, 3]}, {"source": "dialogue system", "target": "challenges in data-driven", "depth": [1, 3]}, {"source": "dialogue system", "target": "data-driven dialogue", "depth": [1, 3]}, {"source": "understanding", "target": "image understanding", "depth": [1, 3]}, {"source": "understanding", "target": "large-scale dataset", "depth": [1, 3]}, {"source": "understanding", "target": "deeper in image", "depth": [1, 3]}, {"source": "understanding", "target": "challenger", "depth": [1, 3]}, {"source": "understanding", "target": "dataset", "depth": [1, 2]}, {"source": "network embedding", "target": "survey on network", "depth": [1, 3]}, {"source": "network embedding", "target": "matrix factorization perspective", "depth": [1, 3]}, {"source": "network embedding", "target": "explicit matrix factorization", "depth": [1, 3]}, {"source": "network embedding", "target": "enhancing network embedding", "depth": [1, 3]}, {"source": "network embedding", "target": "auxiliary information", "depth": [1, 3]}, {"source": "representation learning", "target": "discrete representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "neural discrete representation", "depth": [1, 3]}, {"source": "representation learning", "target": "discrete representation", "depth": [1, 3]}, {"source": "representation learning", "target": "discrete", "depth": [1, 3]}, {"source": "representation learning", "target": "audio representation learning", "depth": [1, 3]}, {"source": "physical layer", "target": "layer security", "depth": [1, 2]}, {"source": "physical layer", "target": "bdma massive mimo", "depth": [1, 3]}, {"source": "physical layer", "target": "beamforming for physical", "depth": [1, 3]}, {"source": "physical layer", "target": "security in bdma", "depth": [1, 3]}, {"source": "physical layer", "target": "machine type communication", "depth": [1, 2]}, {"source": "regression", "target": "hand pose estimation", "depth": [1, 2]}, {"source": "regression", "target": "regression for hand", "depth": [1, 3]}, {"source": "regression", "target": "hand pose", "depth": [1, 2]}, {"source": "regression", "target": "dense", "depth": [1, 3]}, {"source": "regression", "target": "regression problem", "depth": [1, 3]}, {"source": "point cloud", "target": "similarity group proposal", "depth": [1, 3]}, {"source": "point cloud", "target": "point cloud instance", "depth": [1, 3]}, {"source": "point cloud", "target": "cloud instance segmentation", "depth": [1, 3]}, {"source": "point cloud", "target": "group proposal network", "depth": [1, 3]}, {"source": "point cloud", "target": "similarity group", "depth": [1, 3]}, {"source": "image segmentation", "target": "unsupervised image segmentation", "depth": [1, 3]}, {"source": "image segmentation", "target": "fully unsupervised image", "depth": [1, 3]}, {"source": "image segmentation", "target": "deep model", "depth": [1, 2]}, {"source": "image segmentation", "target": "model for fully", "depth": [1, 3]}, {"source": "image segmentation", "target": "fully unsupervised", "depth": [1, 3]}, {"source": "study", "target": "gan distribution", "depth": [1, 3]}, {"source": "study", "target": "study of covariate", "depth": [1, 3]}, {"source": "study", "target": "covariate shift", "depth": [1, 3]}, {"source": "study", "target": "shift in gan", "depth": [1, 3]}, {"source": "study", "target": "classification-based study", "depth": [1, 3]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "efficient uncertainty quantification", "depth": [1, 3]}, {"source": "learning approach", "target": "multiscale method", "depth": [1, 3]}, {"source": "learning approach", "target": "approach for efficient", "depth": [1, 3]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "transfer", "target": "generalized style transfer", "depth": [1, 3]}, {"source": "transfer", "target": "content for generalized", "depth": [1, 3]}, {"source": "transfer", "target": "generalized style", "depth": [1, 3]}, {"source": "transfer", "target": "separating style", "depth": [1, 3]}, {"source": "deep convolutional", "target": "deep convolutional autoencoder", "depth": [1, 2]}, {"source": "deep convolutional", "target": "painter classification", "depth": [1, 3]}, {"source": "deep convolutional", "target": "convolutional autoencoder", "depth": [1, 2]}, {"source": "deep convolutional", "target": "classification using deep", "depth": [1, 2]}, {"source": "deep convolutional", "target": "deeppainter", "depth": [1, 3]}, {"source": "image retrieval", "target": "content-based image retrieval", "depth": [1, 2]}, {"source": "image retrieval", "target": "learning deep representation", "depth": [1, 3]}, {"source": "image retrieval", "target": "deep representation", "depth": [1, 2]}, {"source": "image retrieval", "target": "representations of medical", "depth": [1, 3]}, {"source": "image retrieval", "target": "learning deep", "depth": [1, 3]}, {"source": "relational", "target": "temporal relational reasoning", "depth": [1, 3]}, {"source": "relational", "target": "reasoning in video", "depth": [1, 3]}, {"source": "relational", "target": "relational reasoning", "depth": [1, 3]}, {"source": "relational", "target": "relational theory", "depth": [1, 3]}, {"source": "relational", "target": "semantics for relational", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "adversarial feature augmentation", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "feature augmentation", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "augmentation for unsupervised", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "adversarial feature", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "similarity learning", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "adversarial feature augmentation", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "feature augmentation", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "augmentation for unsupervised", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "adversarial feature", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "similarity learning", "depth": [1, 3]}, {"source": "speech", "target": "visual speech enhancement", "depth": [1, 3]}, {"source": "speech", "target": "speech enhancement", "depth": [1, 2]}, {"source": "speech", "target": "visual speech", "depth": [1, 3]}, {"source": "speech", "target": "enhancement", "depth": [1, 2]}, {"source": "speech", "target": "medical conversation", "depth": [1, 3]}, {"source": "program", "target": "resource analysi", "depth": [1, 3]}, {"source": "program", "target": "probabilistic program", "depth": [1, 3]}, {"source": "program", "target": "bounded expectation", "depth": [1, 3]}, {"source": "program", "target": "analysis for probabilistic", "depth": [1, 3]}, {"source": "program", "target": "expectation", "depth": [1, 3]}, {"source": "signal", "target": "crowd signal", "depth": [1, 3]}, {"source": "signal", "target": "detection in social", "depth": [1, 3]}, {"source": "signal", "target": "networks via crowd", "depth": [1, 3]}, {"source": "signal", "target": "fake news detection", "depth": [1, 3]}, {"source": "signal", "target": "semi-automated signal surveying", "depth": [1, 3]}, {"source": "flow", "target": "video enhancement", "depth": [1, 3]}, {"source": "flow", "target": "task-oriented flow", "depth": [1, 3]}, {"source": "flow", "target": "enhancement with task-oriented", "depth": [1, 3]}, {"source": "flow", "target": "enhancement", "depth": [1, 2]}, {"source": "flow", "target": "flow correlation tracking", "depth": [1, 3]}, {"source": "natural language", "target": "operational natural language", "depth": [1, 3]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 3]}, {"source": "natural language", "target": "language inference model", "depth": [1, 3]}, {"source": "natural language", "target": "inference models enhanced", "depth": [1, 3]}, {"source": "natural language", "target": "neural natural language", "depth": [1, 3]}, {"source": "proof", "target": "proof rule", "depth": [1, 3]}, {"source": "proof", "target": "almost-sure termination", "depth": [1, 3]}, {"source": "proof", "target": "rule for almost-sure", "depth": [1, 3]}, {"source": "proof", "target": "termination", "depth": [1, 3]}, {"source": "proof", "target": "rule", "depth": [1, 3]}, {"source": "explanation", "target": "visual explanation", "depth": [1, 2]}, {"source": "explanation", "target": "extended abstract", "depth": [1, 2]}, {"source": "explanation", "target": "deep visual explanation", "depth": [1, 3]}, {"source": "explanation", "target": "focus deep visual", "depth": [1, 3]}, {"source": "explanation", "target": "focus deep", "depth": [1, 3]}, {"source": "multi-armed bandit", "target": "resizable mini-batch gradient", "depth": [1, 3]}, {"source": "multi-armed bandit", "target": "mini-batch gradient descent", "depth": [1, 3]}, {"source": "multi-armed bandit", "target": "gradient descent based", "depth": [1, 3]}, {"source": "multi-armed bandit", "target": "resizable mini-batch", "depth": [1, 3]}, {"source": "multi-armed bandit", "target": "mini-batch gradient", "depth": [1, 3]}]}