{"node": [["neural network", "convolutional neural network", "deep neural network", "network", "learning", "deep learning"], ["recurrent neural network", "deep convolutional neural", "machine learning", "reinforcement learning", "classification", "machine", "social network", "adversarial network", "generative adversarial network", "generative adversarial", "deep", "big datum", "deep convolutional", "system", "deep reinforcement learning", "deep reinforcement", "wsdm cup", "scorer at wsdm", "triple scoring", "graph", "clustering", "model", "image", "analysis", "algorithm", "optimization", "technique", "recognition", "speech", "game", "code", "method", "datum", "object detection", "detection", "tree", "synthesis", "privacy", "theory", "application", "wireless network", "approach", "path", "communication", "regression", "polar code", "quantum", "massive mimo", "problem", "distributed", "prediction", "time", "information", "text", "market", "generative model", "supervised learning", "robot", "program", "design", "human", "logic", "domain adaptation", "representation", "internet of thing", "sequence", "bound", "deep network", "environment", "collaborative", "social medium", "pose estimation", "generation", "linear system", "shape"], ["artificial neural network", "deep learning architecture", "neural network architecture", "control system", "reinforcement", "vandalism detection", "linear model", "generative adversarial net", "network analysis", "speech recognition", "action recognition", "decoding", "distributed computing", "object", "detection network", "video retrieval", "computing", "online social network", "decoding of polar", "strategy", "channel", "limit", "scene", "convolutional network", "genetic algorithm", "unsupervised domain adaptation", "unsupervised domain", "thing", "embedding", "pose"], ["expressive robotic system", "robotic system", "graph clustering", "free graph", "agent-based model", "classification for comparison-based", "comparison-based interpretability", "conditional generative adversarial", "networks learn density", "adversarial networks learn", "interpretability in machine", "inverse classification", "sparse contour", "edit image", "contours to represent", "represent and edit", "resource-aware session type", "session type", "learn density", "unordered tree inclusion", "integration of optical", "strategic game", "compositional coalgebraic", "semantics of strategic", "deep burst denoising", "burst denoising", "deep burst", "straggling server", "codes for distributed", "coordination method", "coordination", "opf", "predicting triple scoring", "fiddlehead triple scorer", "crowdsourcing-specific feature", "multi-agent deep reinforcement", "hierarchical multi-agent deep", "control with hierarchical", "data cleaning", "cleaning", "open world", "health datum", "triple scoring task", "scoring task", "cup", "enhanced situation awareness", "cnn-based object detection", "detection network ensemble", "rank of expert", "expert", "deciding the existence", "cherry-picking sequence", "sequence is hard", "deciding", "applications to synthesis", "decidable fragment", "order logic", "logic with application", "perfect privacy", "perfect", "cybersecurity and privacy", "taxonomy and survey", "model theory", "knowledge in psoa", "perspectival knowledge", "psoa ruleml", "daos for extreme-scale", "scientific application", "extreme-scale system", "systems in scientific", "future video prediction", "folded recurrent neural", "video prediction", "networks for future", "optimization for consensu", "consensus network", "submodular optimization", "based on deep", "video retrieval based", "heterogeneous wireless network", "learning multiple access", "deep-reinforcement learning multiple", "coalitional game approach", "smart grid", "game approach", "cycling path", "practical approach", "approach to monitor", "fog computing", "meet communication failure", "choreographies meet communication", "communication failure", "bidirectional preferential attachment", "social networks driven", "classification and regression", "kernel for classification", "learning the kernel", "kernel", "belief propagation decoding", "graphs for belief", "belief propagation", "experimental learning", "quantum state", "learning of quantum", "fdd massive mimo", "theory based approach", "graph theory based", "theory based", "strategies for basing", "basing", "deep learning channel", "learning channel", "neural headline generation", "headline generation", "prediction for neural", "neural headline", "limits in reinforcement", "time limit", "privileged information", "altruism impact", "impacts your privileged", "altruism", "scene text recognition", "scene text", "text recognition", "recruitment market", "popularity of job", "job skill", "skills in recruitment", "deep convolutional network", "effective amortized inference", "amortized inference", "inversion of generative", "models for effective", "truck lateral control", "enhancing the performance", "lateral control", "visual based navigation", "mobile robot", "based navigation", "document spanner", "programs for document", "recursive program", "manycore systems design", "systems design", "serendipitous symbiosis", "learning and manycore", "techniques for inferring", "inferring l-system", "l-systems using genetic", "platform for live", "human reconstruction", "motion capturing", "heuristic proof procedure", "heuristic proof", "proof procedure", "keypoint estimation", "view consistency", "intelligent device discovery", "enabling the robot", "urdu transliteration", "sequence network", "networks for roman-urdu", "sparsity and sensitivity", "bounds and exponential", "exponential gap", "alternation", "short text message", "deep network model", "text message", "dynamic embedding", "clustering with dynamic", "environment for visual", "interactive", "personalised peer-learning environment", "grounded goal-driven communication", "collaborative drawing", "goal-driven communication", "relative pose estimation", "rolling shutter relative", "generation of bound", "bounds for polynomial", "automatic generation", "explicit reference governor", "time-delayed linear system", "reference governor", "constrained control", "shape evolution", "shading through shape", "shape from shading"]], "link": [{"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "neural network", "target": "artificial neural network", "depth": [0, 2]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 1]}, {"source": "learning", "target": "network", "depth": [0, 0]}, {"source": "learning", "target": "classification", "depth": [0, 1]}, {"source": "learning", "target": "machine", "depth": [0, 1]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "adversarial network", "depth": [0, 1]}, {"source": "network", "target": "generative adversarial network", "depth": [0, 1]}, {"source": "network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "deep learning", "target": "deep learning architecture", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "big datum", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 1]}, {"source": "deep neural network", "target": "neural network architecture", "depth": [0, 2]}, {"source": "system", "target": "control system", "depth": [1, 2]}, {"source": "system", "target": "expressive robotic system", "depth": [1, 3]}, {"source": "system", "target": "robotic system", "depth": [1, 3]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [1, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [1, 2]}, {"source": "wsdm cup", "target": "scorer at wsdm", "depth": [1, 1]}, {"source": "wsdm cup", "target": "triple scoring", "depth": [1, 1]}, {"source": "wsdm cup", "target": "vandalism detection", "depth": [1, 2]}, {"source": "graph", "target": "graph clustering", "depth": [1, 3]}, {"source": "graph", "target": "clustering", "depth": [1, 1]}, {"source": "graph", "target": "free graph", "depth": [1, 3]}, {"source": "model", "target": "machine learning", "depth": [1, 1]}, {"source": "model", "target": "linear model", "depth": [1, 2]}, {"source": "model", "target": "agent-based model", "depth": [1, 3]}, {"source": "machine learning", "target": "machine", "depth": [1, 1]}, {"source": "machine learning", "target": "classification for comparison-based", "depth": [1, 3]}, {"source": "machine learning", "target": "comparison-based interpretability", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "generative adversarial net", "depth": [1, 2]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "conditional generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "networks learn density", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "adversarial networks learn", "depth": [1, 3]}, {"source": "classification", "target": "classification for comparison-based", "depth": [1, 3]}, {"source": "classification", "target": "comparison-based interpretability", "depth": [1, 3]}, {"source": "classification", "target": "interpretability in machine", "depth": [1, 3]}, {"source": "classification", "target": "inverse classification", "depth": [1, 3]}, {"source": "image", "target": "sparse contour", "depth": [1, 3]}, {"source": "image", "target": "edit image", "depth": [1, 3]}, {"source": "image", "target": "contours to represent", "depth": [1, 3]}, {"source": "image", "target": "represent and edit", "depth": [1, 3]}, {"source": "analysis", "target": "network analysis", "depth": [1, 2]}, {"source": "analysis", "target": "resource-aware session type", "depth": [1, 3]}, {"source": "analysis", "target": "session type", "depth": [1, 3]}, {"source": "adversarial network", "target": "networks learn density", "depth": [1, 3]}, {"source": "adversarial network", "target": "adversarial networks learn", "depth": [1, 3]}, {"source": "adversarial network", "target": "learn density", "depth": [1, 3]}, {"source": "algorithm", "target": "optimization", "depth": [1, 1]}, {"source": "algorithm", "target": "technique", "depth": [1, 1]}, {"source": "algorithm", "target": "unordered tree inclusion", "depth": [1, 3]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 2]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "action recognition", "depth": [1, 2]}, {"source": "recognition", "target": "integration of optical", "depth": [1, 3]}, {"source": "game", "target": "strategic game", "depth": [1, 3]}, {"source": "game", "target": "compositional coalgebraic", "depth": [1, 3]}, {"source": "game", "target": "semantics of strategic", "depth": [1, 3]}, {"source": "deep", "target": "deep burst denoising", "depth": [1, 3]}, {"source": "deep", "target": "burst denoising", "depth": [1, 3]}, {"source": "deep", "target": "deep burst", "depth": [1, 3]}, {"source": "code", "target": "decoding", "depth": [1, 2]}, {"source": "code", "target": "straggling server", "depth": [1, 3]}, {"source": "code", "target": "codes for distributed", "depth": [1, 3]}, {"source": "code", "target": "distributed computing", "depth": [1, 2]}, {"source": "method", "target": "coordination method", "depth": [1, 3]}, {"source": "method", "target": "coordination", "depth": [1, 3]}, {"source": "method", "target": "opf", "depth": [1, 3]}, {"source": "scorer at wsdm", "target": "triple scoring", "depth": [1, 1]}, {"source": "scorer at wsdm", "target": "predicting triple scoring", "depth": [1, 3]}, {"source": "scorer at wsdm", "target": "fiddlehead triple scorer", "depth": [1, 3]}, {"source": "scorer at wsdm", "target": "crowdsourcing-specific feature", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "multi-agent deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "hierarchical multi-agent deep", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "control with hierarchical", "depth": [1, 3]}, {"source": "datum", "target": "data cleaning", "depth": [1, 3]}, {"source": "datum", "target": "cleaning", "depth": [1, 3]}, {"source": "datum", "target": "open world", "depth": [1, 3]}, {"source": "datum", "target": "health datum", "depth": [1, 3]}, {"source": "triple scoring", "target": "triple scoring task", "depth": [1, 3]}, {"source": "triple scoring", "target": "scoring task", "depth": [1, 3]}, {"source": "triple scoring", "target": "cup", "depth": [1, 3]}, {"source": "object detection", "target": "object", "depth": [1, 2]}, {"source": "object detection", "target": "enhanced situation awareness", "depth": [1, 3]}, {"source": "object detection", "target": "cnn-based object detection", "depth": [1, 3]}, {"source": "detection", "target": "detection network ensemble", "depth": [1, 3]}, {"source": "detection", "target": "detection network", "depth": [1, 2]}, {"source": "detection", "target": "rank of expert", "depth": [1, 3]}, {"source": "detection", "target": "expert", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "multi-agent deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "hierarchical multi-agent deep", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "control with hierarchical", "depth": [1, 3]}, {"source": "tree", "target": "deciding the existence", "depth": [1, 3]}, {"source": "tree", "target": "cherry-picking sequence", "depth": [1, 3]}, {"source": "tree", "target": "sequence is hard", "depth": [1, 3]}, {"source": "tree", "target": "deciding", "depth": [1, 3]}, {"source": "synthesis", "target": "applications to synthesis", "depth": [1, 3]}, {"source": "synthesis", "target": "decidable fragment", "depth": [1, 3]}, {"source": "synthesis", "target": "order logic", "depth": [1, 3]}, {"source": "synthesis", "target": "logic with application", "depth": [1, 3]}, {"source": "privacy", "target": "perfect privacy", "depth": [1, 3]}, {"source": "privacy", "target": "perfect", "depth": [1, 3]}, {"source": "privacy", "target": "cybersecurity and privacy", "depth": [1, 3]}, {"source": "privacy", "target": "taxonomy and survey", "depth": [1, 3]}, {"source": "theory", "target": "model theory", "depth": [1, 3]}, {"source": "theory", "target": "knowledge in psoa", "depth": [1, 3]}, {"source": "theory", "target": "perspectival knowledge", "depth": [1, 3]}, {"source": "theory", "target": "psoa ruleml", "depth": [1, 3]}, {"source": "application", "target": "daos for extreme-scale", "depth": [1, 3]}, {"source": "application", "target": "scientific application", "depth": [1, 3]}, {"source": "application", "target": "extreme-scale system", "depth": [1, 3]}, {"source": "application", "target": "systems in scientific", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "future video prediction", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "folded recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "video prediction", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "networks for future", "depth": [1, 3]}, {"source": "optimization", "target": "optimization for consensu", "depth": [1, 3]}, {"source": "optimization", "target": "consensus network", "depth": [1, 3]}, {"source": "optimization", "target": "submodular optimization", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "deep convolutional", "depth": [1, 1]}, {"source": "deep convolutional neural", "target": "based on deep", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "video retrieval based", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "video retrieval", "depth": [1, 2]}, {"source": "wireless network", "target": "heterogeneous wireless network", "depth": [1, 3]}, {"source": "wireless network", "target": "learning multiple access", "depth": [1, 3]}, {"source": "wireless network", "target": "deep-reinforcement learning multiple", "depth": [1, 3]}, {"source": "approach", "target": "coalitional game approach", "depth": [1, 3]}, {"source": "approach", "target": "smart grid", "depth": [1, 3]}, {"source": "approach", "target": "game approach", "depth": [1, 3]}, {"source": "path", "target": "cycling path", "depth": [1, 3]}, {"source": "path", "target": "practical approach", "depth": [1, 3]}, {"source": "path", "target": "approach to monitor", "depth": [1, 3]}, {"source": "big datum", "target": "fog computing", "depth": [1, 3]}, {"source": "big datum", "target": "computing", "depth": [1, 2]}, {"source": "communication", "target": "meet communication failure", "depth": [1, 3]}, {"source": "communication", "target": "choreographies meet communication", "depth": [1, 3]}, {"source": "communication", "target": "communication failure", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 2]}, {"source": "social network", "target": "bidirectional preferential attachment", "depth": [1, 3]}, {"source": "social network", "target": "social networks driven", "depth": [1, 3]}, {"source": "regression", "target": "classification and regression", "depth": [1, 3]}, {"source": "regression", "target": "kernel for classification", "depth": [1, 3]}, {"source": "regression", "target": "learning the kernel", "depth": [1, 3]}, {"source": "regression", "target": "kernel", "depth": [1, 3]}, {"source": "polar code", "target": "decoding of polar", "depth": [1, 2]}, {"source": "polar code", "target": "belief propagation decoding", "depth": [1, 3]}, {"source": "polar code", "target": "graphs for belief", "depth": [1, 3]}, {"source": "polar code", "target": "belief propagation", "depth": [1, 3]}, {"source": "quantum", "target": "experimental learning", "depth": [1, 3]}, {"source": "quantum", "target": "quantum state", "depth": [1, 3]}, {"source": "quantum", "target": "learning of quantum", "depth": [1, 3]}, {"source": "massive mimo", "target": "fdd massive mimo", "depth": [1, 3]}, {"source": "massive mimo", "target": "theory based approach", "depth": [1, 3]}, {"source": "massive mimo", "target": "graph theory based", "depth": [1, 3]}, {"source": "massive mimo", "target": "theory based", "depth": [1, 3]}, {"source": "problem", "target": "strategies for basing", "depth": [1, 3]}, {"source": "problem", "target": "strategy", "depth": [1, 2]}, {"source": "problem", "target": "basing", "depth": [1, 3]}, {"source": "machine", "target": "deep learning channel", "depth": [1, 3]}, {"source": "machine", "target": "learning channel", "depth": [1, 3]}, {"source": "machine", "target": "channel", "depth": [1, 2]}, {"source": "distributed", "target": "straggling server", "depth": [1, 3]}, {"source": "distributed", "target": "codes for distributed", "depth": [1, 3]}, {"source": "distributed", "target": "distributed computing", "depth": [1, 2]}, {"source": "prediction", "target": "neural headline generation", "depth": [1, 3]}, {"source": "prediction", "target": "headline generation", "depth": [1, 3]}, {"source": "prediction", "target": "prediction for neural", "depth": [1, 3]}, {"source": "prediction", "target": "neural headline", "depth": [1, 3]}, {"source": "time", "target": "limits in reinforcement", "depth": [1, 3]}, {"source": "time", "target": "time limit", "depth": [1, 3]}, {"source": "time", "target": "limit", "depth": [1, 2]}, {"source": "information", "target": "privileged information", "depth": [1, 3]}, {"source": "information", "target": "altruism impact", "depth": [1, 3]}, {"source": "information", "target": "impacts your privileged", "depth": [1, 3]}, {"source": "information", "target": "altruism", "depth": [1, 3]}, {"source": "text", "target": "scene text recognition", "depth": [1, 3]}, {"source": "text", "target": "scene text", "depth": [1, 3]}, {"source": "text", "target": "text recognition", "depth": [1, 3]}, {"source": "text", "target": "scene", "depth": [1, 2]}, {"source": "market", "target": "recruitment market", "depth": [1, 3]}, {"source": "market", "target": "popularity of job", "depth": [1, 3]}, {"source": "market", "target": "job skill", "depth": [1, 3]}, {"source": "market", "target": "skills in recruitment", "depth": [1, 3]}, {"source": "speech", "target": "speech recognition", "depth": [1, 2]}, {"source": "deep convolutional", "target": "deep convolutional network", "depth": [1, 3]}, {"source": "deep convolutional", "target": "convolutional network", "depth": [1, 2]}, {"source": "generative model", "target": "effective amortized inference", "depth": [1, 3]}, {"source": "generative model", "target": "amortized inference", "depth": [1, 3]}, {"source": "generative model", "target": "inversion of generative", "depth": [1, 3]}, {"source": "generative model", "target": "models for effective", "depth": [1, 3]}, {"source": "supervised learning", "target": "truck lateral control", "depth": [1, 3]}, {"source": "supervised learning", "target": "enhancing the performance", "depth": [1, 3]}, {"source": "supervised learning", "target": "lateral control", "depth": [1, 3]}, {"source": "robot", "target": "visual based navigation", "depth": [1, 3]}, {"source": "robot", "target": "mobile robot", "depth": [1, 3]}, {"source": "robot", "target": "based navigation", "depth": [1, 3]}, {"source": "program", "target": "document spanner", "depth": [1, 3]}, {"source": "program", "target": "programs for document", "depth": [1, 3]}, {"source": "program", "target": "recursive program", "depth": [1, 3]}, {"source": "design", "target": "manycore systems design", "depth": [1, 3]}, {"source": "design", "target": "systems design", "depth": [1, 3]}, {"source": "design", "target": "serendipitous symbiosis", "depth": [1, 3]}, {"source": "design", "target": "learning and manycore", "depth": [1, 3]}, {"source": "technique", "target": "genetic algorithm", "depth": [1, 2]}, {"source": "technique", "target": "techniques for inferring", "depth": [1, 3]}, {"source": "technique", "target": "inferring l-system", "depth": [1, 3]}, {"source": "technique", "target": "l-systems using genetic", "depth": [1, 3]}, {"source": "human", "target": "platform for live", "depth": [1, 3]}, {"source": "human", "target": "human reconstruction", "depth": [1, 3]}, {"source": "human", "target": "motion capturing", "depth": [1, 3]}, {"source": "logic", "target": "heuristic proof procedure", "depth": [1, 3]}, {"source": "logic", "target": "heuristic proof", "depth": [1, 3]}, {"source": "logic", "target": "proof procedure", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "keypoint estimation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "view consistency", "depth": [1, 3]}, {"source": "representation", "target": "model theory", "depth": [1, 3]}, {"source": "representation", "target": "knowledge in psoa", "depth": [1, 3]}, {"source": "representation", "target": "perspectival knowledge", "depth": [1, 3]}, {"source": "representation", "target": "psoa ruleml", "depth": [1, 3]}, {"source": "internet of thing", "target": "thing", "depth": [1, 2]}, {"source": "internet of thing", "target": "intelligent device discovery", "depth": [1, 3]}, {"source": "internet of thing", "target": "enabling the robot", "depth": [1, 3]}, {"source": "sequence", "target": "urdu transliteration", "depth": [1, 3]}, {"source": "sequence", "target": "sequence network", "depth": [1, 3]}, {"source": "sequence", "target": "networks for roman-urdu", "depth": [1, 3]}, {"source": "bound", "target": "sparsity and sensitivity", "depth": [1, 3]}, {"source": "bound", "target": "bounds and exponential", "depth": [1, 3]}, {"source": "bound", "target": "exponential gap", "depth": [1, 3]}, {"source": "bound", "target": "alternation", "depth": [1, 3]}, {"source": "deep network", "target": "short text message", "depth": [1, 3]}, {"source": "deep network", "target": "deep network model", "depth": [1, 3]}, {"source": "deep network", "target": "text message", "depth": [1, 3]}, {"source": "clustering", "target": "graph clustering", "depth": [1, 3]}, {"source": "clustering", "target": "dynamic embedding", "depth": [1, 3]}, {"source": "clustering", "target": "clustering with dynamic", "depth": [1, 3]}, {"source": "clustering", "target": "embedding", "depth": [1, 2]}, {"source": "environment", "target": "environment for visual", "depth": [1, 3]}, {"source": "environment", "target": "interactive", "depth": [1, 3]}, {"source": "environment", "target": "personalised peer-learning environment", "depth": [1, 3]}, {"source": "collaborative", "target": "grounded goal-driven communication", "depth": [1, 3]}, {"source": "collaborative", "target": "collaborative drawing", "depth": [1, 3]}, {"source": "collaborative", "target": "goal-driven communication", "depth": [1, 3]}, {"source": "pose estimation", "target": "pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "relative pose estimation", "depth": [1, 3]}, {"source": "pose estimation", "target": "rolling shutter relative", "depth": [1, 3]}, {"source": "generation", "target": "generation of bound", "depth": [1, 3]}, {"source": "generation", "target": "bounds for polynomial", "depth": [1, 3]}, {"source": "generation", "target": "automatic generation", "depth": [1, 3]}, {"source": "linear system", "target": "explicit reference governor", "depth": [1, 3]}, {"source": "linear system", "target": "time-delayed linear system", "depth": [1, 3]}, {"source": "linear system", "target": "reference governor", "depth": [1, 3]}, {"source": "linear system", "target": "constrained control", "depth": [1, 3]}, {"source": "shape", "target": "shape evolution", "depth": [1, 3]}, {"source": "shape", "target": "shading through shape", "depth": [1, 3]}, {"source": "shape", "target": "shape from shading", "depth": [1, 3]}]}