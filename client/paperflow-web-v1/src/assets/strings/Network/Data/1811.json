{"node": [["neural network", "convolutional neural network", "deep neural network", "network", "learning", "deep learning", "reinforcement learning", "machine learning", "model", "system", "graph"], ["recurrent neural network", "graph neural network", "deep", "social network", "adversarial network", "generative adversarial network", "deep learning model", "deep reinforcement learning", "deep reinforcement", "reinforcement", "deep convolutional neural", "deep convolutional", "generative model", "language model", "learning model", "adversarial attack", "learning algorithm", "machine", "analysi", "generative adversarial", "network training", "deep network", "detection", "object detection", "algorithm", "prediction", "recognition", "speech recognition", "speech", "face recognition", "video object", "optimization", "framework", "approach", "generalization", "image", "single image", "person re-identification", "point cloud", "point", "cloud", "game", "problem", "theory", "classification", "text classification", "efficient", "video", "generation", "control", "uncertainty", "training", "semantic segmentation", "segmentation", "active learning", "inference", "natural language", "datum", "clustering", "complexity", "representation learning", "tree", "language", "convolutional network", "method", "coding", "feature", "feature selection", "communication", "challenge", "object", "unsupervised learning", "neural machine translation", "machine translation", "neural machine", "robust", "neural language model", "neural language", "speech enhancement", "translation", "gaussian proces", "bayesian optimization", "information retrieval", "structure", "adversarial learning", "question answering", "face", "computing", "distance", "transfer learning", "transfer", "massive mimo", "internet of thing", "pose estimation", "autonomous driving", "bayesian", "dataset", "program", "function", "compression", "study", "anomaly detection", "style transfer", "secure", "domain adaptation", "gradient descent", "time series", "survey", "approximation", "stochastic gradient", "data augmentation", "attack", "human", "design", "stability analysi", "transient stability analysi", "memory", "exploration", "bound", "cnn", "image classification", "action recognition", "reconstruction", "estimation", "emotion recognition", "trajectory", "distribution", "case study", "embedding", "sequence", "adversarial training", "neural architecture", "neural architecture search", "architecture search", "computation", "information", "agent", "online", "extended version", "correlation", "image quality assessment", "quality assessment", "constraint", "error", "process", "relation extraction", "regression", "code", "testing", "text detection", "scene text", "evaluation", "task", "deep learning based", "identification", "representation", "convergence", "perspective", "imitation learning", "keyword spotting", "security", "language understanding", "classifier", "performance", "strong baseline", "retrieval", "generative", "matrix factorization", "flow", "selection", "approximation algorithm", "attention", "lower bound", "smart grid"], ["bayesian deep learning", "bayesian deep", "multi-agent reinforcement learning", "model-based reinforcement learning", "residual convolutional neural", "neural network robustnes", "hardnes", "machine learning algorithm", "smoothed analysi", "supercomputer", "chest radiograph", "fast algorithm", "low-resolution face recognition", "low-resolution face", "multi-objective optimization", "simple", "efficient training", "surface reconstruction", "knapsack", "search", "deep generative model", "deep generative", "matching problem", "video denoising", "denoising", "compressed video", "attack based", "scene graph generation", "graph generation", "interpretable model", "scene graph", "diversity", "optimal control", "bayesian active learning", "signal classification", "natural language inference", "language inference", "subspace clustering", "subspace", "high dimensional", "unsupervised representation learning", "unsupervised representation", "deep representation", "analyzing", "deep convolutional network", "graph convolutional network", "graph convolutional", "natural language processing", "language processing", "grid", "prediction error", "fitting", "fog computing", "architecture", "learning framework", "robust neural network", "learning to discover", "image segmentation", "hyperspectral image", "instance segmentation", "individual treatment effect", "interleaving distance", "mimo system", "monitoring and control", "survival analysi", "optical flow based", "bayesian approach", "bayesian learning", "normalization", "bugs in java", "automatic repair", "verifying", "empirical study", "detection system", "secure network coding", "secure network", "network coding", "security level", "unsupervised domain adaptation", "unsupervised domain", "stochastic gradient descent", "network for person", "tight approximation", "gradient optimization", "model-based reinforcement", "robustnes", "improving", "supervised clustering", "transient stability", "high-dimensional robust", "time", "trajectory optimization", "price", "regression network", "network embedding", "word embedding", "multi-view", "few-shot learning", "physic", "law", "configuration", "geometry", "digraph", "ring", "chasing", "text", "multiview", "image quality", "quality", "comparative study", "interaction", "gaussian process", "decision process", "regression and classification", "weight", "clas", "linear", "scene text detection", "attention network", "understanding", "learning based", "neural network architecture", "hierarchical neural network", "network architecture", "environment", "performance guarantee", "guarantee", "blind", "image retrieval", "generative network", "optimal power flow", "power flow", "ensemble selection", "steiner tree", "packing", "robot imitation learning", "adaptive regularization algorithm", "power system transient", "system transient stability", "kernel", "domain"], ["graph convolutional neural", "cancer cell line", "parametric noise injection", "improve deep neural", "noise injection", "dispersing obnoxious facility", "dispersing obnoxiou", "obnoxious facility", "dispersing", "detailed gpu simulator", "machine learning workload", "wdm system", "achievable rate", "mitigation in wdm", "nonlinearity mitigation", "sparql-owl queries dataset", "dataset and analysi", "queries dataset", "competency question", "adversarial network training", "robust generative adversarial", "learning for supercomputer", "mesh-tensorflow", "multi-purpose perceptual quality", "perceptual quality image", "quality image enhancement", "perceptual quality", "detection in chest", "pneumonia detection", "radiograph", "convolution and prediction", "algorithms for knapsack", "knapsack via convolution", "video object detection", "object detection based", "zero-shot object detection", "loss for zero-shot", "multilingual speech recognition", "multilingual speech", "recognition and synthesi", "synthesis with byte", "external archive", "archive for improved", "improved performance", "flow shape design", "shape design", "design for microfluidic", "microfluidic device", "approach for efficient", "sampling approach", "separate multiple illuminant", "separate multiple", "multiple illuminant", "learning to separate", "completion with generative", "typeface completion", "completion", "generative adversarial transfer", "object class labelling", "fast object clas", "labelling via speech", "object clas", "class labelling", "fitting of geometric", "geometric primitive", "search and pursuit", "game model", "model of search", "pursuit", "convolutional generative model", "flexible indoor scene", "indoor scene synthesi", "unified theory", "theory of sparsification", "sparsification for matching", "diabetes disease evolution", "predicting diabetes disease", "diabetes disease", "disease evolution", "evolution using financial", "explicit interaction model", "interaction model", "model towards text", "explicit interaction", "multiview correlation", "learning from multiview", "task-generalizable adversarial attack", "adversarial attack based", "perceptual metric", "based on perceptual", "model for scene", "online social network", "federated social network", "recommending user", "follow on federated", "system uncertainty", "control of ultra-capacitor", "ultra-capacitors with system", "learnable task-adaptive adam", "adam for network", "hyperadam", "task-adaptive adam", "deep learning method", "evaluating bayesian deep", "electrocardiographic signal classification", "robust active learning", "learning for electrocardiographic", "likelihood-free inference", "recurrent machine", "implicitly low-rank datum", "recovery with implicitly", "matrix recovery", "low-rank datum", "implicitly low-rank", "high dimensional clustering", "dimensional clustering", "geometric terrain", "complexity of treasure", "treasure hunt", "hunt in geometric", "advice complexity", "deep representation learning", "adversarial unsupervised representation", "graph search tree", "recognizing graph search", "search tree", "graph search", "recognizing graph", "analyzing and learning", "types of harassment", "learning the language", "harassment", "fully convolutional network", "natural language understanding", "grid deformation method", "multi-block grid deformation", "grid deformation", "deformation method", "uncertainty propagation", "sparse coding", "propagation in neural", "networks for sparse", "thinging machine", "thinging machine applied", "information leakage", "machine applied", "applied to information", "model prediction error", "forecast lightning", "model prediction", "supervised fitting", "multi-path network communication", "network communication", "throughput requirement", "minimizing", "requirements in multi-path", "fog computing architecture", "survey and challenge", "computing architecture", "modular lightweight network", "lightweight network", "road using modular", "modular lightweight", "detecting the object", "unsupervised learning framework", "robust filter set", "adaptive and robust", "robust filter", "empirical exploration", "exploration of curriculum", "curriculum learning", "lipschitz continuity", "networks with lipschitz", "continuity", "robust mean estimation", "segmental neural language", "words with segmental", "reinforcement learning agent", "learning agent", "communication topology", "organize your deep", "introduction to deep", "hyperspectral image segmentation", "validating hyperspectral image", "enhancement", "semi-supervised multichannel speech", "non-negative matrix factorization", "multichannel speech enhancement", "semi-supervised multichannel", "gaussian process prior", "meta bayesian optimization", "unknown gaussian proces", "meta bayesian", "information retrieval strategy", "structured information retrieval", "retrieval strategy", "strategies for localising", "localising software", "partial automaton semigroup", "automaton semigroup", "structure theory", "theory of partial", "partial automaton", "latent confounder model", "individual treatment", "treatment effect", "effect in latent", "neural learning model", "vertex centrality measure", "massive real network", "computing vertex centrality", "community question answering", "heterogeneous community question", "duplicate question detection", "cross-domain duplicate question", "generality and knowledge", "low-resolution", "large longitudinal database", "computing the interleaving", "distance is np-hard", "interleaving", "adversarial transfer learning", "adversarial transfer", "learning for person", "massive mimo system", "detection for massive", "learning-based ml detection", "massive mimo network", "things oriented approach", "water utility monitoring", "things oriented", "oriented approach", "selection for survival", "analysis with competing", "competing risk", "risks using deep", "human pose estimation", "human pose", "ground plane polling", "plane polling", "estimation of object", "driving", "flow based background", "based background subtraction", "moving camera", "normalizations as bayesian", "stochastic normalization", "learning for neural", "multi-modal neural machine", "repair of real", "real bug", "large-scale experiment", "programs operationally", "quantum program", "elementary function", "convergence theory", "compression schemes exceeding", "unlabeled compression scheme", "compression scheme", "schemes exceeding", "unlabeled compression", "created equal", "training examples created", "created", "systematic mapping study", "anomaly detection system", "real-time anomaly detection", "real-time anomaly", "comprehensive real-time anomaly", "video style transfer", "constrained adversarial learning", "evolvement constrained adversarial", "constrained adversarial", "flexible rate", "adversarial entropy minimization", "adversarial entropy", "entropy minimization", "partial gradient computation", "coded partial gradient", "distributed gradient descent", "gradient computation", "interwoven deep convolutional", "convolutional neural net", "driver behavior recognition", "multi-stream input", "financial time series", "deep sequential model", "benchmarking deep sequential", "deep sequential", "sequential model", "unconstrained xos maximization", "xos maximization", "approximation for unconstrained", "unconstrained xo", "stochastic gradient optimization", "adaptive stochastic gradient", "double adaptive stochastic", "double adaptive", "sepsis treatment", "learning for sepsi", "treatment", "random image cropping", "augmentation using random", "random image", "image cropping", "cropping and patching", "seek to exploit", "criminals attack", "human factor", "exploit", "speech translation", "robustness of speech", "improving the robustnes", "stochastic nmpc design", "nmpc design", "stochastic nmpc", "clustering in stochastic", "nondeterministic selection function", "sequential game", "selection function", "games and nondeterministic", "nondeterministic selection", "design-oriented transient stability", "pll-synchronized voltage-source converter", "design-oriented transient", "generative memory", "dynamics for generative", "learning attractor", "attractor", "bounded local memory", "context-dependent upper-confidence bound", "directed exploration", "bounds for directed", "context-dependent upper-confidence", "non-local video denoising", "denoising by cnn", "non-local video", "large-scale noisy web", "noisy web datum", "large-scale noisy", "noisy web", "web datum", "video action recognition", "video action", "skeleton-based action recognition", "action recognition classifier", "optical flow-based action", "stack overflow post", "reconstruction and analysi", "overflow post", "evolution of stack", "stack overflow", "nearly-linear time", "estimation in nearly-linear", "vocal emotion recognition", "classifier-independent feature analysi", "study of language", "language and classifier-independent", "classifier-independent feature", "improving trajectory optimization", "roadmap framework", "improving trajectory", "suggesting cooking recipe", "source coding", "price of uncertain", "priors in source", "point regression network", "multi-view point regression", "object reconstruction", "point regression", "instance-level human analysi", "human analysi", "instance-level human", "parsing r-cnn", "r-cnn for instance-level", "primary video object", "reversible flow", "segmentation of primary", "primary video", "neural separation", "unobserved distribution", "separation of observed", "observed and unobserved", "separation", "order difference", "dependency parsing", "transfer with order", "study on dependency", "difficulties of cross-lingual", "document", "embedding directed graph", "directed graph", "multi-view inpainting", "rgb-d sequence", "inpainting for rgb-d", "inpainting", "iterative transformer network", "multimodal few-shot learning", "paced adversarial training", "paced adversarial", "training for multimodal", "joint neural architecture", "search and quantization", "joint neural", "models of computation", "reversible model", "embracing the law", "sensor configuration", "geometry of sensor", "information geometry", "ring digraph", "agents on ring", "second-order agent", "online line chasing", "line chasing", "bounds for online", "online line", "text style transfer", "multiple-attribute text style", "text style", "multiple-attribute text", "byzantine quorum system", "federated byzantine quorum", "quorum system", "byzantine quorum", "federated byzantine", "open-domain video", "correlations in open-domain", "spatial pooling strategy", "content-based spatial pooling", "temporal stochastic constraint", "stochastic constraint", "bandits with temporal", "sparsity constraint", "regression with sparsity", "forecast", "infinite-horizon gaussian process", "infinite-horizon", "markov decision process", "joint inference approach", "implicit relation requirement", "encoding implicit relation", "inference approach", "joint inference", "zonal kriging", "classification by zonal", "kriging", "zonal", "class of linear", "linear code", "graph two-sample testing", "practical method", "two-sample testing", "methods for graph", "graph two-sample", "pyramid attention network", "pyramid attention", "model evaluation", "algorithm selection", "model selection", "selection in machine", "unrepresentative video datum", "visual setting", "task understanding", "understanding in visual", "setting", "learning based phase", "based phase reconstruction", "speaker separation", "trigonometric perspective", "attribution-based explanation", "deeper into deep", "explanations of textcnn", "explaining deep learning", "computational cost", "identification of macaque", "macaques for population", "population monitoring", "unique identification", "empirical investigation", "characteristics of deep", "investigation", "challenging common assumption", "sufficient condition", "condition for convergence", "convergences of adam", "adam and rmsprop", "sufficient", "mimic game", "signaling perspective", "mimic", "signaling", "learning multiple default", "multiple default", "defaults for machine", "learning multiple", "architecture in keyword", "spotting", "real environment", "physical-layer security", "work", "physical-layer", "tradeoffs in neural", "low resources context", "task oriented dialog", "resources context", "understanding for task", "fair classifier", "moral philosophy", "philosophy and legislation", "art in fair", "legislation to fair", "blind two-dimensional super-resolution", "two-dimensional super-resolution", "importance of strong", "baselines in bayesian", "deep metric learning", "improved crowding distance", "learning from weight", "cost-sensitive approach", "concept-centered hypertext approach", "network for scene", "segmentation deep network", "minimalistic interactive lung", "interactive lung nodule", "lung nodule segmentation", "nodule segmentation deep", "simulating mobility trajectory", "systematic generalization", "segmentation on multi-modal", "multi-modal mrus", "mri using deep", "splenomegaly segmentation", "training of generative", "kernel-based training", "distribution-preserving steganography based", "steganography based", "multichannel speech", "notes on optimal", "optimal power", "lecture note", "multidimensional feature selection", "multidimensional feature", "mdf", "multidimensional", "algorithm for active", "active friending", "friending in online", "visual attention", "attention for semantic", "criss-cross attention", "ccnet", "fine-grained recognition", "online rectangle packing", "rectangle packing", "bound for online", "online rectangle", "quantization", "adaptive neural architecture", "regret convergence analysi", "dynamic regret convergence", "on-policy robot imitation", "planar steiner tree", "algorithms for planar", "progress and tradeoff", "pre-training graph neural", "networks with kernel", "pre-training graph", "recommendation with graph", "smart grid domain", "grid domain", "perspectives of co-simulation", "smart grid co-simulation"]], "link": [{"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep", "depth": [0, 1]}, {"source": "learning", "target": "network", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "deep", "depth": [0, 1]}, {"source": "network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "network", "target": "adversarial network", "depth": [0, 1]}, {"source": "network", "target": "generative adversarial network", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "bayesian deep learning", "depth": [0, 2]}, {"source": "deep learning", "target": "bayesian deep", "depth": [0, 2]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "model", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "model-based reinforcement learning", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "residual convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "graph convolutional neural", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "cancer cell line", "depth": [0, 3]}, {"source": "model", "target": "generative model", "depth": [0, 1]}, {"source": "model", "target": "language model", "depth": [0, 1]}, {"source": "model", "target": "machine learning", "depth": [0, 0]}, {"source": "model", "target": "learning model", "depth": [0, 1]}, {"source": "model", "target": "system", "depth": [0, 0]}, {"source": "deep neural network", "target": "adversarial attack", "depth": [0, 1]}, {"source": "deep neural network", "target": "parametric noise injection", "depth": [0, 3]}, {"source": "deep neural network", "target": "improve deep neural", "depth": [0, 3]}, {"source": "deep neural network", "target": "neural network robustnes", "depth": [0, 2]}, {"source": "deep neural network", "target": "noise injection", "depth": [0, 3]}, {"source": "graph", "target": "hardnes", "depth": [0, 2]}, {"source": "graph", "target": "dispersing obnoxious facility", "depth": [0, 3]}, {"source": "graph", "target": "dispersing obnoxiou", "depth": [0, 3]}, {"source": "graph", "target": "obnoxious facility", "depth": [0, 3]}, {"source": "graph", "target": "dispersing", "depth": [0, 3]}, {"source": "machine learning", "target": "machine learning algorithm", "depth": [0, 2]}, {"source": "machine learning", "target": "learning algorithm", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "detailed gpu simulator", "depth": [0, 3]}, {"source": "machine learning", "target": "machine learning workload", "depth": [0, 3]}, {"source": "system", "target": "analysi", "depth": [0, 1]}, {"source": "system", "target": "wdm system", "depth": [0, 3]}, {"source": "system", "target": "achievable rate", "depth": [0, 3]}, {"source": "system", "target": "mitigation in wdm", "depth": [0, 3]}, {"source": "system", "target": "nonlinearity mitigation", "depth": [0, 3]}, {"source": "analysi", "target": "smoothed analysi", "depth": [1, 2]}, {"source": "analysi", "target": "sparql-owl queries dataset", "depth": [1, 3]}, {"source": "analysi", "target": "dataset and analysi", "depth": [1, 3]}, {"source": "analysi", "target": "queries dataset", "depth": [1, 3]}, {"source": "analysi", "target": "competency question", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "adversarial network training", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "robust generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "network training", "depth": [1, 1]}, {"source": "deep", "target": "deep network", "depth": [1, 1]}, {"source": "deep", "target": "learning for supercomputer", "depth": [1, 3]}, {"source": "deep", "target": "mesh-tensorflow", "depth": [1, 3]}, {"source": "deep", "target": "supercomputer", "depth": [1, 2]}, {"source": "deep", "target": "deep reinforcement learning", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "multi-purpose perceptual quality", "depth": [1, 3]}, {"source": "adversarial network", "target": "perceptual quality image", "depth": [1, 3]}, {"source": "adversarial network", "target": "quality image enhancement", "depth": [1, 3]}, {"source": "adversarial network", "target": "perceptual quality", "depth": [1, 3]}, {"source": "detection", "target": "object detection", "depth": [1, 1]}, {"source": "detection", "target": "chest radiograph", "depth": [1, 2]}, {"source": "detection", "target": "detection in chest", "depth": [1, 3]}, {"source": "detection", "target": "pneumonia detection", "depth": [1, 3]}, {"source": "detection", "target": "radiograph", "depth": [1, 3]}, {"source": "algorithm", "target": "convolution and prediction", "depth": [1, 3]}, {"source": "algorithm", "target": "algorithms for knapsack", "depth": [1, 3]}, {"source": "algorithm", "target": "knapsack via convolution", "depth": [1, 3]}, {"source": "algorithm", "target": "fast algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "prediction", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "face recognition", "depth": [1, 1]}, {"source": "recognition", "target": "low-resolution face recognition", "depth": [1, 2]}, {"source": "recognition", "target": "low-resolution face", "depth": [1, 2]}, {"source": "object detection", "target": "video object detection", "depth": [1, 3]}, {"source": "object detection", "target": "video object", "depth": [1, 1]}, {"source": "object detection", "target": "object detection based", "depth": [1, 3]}, {"source": "object detection", "target": "zero-shot object detection", "depth": [1, 3]}, {"source": "object detection", "target": "loss for zero-shot", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "multilingual speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "multilingual speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "recognition and synthesi", "depth": [1, 3]}, {"source": "speech recognition", "target": "synthesis with byte", "depth": [1, 3]}, {"source": "optimization", "target": "framework", "depth": [1, 1]}, {"source": "optimization", "target": "external archive", "depth": [1, 3]}, {"source": "optimization", "target": "archive for improved", "depth": [1, 3]}, {"source": "optimization", "target": "improved performance", "depth": [1, 3]}, {"source": "optimization", "target": "multi-objective optimization", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "flow shape design", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "shape design", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "design for microfluidic", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "microfluidic device", "depth": [1, 3]}, {"source": "approach", "target": "simple", "depth": [1, 2]}, {"source": "approach", "target": "approach for efficient", "depth": [1, 3]}, {"source": "approach", "target": "efficient training", "depth": [1, 2]}, {"source": "approach", "target": "sampling approach", "depth": [1, 3]}, {"source": "approach", "target": "generalization", "depth": [1, 1]}, {"source": "image", "target": "single image", "depth": [1, 1]}, {"source": "image", "target": "separate multiple illuminant", "depth": [1, 3]}, {"source": "image", "target": "separate multiple", "depth": [1, 3]}, {"source": "image", "target": "multiple illuminant", "depth": [1, 3]}, {"source": "image", "target": "learning to separate", "depth": [1, 3]}, {"source": "generative adversarial", "target": "person re-identification", "depth": [1, 1]}, {"source": "generative adversarial", "target": "completion with generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "typeface completion", "depth": [1, 3]}, {"source": "generative adversarial", "target": "completion", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative adversarial transfer", "depth": [1, 3]}, {"source": "speech", "target": "object class labelling", "depth": [1, 3]}, {"source": "speech", "target": "fast object clas", "depth": [1, 3]}, {"source": "speech", "target": "labelling via speech", "depth": [1, 3]}, {"source": "speech", "target": "object clas", "depth": [1, 3]}, {"source": "speech", "target": "class labelling", "depth": [1, 3]}, {"source": "point cloud", "target": "point", "depth": [1, 1]}, {"source": "point cloud", "target": "cloud", "depth": [1, 1]}, {"source": "point cloud", "target": "surface reconstruction", "depth": [1, 2]}, {"source": "point cloud", "target": "fitting of geometric", "depth": [1, 3]}, {"source": "point cloud", "target": "geometric primitive", "depth": [1, 3]}, {"source": "prediction", "target": "convolution and prediction", "depth": [1, 3]}, {"source": "prediction", "target": "algorithms for knapsack", "depth": [1, 3]}, {"source": "prediction", "target": "knapsack via convolution", "depth": [1, 3]}, {"source": "prediction", "target": "fast algorithm", "depth": [1, 2]}, {"source": "prediction", "target": "knapsack", "depth": [1, 2]}, {"source": "game", "target": "search and pursuit", "depth": [1, 3]}, {"source": "game", "target": "game model", "depth": [1, 3]}, {"source": "game", "target": "model of search", "depth": [1, 3]}, {"source": "game", "target": "pursuit", "depth": [1, 3]}, {"source": "game", "target": "search", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "generative model", "target": "convolutional generative model", "depth": [1, 3]}, {"source": "generative model", "target": "flexible indoor scene", "depth": [1, 3]}, {"source": "generative model", "target": "indoor scene synthesi", "depth": [1, 3]}, {"source": "problem", "target": "matching problem", "depth": [1, 2]}, {"source": "problem", "target": "unified theory", "depth": [1, 3]}, {"source": "problem", "target": "theory of sparsification", "depth": [1, 3]}, {"source": "problem", "target": "sparsification for matching", "depth": [1, 3]}, {"source": "problem", "target": "theory", "depth": [1, 1]}, {"source": "recurrent neural network", "target": "diabetes disease evolution", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "predicting diabetes disease", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "diabetes disease", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "disease evolution", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "evolution using financial", "depth": [1, 3]}, {"source": "classification", "target": "explicit interaction model", "depth": [1, 3]}, {"source": "classification", "target": "text classification", "depth": [1, 1]}, {"source": "classification", "target": "interaction model", "depth": [1, 3]}, {"source": "classification", "target": "model towards text", "depth": [1, 3]}, {"source": "classification", "target": "explicit interaction", "depth": [1, 3]}, {"source": "efficient", "target": "simple", "depth": [1, 2]}, {"source": "efficient", "target": "approach for efficient", "depth": [1, 3]}, {"source": "efficient", "target": "efficient training", "depth": [1, 2]}, {"source": "efficient", "target": "sampling approach", "depth": [1, 3]}, {"source": "efficient", "target": "generalization", "depth": [1, 1]}, {"source": "video", "target": "video denoising", "depth": [1, 2]}, {"source": "video", "target": "denoising", "depth": [1, 2]}, {"source": "video", "target": "compressed video", "depth": [1, 2]}, {"source": "video", "target": "multiview correlation", "depth": [1, 3]}, {"source": "video", "target": "learning from multiview", "depth": [1, 3]}, {"source": "adversarial attack", "target": "task-generalizable adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "adversarial attack based", "depth": [1, 3]}, {"source": "adversarial attack", "target": "perceptual metric", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack based", "depth": [1, 2]}, {"source": "adversarial attack", "target": "based on perceptual", "depth": [1, 3]}, {"source": "generation", "target": "scene graph generation", "depth": [1, 2]}, {"source": "generation", "target": "graph generation", "depth": [1, 2]}, {"source": "generation", "target": "interpretable model", "depth": [1, 2]}, {"source": "generation", "target": "model for scene", "depth": [1, 3]}, {"source": "generation", "target": "scene graph", "depth": [1, 2]}, {"source": "social network", "target": "diversity", "depth": [1, 2]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "social network", "target": "federated social network", "depth": [1, 3]}, {"source": "social network", "target": "recommending user", "depth": [1, 3]}, {"source": "social network", "target": "follow on federated", "depth": [1, 3]}, {"source": "control", "target": "optimal control", "depth": [1, 2]}, {"source": "control", "target": "system uncertainty", "depth": [1, 3]}, {"source": "control", "target": "control of ultra-capacitor", "depth": [1, 3]}, {"source": "control", "target": "ultra-capacitors with system", "depth": [1, 3]}, {"source": "control", "target": "uncertainty", "depth": [1, 1]}, {"source": "training", "target": "learnable task-adaptive adam", "depth": [1, 3]}, {"source": "training", "target": "network training", "depth": [1, 1]}, {"source": "training", "target": "adam for network", "depth": [1, 3]}, {"source": "training", "target": "hyperadam", "depth": [1, 3]}, {"source": "training", "target": "task-adaptive adam", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "bayesian deep learning", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "deep learning method", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "evaluating bayesian deep", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "bayesian deep", "depth": [1, 2]}, {"source": "active learning", "target": "bayesian active learning", "depth": [1, 2]}, {"source": "active learning", "target": "electrocardiographic signal classification", "depth": [1, 3]}, {"source": "active learning", "target": "robust active learning", "depth": [1, 3]}, {"source": "active learning", "target": "signal classification", "depth": [1, 2]}, {"source": "active learning", "target": "learning for electrocardiographic", "depth": [1, 3]}, {"source": "inference", "target": "likelihood-free inference", "depth": [1, 3]}, {"source": "inference", "target": "natural language inference", "depth": [1, 2]}, {"source": "inference", "target": "language inference", "depth": [1, 2]}, {"source": "inference", "target": "natural language", "depth": [1, 1]}, {"source": "inference", "target": "recurrent machine", "depth": [1, 3]}, {"source": "datum", "target": "implicitly low-rank datum", "depth": [1, 3]}, {"source": "datum", "target": "recovery with implicitly", "depth": [1, 3]}, {"source": "datum", "target": "matrix recovery", "depth": [1, 3]}, {"source": "datum", "target": "low-rank datum", "depth": [1, 3]}, {"source": "datum", "target": "implicitly low-rank", "depth": [1, 3]}, {"source": "clustering", "target": "subspace clustering", "depth": [1, 2]}, {"source": "clustering", "target": "subspace", "depth": [1, 2]}, {"source": "clustering", "target": "high dimensional clustering", "depth": [1, 3]}, {"source": "clustering", "target": "dimensional clustering", "depth": [1, 3]}, {"source": "clustering", "target": "high dimensional", "depth": [1, 2]}, {"source": "complexity", "target": "geometric terrain", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of treasure", "depth": [1, 3]}, {"source": "complexity", "target": "treasure hunt", "depth": [1, 3]}, {"source": "complexity", "target": "hunt in geometric", "depth": [1, 3]}, {"source": "complexity", "target": "advice complexity", "depth": [1, 3]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [1, 2]}, {"source": "representation learning", "target": "unsupervised representation", "depth": [1, 2]}, {"source": "representation learning", "target": "deep representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "deep representation", "depth": [1, 2]}, {"source": "representation learning", "target": "adversarial unsupervised representation", "depth": [1, 3]}, {"source": "tree", "target": "graph search tree", "depth": [1, 3]}, {"source": "tree", "target": "recognizing graph search", "depth": [1, 3]}, {"source": "tree", "target": "search tree", "depth": [1, 3]}, {"source": "tree", "target": "graph search", "depth": [1, 3]}, {"source": "tree", "target": "recognizing graph", "depth": [1, 3]}, {"source": "language", "target": "analyzing and learning", "depth": [1, 3]}, {"source": "language", "target": "types of harassment", "depth": [1, 3]}, {"source": "language", "target": "learning the language", "depth": [1, 3]}, {"source": "language", "target": "analyzing", "depth": [1, 2]}, {"source": "language", "target": "harassment", "depth": [1, 3]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "deep convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "fully convolutional network", "depth": [1, 3]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 2]}, {"source": "natural language", "target": "language processing", "depth": [1, 2]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 2]}, {"source": "natural language", "target": "language inference", "depth": [1, 2]}, {"source": "natural language", "target": "natural language understanding", "depth": [1, 3]}, {"source": "method", "target": "grid deformation method", "depth": [1, 3]}, {"source": "method", "target": "multi-block grid deformation", "depth": [1, 3]}, {"source": "method", "target": "grid deformation", "depth": [1, 3]}, {"source": "method", "target": "deformation method", "depth": [1, 3]}, {"source": "method", "target": "grid", "depth": [1, 2]}, {"source": "uncertainty", "target": "uncertainty propagation", "depth": [1, 3]}, {"source": "uncertainty", "target": "sparse coding", "depth": [1, 3]}, {"source": "uncertainty", "target": "propagation in neural", "depth": [1, 3]}, {"source": "uncertainty", "target": "networks for sparse", "depth": [1, 3]}, {"source": "uncertainty", "target": "coding", "depth": [1, 1]}, {"source": "machine", "target": "thinging machine", "depth": [1, 3]}, {"source": "machine", "target": "thinging machine applied", "depth": [1, 3]}, {"source": "machine", "target": "information leakage", "depth": [1, 3]}, {"source": "machine", "target": "machine applied", "depth": [1, 3]}, {"source": "machine", "target": "applied to information", "depth": [1, 3]}, {"source": "feature", "target": "feature selection", "depth": [1, 1]}, {"source": "feature", "target": "model prediction error", "depth": [1, 3]}, {"source": "feature", "target": "forecast lightning", "depth": [1, 3]}, {"source": "feature", "target": "model prediction", "depth": [1, 3]}, {"source": "feature", "target": "prediction error", "depth": [1, 2]}, {"source": "cloud", "target": "point", "depth": [1, 1]}, {"source": "cloud", "target": "fitting of geometric", "depth": [1, 3]}, {"source": "cloud", "target": "geometric primitive", "depth": [1, 3]}, {"source": "cloud", "target": "supervised fitting", "depth": [1, 3]}, {"source": "cloud", "target": "fitting", "depth": [1, 2]}, {"source": "communication", "target": "multi-path network communication", "depth": [1, 3]}, {"source": "communication", "target": "network communication", "depth": [1, 3]}, {"source": "communication", "target": "throughput requirement", "depth": [1, 3]}, {"source": "communication", "target": "minimizing", "depth": [1, 3]}, {"source": "communication", "target": "requirements in multi-path", "depth": [1, 3]}, {"source": "challenge", "target": "fog computing architecture", "depth": [1, 3]}, {"source": "challenge", "target": "survey and challenge", "depth": [1, 3]}, {"source": "challenge", "target": "computing architecture", "depth": [1, 3]}, {"source": "challenge", "target": "fog computing", "depth": [1, 2]}, {"source": "challenge", "target": "architecture", "depth": [1, 2]}, {"source": "object", "target": "modular lightweight network", "depth": [1, 3]}, {"source": "object", "target": "lightweight network", "depth": [1, 3]}, {"source": "object", "target": "road using modular", "depth": [1, 3]}, {"source": "object", "target": "modular lightweight", "depth": [1, 3]}, {"source": "object", "target": "detecting the object", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "unsupervised learning framework", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "robust filter set", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "learning framework", "depth": [1, 2]}, {"source": "unsupervised learning", "target": "adaptive and robust", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "robust filter", "depth": [1, 3]}, {"source": "neural machine translation", "target": "machine translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "empirical exploration", "depth": [1, 3]}, {"source": "neural machine translation", "target": "exploration of curriculum", "depth": [1, 3]}, {"source": "neural machine translation", "target": "curriculum learning", "depth": [1, 3]}, {"source": "robust", "target": "robust neural network", "depth": [1, 2]}, {"source": "robust", "target": "lipschitz continuity", "depth": [1, 3]}, {"source": "robust", "target": "networks with lipschitz", "depth": [1, 3]}, {"source": "robust", "target": "continuity", "depth": [1, 3]}, {"source": "robust", "target": "robust mean estimation", "depth": [1, 3]}, {"source": "language model", "target": "neural language model", "depth": [1, 1]}, {"source": "language model", "target": "neural language", "depth": [1, 1]}, {"source": "language model", "target": "segmental neural language", "depth": [1, 3]}, {"source": "language model", "target": "learning to discover", "depth": [1, 2]}, {"source": "language model", "target": "words with segmental", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning agent", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "learning agent", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "communication topology", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "organize your deep", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "introduction to deep", "depth": [1, 3]}, {"source": "segmentation", "target": "image segmentation", "depth": [1, 2]}, {"source": "segmentation", "target": "hyperspectral image segmentation", "depth": [1, 3]}, {"source": "segmentation", "target": "validating hyperspectral image", "depth": [1, 3]}, {"source": "segmentation", "target": "hyperspectral image", "depth": [1, 2]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 2]}, {"source": "speech enhancement", "target": "enhancement", "depth": [1, 3]}, {"source": "speech enhancement", "target": "semi-supervised multichannel speech", "depth": [1, 3]}, {"source": "speech enhancement", "target": "non-negative matrix factorization", "depth": [1, 3]}, {"source": "speech enhancement", "target": "multichannel speech enhancement", "depth": [1, 3]}, {"source": "speech enhancement", "target": "semi-supervised multichannel", "depth": [1, 3]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "translation", "depth": [1, 1]}, {"source": "machine translation", "target": "empirical exploration", "depth": [1, 3]}, {"source": "machine translation", "target": "exploration of curriculum", "depth": [1, 3]}, {"source": "machine translation", "target": "curriculum learning", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process prior", "depth": [1, 3]}, {"source": "gaussian proces", "target": "meta bayesian optimization", "depth": [1, 3]}, {"source": "gaussian proces", "target": "unknown gaussian proces", "depth": [1, 3]}, {"source": "gaussian proces", "target": "meta bayesian", "depth": [1, 3]}, {"source": "gaussian proces", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "information retrieval", "target": "information retrieval strategy", "depth": [1, 3]}, {"source": "information retrieval", "target": "structured information retrieval", "depth": [1, 3]}, {"source": "information retrieval", "target": "retrieval strategy", "depth": [1, 3]}, {"source": "information retrieval", "target": "strategies for localising", "depth": [1, 3]}, {"source": "information retrieval", "target": "localising software", "depth": [1, 3]}, {"source": "structure", "target": "partial automaton semigroup", "depth": [1, 3]}, {"source": "structure", "target": "automaton semigroup", "depth": [1, 3]}, {"source": "structure", "target": "structure theory", "depth": [1, 3]}, {"source": "structure", "target": "theory of partial", "depth": [1, 3]}, {"source": "structure", "target": "partial automaton", "depth": [1, 3]}, {"source": "adversarial learning", "target": "individual treatment effect", "depth": [1, 2]}, {"source": "adversarial learning", "target": "latent confounder model", "depth": [1, 3]}, {"source": "adversarial learning", "target": "individual treatment", "depth": [1, 3]}, {"source": "adversarial learning", "target": "treatment effect", "depth": [1, 3]}, {"source": "adversarial learning", "target": "effect in latent", "depth": [1, 3]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 1]}, {"source": "learning model", "target": "neural learning model", "depth": [1, 3]}, {"source": "learning model", "target": "vertex centrality measure", "depth": [1, 3]}, {"source": "learning model", "target": "massive real network", "depth": [1, 3]}, {"source": "learning model", "target": "computing vertex centrality", "depth": [1, 3]}, {"source": "question answering", "target": "community question answering", "depth": [1, 3]}, {"source": "question answering", "target": "heterogeneous community question", "depth": [1, 3]}, {"source": "question answering", "target": "duplicate question detection", "depth": [1, 3]}, {"source": "question answering", "target": "cross-domain duplicate question", "depth": [1, 3]}, {"source": "question answering", "target": "generality and knowledge", "depth": [1, 3]}, {"source": "face recognition", "target": "low-resolution face recognition", "depth": [1, 2]}, {"source": "face recognition", "target": "low-resolution face", "depth": [1, 2]}, {"source": "face recognition", "target": "face", "depth": [1, 1]}, {"source": "face recognition", "target": "low-resolution", "depth": [1, 3]}, {"source": "face recognition", "target": "large longitudinal database", "depth": [1, 3]}, {"source": "computing", "target": "computing the interleaving", "depth": [1, 3]}, {"source": "computing", "target": "distance is np-hard", "depth": [1, 3]}, {"source": "computing", "target": "interleaving distance", "depth": [1, 2]}, {"source": "computing", "target": "interleaving", "depth": [1, 3]}, {"source": "computing", "target": "distance", "depth": [1, 1]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 1]}, {"source": "transfer learning", "target": "generative adversarial transfer", "depth": [1, 3]}, {"source": "transfer learning", "target": "adversarial transfer learning", "depth": [1, 3]}, {"source": "transfer learning", "target": "adversarial transfer", "depth": [1, 3]}, {"source": "transfer learning", "target": "learning for person", "depth": [1, 3]}, {"source": "massive mimo", "target": "massive mimo system", "depth": [1, 3]}, {"source": "massive mimo", "target": "detection for massive", "depth": [1, 3]}, {"source": "massive mimo", "target": "mimo system", "depth": [1, 2]}, {"source": "massive mimo", "target": "learning-based ml detection", "depth": [1, 3]}, {"source": "massive mimo", "target": "massive mimo network", "depth": [1, 3]}, {"source": "internet of thing", "target": "things oriented approach", "depth": [1, 3]}, {"source": "internet of thing", "target": "water utility monitoring", "depth": [1, 3]}, {"source": "internet of thing", "target": "monitoring and control", "depth": [1, 2]}, {"source": "internet of thing", "target": "things oriented", "depth": [1, 3]}, {"source": "internet of thing", "target": "oriented approach", "depth": [1, 3]}, {"source": "feature selection", "target": "selection for survival", "depth": [1, 3]}, {"source": "feature selection", "target": "survival analysi", "depth": [1, 2]}, {"source": "feature selection", "target": "analysis with competing", "depth": [1, 3]}, {"source": "feature selection", "target": "competing risk", "depth": [1, 3]}, {"source": "feature selection", "target": "risks using deep", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 3]}, {"source": "pose estimation", "target": "ground plane polling", "depth": [1, 3]}, {"source": "pose estimation", "target": "plane polling", "depth": [1, 3]}, {"source": "pose estimation", "target": "estimation of object", "depth": [1, 3]}, {"source": "autonomous driving", "target": "driving", "depth": [1, 3]}, {"source": "autonomous driving", "target": "flow based background", "depth": [1, 3]}, {"source": "autonomous driving", "target": "based background subtraction", "depth": [1, 3]}, {"source": "autonomous driving", "target": "optical flow based", "depth": [1, 2]}, {"source": "autonomous driving", "target": "moving camera", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian approach", "depth": [1, 2]}, {"source": "bayesian", "target": "bayesian learning", "depth": [1, 2]}, {"source": "bayesian", "target": "normalizations as bayesian", "depth": [1, 3]}, {"source": "bayesian", "target": "stochastic normalization", "depth": [1, 3]}, {"source": "bayesian", "target": "normalization", "depth": [1, 2]}, {"source": "neural machine", "target": "empirical exploration", "depth": [1, 3]}, {"source": "neural machine", "target": "exploration of curriculum", "depth": [1, 3]}, {"source": "neural machine", "target": "curriculum learning", "depth": [1, 3]}, {"source": "neural machine", "target": "learning for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "multi-modal neural machine", "depth": [1, 3]}, {"source": "dataset", "target": "bugs in java", "depth": [1, 2]}, {"source": "dataset", "target": "repair of real", "depth": [1, 3]}, {"source": "dataset", "target": "real bug", "depth": [1, 3]}, {"source": "dataset", "target": "automatic repair", "depth": [1, 2]}, {"source": "dataset", "target": "large-scale experiment", "depth": [1, 3]}, {"source": "program", "target": "programs operationally", "depth": [1, 3]}, {"source": "program", "target": "verifying", "depth": [1, 2]}, {"source": "program", "target": "function", "depth": [1, 1]}, {"source": "program", "target": "quantum program", "depth": [1, 3]}, {"source": "program", "target": "elementary function", "depth": [1, 3]}, {"source": "theory", "target": "matching problem", "depth": [1, 2]}, {"source": "theory", "target": "unified theory", "depth": [1, 3]}, {"source": "theory", "target": "theory of sparsification", "depth": [1, 3]}, {"source": "theory", "target": "sparsification for matching", "depth": [1, 3]}, {"source": "theory", "target": "convergence theory", "depth": [1, 3]}, {"source": "compression", "target": "compression schemes exceeding", "depth": [1, 3]}, {"source": "compression", "target": "unlabeled compression scheme", "depth": [1, 3]}, {"source": "compression", "target": "compression scheme", "depth": [1, 3]}, {"source": "compression", "target": "schemes exceeding", "depth": [1, 3]}, {"source": "compression", "target": "unlabeled compression", "depth": [1, 3]}, {"source": "study", "target": "created equal", "depth": [1, 3]}, {"source": "study", "target": "training examples created", "depth": [1, 3]}, {"source": "study", "target": "empirical study", "depth": [1, 2]}, {"source": "study", "target": "created", "depth": [1, 3]}, {"source": "study", "target": "systematic mapping study", "depth": [1, 3]}, {"source": "anomaly detection", "target": "anomaly detection system", "depth": [1, 3]}, {"source": "anomaly detection", "target": "real-time anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "detection system", "depth": [1, 2]}, {"source": "anomaly detection", "target": "real-time anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "comprehensive real-time anomaly", "depth": [1, 3]}, {"source": "style transfer", "target": "transfer", "depth": [1, 1]}, {"source": "style transfer", "target": "video style transfer", "depth": [1, 3]}, {"source": "style transfer", "target": "constrained adversarial learning", "depth": [1, 3]}, {"source": "style transfer", "target": "evolvement constrained adversarial", "depth": [1, 3]}, {"source": "style transfer", "target": "constrained adversarial", "depth": [1, 3]}, {"source": "secure", "target": "secure network coding", "depth": [1, 2]}, {"source": "secure", "target": "secure network", "depth": [1, 2]}, {"source": "secure", "target": "network coding", "depth": [1, 2]}, {"source": "secure", "target": "security level", "depth": [1, 2]}, {"source": "secure", "target": "flexible rate", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adversarial entropy minimization", "depth": [1, 3]}, {"source": "domain adaptation", "target": "adversarial entropy", "depth": [1, 3]}, {"source": "domain adaptation", "target": "entropy minimization", "depth": [1, 3]}, {"source": "gradient descent", "target": "stochastic gradient descent", "depth": [1, 2]}, {"source": "gradient descent", "target": "partial gradient computation", "depth": [1, 3]}, {"source": "gradient descent", "target": "coded partial gradient", "depth": [1, 3]}, {"source": "gradient descent", "target": "distributed gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "gradient computation", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "deep convolutional", "depth": [1, 1]}, {"source": "deep convolutional neural", "target": "interwoven deep convolutional", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "convolutional neural net", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "driver behavior recognition", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "multi-stream input", "depth": [1, 3]}, {"source": "time series", "target": "financial time series", "depth": [1, 3]}, {"source": "time series", "target": "deep sequential model", "depth": [1, 3]}, {"source": "time series", "target": "benchmarking deep sequential", "depth": [1, 3]}, {"source": "time series", "target": "deep sequential", "depth": [1, 3]}, {"source": "time series", "target": "sequential model", "depth": [1, 3]}, {"source": "person re-identification", "target": "network for person", "depth": [1, 2]}, {"source": "person re-identification", "target": "generative adversarial transfer", "depth": [1, 3]}, {"source": "person re-identification", "target": "adversarial transfer learning", "depth": [1, 3]}, {"source": "person re-identification", "target": "adversarial transfer", "depth": [1, 3]}, {"source": "person re-identification", "target": "learning for person", "depth": [1, 3]}, {"source": "survey", "target": "fog computing architecture", "depth": [1, 3]}, {"source": "survey", "target": "survey and challenge", "depth": [1, 3]}, {"source": "survey", "target": "computing architecture", "depth": [1, 3]}, {"source": "survey", "target": "fog computing", "depth": [1, 2]}, {"source": "survey", "target": "architecture", "depth": [1, 2]}, {"source": "approximation", "target": "tight approximation", "depth": [1, 2]}, {"source": "approximation", "target": "unconstrained xos maximization", "depth": [1, 3]}, {"source": "approximation", "target": "xos maximization", "depth": [1, 3]}, {"source": "approximation", "target": "approximation for unconstrained", "depth": [1, 3]}, {"source": "approximation", "target": "unconstrained xo", "depth": [1, 3]}, {"source": "stochastic gradient", "target": "stochastic gradient optimization", "depth": [1, 3]}, {"source": "stochastic gradient", "target": "adaptive stochastic gradient", "depth": [1, 3]}, {"source": "stochastic gradient", "target": "double adaptive stochastic", "depth": [1, 3]}, {"source": "stochastic gradient", "target": "gradient optimization", "depth": [1, 2]}, {"source": "stochastic gradient", "target": "double adaptive", "depth": [1, 3]}, {"source": "reinforcement", "target": "model-based reinforcement learning", "depth": [1, 2]}, {"source": "reinforcement", "target": "sepsis treatment", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning for sepsi", "depth": [1, 3]}, {"source": "reinforcement", "target": "model-based reinforcement", "depth": [1, 2]}, {"source": "reinforcement", "target": "treatment", "depth": [1, 3]}, {"source": "data augmentation", "target": "random image cropping", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation using random", "depth": [1, 3]}, {"source": "data augmentation", "target": "random image", "depth": [1, 3]}, {"source": "data augmentation", "target": "image cropping", "depth": [1, 3]}, {"source": "data augmentation", "target": "cropping and patching", "depth": [1, 3]}, {"source": "attack", "target": "seek to exploit", "depth": [1, 3]}, {"source": "attack", "target": "criminals attack", "depth": [1, 3]}, {"source": "attack", "target": "human factor", "depth": [1, 3]}, {"source": "attack", "target": "exploit", "depth": [1, 3]}, {"source": "attack", "target": "human", "depth": [1, 1]}, {"source": "translation", "target": "speech translation", "depth": [1, 3]}, {"source": "translation", "target": "robustness of speech", "depth": [1, 3]}, {"source": "translation", "target": "improving the robustnes", "depth": [1, 3]}, {"source": "translation", "target": "robustnes", "depth": [1, 2]}, {"source": "translation", "target": "improving", "depth": [1, 2]}, {"source": "design", "target": "stochastic nmpc design", "depth": [1, 3]}, {"source": "design", "target": "nmpc design", "depth": [1, 3]}, {"source": "design", "target": "stochastic nmpc", "depth": [1, 3]}, {"source": "design", "target": "supervised clustering", "depth": [1, 2]}, {"source": "design", "target": "clustering in stochastic", "depth": [1, 3]}, {"source": "function", "target": "nondeterministic selection function", "depth": [1, 3]}, {"source": "function", "target": "sequential game", "depth": [1, 3]}, {"source": "function", "target": "selection function", "depth": [1, 3]}, {"source": "function", "target": "games and nondeterministic", "depth": [1, 3]}, {"source": "function", "target": "nondeterministic selection", "depth": [1, 3]}, {"source": "stability analysi", "target": "transient stability analysi", "depth": [1, 1]}, {"source": "stability analysi", "target": "transient stability", "depth": [1, 2]}, {"source": "stability analysi", "target": "design-oriented transient stability", "depth": [1, 3]}, {"source": "stability analysi", "target": "pll-synchronized voltage-source converter", "depth": [1, 3]}, {"source": "stability analysi", "target": "design-oriented transient", "depth": [1, 3]}, {"source": "memory", "target": "generative memory", "depth": [1, 3]}, {"source": "memory", "target": "dynamics for generative", "depth": [1, 3]}, {"source": "memory", "target": "learning attractor", "depth": [1, 3]}, {"source": "memory", "target": "attractor", "depth": [1, 3]}, {"source": "memory", "target": "bounded local memory", "depth": [1, 3]}, {"source": "exploration", "target": "context-dependent upper-confidence bound", "depth": [1, 3]}, {"source": "exploration", "target": "directed exploration", "depth": [1, 3]}, {"source": "exploration", "target": "bounds for directed", "depth": [1, 3]}, {"source": "exploration", "target": "context-dependent upper-confidence", "depth": [1, 3]}, {"source": "exploration", "target": "bound", "depth": [1, 1]}, {"source": "cnn", "target": "non-local video denoising", "depth": [1, 3]}, {"source": "cnn", "target": "denoising by cnn", "depth": [1, 3]}, {"source": "cnn", "target": "video denoising", "depth": [1, 2]}, {"source": "cnn", "target": "non-local video", "depth": [1, 3]}, {"source": "cnn", "target": "denoising", "depth": [1, 2]}, {"source": "image classification", "target": "large-scale noisy web", "depth": [1, 3]}, {"source": "image classification", "target": "noisy web datum", "depth": [1, 3]}, {"source": "image classification", "target": "large-scale noisy", "depth": [1, 3]}, {"source": "image classification", "target": "noisy web", "depth": [1, 3]}, {"source": "image classification", "target": "web datum", "depth": [1, 3]}, {"source": "action recognition", "target": "video action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "video action", "depth": [1, 3]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "action recognition classifier", "depth": [1, 3]}, {"source": "action recognition", "target": "optical flow-based action", "depth": [1, 3]}, {"source": "reconstruction", "target": "stack overflow post", "depth": [1, 3]}, {"source": "reconstruction", "target": "reconstruction and analysi", "depth": [1, 3]}, {"source": "reconstruction", "target": "overflow post", "depth": [1, 3]}, {"source": "reconstruction", "target": "evolution of stack", "depth": [1, 3]}, {"source": "reconstruction", "target": "stack overflow", "depth": [1, 3]}, {"source": "estimation", "target": "robust mean estimation", "depth": [1, 3]}, {"source": "estimation", "target": "high-dimensional robust", "depth": [1, 2]}, {"source": "estimation", "target": "nearly-linear time", "depth": [1, 3]}, {"source": "estimation", "target": "estimation in nearly-linear", "depth": [1, 3]}, {"source": "estimation", "target": "time", "depth": [1, 2]}, {"source": "emotion recognition", "target": "vocal emotion recognition", "depth": [1, 3]}, {"source": "emotion recognition", "target": "classifier-independent feature analysi", "depth": [1, 3]}, {"source": "emotion recognition", "target": "study of language", "depth": [1, 3]}, {"source": "emotion recognition", "target": "language and classifier-independent", "depth": [1, 3]}, {"source": "emotion recognition", "target": "classifier-independent feature", "depth": [1, 3]}, {"source": "framework", "target": "improving trajectory optimization", "depth": [1, 3]}, {"source": "framework", "target": "roadmap framework", "depth": [1, 3]}, {"source": "framework", "target": "trajectory optimization", "depth": [1, 2]}, {"source": "framework", "target": "improving trajectory", "depth": [1, 3]}, {"source": "framework", "target": "trajectory", "depth": [1, 1]}, {"source": "bayesian optimization", "target": "gaussian process prior", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "meta bayesian optimization", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "unknown gaussian proces", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "meta bayesian", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "suggesting cooking recipe", "depth": [1, 3]}, {"source": "coding", "target": "source coding", "depth": [1, 3]}, {"source": "coding", "target": "price of uncertain", "depth": [1, 3]}, {"source": "coding", "target": "priors in source", "depth": [1, 3]}, {"source": "coding", "target": "price", "depth": [1, 2]}, {"source": "coding", "target": "uncertainty propagation", "depth": [1, 3]}, {"source": "single image", "target": "point regression network", "depth": [1, 3]}, {"source": "single image", "target": "multi-view point regression", "depth": [1, 3]}, {"source": "single image", "target": "object reconstruction", "depth": [1, 3]}, {"source": "single image", "target": "point regression", "depth": [1, 3]}, {"source": "single image", "target": "regression network", "depth": [1, 2]}, {"source": "human", "target": "instance-level human analysi", "depth": [1, 3]}, {"source": "human", "target": "human analysi", "depth": [1, 3]}, {"source": "human", "target": "instance-level human", "depth": [1, 3]}, {"source": "human", "target": "parsing r-cnn", "depth": [1, 3]}, {"source": "human", "target": "r-cnn for instance-level", "depth": [1, 3]}, {"source": "video object", "target": "video object detection", "depth": [1, 3]}, {"source": "video object", "target": "primary video object", "depth": [1, 3]}, {"source": "video object", "target": "reversible flow", "depth": [1, 3]}, {"source": "video object", "target": "segmentation of primary", "depth": [1, 3]}, {"source": "video object", "target": "primary video", "depth": [1, 3]}, {"source": "distribution", "target": "neural separation", "depth": [1, 3]}, {"source": "distribution", "target": "unobserved distribution", "depth": [1, 3]}, {"source": "distribution", "target": "separation of observed", "depth": [1, 3]}, {"source": "distribution", "target": "observed and unobserved", "depth": [1, 3]}, {"source": "distribution", "target": "separation", "depth": [1, 3]}, {"source": "case study", "target": "order difference", "depth": [1, 3]}, {"source": "case study", "target": "dependency parsing", "depth": [1, 3]}, {"source": "case study", "target": "transfer with order", "depth": [1, 3]}, {"source": "case study", "target": "study on dependency", "depth": [1, 3]}, {"source": "case study", "target": "difficulties of cross-lingual", "depth": [1, 3]}, {"source": "embedding", "target": "network embedding", "depth": [1, 2]}, {"source": "embedding", "target": "document", "depth": [1, 3]}, {"source": "embedding", "target": "word embedding", "depth": [1, 2]}, {"source": "embedding", "target": "embedding directed graph", "depth": [1, 3]}, {"source": "embedding", "target": "directed graph", "depth": [1, 3]}, {"source": "sequence", "target": "multi-view inpainting", "depth": [1, 3]}, {"source": "sequence", "target": "rgb-d sequence", "depth": [1, 3]}, {"source": "sequence", "target": "inpainting for rgb-d", "depth": [1, 3]}, {"source": "sequence", "target": "inpainting", "depth": [1, 3]}, {"source": "sequence", "target": "multi-view", "depth": [1, 2]}, {"source": "point", "target": "fitting of geometric", "depth": [1, 3]}, {"source": "point", "target": "geometric primitive", "depth": [1, 3]}, {"source": "point", "target": "supervised fitting", "depth": [1, 3]}, {"source": "point", "target": "fitting", "depth": [1, 2]}, {"source": "point", "target": "iterative transformer network", "depth": [1, 3]}, {"source": "adversarial training", "target": "multimodal few-shot learning", "depth": [1, 3]}, {"source": "adversarial training", "target": "paced adversarial training", "depth": [1, 3]}, {"source": "adversarial training", "target": "few-shot learning", "depth": [1, 2]}, {"source": "adversarial training", "target": "paced adversarial", "depth": [1, 3]}, {"source": "adversarial training", "target": "training for multimodal", "depth": [1, 3]}, {"source": "neural architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "joint neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "search and quantization", "depth": [1, 3]}, {"source": "neural architecture", "target": "joint neural", "depth": [1, 3]}, {"source": "computation", "target": "models of computation", "depth": [1, 3]}, {"source": "computation", "target": "reversible model", "depth": [1, 3]}, {"source": "computation", "target": "embracing the law", "depth": [1, 3]}, {"source": "computation", "target": "physic", "depth": [1, 2]}, {"source": "computation", "target": "law", "depth": [1, 2]}, {"source": "information", "target": "sensor configuration", "depth": [1, 3]}, {"source": "information", "target": "geometry of sensor", "depth": [1, 3]}, {"source": "information", "target": "information geometry", "depth": [1, 3]}, {"source": "information", "target": "configuration", "depth": [1, 2]}, {"source": "information", "target": "geometry", "depth": [1, 2]}, {"source": "agent", "target": "ring digraph", "depth": [1, 3]}, {"source": "agent", "target": "agents on ring", "depth": [1, 3]}, {"source": "agent", "target": "second-order agent", "depth": [1, 3]}, {"source": "agent", "target": "digraph", "depth": [1, 2]}, {"source": "agent", "target": "ring", "depth": [1, 2]}, {"source": "online", "target": "online line chasing", "depth": [1, 3]}, {"source": "online", "target": "line chasing", "depth": [1, 3]}, {"source": "online", "target": "bounds for online", "depth": [1, 3]}, {"source": "online", "target": "online line", "depth": [1, 3]}, {"source": "online", "target": "chasing", "depth": [1, 2]}, {"source": "transfer", "target": "text style transfer", "depth": [1, 3]}, {"source": "transfer", "target": "multiple-attribute text style", "depth": [1, 3]}, {"source": "transfer", "target": "text style", "depth": [1, 3]}, {"source": "transfer", "target": "multiple-attribute text", "depth": [1, 3]}, {"source": "transfer", "target": "text", "depth": [1, 2]}, {"source": "extended version", "target": "byzantine quorum system", "depth": [1, 3]}, {"source": "extended version", "target": "federated byzantine quorum", "depth": [1, 3]}, {"source": "extended version", "target": "quorum system", "depth": [1, 3]}, {"source": "extended version", "target": "byzantine quorum", "depth": [1, 3]}, {"source": "extended version", "target": "federated byzantine", "depth": [1, 3]}, {"source": "correlation", "target": "multiview correlation", "depth": [1, 3]}, {"source": "correlation", "target": "learning from multiview", "depth": [1, 3]}, {"source": "correlation", "target": "open-domain video", "depth": [1, 3]}, {"source": "correlation", "target": "correlations in open-domain", "depth": [1, 3]}, {"source": "correlation", "target": "multiview", "depth": [1, 2]}, {"source": "image quality assessment", "target": "image quality", "depth": [1, 2]}, {"source": "image quality assessment", "target": "quality", "depth": [1, 2]}, {"source": "image quality assessment", "target": "spatial pooling strategy", "depth": [1, 3]}, {"source": "image quality assessment", "target": "content-based spatial pooling", "depth": [1, 3]}, {"source": "image quality assessment", "target": "comparative study", "depth": [1, 2]}, {"source": "quality assessment", "target": "image quality", "depth": [1, 2]}, {"source": "quality assessment", "target": "quality", "depth": [1, 2]}, {"source": "quality assessment", "target": "spatial pooling strategy", "depth": [1, 3]}, {"source": "quality assessment", "target": "content-based spatial pooling", "depth": [1, 3]}, {"source": "quality assessment", "target": "comparative study", "depth": [1, 2]}, {"source": "constraint", "target": "temporal stochastic constraint", "depth": [1, 3]}, {"source": "constraint", "target": "stochastic constraint", "depth": [1, 3]}, {"source": "constraint", "target": "bandits with temporal", "depth": [1, 3]}, {"source": "constraint", "target": "sparsity constraint", "depth": [1, 3]}, {"source": "constraint", "target": "regression with sparsity", "depth": [1, 3]}, {"source": "text classification", "target": "explicit interaction model", "depth": [1, 3]}, {"source": "text classification", "target": "interaction model", "depth": [1, 3]}, {"source": "text classification", "target": "model towards text", "depth": [1, 3]}, {"source": "text classification", "target": "explicit interaction", "depth": [1, 3]}, {"source": "text classification", "target": "interaction", "depth": [1, 2]}, {"source": "error", "target": "model prediction error", "depth": [1, 3]}, {"source": "error", "target": "forecast lightning", "depth": [1, 3]}, {"source": "error", "target": "model prediction", "depth": [1, 3]}, {"source": "error", "target": "prediction error", "depth": [1, 2]}, {"source": "error", "target": "forecast", "depth": [1, 3]}, {"source": "process", "target": "infinite-horizon gaussian process", "depth": [1, 3]}, {"source": "process", "target": "gaussian process", "depth": [1, 2]}, {"source": "process", "target": "infinite-horizon", "depth": [1, 3]}, {"source": "process", "target": "markov decision process", "depth": [1, 3]}, {"source": "process", "target": "decision process", "depth": [1, 2]}, {"source": "relation extraction", "target": "joint inference approach", "depth": [1, 3]}, {"source": "relation extraction", "target": "implicit relation requirement", "depth": [1, 3]}, {"source": "relation extraction", "target": "encoding implicit relation", "depth": [1, 3]}, {"source": "relation extraction", "target": "inference approach", "depth": [1, 3]}, {"source": "relation extraction", "target": "joint inference", "depth": [1, 3]}, {"source": "regression", "target": "zonal kriging", "depth": [1, 3]}, {"source": "regression", "target": "classification by zonal", "depth": [1, 3]}, {"source": "regression", "target": "regression and classification", "depth": [1, 2]}, {"source": "regression", "target": "kriging", "depth": [1, 3]}, {"source": "regression", "target": "zonal", "depth": [1, 3]}, {"source": "code", "target": "class of linear", "depth": [1, 3]}, {"source": "code", "target": "linear code", "depth": [1, 3]}, {"source": "code", "target": "weight", "depth": [1, 2]}, {"source": "code", "target": "clas", "depth": [1, 2]}, {"source": "code", "target": "linear", "depth": [1, 2]}, {"source": "testing", "target": "graph two-sample testing", "depth": [1, 3]}, {"source": "testing", "target": "practical method", "depth": [1, 3]}, {"source": "testing", "target": "two-sample testing", "depth": [1, 3]}, {"source": "testing", "target": "methods for graph", "depth": [1, 3]}, {"source": "testing", "target": "graph two-sample", "depth": [1, 3]}, {"source": "text detection", "target": "scene text detection", "depth": [1, 2]}, {"source": "text detection", "target": "scene text", "depth": [1, 1]}, {"source": "text detection", "target": "pyramid attention network", "depth": [1, 3]}, {"source": "text detection", "target": "pyramid attention", "depth": [1, 3]}, {"source": "text detection", "target": "attention network", "depth": [1, 2]}, {"source": "evaluation", "target": "model evaluation", "depth": [1, 3]}, {"source": "evaluation", "target": "algorithm selection", "depth": [1, 3]}, {"source": "evaluation", "target": "model selection", "depth": [1, 3]}, {"source": "evaluation", "target": "selection in machine", "depth": [1, 3]}, {"source": "evaluation", "target": "unrepresentative video datum", "depth": [1, 3]}, {"source": "task", "target": "visual setting", "depth": [1, 3]}, {"source": "task", "target": "task understanding", "depth": [1, 3]}, {"source": "task", "target": "understanding in visual", "depth": [1, 3]}, {"source": "task", "target": "setting", "depth": [1, 3]}, {"source": "task", "target": "understanding", "depth": [1, 2]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 2]}, {"source": "deep learning based", "target": "learning based phase", "depth": [1, 3]}, {"source": "deep learning based", "target": "based phase reconstruction", "depth": [1, 3]}, {"source": "deep learning based", "target": "speaker separation", "depth": [1, 3]}, {"source": "deep learning based", "target": "trigonometric perspective", "depth": [1, 3]}, {"source": "deep learning model", "target": "attribution-based explanation", "depth": [1, 3]}, {"source": "deep learning model", "target": "deeper into deep", "depth": [1, 3]}, {"source": "deep learning model", "target": "explanations of textcnn", "depth": [1, 3]}, {"source": "deep learning model", "target": "explaining deep learning", "depth": [1, 3]}, {"source": "deep learning model", "target": "computational cost", "depth": [1, 3]}, {"source": "identification", "target": "monitoring and control", "depth": [1, 2]}, {"source": "identification", "target": "identification of macaque", "depth": [1, 3]}, {"source": "identification", "target": "macaques for population", "depth": [1, 3]}, {"source": "identification", "target": "population monitoring", "depth": [1, 3]}, {"source": "identification", "target": "unique identification", "depth": [1, 3]}, {"source": "representation", "target": "deep representation", "depth": [1, 2]}, {"source": "representation", "target": "empirical investigation", "depth": [1, 3]}, {"source": "representation", "target": "characteristics of deep", "depth": [1, 3]}, {"source": "representation", "target": "investigation", "depth": [1, 3]}, {"source": "representation", "target": "challenging common assumption", "depth": [1, 3]}, {"source": "convergence", "target": "sufficient condition", "depth": [1, 3]}, {"source": "convergence", "target": "condition for convergence", "depth": [1, 3]}, {"source": "convergence", "target": "convergences of adam", "depth": [1, 3]}, {"source": "convergence", "target": "adam and rmsprop", "depth": [1, 3]}, {"source": "convergence", "target": "sufficient", "depth": [1, 3]}, {"source": "perspective", "target": "mimic game", "depth": [1, 3]}, {"source": "perspective", "target": "signaling perspective", "depth": [1, 3]}, {"source": "perspective", "target": "mimic", "depth": [1, 3]}, {"source": "perspective", "target": "signaling", "depth": [1, 3]}, {"source": "perspective", "target": "imitation learning", "depth": [1, 1]}, {"source": "learning algorithm", "target": "machine learning algorithm", "depth": [1, 2]}, {"source": "learning algorithm", "target": "learning multiple default", "depth": [1, 3]}, {"source": "learning algorithm", "target": "multiple default", "depth": [1, 3]}, {"source": "learning algorithm", "target": "defaults for machine", "depth": [1, 3]}, {"source": "learning algorithm", "target": "learning multiple", "depth": [1, 3]}, {"source": "keyword spotting", "target": "neural network architecture", "depth": [1, 2]}, {"source": "keyword spotting", "target": "hierarchical neural network", "depth": [1, 2]}, {"source": "keyword spotting", "target": "network architecture", "depth": [1, 2]}, {"source": "keyword spotting", "target": "architecture in keyword", "depth": [1, 3]}, {"source": "keyword spotting", "target": "spotting", "depth": [1, 3]}, {"source": "security", "target": "real environment", "depth": [1, 3]}, {"source": "security", "target": "physical-layer security", "depth": [1, 3]}, {"source": "security", "target": "environment", "depth": [1, 2]}, {"source": "security", "target": "work", "depth": [1, 3]}, {"source": "security", "target": "physical-layer", "depth": [1, 3]}, {"source": "neural language model", "target": "neural language", "depth": [1, 1]}, {"source": "neural language model", "target": "segmental neural language", "depth": [1, 3]}, {"source": "neural language model", "target": "learning to discover", "depth": [1, 2]}, {"source": "neural language model", "target": "words with segmental", "depth": [1, 3]}, {"source": "neural language model", "target": "tradeoffs in neural", "depth": [1, 3]}, {"source": "language understanding", "target": "natural language understanding", "depth": [1, 3]}, {"source": "language understanding", "target": "low resources context", "depth": [1, 3]}, {"source": "language understanding", "target": "task oriented dialog", "depth": [1, 3]}, {"source": "language understanding", "target": "resources context", "depth": [1, 3]}, {"source": "language understanding", "target": "understanding for task", "depth": [1, 3]}, {"source": "classifier", "target": "fair classifier", "depth": [1, 3]}, {"source": "classifier", "target": "moral philosophy", "depth": [1, 3]}, {"source": "classifier", "target": "philosophy and legislation", "depth": [1, 3]}, {"source": "classifier", "target": "art in fair", "depth": [1, 3]}, {"source": "classifier", "target": "legislation to fair", "depth": [1, 3]}, {"source": "performance", "target": "performance guarantee", "depth": [1, 2]}, {"source": "performance", "target": "blind two-dimensional super-resolution", "depth": [1, 3]}, {"source": "performance", "target": "guarantee", "depth": [1, 2]}, {"source": "performance", "target": "two-dimensional super-resolution", "depth": [1, 3]}, {"source": "performance", "target": "blind", "depth": [1, 2]}, {"source": "strong baseline", "target": "bayesian deep learning", "depth": [1, 2]}, {"source": "strong baseline", "target": "importance of strong", "depth": [1, 3]}, {"source": "strong baseline", "target": "baselines in bayesian", "depth": [1, 3]}, {"source": "strong baseline", "target": "bayesian deep", "depth": [1, 2]}, {"source": "strong baseline", "target": "deep metric learning", "depth": [1, 3]}, {"source": "distance", "target": "computing the interleaving", "depth": [1, 3]}, {"source": "distance", "target": "distance is np-hard", "depth": [1, 3]}, {"source": "distance", "target": "interleaving distance", "depth": [1, 2]}, {"source": "distance", "target": "interleaving", "depth": [1, 3]}, {"source": "distance", "target": "improved crowding distance", "depth": [1, 3]}, {"source": "retrieval", "target": "learning from weight", "depth": [1, 3]}, {"source": "retrieval", "target": "cost-sensitive approach", "depth": [1, 3]}, {"source": "retrieval", "target": "weight", "depth": [1, 2]}, {"source": "retrieval", "target": "image retrieval", "depth": [1, 2]}, {"source": "retrieval", "target": "concept-centered hypertext approach", "depth": [1, 3]}, {"source": "scene text", "target": "scene text detection", "depth": [1, 2]}, {"source": "scene text", "target": "pyramid attention network", "depth": [1, 3]}, {"source": "scene text", "target": "pyramid attention", "depth": [1, 3]}, {"source": "scene text", "target": "attention network", "depth": [1, 2]}, {"source": "scene text", "target": "network for scene", "depth": [1, 3]}, {"source": "deep network", "target": "segmentation deep network", "depth": [1, 3]}, {"source": "deep network", "target": "minimalistic interactive lung", "depth": [1, 3]}, {"source": "deep network", "target": "interactive lung nodule", "depth": [1, 3]}, {"source": "deep network", "target": "lung nodule segmentation", "depth": [1, 3]}, {"source": "deep network", "target": "nodule segmentation deep", "depth": [1, 3]}, {"source": "trajectory", "target": "improving trajectory optimization", "depth": [1, 3]}, {"source": "trajectory", "target": "roadmap framework", "depth": [1, 3]}, {"source": "trajectory", "target": "trajectory optimization", "depth": [1, 2]}, {"source": "trajectory", "target": "improving trajectory", "depth": [1, 3]}, {"source": "trajectory", "target": "simulating mobility trajectory", "depth": [1, 3]}, {"source": "network training", "target": "adversarial network training", "depth": [1, 3]}, {"source": "network training", "target": "learnable task-adaptive adam", "depth": [1, 3]}, {"source": "network training", "target": "adam for network", "depth": [1, 3]}, {"source": "network training", "target": "hyperadam", "depth": [1, 3]}, {"source": "network training", "target": "task-adaptive adam", "depth": [1, 3]}, {"source": "generalization", "target": "simple", "depth": [1, 2]}, {"source": "generalization", "target": "approach for efficient", "depth": [1, 3]}, {"source": "generalization", "target": "efficient training", "depth": [1, 2]}, {"source": "generalization", "target": "sampling approach", "depth": [1, 3]}, {"source": "generalization", "target": "systematic generalization", "depth": [1, 3]}, {"source": "deep convolutional", "target": "deep convolutional network", "depth": [1, 2]}, {"source": "deep convolutional", "target": "segmentation on multi-modal", "depth": [1, 3]}, {"source": "deep convolutional", "target": "multi-modal mrus", "depth": [1, 3]}, {"source": "deep convolutional", "target": "mri using deep", "depth": [1, 3]}, {"source": "deep convolutional", "target": "splenomegaly segmentation", "depth": [1, 3]}, {"source": "generative", "target": "generative network", "depth": [1, 2]}, {"source": "generative", "target": "training of generative", "depth": [1, 3]}, {"source": "generative", "target": "kernel-based training", "depth": [1, 3]}, {"source": "generative", "target": "distribution-preserving steganography based", "depth": [1, 3]}, {"source": "generative", "target": "steganography based", "depth": [1, 3]}, {"source": "matrix factorization", "target": "semi-supervised multichannel speech", "depth": [1, 3]}, {"source": "matrix factorization", "target": "non-negative matrix factorization", "depth": [1, 3]}, {"source": "matrix factorization", "target": "multichannel speech enhancement", "depth": [1, 3]}, {"source": "matrix factorization", "target": "semi-supervised multichannel", "depth": [1, 3]}, {"source": "matrix factorization", "target": "multichannel speech", "depth": [1, 3]}, {"source": "flow", "target": "optimal power flow", "depth": [1, 2]}, {"source": "flow", "target": "power flow", "depth": [1, 2]}, {"source": "flow", "target": "notes on optimal", "depth": [1, 3]}, {"source": "flow", "target": "optimal power", "depth": [1, 3]}, {"source": "flow", "target": "lecture note", "depth": [1, 3]}, {"source": "bound", "target": "online line chasing", "depth": [1, 3]}, {"source": "bound", "target": "line chasing", "depth": [1, 3]}, {"source": "bound", "target": "bounds for online", "depth": [1, 3]}, {"source": "bound", "target": "online line", "depth": [1, 3]}, {"source": "bound", "target": "chasing", "depth": [1, 2]}, {"source": "selection", "target": "multidimensional feature selection", "depth": [1, 3]}, {"source": "selection", "target": "multidimensional feature", "depth": [1, 3]}, {"source": "selection", "target": "mdf", "depth": [1, 3]}, {"source": "selection", "target": "multidimensional", "depth": [1, 3]}, {"source": "selection", "target": "ensemble selection", "depth": [1, 2]}, {"source": "approximation algorithm", "target": "online social network", "depth": [1, 3]}, {"source": "approximation algorithm", "target": "algorithm for active", "depth": [1, 3]}, {"source": "approximation algorithm", "target": "active friending", "depth": [1, 3]}, {"source": "approximation algorithm", "target": "friending in online", "depth": [1, 3]}, {"source": "approximation algorithm", "target": "steiner tree", "depth": [1, 2]}, {"source": "attention", "target": "visual attention", "depth": [1, 3]}, {"source": "attention", "target": "attention for semantic", "depth": [1, 3]}, {"source": "attention", "target": "criss-cross attention", "depth": [1, 3]}, {"source": "attention", "target": "ccnet", "depth": [1, 3]}, {"source": "attention", "target": "fine-grained recognition", "depth": [1, 3]}, {"source": "lower bound", "target": "online rectangle packing", "depth": [1, 3]}, {"source": "lower bound", "target": "rectangle packing", "depth": [1, 3]}, {"source": "lower bound", "target": "bound for online", "depth": [1, 3]}, {"source": "lower bound", "target": "online rectangle", "depth": [1, 3]}, {"source": "lower bound", "target": "packing", "depth": [1, 2]}, {"source": "architecture search", "target": "joint neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "search and quantization", "depth": [1, 3]}, {"source": "architecture search", "target": "joint neural", "depth": [1, 3]}, {"source": "architecture search", "target": "quantization", "depth": [1, 3]}, {"source": "architecture search", "target": "adaptive neural architecture", "depth": [1, 3]}, {"source": "imitation learning", "target": "robot imitation learning", "depth": [1, 2]}, {"source": "imitation learning", "target": "regret convergence analysi", "depth": [1, 3]}, {"source": "imitation learning", "target": "adaptive regularization algorithm", "depth": [1, 2]}, {"source": "imitation learning", "target": "dynamic regret convergence", "depth": [1, 3]}, {"source": "imitation learning", "target": "on-policy robot imitation", "depth": [1, 3]}, {"source": "neural architecture search", "target": "joint neural architecture", "depth": [1, 3]}, {"source": "neural architecture search", "target": "search and quantization", "depth": [1, 3]}, {"source": "neural architecture search", "target": "joint neural", "depth": [1, 3]}, {"source": "neural architecture search", "target": "quantization", "depth": [1, 3]}, {"source": "neural architecture search", "target": "adaptive neural architecture", "depth": [1, 3]}, {"source": "transient stability analysi", "target": "transient stability", "depth": [1, 2]}, {"source": "transient stability analysi", "target": "power system transient", "depth": [1, 2]}, {"source": "transient stability analysi", "target": "system transient stability", "depth": [1, 2]}, {"source": "transient stability analysi", "target": "design-oriented transient stability", "depth": [1, 3]}, {"source": "transient stability analysi", "target": "pll-synchronized voltage-source converter", "depth": [1, 3]}, {"source": "face", "target": "low-resolution face recognition", "depth": [1, 2]}, {"source": "face", "target": "low-resolution face", "depth": [1, 2]}, {"source": "face", "target": "low-resolution", "depth": [1, 3]}, {"source": "face", "target": "planar steiner tree", "depth": [1, 3]}, {"source": "face", "target": "algorithms for planar", "depth": [1, 3]}, {"source": "neural language", "target": "segmental neural language", "depth": [1, 3]}, {"source": "neural language", "target": "learning to discover", "depth": [1, 2]}, {"source": "neural language", "target": "words with segmental", "depth": [1, 3]}, {"source": "neural language", "target": "tradeoffs in neural", "depth": [1, 3]}, {"source": "neural language", "target": "progress and tradeoff", "depth": [1, 3]}, {"source": "graph neural network", "target": "pre-training graph neural", "depth": [1, 3]}, {"source": "graph neural network", "target": "networks with kernel", "depth": [1, 3]}, {"source": "graph neural network", "target": "pre-training graph", "depth": [1, 3]}, {"source": "graph neural network", "target": "kernel", "depth": [1, 2]}, {"source": "graph neural network", "target": "recommendation with graph", "depth": [1, 3]}, {"source": "smart grid", "target": "smart grid domain", "depth": [1, 3]}, {"source": "smart grid", "target": "grid domain", "depth": [1, 3]}, {"source": "smart grid", "target": "perspectives of co-simulation", "depth": [1, 3]}, {"source": "smart grid", "target": "domain", "depth": [1, 2]}, {"source": "smart grid", "target": "smart grid co-simulation", "depth": [1, 3]}]}