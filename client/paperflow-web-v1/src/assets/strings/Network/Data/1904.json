{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "deep learning", "reinforcement learning", "machine learning", "system", "model", "object detection", "detection"], ["recurrent neural network", "graph neural network", "deep", "few-shot learning", "convolutional network", "social network", "convolutional", "wireless network", "learning model", "deep learning based", "machine", "deep convolutional neural", "deep reinforcement learning", "deep reinforcement", "cyber-physical system", "language model", "translation", "object", "study", "community detection", "analysi", "image", "single image", "graph", "algorithm", "problem", "matching", "classification", "text classification", "datum", "data augmentation", "gan", "software engineering", "thing", "prediction", "adversarial network", "generative adversarial network", "generative adversarial", "data analysi", "person re-identification", "recognition", "speech recognition", "speech", "action recognition", "domain adaptation", "segmentation", "instance segmentation", "object segmentation", "semantic segmentation", "video object segmentation", "tracking", "graph convolutional network", "generation", "text generation", "approach", "planning", "point cloud", "embedding", "word embedding", "dataset", "challenge", "optimization", "setting", "estimation", "pose estimation", "human pose estimation", "human pose", "survey", "logic", "task", "code", "source code", "representation", "application", "research", "method", "representation learning", "adversarial attack", "attack", "transfer learning", "transfer", "communication", "big datum", "video", "natural language", "online", "blockchain", "case study", "time series", "efficient", "question answering", "answering", "function", "modeling", "training", "image classification", "game", "attention", "matrix", "matrix completion", "knowledge distillation", "distillation", "quantum", "synthesi", "transformer", "knowledge graph", "recommendation", "design", "information", "theory", "adversarial learning", "computing", "computation", "los", "learning approach", "generative model", "social medium", "hidden markov model", "hidden markov", "markov model", "word", "face", "search", "metric learning", "image segmentation", "weakly supervised", "complexity", "learning based", "channel", "unsupervised learning", "language", "reconstruction", "image super-resolution", "time", "context", "domain", "deep network", "lower bound", "load balancing", "control", "programming", "decision making", "edge", "relation", "feature learning", "environment", "review", "internet of thing", "autoencoder", "bound", "shape", "framework", "tree", "text", "verification", "artificial neural network", "motion", "group", "linear", "image retrieval", "bayesian", "active learning", "generalization"], ["deep learning model", "unsupervised deep learning", "distributed machine learning", "distributed machine", "automated machine learning", "deep convolutional", "reinforcement learning agent", "performance", "salient object detection", "salient object", "early detection", "discovery", "planar graph", "approximation algorithm", "multi-label classification", "augmentation", "optimization problem", "solution", "software", "evaluation", "adversarial domain adaptation", "unsupervised domain adaptation", "unsupervised domain", "adversarial domain", "video object", "graph convolutional", "cloud", "sensor fusion", "morphable model", "pose", "event", "supervised semantic segmentation", "weakly supervised semantic", "neural logic", "program", "neural model", "suggestion mining", "automatic speech recognition", "system based", "quantum algorithm", "image dehazing", "video generation", "re-identification", "wireless communication", "wireles", "dimension", "secure", "security", "open source", "support vector machine", "vector machine", "efficient algorithm", "regret", "opportunity", "adversarial training", "self-attention network", "completion", "mining", "contextualized word embedding", "gender bia", "knowledge", "asr", "knowledge graph embedding", "graph embedding", "style transfer", "computational", "intrusion detection", "machine learning approach", "medium", "deep metric learning", "recommender system", "identification", "spoken language", "image reconstruction", "deep image", "load balancing algorithm", "distributed system", "balancing algorithm", "predictive control", "genetic programming", "impairments and disability", "situationally-induced impairment", "impairment", "disability", "unsupervised feature learning", "spiking neural network", "stochastic block model", "block model", "community", "engineering", "tight bound", "bounds for online", "support vector", "neural network model", "network model", "semantic representation", "sound", "mathbb"], ["distributed acoustic sensor", "neural networks approach", "classic versus image", "acoustic sensor", "networks approach", "smart laptop bag", "pulmonary nodule detection", "smartphone travel survey", "ensemble convolutional neural", "learning agent", "progressive recovery", "storage system", "dagstuhl seminar", "learning system", "probabilistic graphical model", "dynamic inference", "graphical model", "weakly supervised object", "neighbourhood discovery", "learning by neighbourhood", "scene flow estimation", "listen", "satellite image", "sharpness of satellite", "assessing the sharpnes", "planar", "scene graph prediction", "limited label", "graph prediction", "min-distance problem", "algorithms for min-distance", "class specific", "specific or shared", "clas", "augmentation using gan", "data analysis script", "convolutional recurrent neural", "neural network explanation", "evaluating recurrent neural", "network explanation", "evaluating recurrent", "multistage optimization problem", "predictions to prescription", "prescriptions in multistage", "multistage optimization", "multi-modal generative adversarial", "cycle-consistent adversarial network", "synthetic data augmentation", "evaluation and detection", "risks of webgl", "risk", "introduction to person", "re-identification with generative", "periodic motion recognition", "topological signature", "domain adaptation based", "segmentation and tracking", "optimized convolutional network", "graph optimized convolutional", "recovery for interdependent", "copy mechanism", "training for character-based", "mechanism and tailored", "tailored training", "recognition as planning", "approaches for goal", "goal recognition", "landmark-based approach", "accelerating lidar point", "point cloud annotation", "lidar point cloud", "alternative weighting scheme", "weighting scheme", "alternative weighting", "elmo embedding", "model and generative", "challenge dataset", "generate synthetic dataset", "learning to generate", "synthetic dataset", "dispersed setting", "semi-bandit optimization", "dispersed", "semi-bandit", "motion estimation", "asynchronou", "unifying part detection", "multi-person pose estimation", "class-wise region masking", "filling rate guided", "rate guided los", "face data augmentation", "survey on face", "face datum", "neural logic machine", "logic machine", "neural model ensemble", "ensemble for suggestion", "task driven object", "multichannel speech recognition", "multichannel speech", "mismatch condition", "reed-solomon code", "twisted reed-solomon code", "based on twisted", "learning anticipated representation", "forecasting by learning", "anticipated representation", "learning anticipated", "flare", "algorithm for st-connectivity", "st-connectivity", "bilevel paradigm", "paradigm", "bilevel", "enhancing nmt", "code-switching for enhancing", "product representation learning", "product representation", "datasets for product", "productnet", "collection of high-quality", "black-box adversarial attack", "cycle-consistent adversarial gan", "adversarial gan", "attack and defense", "representation similarity analysi", "efficient task taxonomy", "similarity analysi", "analysis for efficient", "single image dehazing", "face video generation", "image and landmark", "attention for person", "relation-aware global attention", "lte", "software-defined radio implementation", "software-defined radio", "deeppr", "big data system", "data system", "study and comparison", "solutions for big", "qualitative study", "face video", "landmark", "masses in mammogram", "method to localize", "localize mass", "unsupervised method", "mammogram", "interdisciplinary study", "fake news early", "natural language inference", "language inference", "virtual assistant command", "natural language semantic", "language semantic parser", "online metric matching", "stochastic online metric", "metric matching", "pose-based action recognition", "efficient real-time pose-based", "real-time pose-based action", "simple yet efficient", "efficient real-time", "internet", "permissionles", "decentralize the internet", "open source development", "source development", "study of bountysource", "development on github", "fault diagnosi", "applications in estimation", "target tracking", "pattern of time", "diagnosis and target", "fast delivery problem", "delivery problem", "fast delivery", "energy efficient", "video question answering", "grounding for video", "video question", "spatio-temporal grounding", "smooth function", "regret of convex", "convex and smooth", "adaptive regret", "broadband beamforming", "acoustic modeling", "modeling for broadband", "beamforming", "broadband", "iwildcam", "real-world reinforcement learning", "real-world reinforcement", "enabling training mode", "enabling training", "training mode", "human brain", "speech translation", "deep self-attention network", "deep self-attention", "resource speech challenge", "shared", "multi-objective particle swarm", "zielonka algorithm", "parity game", "quasi-polynomial time", "algorithm in quasi-polynomial", "zielonka", "spotting using hierarchical", "hierarchical network", "topic spotting", "spotting", "attention model", "adaptive matrix completion", "items in tail", "adaptive matrix", "mining from online", "online review", "reviews using ulmfit", "bias in contextualized", "contextualized word", "cross-lingual word embedding", "mutual knowledge distillation", "online mutual knowledge", "fusion for online", "self-organizing quantum network", "quantum network", "self-organizing quantum", "self-organizing", "accurate neural network", "synthesis of compact", "compact and accurate", "scann", "explaining black box", "context for asr", "transformers with convolutional", "convolutional context", "searching scoring function", "searching scoring", "scoring function", "decrease your gpa", "increase or decrease", "grade-aware course recommendation", "gpa", "increase", "photorealistic style transfer", "network for photorealistic", "photorealistic style", "high-resolution network", "computational level design", "intentional computational level", "level design", "computational level", "non-stochastic information theory", "information theory", "non-stochastic information", "information aggregation", "simulating execution time", "execution time", "time of tensor", "tensor program", "programs using graph", "computer network", "learning for intrusion", "detection in computer", "statistical classification", "compact semi-algebraic set", "computing the volume", "semi-algebraic set", "volume of compact", "compact semi-algebraic", "speeding up repeated", "repeated computation", "learning to prune", "prune", "speeding", "delta los", "deltum", "multi-weather relocalization", "gn-net", "gauss-newton los", "based adaptive system", "context based adaptive", "adaptive system", "context based", "matching perceptual feature", "implicit generative model", "learning implicit generative", "perceptual feature", "models by matching", "online social network", "influence of medium", "ideology of content", "content in online", "models for commercial", "text normalization", "normalization in social", "adapting sequence", "models for text", "disease progression pathway", "progression pathway", "analytics with hidden", "k-spectra", "neuro-symbolic concept learner", "interpreting scene", "concept learner", "natural supervision", "reference product search", "product search", "reference product", "product", "reference", "rescaled hinge los", "robust metric learning", "metric learning based", "hinge los", "depth prediction network", "absolute human pose", "prediction network", "estimation with depth", "mumford-shah loss functional", "functional for image", "segmentation with deep", "mumford-shah los", "medical image segmentation", "supervised object detection", "weakly supervised action", "supervised action segmentation", "fast weakly supervised", "gan to wgan", "wgan", "binary sequence", "binary", "optimal autocorrelation magnitude", "sequences of period", "autocorrelation magnitude", "make deep learning", "item response theory", "learning based knowledge", "based knowledge tracing", "gaussian many-access channel", "many-access channel", "unit-energy of gaussian", "gaussian many-acces", "capacity per unit-energy", "deep non-rigid structure", "structure from motion", "model using deep", "lifting autoencoder", "machine learning model", "analyzing the benefit", "benefits of communication", "communication channel", "networks with eigenpooling", "knowledge graph convolutional", "networks for recommender", "language identification", "cuneiform language identification", "cuneiform language", "sparsity to data-adaptive", "data-adaptive method", "methods and machine", "trace reconstruction", "lagrange interpolation", "development of lagrange", "deep image super-resolution", "robustness of deep", "evaluating robustnes", "super-resolution against adversarial", "predicting student performance", "query-focused sentence compression", "linear time", "sentence compression", "compression in linear", "query-focused sentence", "domain randomization", "randomization", "network-driven domain randomization", "network-driven domain", "deceptionnet", "spatial shortcut network", "friends or enemy", "tracking relationship", "permanent friend", "relationships between nation", "enemy", "binarized deep network", "training binarized deep", "regularizing activation distribution", "activation distribution", "distribution for training", "conditional lower bound", "conditional lower", "bound on graph", "graph connectivity", "connectivity in mapreduce", "route constrained optimization", "constrained optimization", "distillation via route", "route constrained", "dynamic load balancing", "dynamic load", "attention-based predictive control", "perceptual attention-based predictive", "frontal plane bipedal", "dynamics control", "dynamic programming", "data invariant", "synthesis for programming", "programming with datum", "interaction-aware decision making", "merging scenario", "making with adaptive", "adaptive strategy", "strategies under merging", "spectral partitioning", "unobserved edge", "partitioning of time-varying", "time-varying network", "networks with unobserved", "sparsely interacting worker", "sparse rank-one matrix", "rank-one matrix completion", "interacting worker", "disabilities research", "image-text discourse relation", "discourse relation", "cite", "corpus of image-text", "image-text discourse", "student performance", "empowered wireless network", "empowered wireles", "roadmap", "empowered", "connected spiking neural", "locally connected spiking", "connected spiking", "sparse hypergraph stochastic", "hypergraph stochastic block", "software engineering research", "engineering research", "things star-free", "blockchain-based decentralized self-balancing", "tvqa", "generating entity-specific post-modifier", "quantized vcg mechanism", "polymatroid environment", "vcg mechanism", "mechanisms for polymatroid", "quantized vcg", "affinity graph", "guiding video object", "guiding video", "reducing gender bia", "word-level language model", "reducing gender", "identifying and reducing", "big healthcare datum", "open research issue", "healthcare datum", "review and open", "rise of internet", "defense", "defenses to transferable", "transferable adversarial", "evading defense", "translation-invariant attack", "extreme multi-label classification", "autoencoder for extreme", "extreme multi-label", "ranking-based autoencoder", "construction equipment detection", "learning based solution", "equipment detection", "development to deployment", "learning based robot", "online edge coloring", "edge coloring", "online edge", "pathology image analysi", "neural network approach", "digital pathology image", "advanced deep convolutional", "art with transparent", "geometric shape", "evolved art", "overlapping", "transparent", "instance", "reflections by combining", "combining semantic", "semantic and instance", "detecting reflection", "learning fair representation", "adversarial framework", "fair representation", "learning fair", "fair", "dominator chromatic number", "orientations of tree", "chromatic number", "numbers of orientation", "match graph", "text summarization", "transcribing mixed handwritten", "machine-printed text", "tmixt", "flow for transcribing", "verification of support", "robustness verification", "unifying question answering", "span extraction", "regression via span", "unifying question", "legal document review", "multilayer perceptron artificial", "perceptron artificial neural", "drought using multilayer", "goal", "rich semantic representation", "neural text generation", "generation from rich", "neural text", "sound of motion", "sensing matrix design", "rotation group", "matrix design", "design and sparse", "sparse recovery", "january 06-11", "schloss dagstuhl", "explainable software", "software for cyber-physical", "linear rank distance", "rank distance code", "linear rank", "rank distance", "sketch-based image retrieval", "zero-shot sketch-based image", "sketch-based image", "deep discrete cross-domain", "garment image retrieval", "guiding", "bayesian approach", "bcma-e", "cma-e", "robust optimisation", "robust", "guidelines for datum", "analysis script", "guideline", "script", "disagreement-based active learning", "online setting", "learning in online", "representativeness and informativenes", "informativeness for active", "hybrid approach", "approach with optimization", "optimization and metric-based", "metric-based meta-learner", "meta-learner for few-shot", "rare class", "improve generalization", "generalization for rare", "synthetic examples improve", "class", "source code edit", "modeling source code", "code edit", "networks for modeling", "modeling source"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "deep", "depth": [0, 1]}, {"source": "learning", "target": "few-shot learning", "depth": [0, 1]}, {"source": "network", "target": "convolutional network", "depth": [0, 1]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "convolutional", "depth": [0, 1]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "wireless network", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 2]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 1]}, {"source": "deep learning", "target": "unsupervised deep learning", "depth": [0, 2]}, {"source": "deep neural network", "target": "distributed acoustic sensor", "depth": [0, 3]}, {"source": "deep neural network", "target": "neural networks approach", "depth": [0, 3]}, {"source": "deep neural network", "target": "classic versus image", "depth": [0, 3]}, {"source": "deep neural network", "target": "acoustic sensor", "depth": [0, 3]}, {"source": "deep neural network", "target": "networks approach", "depth": [0, 3]}, {"source": "machine learning", "target": "distributed machine learning", "depth": [0, 2]}, {"source": "machine learning", "target": "distributed machine", "depth": [0, 2]}, {"source": "machine learning", "target": "automated machine learning", "depth": [0, 2]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "smart laptop bag", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "pulmonary nodule detection", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "smartphone travel survey", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "ensemble convolutional neural", "depth": [0, 3]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement learning agent", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "learning agent", "depth": [0, 3]}, {"source": "reinforcement learning", "target": "progressive recovery", "depth": [0, 3]}, {"source": "system", "target": "storage system", "depth": [0, 3]}, {"source": "system", "target": "dagstuhl seminar", "depth": [0, 3]}, {"source": "system", "target": "cyber-physical system", "depth": [0, 1]}, {"source": "system", "target": "performance", "depth": [0, 2]}, {"source": "system", "target": "learning system", "depth": [0, 3]}, {"source": "model", "target": "language model", "depth": [0, 1]}, {"source": "model", "target": "translation", "depth": [0, 1]}, {"source": "model", "target": "probabilistic graphical model", "depth": [0, 3]}, {"source": "model", "target": "dynamic inference", "depth": [0, 3]}, {"source": "model", "target": "graphical model", "depth": [0, 3]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "salient object detection", "depth": [0, 2]}, {"source": "object detection", "target": "detection", "depth": [0, 0]}, {"source": "object detection", "target": "salient object", "depth": [0, 2]}, {"source": "object detection", "target": "weakly supervised object", "depth": [0, 3]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "study", "depth": [0, 1]}, {"source": "detection", "target": "community detection", "depth": [0, 1]}, {"source": "detection", "target": "early detection", "depth": [0, 2]}, {"source": "detection", "target": "analysi", "depth": [0, 1]}, {"source": "deep", "target": "unsupervised deep learning", "depth": [1, 2]}, {"source": "deep", "target": "neighbourhood discovery", "depth": [1, 3]}, {"source": "deep", "target": "learning by neighbourhood", "depth": [1, 3]}, {"source": "deep", "target": "discovery", "depth": [1, 2]}, {"source": "deep", "target": "scene flow estimation", "depth": [1, 3]}, {"source": "image", "target": "single image", "depth": [1, 1]}, {"source": "image", "target": "listen", "depth": [1, 3]}, {"source": "image", "target": "satellite image", "depth": [1, 3]}, {"source": "image", "target": "sharpness of satellite", "depth": [1, 3]}, {"source": "image", "target": "assessing the sharpnes", "depth": [1, 3]}, {"source": "graph", "target": "planar graph", "depth": [1, 2]}, {"source": "graph", "target": "planar", "depth": [1, 3]}, {"source": "graph", "target": "scene graph prediction", "depth": [1, 3]}, {"source": "graph", "target": "limited label", "depth": [1, 3]}, {"source": "graph", "target": "graph prediction", "depth": [1, 3]}, {"source": "algorithm", "target": "problem", "depth": [1, 1]}, {"source": "algorithm", "target": "matching", "depth": [1, 1]}, {"source": "algorithm", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "min-distance problem", "depth": [1, 3]}, {"source": "algorithm", "target": "algorithms for min-distance", "depth": [1, 3]}, {"source": "classification", "target": "multi-label classification", "depth": [1, 2]}, {"source": "classification", "target": "text classification", "depth": [1, 1]}, {"source": "classification", "target": "class specific", "depth": [1, 3]}, {"source": "classification", "target": "specific or shared", "depth": [1, 3]}, {"source": "classification", "target": "clas", "depth": [1, 3]}, {"source": "datum", "target": "data augmentation", "depth": [1, 1]}, {"source": "datum", "target": "augmentation using gan", "depth": [1, 3]}, {"source": "datum", "target": "augmentation", "depth": [1, 2]}, {"source": "datum", "target": "gan", "depth": [1, 1]}, {"source": "datum", "target": "data analysis script", "depth": [1, 3]}, {"source": "problem", "target": "optimization problem", "depth": [1, 2]}, {"source": "problem", "target": "software engineering", "depth": [1, 1]}, {"source": "problem", "target": "solution", "depth": [1, 2]}, {"source": "problem", "target": "thing", "depth": [1, 1]}, {"source": "problem", "target": "software", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "convolutional recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "neural network explanation", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "evaluating recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "network explanation", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "evaluating recurrent", "depth": [1, 3]}, {"source": "prediction", "target": "multistage optimization problem", "depth": [1, 3]}, {"source": "prediction", "target": "optimization problem", "depth": [1, 2]}, {"source": "prediction", "target": "predictions to prescription", "depth": [1, 3]}, {"source": "prediction", "target": "prescriptions in multistage", "depth": [1, 3]}, {"source": "prediction", "target": "multistage optimization", "depth": [1, 3]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "multi-modal generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "cycle-consistent adversarial network", "depth": [1, 3]}, {"source": "adversarial network", "target": "synthetic data augmentation", "depth": [1, 3]}, {"source": "analysi", "target": "data analysi", "depth": [1, 1]}, {"source": "analysi", "target": "evaluation and detection", "depth": [1, 3]}, {"source": "analysi", "target": "risks of webgl", "depth": [1, 3]}, {"source": "analysi", "target": "evaluation", "depth": [1, 2]}, {"source": "analysi", "target": "risk", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "multi-modal generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "introduction to person", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "person re-identification", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "re-identification with generative", "depth": [1, 3]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "periodic motion recognition", "depth": [1, 3]}, {"source": "recognition", "target": "topological signature", "depth": [1, 3]}, {"source": "domain adaptation", "target": "adversarial domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adversarial domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "domain adaptation based", "depth": [1, 3]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "object segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "video object segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "video object", "depth": [1, 2]}, {"source": "object", "target": "object segmentation", "depth": [1, 1]}, {"source": "object", "target": "video object segmentation", "depth": [1, 1]}, {"source": "object", "target": "segmentation and tracking", "depth": [1, 3]}, {"source": "object", "target": "video object", "depth": [1, 2]}, {"source": "object", "target": "tracking", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "optimized convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph optimized convolutional", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning agent", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "learning agent", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "progressive recovery", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "recovery for interdependent", "depth": [1, 3]}, {"source": "generation", "target": "text generation", "depth": [1, 1]}, {"source": "generation", "target": "copy mechanism", "depth": [1, 3]}, {"source": "generation", "target": "training for character-based", "depth": [1, 3]}, {"source": "generation", "target": "mechanism and tailored", "depth": [1, 3]}, {"source": "generation", "target": "tailored training", "depth": [1, 3]}, {"source": "approach", "target": "recognition as planning", "depth": [1, 3]}, {"source": "approach", "target": "approaches for goal", "depth": [1, 3]}, {"source": "approach", "target": "goal recognition", "depth": [1, 3]}, {"source": "approach", "target": "landmark-based approach", "depth": [1, 3]}, {"source": "approach", "target": "planning", "depth": [1, 1]}, {"source": "point cloud", "target": "cloud", "depth": [1, 2]}, {"source": "point cloud", "target": "accelerating lidar point", "depth": [1, 3]}, {"source": "point cloud", "target": "point cloud annotation", "depth": [1, 3]}, {"source": "point cloud", "target": "lidar point cloud", "depth": [1, 3]}, {"source": "point cloud", "target": "sensor fusion", "depth": [1, 2]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "alternative weighting scheme", "depth": [1, 3]}, {"source": "embedding", "target": "weighting scheme", "depth": [1, 3]}, {"source": "embedding", "target": "alternative weighting", "depth": [1, 3]}, {"source": "embedding", "target": "elmo embedding", "depth": [1, 3]}, {"source": "generative adversarial", "target": "introduction to person", "depth": [1, 3]}, {"source": "generative adversarial", "target": "person re-identification", "depth": [1, 1]}, {"source": "generative adversarial", "target": "re-identification with generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "morphable model", "depth": [1, 2]}, {"source": "generative adversarial", "target": "model and generative", "depth": [1, 3]}, {"source": "dataset", "target": "challenge dataset", "depth": [1, 3]}, {"source": "dataset", "target": "challenge", "depth": [1, 1]}, {"source": "dataset", "target": "generate synthetic dataset", "depth": [1, 3]}, {"source": "dataset", "target": "learning to generate", "depth": [1, 3]}, {"source": "dataset", "target": "synthetic dataset", "depth": [1, 3]}, {"source": "optimization", "target": "dispersed setting", "depth": [1, 3]}, {"source": "optimization", "target": "semi-bandit optimization", "depth": [1, 3]}, {"source": "optimization", "target": "setting", "depth": [1, 1]}, {"source": "optimization", "target": "dispersed", "depth": [1, 3]}, {"source": "optimization", "target": "semi-bandit", "depth": [1, 3]}, {"source": "estimation", "target": "pose estimation", "depth": [1, 1]}, {"source": "estimation", "target": "pose", "depth": [1, 2]}, {"source": "estimation", "target": "motion estimation", "depth": [1, 3]}, {"source": "estimation", "target": "event", "depth": [1, 2]}, {"source": "estimation", "target": "asynchronou", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "unifying part detection", "depth": [1, 3]}, {"source": "pose estimation", "target": "multi-person pose estimation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "supervised semantic segmentation", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "weakly supervised semantic", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "class-wise region masking", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "filling rate guided", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "rate guided los", "depth": [1, 3]}, {"source": "survey", "target": "face data augmentation", "depth": [1, 3]}, {"source": "survey", "target": "data augmentation", "depth": [1, 1]}, {"source": "survey", "target": "survey on face", "depth": [1, 3]}, {"source": "survey", "target": "face datum", "depth": [1, 3]}, {"source": "survey", "target": "augmentation", "depth": [1, 2]}, {"source": "logic", "target": "neural logic", "depth": [1, 2]}, {"source": "logic", "target": "program", "depth": [1, 2]}, {"source": "logic", "target": "neural logic machine", "depth": [1, 3]}, {"source": "logic", "target": "logic machine", "depth": [1, 3]}, {"source": "logic", "target": "machine", "depth": [1, 1]}, {"source": "task", "target": "neural model ensemble", "depth": [1, 3]}, {"source": "task", "target": "neural model", "depth": [1, 2]}, {"source": "task", "target": "suggestion mining", "depth": [1, 2]}, {"source": "task", "target": "ensemble for suggestion", "depth": [1, 3]}, {"source": "task", "target": "task driven object", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "automatic speech recognition", "depth": [1, 2]}, {"source": "speech recognition", "target": "multichannel speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "multichannel speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "mismatch condition", "depth": [1, 3]}, {"source": "code", "target": "reed-solomon code", "depth": [1, 3]}, {"source": "code", "target": "source code", "depth": [1, 1]}, {"source": "code", "target": "twisted reed-solomon code", "depth": [1, 3]}, {"source": "code", "target": "system based", "depth": [1, 2]}, {"source": "code", "target": "based on twisted", "depth": [1, 3]}, {"source": "representation", "target": "learning anticipated representation", "depth": [1, 3]}, {"source": "representation", "target": "forecasting by learning", "depth": [1, 3]}, {"source": "representation", "target": "anticipated representation", "depth": [1, 3]}, {"source": "representation", "target": "learning anticipated", "depth": [1, 3]}, {"source": "representation", "target": "flare", "depth": [1, 3]}, {"source": "application", "target": "research", "depth": [1, 1]}, {"source": "application", "target": "method", "depth": [1, 1]}, {"source": "application", "target": "algorithm for st-connectivity", "depth": [1, 3]}, {"source": "application", "target": "quantum algorithm", "depth": [1, 2]}, {"source": "application", "target": "st-connectivity", "depth": [1, 3]}, {"source": "translation", "target": "bilevel paradigm", "depth": [1, 3]}, {"source": "translation", "target": "paradigm", "depth": [1, 3]}, {"source": "translation", "target": "bilevel", "depth": [1, 3]}, {"source": "translation", "target": "enhancing nmt", "depth": [1, 3]}, {"source": "translation", "target": "code-switching for enhancing", "depth": [1, 3]}, {"source": "representation learning", "target": "product representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "product representation", "depth": [1, 3]}, {"source": "representation learning", "target": "datasets for product", "depth": [1, 3]}, {"source": "representation learning", "target": "productnet", "depth": [1, 3]}, {"source": "representation learning", "target": "collection of high-quality", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "black-box adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "cycle-consistent adversarial gan", "depth": [1, 3]}, {"source": "adversarial attack", "target": "adversarial gan", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack and defense", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 1]}, {"source": "transfer learning", "target": "representation similarity analysi", "depth": [1, 3]}, {"source": "transfer learning", "target": "efficient task taxonomy", "depth": [1, 3]}, {"source": "transfer learning", "target": "similarity analysi", "depth": [1, 3]}, {"source": "transfer learning", "target": "analysis for efficient", "depth": [1, 3]}, {"source": "single image", "target": "single image dehazing", "depth": [1, 3]}, {"source": "single image", "target": "image dehazing", "depth": [1, 2]}, {"source": "single image", "target": "face video generation", "depth": [1, 3]}, {"source": "single image", "target": "image and landmark", "depth": [1, 3]}, {"source": "single image", "target": "video generation", "depth": [1, 2]}, {"source": "person re-identification", "target": "re-identification", "depth": [1, 2]}, {"source": "person re-identification", "target": "attention for person", "depth": [1, 3]}, {"source": "person re-identification", "target": "introduction to person", "depth": [1, 3]}, {"source": "person re-identification", "target": "re-identification with generative", "depth": [1, 3]}, {"source": "person re-identification", "target": "relation-aware global attention", "depth": [1, 3]}, {"source": "communication", "target": "wireless communication", "depth": [1, 2]}, {"source": "communication", "target": "lte", "depth": [1, 3]}, {"source": "communication", "target": "wireles", "depth": [1, 2]}, {"source": "communication", "target": "software-defined radio implementation", "depth": [1, 3]}, {"source": "communication", "target": "software-defined radio", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning agent", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "learning agent", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "progressive recovery", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "recovery for interdependent", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "deeppr", "depth": [1, 3]}, {"source": "big datum", "target": "big data system", "depth": [1, 3]}, {"source": "big datum", "target": "data system", "depth": [1, 3]}, {"source": "big datum", "target": "study and comparison", "depth": [1, 3]}, {"source": "big datum", "target": "solutions for big", "depth": [1, 3]}, {"source": "big datum", "target": "qualitative study", "depth": [1, 3]}, {"source": "video", "target": "video generation", "depth": [1, 2]}, {"source": "video", "target": "face video generation", "depth": [1, 3]}, {"source": "video", "target": "image and landmark", "depth": [1, 3]}, {"source": "video", "target": "face video", "depth": [1, 3]}, {"source": "video", "target": "landmark", "depth": [1, 3]}, {"source": "method", "target": "masses in mammogram", "depth": [1, 3]}, {"source": "method", "target": "method to localize", "depth": [1, 3]}, {"source": "method", "target": "localize mass", "depth": [1, 3]}, {"source": "method", "target": "unsupervised method", "depth": [1, 3]}, {"source": "method", "target": "mammogram", "depth": [1, 3]}, {"source": "study", "target": "early detection", "depth": [1, 2]}, {"source": "study", "target": "interdisciplinary study", "depth": [1, 3]}, {"source": "study", "target": "fake news early", "depth": [1, 3]}, {"source": "study", "target": "satellite image", "depth": [1, 3]}, {"source": "study", "target": "sharpness of satellite", "depth": [1, 3]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 3]}, {"source": "natural language", "target": "language inference", "depth": [1, 3]}, {"source": "natural language", "target": "virtual assistant command", "depth": [1, 3]}, {"source": "natural language", "target": "natural language semantic", "depth": [1, 3]}, {"source": "natural language", "target": "language semantic parser", "depth": [1, 3]}, {"source": "matching", "target": "online", "depth": [1, 1]}, {"source": "matching", "target": "dimension", "depth": [1, 2]}, {"source": "matching", "target": "online metric matching", "depth": [1, 3]}, {"source": "matching", "target": "stochastic online metric", "depth": [1, 3]}, {"source": "matching", "target": "metric matching", "depth": [1, 3]}, {"source": "action recognition", "target": "pose-based action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "efficient real-time pose-based", "depth": [1, 3]}, {"source": "action recognition", "target": "real-time pose-based action", "depth": [1, 3]}, {"source": "action recognition", "target": "simple yet efficient", "depth": [1, 3]}, {"source": "action recognition", "target": "efficient real-time", "depth": [1, 3]}, {"source": "blockchain", "target": "internet", "depth": [1, 3]}, {"source": "blockchain", "target": "secure", "depth": [1, 2]}, {"source": "blockchain", "target": "security", "depth": [1, 2]}, {"source": "blockchain", "target": "permissionles", "depth": [1, 3]}, {"source": "blockchain", "target": "decentralize the internet", "depth": [1, 3]}, {"source": "case study", "target": "open source development", "depth": [1, 3]}, {"source": "case study", "target": "open source", "depth": [1, 2]}, {"source": "case study", "target": "source development", "depth": [1, 3]}, {"source": "case study", "target": "study of bountysource", "depth": [1, 3]}, {"source": "case study", "target": "development on github", "depth": [1, 3]}, {"source": "machine", "target": "neural logic machine", "depth": [1, 3]}, {"source": "machine", "target": "logic machine", "depth": [1, 3]}, {"source": "machine", "target": "neural logic", "depth": [1, 2]}, {"source": "machine", "target": "support vector machine", "depth": [1, 2]}, {"source": "machine", "target": "vector machine", "depth": [1, 2]}, {"source": "time series", "target": "fault diagnosi", "depth": [1, 3]}, {"source": "time series", "target": "applications in estimation", "depth": [1, 3]}, {"source": "time series", "target": "target tracking", "depth": [1, 3]}, {"source": "time series", "target": "pattern of time", "depth": [1, 3]}, {"source": "time series", "target": "diagnosis and target", "depth": [1, 3]}, {"source": "efficient", "target": "fast delivery problem", "depth": [1, 3]}, {"source": "efficient", "target": "delivery problem", "depth": [1, 3]}, {"source": "efficient", "target": "efficient algorithm", "depth": [1, 2]}, {"source": "efficient", "target": "fast delivery", "depth": [1, 3]}, {"source": "efficient", "target": "energy efficient", "depth": [1, 3]}, {"source": "question answering", "target": "answering", "depth": [1, 1]}, {"source": "question answering", "target": "video question answering", "depth": [1, 3]}, {"source": "question answering", "target": "grounding for video", "depth": [1, 3]}, {"source": "question answering", "target": "video question", "depth": [1, 3]}, {"source": "question answering", "target": "spatio-temporal grounding", "depth": [1, 3]}, {"source": "function", "target": "smooth function", "depth": [1, 3]}, {"source": "function", "target": "regret of convex", "depth": [1, 3]}, {"source": "function", "target": "convex and smooth", "depth": [1, 3]}, {"source": "function", "target": "adaptive regret", "depth": [1, 3]}, {"source": "function", "target": "regret", "depth": [1, 2]}, {"source": "modeling", "target": "broadband beamforming", "depth": [1, 3]}, {"source": "modeling", "target": "acoustic modeling", "depth": [1, 3]}, {"source": "modeling", "target": "modeling for broadband", "depth": [1, 3]}, {"source": "modeling", "target": "beamforming", "depth": [1, 3]}, {"source": "modeling", "target": "broadband", "depth": [1, 3]}, {"source": "challenge", "target": "challenge dataset", "depth": [1, 3]}, {"source": "challenge", "target": "iwildcam", "depth": [1, 3]}, {"source": "challenge", "target": "opportunity", "depth": [1, 2]}, {"source": "challenge", "target": "real-world reinforcement learning", "depth": [1, 3]}, {"source": "challenge", "target": "real-world reinforcement", "depth": [1, 3]}, {"source": "training", "target": "adversarial training", "depth": [1, 2]}, {"source": "training", "target": "enabling training mode", "depth": [1, 3]}, {"source": "training", "target": "enabling training", "depth": [1, 3]}, {"source": "training", "target": "training mode", "depth": [1, 3]}, {"source": "training", "target": "human brain", "depth": [1, 3]}, {"source": "speech", "target": "speech translation", "depth": [1, 3]}, {"source": "speech", "target": "deep self-attention network", "depth": [1, 3]}, {"source": "speech", "target": "deep self-attention", "depth": [1, 3]}, {"source": "speech", "target": "self-attention network", "depth": [1, 2]}, {"source": "speech", "target": "resource speech challenge", "depth": [1, 3]}, {"source": "image classification", "target": "class specific", "depth": [1, 3]}, {"source": "image classification", "target": "specific or shared", "depth": [1, 3]}, {"source": "image classification", "target": "clas", "depth": [1, 3]}, {"source": "image classification", "target": "shared", "depth": [1, 3]}, {"source": "image classification", "target": "multi-objective particle swarm", "depth": [1, 3]}, {"source": "game", "target": "zielonka algorithm", "depth": [1, 3]}, {"source": "game", "target": "parity game", "depth": [1, 3]}, {"source": "game", "target": "quasi-polynomial time", "depth": [1, 3]}, {"source": "game", "target": "algorithm in quasi-polynomial", "depth": [1, 3]}, {"source": "game", "target": "zielonka", "depth": [1, 3]}, {"source": "attention", "target": "spotting using hierarchical", "depth": [1, 3]}, {"source": "attention", "target": "hierarchical network", "depth": [1, 3]}, {"source": "attention", "target": "topic spotting", "depth": [1, 3]}, {"source": "attention", "target": "spotting", "depth": [1, 3]}, {"source": "attention", "target": "attention model", "depth": [1, 3]}, {"source": "matrix", "target": "matrix completion", "depth": [1, 1]}, {"source": "matrix", "target": "completion", "depth": [1, 2]}, {"source": "matrix", "target": "adaptive matrix completion", "depth": [1, 3]}, {"source": "matrix", "target": "items in tail", "depth": [1, 3]}, {"source": "matrix", "target": "adaptive matrix", "depth": [1, 3]}, {"source": "online", "target": "mining from online", "depth": [1, 3]}, {"source": "online", "target": "online review", "depth": [1, 3]}, {"source": "online", "target": "suggestion mining", "depth": [1, 2]}, {"source": "online", "target": "reviews using ulmfit", "depth": [1, 3]}, {"source": "online", "target": "mining", "depth": [1, 2]}, {"source": "word embedding", "target": "contextualized word embedding", "depth": [1, 2]}, {"source": "word embedding", "target": "gender bia", "depth": [1, 2]}, {"source": "word embedding", "target": "bias in contextualized", "depth": [1, 3]}, {"source": "word embedding", "target": "contextualized word", "depth": [1, 3]}, {"source": "word embedding", "target": "cross-lingual word embedding", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "distillation", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "knowledge", "depth": [1, 2]}, {"source": "knowledge distillation", "target": "mutual knowledge distillation", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "online mutual knowledge", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "fusion for online", "depth": [1, 3]}, {"source": "quantum", "target": "self-organizing quantum network", "depth": [1, 3]}, {"source": "quantum", "target": "quantum network", "depth": [1, 3]}, {"source": "quantum", "target": "self-organizing quantum", "depth": [1, 3]}, {"source": "quantum", "target": "self-organizing", "depth": [1, 3]}, {"source": "quantum", "target": "algorithm for st-connectivity", "depth": [1, 3]}, {"source": "synthesi", "target": "accurate neural network", "depth": [1, 3]}, {"source": "synthesi", "target": "synthesis of compact", "depth": [1, 3]}, {"source": "synthesi", "target": "compact and accurate", "depth": [1, 3]}, {"source": "synthesi", "target": "scann", "depth": [1, 3]}, {"source": "synthesi", "target": "explaining black box", "depth": [1, 3]}, {"source": "convolutional", "target": "context for asr", "depth": [1, 3]}, {"source": "convolutional", "target": "transformers with convolutional", "depth": [1, 3]}, {"source": "convolutional", "target": "asr", "depth": [1, 2]}, {"source": "convolutional", "target": "convolutional context", "depth": [1, 3]}, {"source": "convolutional", "target": "transformer", "depth": [1, 1]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 2]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 2]}, {"source": "knowledge graph", "target": "searching scoring function", "depth": [1, 3]}, {"source": "knowledge graph", "target": "searching scoring", "depth": [1, 3]}, {"source": "knowledge graph", "target": "scoring function", "depth": [1, 3]}, {"source": "recommendation", "target": "decrease your gpa", "depth": [1, 3]}, {"source": "recommendation", "target": "increase or decrease", "depth": [1, 3]}, {"source": "recommendation", "target": "grade-aware course recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "gpa", "depth": [1, 3]}, {"source": "recommendation", "target": "increase", "depth": [1, 3]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "transfer", "target": "photorealistic style transfer", "depth": [1, 3]}, {"source": "transfer", "target": "network for photorealistic", "depth": [1, 3]}, {"source": "transfer", "target": "photorealistic style", "depth": [1, 3]}, {"source": "transfer", "target": "high-resolution network", "depth": [1, 3]}, {"source": "design", "target": "computational level design", "depth": [1, 3]}, {"source": "design", "target": "intentional computational level", "depth": [1, 3]}, {"source": "design", "target": "level design", "depth": [1, 3]}, {"source": "design", "target": "computational level", "depth": [1, 3]}, {"source": "design", "target": "computational", "depth": [1, 2]}, {"source": "information", "target": "non-stochastic information theory", "depth": [1, 3]}, {"source": "information", "target": "information theory", "depth": [1, 3]}, {"source": "information", "target": "non-stochastic information", "depth": [1, 3]}, {"source": "information", "target": "theory", "depth": [1, 1]}, {"source": "information", "target": "information aggregation", "depth": [1, 3]}, {"source": "graph neural network", "target": "simulating execution time", "depth": [1, 3]}, {"source": "graph neural network", "target": "execution time", "depth": [1, 3]}, {"source": "graph neural network", "target": "time of tensor", "depth": [1, 3]}, {"source": "graph neural network", "target": "tensor program", "depth": [1, 3]}, {"source": "graph neural network", "target": "programs using graph", "depth": [1, 3]}, {"source": "adversarial learning", "target": "computer network", "depth": [1, 3]}, {"source": "adversarial learning", "target": "learning for intrusion", "depth": [1, 3]}, {"source": "adversarial learning", "target": "intrusion detection", "depth": [1, 2]}, {"source": "adversarial learning", "target": "detection in computer", "depth": [1, 3]}, {"source": "adversarial learning", "target": "statistical classification", "depth": [1, 3]}, {"source": "computing", "target": "compact semi-algebraic set", "depth": [1, 3]}, {"source": "computing", "target": "computing the volume", "depth": [1, 3]}, {"source": "computing", "target": "semi-algebraic set", "depth": [1, 3]}, {"source": "computing", "target": "volume of compact", "depth": [1, 3]}, {"source": "computing", "target": "compact semi-algebraic", "depth": [1, 3]}, {"source": "computation", "target": "speeding up repeated", "depth": [1, 3]}, {"source": "computation", "target": "repeated computation", "depth": [1, 3]}, {"source": "computation", "target": "learning to prune", "depth": [1, 3]}, {"source": "computation", "target": "prune", "depth": [1, 3]}, {"source": "computation", "target": "speeding", "depth": [1, 3]}, {"source": "los", "target": "delta los", "depth": [1, 3]}, {"source": "los", "target": "deltum", "depth": [1, 3]}, {"source": "los", "target": "multi-weather relocalization", "depth": [1, 3]}, {"source": "los", "target": "gn-net", "depth": [1, 3]}, {"source": "los", "target": "gauss-newton los", "depth": [1, 3]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "based adaptive system", "depth": [1, 3]}, {"source": "learning approach", "target": "context based adaptive", "depth": [1, 3]}, {"source": "learning approach", "target": "adaptive system", "depth": [1, 3]}, {"source": "learning approach", "target": "context based", "depth": [1, 3]}, {"source": "generative model", "target": "matching perceptual feature", "depth": [1, 3]}, {"source": "generative model", "target": "implicit generative model", "depth": [1, 3]}, {"source": "generative model", "target": "learning implicit generative", "depth": [1, 3]}, {"source": "generative model", "target": "perceptual feature", "depth": [1, 3]}, {"source": "generative model", "target": "models by matching", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "social network", "target": "influence of medium", "depth": [1, 3]}, {"source": "social network", "target": "ideology of content", "depth": [1, 3]}, {"source": "social network", "target": "content in online", "depth": [1, 3]}, {"source": "social network", "target": "models for commercial", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "text normalization", "depth": [1, 3]}, {"source": "social medium", "target": "normalization in social", "depth": [1, 3]}, {"source": "social medium", "target": "adapting sequence", "depth": [1, 3]}, {"source": "social medium", "target": "models for text", "depth": [1, 3]}, {"source": "hidden markov model", "target": "hidden markov", "depth": [1, 1]}, {"source": "hidden markov model", "target": "markov model", "depth": [1, 1]}, {"source": "hidden markov model", "target": "disease progression pathway", "depth": [1, 3]}, {"source": "hidden markov model", "target": "progression pathway", "depth": [1, 3]}, {"source": "hidden markov model", "target": "analytics with hidden", "depth": [1, 3]}, {"source": "word", "target": "k-spectra", "depth": [1, 3]}, {"source": "word", "target": "neuro-symbolic concept learner", "depth": [1, 3]}, {"source": "word", "target": "interpreting scene", "depth": [1, 3]}, {"source": "word", "target": "concept learner", "depth": [1, 3]}, {"source": "word", "target": "natural supervision", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "face data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "survey on face", "depth": [1, 3]}, {"source": "data augmentation", "target": "face datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "face", "depth": [1, 1]}, {"source": "search", "target": "reference product search", "depth": [1, 3]}, {"source": "search", "target": "product search", "depth": [1, 3]}, {"source": "search", "target": "reference product", "depth": [1, 3]}, {"source": "search", "target": "product", "depth": [1, 3]}, {"source": "search", "target": "reference", "depth": [1, 3]}, {"source": "metric learning", "target": "deep metric learning", "depth": [1, 2]}, {"source": "metric learning", "target": "rescaled hinge los", "depth": [1, 3]}, {"source": "metric learning", "target": "robust metric learning", "depth": [1, 3]}, {"source": "metric learning", "target": "metric learning based", "depth": [1, 3]}, {"source": "metric learning", "target": "hinge los", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human pose", "target": "depth prediction network", "depth": [1, 3]}, {"source": "human pose", "target": "absolute human pose", "depth": [1, 3]}, {"source": "human pose", "target": "prediction network", "depth": [1, 3]}, {"source": "human pose", "target": "estimation with depth", "depth": [1, 3]}, {"source": "image segmentation", "target": "mumford-shah loss functional", "depth": [1, 3]}, {"source": "image segmentation", "target": "functional for image", "depth": [1, 3]}, {"source": "image segmentation", "target": "segmentation with deep", "depth": [1, 3]}, {"source": "image segmentation", "target": "mumford-shah los", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised object", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised object detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised action", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised action segmentation", "depth": [1, 3]}, {"source": "weakly supervised", "target": "fast weakly supervised", "depth": [1, 3]}, {"source": "gan", "target": "gan to wgan", "depth": [1, 3]}, {"source": "gan", "target": "wgan", "depth": [1, 3]}, {"source": "gan", "target": "augmentation using gan", "depth": [1, 3]}, {"source": "gan", "target": "augmentation", "depth": [1, 2]}, {"source": "gan", "target": "cycle-consistent adversarial gan", "depth": [1, 3]}, {"source": "complexity", "target": "binary sequence", "depth": [1, 3]}, {"source": "complexity", "target": "binary", "depth": [1, 3]}, {"source": "complexity", "target": "optimal autocorrelation magnitude", "depth": [1, 3]}, {"source": "complexity", "target": "sequences of period", "depth": [1, 3]}, {"source": "complexity", "target": "autocorrelation magnitude", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 1]}, {"source": "deep learning based", "target": "make deep learning", "depth": [1, 3]}, {"source": "deep learning based", "target": "item response theory", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based knowledge", "depth": [1, 3]}, {"source": "deep learning based", "target": "based knowledge tracing", "depth": [1, 3]}, {"source": "channel", "target": "gaussian many-access channel", "depth": [1, 3]}, {"source": "channel", "target": "many-access channel", "depth": [1, 3]}, {"source": "channel", "target": "unit-energy of gaussian", "depth": [1, 3]}, {"source": "channel", "target": "gaussian many-acces", "depth": [1, 3]}, {"source": "channel", "target": "capacity per unit-energy", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "deep non-rigid structure", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "morphable model", "depth": [1, 2]}, {"source": "unsupervised learning", "target": "structure from motion", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "model using deep", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "lifting autoencoder", "depth": [1, 3]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 2]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 3]}, {"source": "learning model", "target": "analyzing the benefit", "depth": [1, 3]}, {"source": "learning model", "target": "benefits of communication", "depth": [1, 3]}, {"source": "learning model", "target": "communication channel", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "networks with eigenpooling", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "knowledge graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "recommender system", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "networks for recommender", "depth": [1, 3]}, {"source": "language", "target": "language identification", "depth": [1, 3]}, {"source": "language", "target": "identification", "depth": [1, 2]}, {"source": "language", "target": "spoken language", "depth": [1, 2]}, {"source": "language", "target": "cuneiform language identification", "depth": [1, 3]}, {"source": "language", "target": "cuneiform language", "depth": [1, 3]}, {"source": "reconstruction", "target": "image reconstruction", "depth": [1, 2]}, {"source": "reconstruction", "target": "sparsity to data-adaptive", "depth": [1, 3]}, {"source": "reconstruction", "target": "data-adaptive method", "depth": [1, 3]}, {"source": "reconstruction", "target": "methods and machine", "depth": [1, 3]}, {"source": "reconstruction", "target": "trace reconstruction", "depth": [1, 3]}, {"source": "theory", "target": "non-stochastic information theory", "depth": [1, 3]}, {"source": "theory", "target": "information theory", "depth": [1, 3]}, {"source": "theory", "target": "non-stochastic information", "depth": [1, 3]}, {"source": "theory", "target": "lagrange interpolation", "depth": [1, 3]}, {"source": "theory", "target": "development of lagrange", "depth": [1, 3]}, {"source": "image super-resolution", "target": "deep image super-resolution", "depth": [1, 3]}, {"source": "image super-resolution", "target": "robustness of deep", "depth": [1, 3]}, {"source": "image super-resolution", "target": "deep image", "depth": [1, 2]}, {"source": "image super-resolution", "target": "evaluating robustnes", "depth": [1, 3]}, {"source": "image super-resolution", "target": "super-resolution against adversarial", "depth": [1, 3]}, {"source": "hidden markov", "target": "markov model", "depth": [1, 1]}, {"source": "hidden markov", "target": "disease progression pathway", "depth": [1, 3]}, {"source": "hidden markov", "target": "progression pathway", "depth": [1, 3]}, {"source": "hidden markov", "target": "analytics with hidden", "depth": [1, 3]}, {"source": "hidden markov", "target": "predicting student performance", "depth": [1, 3]}, {"source": "time", "target": "query-focused sentence compression", "depth": [1, 3]}, {"source": "time", "target": "linear time", "depth": [1, 3]}, {"source": "time", "target": "sentence compression", "depth": [1, 3]}, {"source": "time", "target": "compression in linear", "depth": [1, 3]}, {"source": "time", "target": "query-focused sentence", "depth": [1, 3]}, {"source": "transformer", "target": "context for asr", "depth": [1, 3]}, {"source": "transformer", "target": "transformers with convolutional", "depth": [1, 3]}, {"source": "transformer", "target": "asr", "depth": [1, 2]}, {"source": "transformer", "target": "convolutional context", "depth": [1, 3]}, {"source": "transformer", "target": "context", "depth": [1, 1]}, {"source": "domain", "target": "domain randomization", "depth": [1, 3]}, {"source": "domain", "target": "randomization", "depth": [1, 3]}, {"source": "domain", "target": "network-driven domain randomization", "depth": [1, 3]}, {"source": "domain", "target": "network-driven domain", "depth": [1, 3]}, {"source": "domain", "target": "deceptionnet", "depth": [1, 3]}, {"source": "human pose estimation", "target": "depth prediction network", "depth": [1, 3]}, {"source": "human pose estimation", "target": "absolute human pose", "depth": [1, 3]}, {"source": "human pose estimation", "target": "prediction network", "depth": [1, 3]}, {"source": "human pose estimation", "target": "estimation with depth", "depth": [1, 3]}, {"source": "human pose estimation", "target": "spatial shortcut network", "depth": [1, 3]}, {"source": "tracking", "target": "friends or enemy", "depth": [1, 3]}, {"source": "tracking", "target": "tracking relationship", "depth": [1, 3]}, {"source": "tracking", "target": "permanent friend", "depth": [1, 3]}, {"source": "tracking", "target": "relationships between nation", "depth": [1, 3]}, {"source": "tracking", "target": "enemy", "depth": [1, 3]}, {"source": "deep network", "target": "binarized deep network", "depth": [1, 3]}, {"source": "deep network", "target": "training binarized deep", "depth": [1, 3]}, {"source": "deep network", "target": "regularizing activation distribution", "depth": [1, 3]}, {"source": "deep network", "target": "activation distribution", "depth": [1, 3]}, {"source": "deep network", "target": "distribution for training", "depth": [1, 3]}, {"source": "lower bound", "target": "conditional lower bound", "depth": [1, 3]}, {"source": "lower bound", "target": "conditional lower", "depth": [1, 3]}, {"source": "lower bound", "target": "bound on graph", "depth": [1, 3]}, {"source": "lower bound", "target": "graph connectivity", "depth": [1, 3]}, {"source": "lower bound", "target": "connectivity in mapreduce", "depth": [1, 3]}, {"source": "distillation", "target": "route constrained optimization", "depth": [1, 3]}, {"source": "distillation", "target": "constrained optimization", "depth": [1, 3]}, {"source": "distillation", "target": "distillation via route", "depth": [1, 3]}, {"source": "distillation", "target": "route constrained", "depth": [1, 3]}, {"source": "distillation", "target": "knowledge", "depth": [1, 2]}, {"source": "load balancing", "target": "load balancing algorithm", "depth": [1, 2]}, {"source": "load balancing", "target": "distributed system", "depth": [1, 2]}, {"source": "load balancing", "target": "balancing algorithm", "depth": [1, 2]}, {"source": "load balancing", "target": "dynamic load balancing", "depth": [1, 3]}, {"source": "load balancing", "target": "dynamic load", "depth": [1, 3]}, {"source": "control", "target": "attention-based predictive control", "depth": [1, 3]}, {"source": "control", "target": "perceptual attention-based predictive", "depth": [1, 3]}, {"source": "control", "target": "predictive control", "depth": [1, 2]}, {"source": "control", "target": "frontal plane bipedal", "depth": [1, 3]}, {"source": "control", "target": "dynamics control", "depth": [1, 3]}, {"source": "programming", "target": "dynamic programming", "depth": [1, 3]}, {"source": "programming", "target": "genetic programming", "depth": [1, 2]}, {"source": "programming", "target": "data invariant", "depth": [1, 3]}, {"source": "programming", "target": "synthesis for programming", "depth": [1, 3]}, {"source": "programming", "target": "programming with datum", "depth": [1, 3]}, {"source": "decision making", "target": "interaction-aware decision making", "depth": [1, 3]}, {"source": "decision making", "target": "merging scenario", "depth": [1, 3]}, {"source": "decision making", "target": "making with adaptive", "depth": [1, 3]}, {"source": "decision making", "target": "adaptive strategy", "depth": [1, 3]}, {"source": "decision making", "target": "strategies under merging", "depth": [1, 3]}, {"source": "edge", "target": "spectral partitioning", "depth": [1, 3]}, {"source": "edge", "target": "unobserved edge", "depth": [1, 3]}, {"source": "edge", "target": "partitioning of time-varying", "depth": [1, 3]}, {"source": "edge", "target": "time-varying network", "depth": [1, 3]}, {"source": "edge", "target": "networks with unobserved", "depth": [1, 3]}, {"source": "matrix completion", "target": "completion", "depth": [1, 2]}, {"source": "matrix completion", "target": "sparsely interacting worker", "depth": [1, 3]}, {"source": "matrix completion", "target": "sparse rank-one matrix", "depth": [1, 3]}, {"source": "matrix completion", "target": "rank-one matrix completion", "depth": [1, 3]}, {"source": "matrix completion", "target": "interacting worker", "depth": [1, 3]}, {"source": "research", "target": "disabilities research", "depth": [1, 3]}, {"source": "research", "target": "impairments and disability", "depth": [1, 2]}, {"source": "research", "target": "situationally-induced impairment", "depth": [1, 2]}, {"source": "research", "target": "impairment", "depth": [1, 2]}, {"source": "research", "target": "disability", "depth": [1, 2]}, {"source": "relation", "target": "image-text discourse relation", "depth": [1, 3]}, {"source": "relation", "target": "discourse relation", "depth": [1, 3]}, {"source": "relation", "target": "cite", "depth": [1, 3]}, {"source": "relation", "target": "corpus of image-text", "depth": [1, 3]}, {"source": "relation", "target": "image-text discourse", "depth": [1, 3]}, {"source": "markov model", "target": "disease progression pathway", "depth": [1, 3]}, {"source": "markov model", "target": "progression pathway", "depth": [1, 3]}, {"source": "markov model", "target": "analytics with hidden", "depth": [1, 3]}, {"source": "markov model", "target": "predicting student performance", "depth": [1, 3]}, {"source": "markov model", "target": "student performance", "depth": [1, 3]}, {"source": "wireless network", "target": "empowered wireless network", "depth": [1, 3]}, {"source": "wireless network", "target": "empowered wireles", "depth": [1, 3]}, {"source": "wireless network", "target": "roadmap", "depth": [1, 3]}, {"source": "wireless network", "target": "empowered", "depth": [1, 3]}, {"source": "wireless network", "target": "wireles", "depth": [1, 2]}, {"source": "feature learning", "target": "unsupervised feature learning", "depth": [1, 2]}, {"source": "feature learning", "target": "connected spiking neural", "depth": [1, 3]}, {"source": "feature learning", "target": "spiking neural network", "depth": [1, 2]}, {"source": "feature learning", "target": "locally connected spiking", "depth": [1, 3]}, {"source": "feature learning", "target": "connected spiking", "depth": [1, 3]}, {"source": "community detection", "target": "stochastic block model", "depth": [1, 2]}, {"source": "community detection", "target": "block model", "depth": [1, 2]}, {"source": "community detection", "target": "community", "depth": [1, 2]}, {"source": "community detection", "target": "sparse hypergraph stochastic", "depth": [1, 3]}, {"source": "community detection", "target": "hypergraph stochastic block", "depth": [1, 3]}, {"source": "software engineering", "target": "software", "depth": [1, 2]}, {"source": "software engineering", "target": "engineering", "depth": [1, 2]}, {"source": "software engineering", "target": "solution", "depth": [1, 2]}, {"source": "software engineering", "target": "software engineering research", "depth": [1, 3]}, {"source": "software engineering", "target": "engineering research", "depth": [1, 3]}, {"source": "thing", "target": "solution", "depth": [1, 2]}, {"source": "thing", "target": "software", "depth": [1, 2]}, {"source": "thing", "target": "engineering", "depth": [1, 2]}, {"source": "thing", "target": "things star-free", "depth": [1, 3]}, {"source": "thing", "target": "blockchain-based decentralized self-balancing", "depth": [1, 3]}, {"source": "answering", "target": "video question answering", "depth": [1, 3]}, {"source": "answering", "target": "grounding for video", "depth": [1, 3]}, {"source": "answering", "target": "video question", "depth": [1, 3]}, {"source": "answering", "target": "spatio-temporal grounding", "depth": [1, 3]}, {"source": "answering", "target": "tvqa", "depth": [1, 3]}, {"source": "context", "target": "context for asr", "depth": [1, 3]}, {"source": "context", "target": "transformers with convolutional", "depth": [1, 3]}, {"source": "context", "target": "asr", "depth": [1, 2]}, {"source": "context", "target": "convolutional context", "depth": [1, 3]}, {"source": "context", "target": "generating entity-specific post-modifier", "depth": [1, 3]}, {"source": "environment", "target": "quantized vcg mechanism", "depth": [1, 3]}, {"source": "environment", "target": "polymatroid environment", "depth": [1, 3]}, {"source": "environment", "target": "vcg mechanism", "depth": [1, 3]}, {"source": "environment", "target": "mechanisms for polymatroid", "depth": [1, 3]}, {"source": "environment", "target": "quantized vcg", "depth": [1, 3]}, {"source": "face", "target": "face data augmentation", "depth": [1, 3]}, {"source": "face", "target": "survey on face", "depth": [1, 3]}, {"source": "face", "target": "face datum", "depth": [1, 3]}, {"source": "face", "target": "augmentation", "depth": [1, 2]}, {"source": "face", "target": "affinity graph", "depth": [1, 3]}, {"source": "object segmentation", "target": "video object segmentation", "depth": [1, 1]}, {"source": "object segmentation", "target": "video object", "depth": [1, 2]}, {"source": "object segmentation", "target": "segmentation and tracking", "depth": [1, 3]}, {"source": "object segmentation", "target": "guiding video object", "depth": [1, 3]}, {"source": "object segmentation", "target": "guiding video", "depth": [1, 3]}, {"source": "review", "target": "mining from online", "depth": [1, 3]}, {"source": "review", "target": "online review", "depth": [1, 3]}, {"source": "review", "target": "suggestion mining", "depth": [1, 2]}, {"source": "review", "target": "reviews using ulmfit", "depth": [1, 3]}, {"source": "review", "target": "mining", "depth": [1, 2]}, {"source": "language model", "target": "reducing gender bia", "depth": [1, 3]}, {"source": "language model", "target": "word-level language model", "depth": [1, 3]}, {"source": "language model", "target": "reducing gender", "depth": [1, 3]}, {"source": "language model", "target": "gender bia", "depth": [1, 2]}, {"source": "language model", "target": "identifying and reducing", "depth": [1, 3]}, {"source": "internet of thing", "target": "big healthcare datum", "depth": [1, 3]}, {"source": "internet of thing", "target": "open research issue", "depth": [1, 3]}, {"source": "internet of thing", "target": "healthcare datum", "depth": [1, 3]}, {"source": "internet of thing", "target": "review and open", "depth": [1, 3]}, {"source": "internet of thing", "target": "rise of internet", "depth": [1, 3]}, {"source": "attack", "target": "defense", "depth": [1, 3]}, {"source": "attack", "target": "defenses to transferable", "depth": [1, 3]}, {"source": "attack", "target": "transferable adversarial", "depth": [1, 3]}, {"source": "attack", "target": "evading defense", "depth": [1, 3]}, {"source": "attack", "target": "translation-invariant attack", "depth": [1, 3]}, {"source": "autoencoder", "target": "extreme multi-label classification", "depth": [1, 3]}, {"source": "autoencoder", "target": "multi-label classification", "depth": [1, 2]}, {"source": "autoencoder", "target": "autoencoder for extreme", "depth": [1, 3]}, {"source": "autoencoder", "target": "extreme multi-label", "depth": [1, 3]}, {"source": "autoencoder", "target": "ranking-based autoencoder", "depth": [1, 3]}, {"source": "learning based", "target": "construction equipment detection", "depth": [1, 3]}, {"source": "learning based", "target": "learning based solution", "depth": [1, 3]}, {"source": "learning based", "target": "equipment detection", "depth": [1, 3]}, {"source": "learning based", "target": "development to deployment", "depth": [1, 3]}, {"source": "learning based", "target": "learning based robot", "depth": [1, 3]}, {"source": "bound", "target": "tight bound", "depth": [1, 2]}, {"source": "bound", "target": "online edge coloring", "depth": [1, 3]}, {"source": "bound", "target": "edge coloring", "depth": [1, 3]}, {"source": "bound", "target": "bounds for online", "depth": [1, 2]}, {"source": "bound", "target": "online edge", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "deep convolutional", "depth": [1, 2]}, {"source": "deep convolutional neural", "target": "pathology image analysi", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "neural network approach", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "digital pathology image", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "advanced deep convolutional", "depth": [1, 3]}, {"source": "shape", "target": "art with transparent", "depth": [1, 3]}, {"source": "shape", "target": "geometric shape", "depth": [1, 3]}, {"source": "shape", "target": "evolved art", "depth": [1, 3]}, {"source": "shape", "target": "overlapping", "depth": [1, 3]}, {"source": "shape", "target": "transparent", "depth": [1, 3]}, {"source": "instance segmentation", "target": "instance", "depth": [1, 3]}, {"source": "instance segmentation", "target": "reflections by combining", "depth": [1, 3]}, {"source": "instance segmentation", "target": "combining semantic", "depth": [1, 3]}, {"source": "instance segmentation", "target": "semantic and instance", "depth": [1, 3]}, {"source": "instance segmentation", "target": "detecting reflection", "depth": [1, 3]}, {"source": "framework", "target": "learning fair representation", "depth": [1, 3]}, {"source": "framework", "target": "adversarial framework", "depth": [1, 3]}, {"source": "framework", "target": "fair representation", "depth": [1, 3]}, {"source": "framework", "target": "learning fair", "depth": [1, 3]}, {"source": "framework", "target": "fair", "depth": [1, 3]}, {"source": "tree", "target": "dominator chromatic number", "depth": [1, 3]}, {"source": "tree", "target": "orientations of tree", "depth": [1, 3]}, {"source": "tree", "target": "chromatic number", "depth": [1, 3]}, {"source": "tree", "target": "numbers of orientation", "depth": [1, 3]}, {"source": "tree", "target": "match graph", "depth": [1, 3]}, {"source": "text", "target": "text summarization", "depth": [1, 3]}, {"source": "text", "target": "transcribing mixed handwritten", "depth": [1, 3]}, {"source": "text", "target": "machine-printed text", "depth": [1, 3]}, {"source": "text", "target": "tmixt", "depth": [1, 3]}, {"source": "text", "target": "flow for transcribing", "depth": [1, 3]}, {"source": "verification", "target": "support vector machine", "depth": [1, 2]}, {"source": "verification", "target": "vector machine", "depth": [1, 2]}, {"source": "verification", "target": "verification of support", "depth": [1, 3]}, {"source": "verification", "target": "support vector", "depth": [1, 2]}, {"source": "verification", "target": "robustness verification", "depth": [1, 3]}, {"source": "text classification", "target": "unifying question answering", "depth": [1, 3]}, {"source": "text classification", "target": "span extraction", "depth": [1, 3]}, {"source": "text classification", "target": "regression via span", "depth": [1, 3]}, {"source": "text classification", "target": "unifying question", "depth": [1, 3]}, {"source": "text classification", "target": "legal document review", "depth": [1, 3]}, {"source": "artificial neural network", "target": "neural network model", "depth": [1, 2]}, {"source": "artificial neural network", "target": "multilayer perceptron artificial", "depth": [1, 3]}, {"source": "artificial neural network", "target": "perceptron artificial neural", "depth": [1, 3]}, {"source": "artificial neural network", "target": "network model", "depth": [1, 2]}, {"source": "artificial neural network", "target": "drought using multilayer", "depth": [1, 3]}, {"source": "planning", "target": "recognition as planning", "depth": [1, 3]}, {"source": "planning", "target": "approaches for goal", "depth": [1, 3]}, {"source": "planning", "target": "goal recognition", "depth": [1, 3]}, {"source": "planning", "target": "landmark-based approach", "depth": [1, 3]}, {"source": "planning", "target": "goal", "depth": [1, 3]}, {"source": "text generation", "target": "rich semantic representation", "depth": [1, 3]}, {"source": "text generation", "target": "neural text generation", "depth": [1, 3]}, {"source": "text generation", "target": "semantic representation", "depth": [1, 2]}, {"source": "text generation", "target": "generation from rich", "depth": [1, 3]}, {"source": "text generation", "target": "neural text", "depth": [1, 3]}, {"source": "motion", "target": "motion estimation", "depth": [1, 3]}, {"source": "motion", "target": "event", "depth": [1, 2]}, {"source": "motion", "target": "asynchronou", "depth": [1, 3]}, {"source": "motion", "target": "sound of motion", "depth": [1, 3]}, {"source": "motion", "target": "sound", "depth": [1, 2]}, {"source": "group", "target": "sensing matrix design", "depth": [1, 3]}, {"source": "group", "target": "rotation group", "depth": [1, 3]}, {"source": "group", "target": "matrix design", "depth": [1, 3]}, {"source": "group", "target": "design and sparse", "depth": [1, 3]}, {"source": "group", "target": "sparse recovery", "depth": [1, 3]}, {"source": "cyber-physical system", "target": "january 06-11", "depth": [1, 3]}, {"source": "cyber-physical system", "target": "dagstuhl seminar", "depth": [1, 3]}, {"source": "cyber-physical system", "target": "schloss dagstuhl", "depth": [1, 3]}, {"source": "cyber-physical system", "target": "explainable software", "depth": [1, 3]}, {"source": "cyber-physical system", "target": "software for cyber-physical", "depth": [1, 3]}, {"source": "linear", "target": "mathbb", "depth": [1, 2]}, {"source": "linear", "target": "linear rank distance", "depth": [1, 3]}, {"source": "linear", "target": "rank distance code", "depth": [1, 3]}, {"source": "linear", "target": "linear rank", "depth": [1, 3]}, {"source": "linear", "target": "rank distance", "depth": [1, 3]}, {"source": "image retrieval", "target": "sketch-based image retrieval", "depth": [1, 3]}, {"source": "image retrieval", "target": "zero-shot sketch-based image", "depth": [1, 3]}, {"source": "image retrieval", "target": "sketch-based image", "depth": [1, 3]}, {"source": "image retrieval", "target": "deep discrete cross-domain", "depth": [1, 3]}, {"source": "image retrieval", "target": "garment image retrieval", "depth": [1, 3]}, {"source": "video object segmentation", "target": "video object", "depth": [1, 2]}, {"source": "video object segmentation", "target": "segmentation and tracking", "depth": [1, 3]}, {"source": "video object segmentation", "target": "guiding video object", "depth": [1, 3]}, {"source": "video object segmentation", "target": "guiding video", "depth": [1, 3]}, {"source": "video object segmentation", "target": "guiding", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian approach", "depth": [1, 3]}, {"source": "bayesian", "target": "bcma-e", "depth": [1, 3]}, {"source": "bayesian", "target": "cma-e", "depth": [1, 3]}, {"source": "bayesian", "target": "robust optimisation", "depth": [1, 3]}, {"source": "bayesian", "target": "robust", "depth": [1, 3]}, {"source": "data analysi", "target": "data analysis script", "depth": [1, 3]}, {"source": "data analysi", "target": "guidelines for datum", "depth": [1, 3]}, {"source": "data analysi", "target": "analysis script", "depth": [1, 3]}, {"source": "data analysi", "target": "guideline", "depth": [1, 3]}, {"source": "data analysi", "target": "script", "depth": [1, 3]}, {"source": "setting", "target": "dispersed setting", "depth": [1, 3]}, {"source": "setting", "target": "semi-bandit optimization", "depth": [1, 3]}, {"source": "setting", "target": "dispersed", "depth": [1, 3]}, {"source": "setting", "target": "semi-bandit", "depth": [1, 3]}, {"source": "setting", "target": "disagreement-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "disagreement-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "online setting", "depth": [1, 3]}, {"source": "active learning", "target": "learning in online", "depth": [1, 3]}, {"source": "active learning", "target": "representativeness and informativenes", "depth": [1, 3]}, {"source": "active learning", "target": "informativeness for active", "depth": [1, 3]}, {"source": "few-shot learning", "target": "hybrid approach", "depth": [1, 3]}, {"source": "few-shot learning", "target": "approach with optimization", "depth": [1, 3]}, {"source": "few-shot learning", "target": "optimization and metric-based", "depth": [1, 3]}, {"source": "few-shot learning", "target": "metric-based meta-learner", "depth": [1, 3]}, {"source": "few-shot learning", "target": "meta-learner for few-shot", "depth": [1, 3]}, {"source": "generalization", "target": "rare class", "depth": [1, 3]}, {"source": "generalization", "target": "improve generalization", "depth": [1, 3]}, {"source": "generalization", "target": "generalization for rare", "depth": [1, 3]}, {"source": "generalization", "target": "synthetic examples improve", "depth": [1, 3]}, {"source": "generalization", "target": "class", "depth": [1, 3]}, {"source": "source code", "target": "source code edit", "depth": [1, 3]}, {"source": "source code", "target": "modeling source code", "depth": [1, 3]}, {"source": "source code", "target": "code edit", "depth": [1, 3]}, {"source": "source code", "target": "networks for modeling", "depth": [1, 3]}, {"source": "source code", "target": "modeling source", "depth": [1, 3]}]}