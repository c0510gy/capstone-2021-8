{"node": [["neural network", "deep neural network", "network", "convolutional neural network", "learning", "reinforcement learning", "deep learning", "machine learning", "model", "system", "machine translation"], ["graph neural network", "reinforcement", "transfer learning", "adversarial network", "classification", "robustnes", "deep reinforcement learning", "deep reinforcement", "deep", "deep learning approach", "learning approach", "deep learning based", "generative model", "analysi", "machine learning approach", "machine", "neural machine translation", "neural machine", "translation", "domain adaptation", "graph", "representation", "deep generative model", "deep generative", "detection", "object detection", "community detection", "algorithm", "datum", "sentiment analysi", "performance", "image classification", "embedding", "word embedding", "recognition", "speech recognition", "speech", "generation", "optimization", "generative adversarial network", "generative adversarial", "image", "dataset", "question answering", "natural language", "representation learning", "code", "object", "game", "problem", "natural language processing", "prediction", "adversarial attack", "attack", "estimation", "modeling", "social medium", "image segmentation", "medical image segmentation", "medical image", "neural architecture search", "neural architecture", "architecture search", "word", "inference", "fair", "semantic segmentation", "segmentation", "method", "convolutional network", "graph convolutional network", "graph convolutional", "function", "evaluation", "training", "adversarial training", "video", "challenge", "study", "image captioning", "language", "approach", "exploration", "wireless sensor network", "sensor network", "point cloud", "anomaly detection", "feature", "policy", "regression", "extended version", "adaptation", "generalization", "maximization", "edge", "finite element", "finite element method", "element method", "search", "action recognition", "classifier", "robust", "bia", "testing", "active learning", "bandit", "variational inference", "protocol", "gradient descent", "clustering", "survey", "blockchain", "information", "monte carlo", "reasoning", "variational autoencoder", "time series", "control", "unsupervised learning", "data analysi", "case study", "process", "optimal transport", "transport", "distributed", "communication", "policy gradient", "action space", "language model", "review", "sampling", "autonomous driving", "environment", "coding", "program", "time", "social network", "text", "structure", "dynamical system", "vision", "computer vision", "data augmentation", "agent", "space", "channel", "multiple acces", "relation extraction", "knowledge graph", "planning", "solution", "tool", "face", "user", "tutorial", "query", "privacy", "adversarial learning", "variance reduction", "multi-task learning", "artificial intelligence", "generative", "security", "efficient", "verification", "matrix", "sequence", "gradient", "pose estimation", "style transfer", "reading comprehension", "weakly supervised"], ["recurrent neural network", "complex network", "inverse reinforcement learning", "multi-agent reinforcement learning", "ising model", "neural network based", "deep convolutional neural", "neural network model", "reinforcement learning approach", "performance analysi", "text classification", "zero-shot learning", "noisy", "activity recognition", "policy optimization", "bayesian optimization", "visual question answering", "visual question", "meta-learning", "information bottleneck", "hyperspectral image classification", "hyperspectral image", "generalized", "language processing", "literature review", "gender bia", "self-supervised representation", "black-box adversarial attack", "bilingual word embedding", "bilingual word", "adversarial robustnes", "shared task", "deep convolutional network", "deep convolutional", "reward", "neural network training", "network training", "infty", "captioning", "wireless sensor", "number", "normalizing flow", "point", "instance", "deep feature", "learning policy", "extended", "version", "markov decision process", "decision process", "medium", "social media datum", "empirical study", "linear bandit", "action", "sentiment classification", "consensus protocol", "rate control protocol", "control protocol", "rate control", "rcp", "distributed learning", "autoencoder", "topological data analysi", "intrusion detection", "big datum", "mining", "fairnes", "neural language model", "neural language", "driving", "autonomou", "echo chamber", "multiple", "parameter estimation", "model robustnes", "community", "conservation law", "non-orthogonal multiple acces", "vehicular network", "verification tool", "singular value decomposition", "complexity analysi", "complexity", "detecting", "distribution", "revisited", "comprehension", "machine reading"], ["study on deep", "disentanglement of appearance", "appearance and perspective", "accurate deep neural", "accurate deep", "simple sentence representation", "relating simple sentence", "independence system", "operating system", "library for molecular", "molecular geometry", "mgo", "adversarial machine learning", "historical register book", "effective compressed multi-function", "compressed multi-function convolutional", "multi-function convolutional neural", "machine translation robustnes", "split graph", "citation graph", "generalized petersen graph", "domination in generalized", "classifying logistic vehicle", "cities using deep", "physical adversarial patch", "physical adversarial", "adversarial patch", "evolutionary algorithm", "complex error function", "real axi", "remark on algorithm", "loss of accuracy", "limited datum", "coloring with limited", "few-shot colorization", "memory-augmented network", "colorization via memory-augmented", "adaptation and learning", "subspace constraint", "classification via retrieval", "clarel", "embeddings for community", "simplicial complex", "detection in simplicial", "noisy speech", "perspective in generative", "lexical shortcut", "representation bottleneck", "bottleneck in neural", "global routing", "approach for global", "broadcast beam optimization", "adversarial pixel-level generation", "semantic image", "generation of semantic", "pixel-level generation", "adversarial pixel-level", "distributed optimization", "over-parameterized learning", "optimization for over-parameterized", "unsupervised deep visual", "deep visual odometry", "stacked generative adversarial", "fisheye image", "face and object", "detection in fisheye", "video question answering", "convolutional self-attention network", "meta-learning of textual", "textual representation", "connectivity-optimized representation learning", "information bottleneck decoding", "bottleneck decoding", "decoding of rate-compatible", "bottleneck", "image enhancement algorithm", "cnn-based hyperspectral image", "optimizing cnn-based hyperspectral", "classification on fpga", "supervised object detection", "weakly supervised object", "supervised object", "translation with lexical", "patience game", "winnability of klondike", "klondike solitaire", "winnability", "klondike", "higher-order generalized", "methods for hyperbolic", "hyperbolic problem", "higher-order", "language processing task", "supervised contextual embedding", "processing task", "contextual embedding", "mitigating gender bia", "large-scale bipartite graph", "efficient self-supervised representation", "self-supervised representation learning", "bipartite graph", "adversarial bit prediction", "bit prediction", "sampling for adversarial", "adversarial bit", "thompson sampling", "cope with adversarial", "learning to cope", "cope", "reinforcement learning meet", "pedestrian localization", "uncertainty estimation", "localization and uncertainty", "monocular", "monoloco", "modeling of user's", "users' behavior", "behavior on social", "cross-platform modeling", "learning bilingual word", "lexical definition", "translation robustnes", "r\u00e9nyi fair inference", "fair inference", "r\u00e9nyi fair", "r\u00e9nyi", "lidar surrounding view", "real-time model", "model for semantic", "surrounding view", "minimizing star-convex function", "methods for minimizing", "minimizing star-convex", "star-convex function", "minimizing", "robustness and robust", "evaluation of abramowitz", "abramowitz function", "complex plane", "abramowitz", "two-stream reward", "split q learning", "learning with two-stream", "risk-sensitive reinforcement learning", "worrisome impact", "inter-rater bia", "video parsing accessible", "video parsing", "cnns for video", "making cnn", "unsupervised video interpolation", "synthetic dataset", "dataset for deep", "dataset and baseline", "baseline", "attack on neural", "pinpointing performance inefficiency", "inefficiencies in java", "performance inefficiency", "transforming object", "objects into word", "transforming", "combinatorial generation", "permutation language", "generation via permutation", "combinatorial", "armenian language", "function learning", "approach to model", "model exploration", "java generic", "autonomous wireless sensor", "large-scale autonomous wireles", "autonomous wireles", "humans and machine", "notion of number", "number in human", "notion", "point cloud generation", "continuous normalizing flow", "cloud generation", "generation with continuou", "joint representation learning", "content and connection", "detection with joint", "joint representation", "learning of content", "wireless trajectory datum", "trajectory datum", "segmentation of wireles", "video-driven speech reconstruction", "speech reconstruction", "reconstruction using generative", "video-driven speech", "graph generative adversarial", "emotions from walking", "walking using affective", "affective and deep", "identifying emotion", "quantile regression", "policies through quantile", "quantile", "based learning", "user portrait", "portrait through social", "modeling of user", "professional post-editor", "user study", "adaptation of nmt", "nmt for professional", "generalized linear bandit", "exploration in generalized", "generalized linear", "randomized exploration", "unsupervised domain adaptation", "adversarial domain adaptation", "generative framework", "learning with adversarial", "hurt generalization", "training can hurt", "hurt", "descent based adversarial", "loss and decay", "decay of linguistic", "linguistic richnes", "richness in machine", "lost in translation", "edge addition", "maximization through edge", "k-core maximization", "addition", "element", "trefftz finite element", "curvilinear polygon", "action recognition challenge", "recognition challenge", "fbk-hupba submission", "submission", "scalable neural architecture", "entropic risk measure", "policy search", "risk measure", "measure in policy", "entropic risk", "solved", "probing sentiment classification", "sentiment", "assessing and probing", "bias in classifier", "classifiers using generative", "characterizing bia", "plane", "angle regression path", "testing and variable", "variable selection", "angle regression", "multiple testing", "feature-wise linear modulation", "linear modulation", "networks with feature-wise", "coupled graph neural", "prediction on social", "reject option classifier", "online active learning", "option classifier", "learning of reject", "reject option", "advancing speech recognition", "advancing speech", "volumetric medical image", "stochastic multi-domain learning", "semi-supervised stochastic multi-domain", "learning using variational", "stochastic multi-domain", "multi-domain learning", "secret gradient descent", "privacy-preserving distributed learning", "learning with secret", "secret gradient", "large-scale autonomou", "atomic fission", "fission", "models with clustering", "learning for deep", "graph datum", "representations of graph", "learning representation", "backhaul network", "informative image captioning", "sources of information", "captioning with external", "external source", "multilevel monte carlo", "monte carlo finite", "carlo finite volume", "finite volume method", "random conservation law", "multi-scale self-guided attention", "self-guided attention", "attention for medical", "search for volumetric", "one-shot neural architecture", "captioning with reasoning", "figure captioning", "sequence-level training", "reasoning and sequence-level", "non-negative matrix factorisation", "probabilistic non-negative matrix", "matrix factorisation", "autoencoder for probabilistic", "time series merge", "series merge tree", "horizon visibility graph", "trees are dual", "visibility graph", "perception and control", "learning of object", "object keypoint", "keypoints for perception", "near-optimal statistical estimation", "big data analysi", "multivariate big datum", "multiple case study", "industrial multiple case", "initial result", "industrial multiple", "multiple case", "neural process", "network generative process", "generative process", "discovery of family", "families of network", "blockchain mining", "speeding up blockchain", "for-loop for speeding", "speeding", "fairness testing", "testing via optimal", "fliptest", "random feature", "learning with random", "healthcare network", "backscatter communication", "communications for healthcare", "applications of backscatter", "backscatter", "discrete action space", "direct policy gradient", "optimization of policy", "policies in discrete", "pre-trained language model", "transformer language model", "transformer language", "robotic supervised autonomy", "supervised autonomy", "robotic supervised", "autonomy", "supervised", "robust training", "training for graph", "certifiable robustnes", "accurate depth", "detection in autonomou", "pseudo-lidar", "complex belief function", "generalization of dempster-shafer", "speech translation", "unknown cluttered environment", "cluttered environment", "autonomous navigation", "navigation of mav", "mavs in unknown", "fighting quantization bia", "fighting quantization", "comparing machine learning", "register book", "approaches for table", "crowdsourced live streaming", "predictive coding", "critical review", "prednet and predictive", "predictive", "arbitrary varying channel", "neural-based program decompiler", "program decompiler", "decompiler", "faceted dataflow program", "dataflow program", "feedback vertex set", "detecting feedback vertex", "sets of size", "feedback vertex", "vertex set", "modeling echo chamber", "modeling echo", "chambers and polarization", "polarization dynamic", "multiple classifier", "attacks against multiple", "robust attack", "linear attitude estimator", "code-switched text", "model for code-switched", "text spotting", "related work", "structure your related", "work", "structure learning", "covariance query", "surrogate-based parameter estimation", "estimation in dynamical", "meta-model framework", "framework for surrogate-based", "fourier perspective", "perspective on model", "robustness in computer", "hyperbolic space", "hierarchical reinforcement learning", "adaptation for hierarchical", "hierarchical reinforcement", "sub-policy adaptation", "blstm acoustic model", "preliminary study", "study on datum", "augmentation of deep", "learning for image", "augmentation", "disparate impact", "agents allowed", "cooperate or defect", "allowed to cooperate", "no-boarding", "bus", "deep decoder structure", "decoder structure based", "encoder-decoder based model", "deep decoder", "growing action space", "growing action", "growing", "guided graph convolutional", "k-core", "inputs to deep", "models using typicality", "partitioned finite element", "partitioned finite", "method for power-preserving", "timing side channel", "side channel", "mitigation of timing", "timing side", "quantitative mitigation", "landmark-dependent multi-scale patch", "cephalometric landmark identification", "learning based cephalometric", "based cephalometric landmark", "multi-scale patch", "cache-aided non-orthogonal multiple", "vehicular", "code multiple acces", "power flow", "calculation of probabilistic", "probabilistic power flow", "model-based deep learning", "probabilistic power", "relation extraction dataset", "document-level relation extraction", "extraction dataset", "large-scale document-level relation", "docred", "knowledge graph construction", "graph construction", "scalable knowledge graph", "construction from twitter", "scalable knowledge", "cyber defence exercise", "defence exercise", "concept of cyber", "cyber defence", "cdx", "google landmark recognition", "landmark recognition", "solution to google", "google landmark", "team jl solution", "classifier parameter estimation", "program verification tool", "detection with program", "program verification", "invariant detection", "datasets for face", "face obscuration", "smartphone user", "identifying smartphone user", "impact of mood", "mood on identifying", "identifying smartphone", "analysis of singular", "singular", "utility-preserving privacy mechanism", "counting query", "privacy mechanism", "mechanisms for counting", "utility-preserving privacy", "visually-guided cognitive representation", "reconstructing perceived image", "perceived image", "images from brain", "brain activity", "control variate", "weizs\u00e4cker model", "weizs\u00e4cker", "reduction for effective", "effective energy", "graph star net", "generalized multi-task learning", "star net", "net for generalized", "graph star", "making quality assurance", "quality assurance process", "assurance processes leaner", "quality assurance", "intelligence helps making", "dependency tree", "model for punctuation", "punctuation in dependency", "tree", "generative recursion", "backhaul", "security assessment", "assessment of enterprise", "challenges for security", "multiscale finite element", "efficient algorithm", "categorical distribution", "algorithms for modifying", "modifying and sampling", "verification of neural", "automatic verification", "heap-manipulating program", "verification of heap-manipulating", "heap-manipulating", "transport network", "positive definite matrix", "riemannian optimization", "definite matrix", "simplex of positive", "positive definite", "unsupervised representation learning", "dna sequence", "learning of dna", "unsupervised representation", "sequence generation", "leakage from gradient", "deep leakage", "leakage", "ranking policy gradient", "ranking policy", "object pose estimation", "robotics revisited", "object pose", "pose", "fourier", "image style transfer", "arbitrary image style", "peer-regularized feature recombination", "two-stage peer-regularized feature", "feature recombination", "machine reading comprehension", "multi-hop reading comprehension", "multi-hop reading", "instability in weakly", "utilizing the instability"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 2]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "transfer learning", "depth": [0, 1]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "complex network", "depth": [0, 2]}, {"source": "network", "target": "adversarial network", "depth": [0, 1]}, {"source": "network", "target": "classification", "depth": [0, 1]}, {"source": "network", "target": "robustnes", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "inverse reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 1]}, {"source": "deep learning", "target": "study on deep", "depth": [0, 3]}, {"source": "model", "target": "generative model", "depth": [0, 1]}, {"source": "model", "target": "analysi", "depth": [0, 1]}, {"source": "model", "target": "ising model", "depth": [0, 2]}, {"source": "model", "target": "disentanglement of appearance", "depth": [0, 3]}, {"source": "model", "target": "appearance and perspective", "depth": [0, 3]}, {"source": "deep neural network", "target": "neural network based", "depth": [0, 2]}, {"source": "deep neural network", "target": "accurate deep neural", "depth": [0, 3]}, {"source": "deep neural network", "target": "accurate deep", "depth": [0, 3]}, {"source": "deep neural network", "target": "simple sentence representation", "depth": [0, 3]}, {"source": "deep neural network", "target": "relating simple sentence", "depth": [0, 3]}, {"source": "system", "target": "independence system", "depth": [0, 3]}, {"source": "system", "target": "operating system", "depth": [0, 3]}, {"source": "system", "target": "library for molecular", "depth": [0, 3]}, {"source": "system", "target": "molecular geometry", "depth": [0, 3]}, {"source": "system", "target": "mgo", "depth": [0, 3]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 1]}, {"source": "machine learning", "target": "learning approach", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "adversarial machine learning", "depth": [0, 3]}, {"source": "machine learning", "target": "historical register book", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "neural network model", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "effective compressed multi-function", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "compressed multi-function convolutional", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "multi-function convolutional neural", "depth": [0, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [0, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [0, 1]}, {"source": "machine translation", "target": "translation", "depth": [0, 1]}, {"source": "machine translation", "target": "domain adaptation", "depth": [0, 1]}, {"source": "machine translation", "target": "machine translation robustnes", "depth": [0, 3]}, {"source": "graph", "target": "split graph", "depth": [1, 3]}, {"source": "graph", "target": "citation graph", "depth": [1, 3]}, {"source": "graph", "target": "representation", "depth": [1, 1]}, {"source": "graph", "target": "generalized petersen graph", "depth": [1, 3]}, {"source": "graph", "target": "domination in generalized", "depth": [1, 3]}, {"source": "deep", "target": "deep generative model", "depth": [1, 1]}, {"source": "deep", "target": "deep generative", "depth": [1, 1]}, {"source": "deep", "target": "generative model", "depth": [1, 1]}, {"source": "deep", "target": "classifying logistic vehicle", "depth": [1, 3]}, {"source": "deep", "target": "cities using deep", "depth": [1, 3]}, {"source": "detection", "target": "object detection", "depth": [1, 1]}, {"source": "detection", "target": "community detection", "depth": [1, 1]}, {"source": "detection", "target": "physical adversarial patch", "depth": [1, 3]}, {"source": "detection", "target": "physical adversarial", "depth": [1, 3]}, {"source": "detection", "target": "adversarial patch", "depth": [1, 3]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "deep reinforcement learning", "depth": [1, 1]}, {"source": "learning approach", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "algorithm", "target": "evolutionary algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "complex error function", "depth": [1, 3]}, {"source": "algorithm", "target": "real axi", "depth": [1, 3]}, {"source": "algorithm", "target": "remark on algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "loss of accuracy", "depth": [1, 3]}, {"source": "datum", "target": "limited datum", "depth": [1, 3]}, {"source": "datum", "target": "coloring with limited", "depth": [1, 3]}, {"source": "datum", "target": "few-shot colorization", "depth": [1, 3]}, {"source": "datum", "target": "memory-augmented network", "depth": [1, 3]}, {"source": "datum", "target": "colorization via memory-augmented", "depth": [1, 3]}, {"source": "analysi", "target": "sentiment analysi", "depth": [1, 1]}, {"source": "analysi", "target": "performance analysi", "depth": [1, 2]}, {"source": "analysi", "target": "performance", "depth": [1, 1]}, {"source": "analysi", "target": "adaptation and learning", "depth": [1, 3]}, {"source": "analysi", "target": "subspace constraint", "depth": [1, 3]}, {"source": "classification", "target": "text classification", "depth": [1, 2]}, {"source": "classification", "target": "image classification", "depth": [1, 1]}, {"source": "classification", "target": "classification via retrieval", "depth": [1, 3]}, {"source": "classification", "target": "clarel", "depth": [1, 3]}, {"source": "classification", "target": "zero-shot learning", "depth": [1, 2]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "embeddings for community", "depth": [1, 3]}, {"source": "embedding", "target": "simplicial complex", "depth": [1, 3]}, {"source": "embedding", "target": "community detection", "depth": [1, 1]}, {"source": "embedding", "target": "detection in simplicial", "depth": [1, 3]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "noisy speech", "depth": [1, 3]}, {"source": "recognition", "target": "noisy", "depth": [1, 2]}, {"source": "recognition", "target": "activity recognition", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 1]}, {"source": "generative model", "target": "deep generative", "depth": [1, 1]}, {"source": "generative model", "target": "disentanglement of appearance", "depth": [1, 3]}, {"source": "generative model", "target": "appearance and perspective", "depth": [1, 3]}, {"source": "generative model", "target": "perspective in generative", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "domain adaptation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "lexical shortcut", "depth": [1, 3]}, {"source": "neural machine translation", "target": "representation bottleneck", "depth": [1, 3]}, {"source": "neural machine translation", "target": "bottleneck in neural", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "global routing", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "approach for global", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "broadcast beam optimization", "depth": [1, 3]}, {"source": "generation", "target": "adversarial pixel-level generation", "depth": [1, 3]}, {"source": "generation", "target": "semantic image", "depth": [1, 3]}, {"source": "generation", "target": "generation of semantic", "depth": [1, 3]}, {"source": "generation", "target": "pixel-level generation", "depth": [1, 3]}, {"source": "generation", "target": "adversarial pixel-level", "depth": [1, 3]}, {"source": "optimization", "target": "policy optimization", "depth": [1, 2]}, {"source": "optimization", "target": "distributed optimization", "depth": [1, 3]}, {"source": "optimization", "target": "bayesian optimization", "depth": [1, 2]}, {"source": "optimization", "target": "over-parameterized learning", "depth": [1, 3]}, {"source": "optimization", "target": "optimization for over-parameterized", "depth": [1, 3]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "unsupervised deep visual", "depth": [1, 3]}, {"source": "adversarial network", "target": "deep visual odometry", "depth": [1, 3]}, {"source": "adversarial network", "target": "stacked generative adversarial", "depth": [1, 3]}, {"source": "image", "target": "dataset", "depth": [1, 1]}, {"source": "image", "target": "fisheye image", "depth": [1, 3]}, {"source": "image", "target": "face and object", "depth": [1, 3]}, {"source": "image", "target": "object detection", "depth": [1, 1]}, {"source": "image", "target": "detection in fisheye", "depth": [1, 3]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question", "depth": [1, 2]}, {"source": "question answering", "target": "natural language", "depth": [1, 1]}, {"source": "question answering", "target": "video question answering", "depth": [1, 3]}, {"source": "question answering", "target": "convolutional self-attention network", "depth": [1, 3]}, {"source": "representation", "target": "representation learning", "depth": [1, 1]}, {"source": "representation", "target": "meta-learning of textual", "depth": [1, 3]}, {"source": "representation", "target": "textual representation", "depth": [1, 3]}, {"source": "representation", "target": "meta-learning", "depth": [1, 2]}, {"source": "representation", "target": "connectivity-optimized representation learning", "depth": [1, 3]}, {"source": "code", "target": "information bottleneck decoding", "depth": [1, 3]}, {"source": "code", "target": "bottleneck decoding", "depth": [1, 3]}, {"source": "code", "target": "information bottleneck", "depth": [1, 2]}, {"source": "code", "target": "decoding of rate-compatible", "depth": [1, 3]}, {"source": "code", "target": "bottleneck", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "unsupervised deep visual", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "deep visual odometry", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "stacked generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "image enhancement algorithm", "depth": [1, 3]}, {"source": "image classification", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image", "depth": [1, 2]}, {"source": "image classification", "target": "cnn-based hyperspectral image", "depth": [1, 3]}, {"source": "image classification", "target": "optimizing cnn-based hyperspectral", "depth": [1, 3]}, {"source": "image classification", "target": "classification on fpga", "depth": [1, 3]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "supervised object detection", "depth": [1, 3]}, {"source": "object detection", "target": "weakly supervised object", "depth": [1, 3]}, {"source": "object detection", "target": "supervised object", "depth": [1, 3]}, {"source": "object detection", "target": "physical adversarial patch", "depth": [1, 3]}, {"source": "neural machine", "target": "domain adaptation", "depth": [1, 1]}, {"source": "neural machine", "target": "lexical shortcut", "depth": [1, 3]}, {"source": "neural machine", "target": "representation bottleneck", "depth": [1, 3]}, {"source": "neural machine", "target": "bottleneck in neural", "depth": [1, 3]}, {"source": "neural machine", "target": "translation with lexical", "depth": [1, 3]}, {"source": "game", "target": "patience game", "depth": [1, 3]}, {"source": "game", "target": "winnability of klondike", "depth": [1, 3]}, {"source": "game", "target": "klondike solitaire", "depth": [1, 3]}, {"source": "game", "target": "winnability", "depth": [1, 3]}, {"source": "game", "target": "klondike", "depth": [1, 3]}, {"source": "problem", "target": "higher-order generalized", "depth": [1, 3]}, {"source": "problem", "target": "methods for hyperbolic", "depth": [1, 3]}, {"source": "problem", "target": "hyperbolic problem", "depth": [1, 3]}, {"source": "problem", "target": "higher-order", "depth": [1, 3]}, {"source": "problem", "target": "generalized", "depth": [1, 2]}, {"source": "transfer learning", "target": "language processing task", "depth": [1, 3]}, {"source": "transfer learning", "target": "natural language processing", "depth": [1, 1]}, {"source": "transfer learning", "target": "supervised contextual embedding", "depth": [1, 3]}, {"source": "transfer learning", "target": "processing task", "depth": [1, 3]}, {"source": "transfer learning", "target": "contextual embedding", "depth": [1, 3]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 1]}, {"source": "natural language", "target": "language processing", "depth": [1, 2]}, {"source": "natural language", "target": "mitigating gender bia", "depth": [1, 3]}, {"source": "natural language", "target": "literature review", "depth": [1, 2]}, {"source": "natural language", "target": "gender bia", "depth": [1, 2]}, {"source": "representation learning", "target": "large-scale bipartite graph", "depth": [1, 3]}, {"source": "representation learning", "target": "efficient self-supervised representation", "depth": [1, 3]}, {"source": "representation learning", "target": "self-supervised representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "bipartite graph", "depth": [1, 3]}, {"source": "representation learning", "target": "self-supervised representation", "depth": [1, 2]}, {"source": "prediction", "target": "adversarial bit prediction", "depth": [1, 3]}, {"source": "prediction", "target": "bit prediction", "depth": [1, 3]}, {"source": "prediction", "target": "sampling for adversarial", "depth": [1, 3]}, {"source": "prediction", "target": "adversarial bit", "depth": [1, 3]}, {"source": "prediction", "target": "thompson sampling", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "black-box adversarial attack", "depth": [1, 2]}, {"source": "adversarial attack", "target": "cope with adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "learning to cope", "depth": [1, 3]}, {"source": "adversarial attack", "target": "cope", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "global routing", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "approach for global", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "broadcast beam optimization", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning meet", "depth": [1, 3]}, {"source": "estimation", "target": "pedestrian localization", "depth": [1, 3]}, {"source": "estimation", "target": "uncertainty estimation", "depth": [1, 3]}, {"source": "estimation", "target": "localization and uncertainty", "depth": [1, 3]}, {"source": "estimation", "target": "monocular", "depth": [1, 3]}, {"source": "estimation", "target": "monoloco", "depth": [1, 3]}, {"source": "modeling", "target": "social medium", "depth": [1, 1]}, {"source": "modeling", "target": "modeling of user's", "depth": [1, 3]}, {"source": "modeling", "target": "users' behavior", "depth": [1, 3]}, {"source": "modeling", "target": "behavior on social", "depth": [1, 3]}, {"source": "modeling", "target": "cross-platform modeling", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "image segmentation", "target": "neural architecture search", "depth": [1, 1]}, {"source": "image segmentation", "target": "neural architecture", "depth": [1, 1]}, {"source": "image segmentation", "target": "architecture search", "depth": [1, 1]}, {"source": "word embedding", "target": "bilingual word embedding", "depth": [1, 2]}, {"source": "word embedding", "target": "bilingual word", "depth": [1, 2]}, {"source": "word embedding", "target": "word", "depth": [1, 1]}, {"source": "word embedding", "target": "learning bilingual word", "depth": [1, 3]}, {"source": "word embedding", "target": "lexical definition", "depth": [1, 3]}, {"source": "robustnes", "target": "adversarial robustnes", "depth": [1, 2]}, {"source": "robustnes", "target": "attack", "depth": [1, 1]}, {"source": "robustnes", "target": "machine translation robustnes", "depth": [1, 3]}, {"source": "robustnes", "target": "translation robustnes", "depth": [1, 3]}, {"source": "robustnes", "target": "shared task", "depth": [1, 2]}, {"source": "inference", "target": "r\u00e9nyi fair inference", "depth": [1, 3]}, {"source": "inference", "target": "fair inference", "depth": [1, 3]}, {"source": "inference", "target": "r\u00e9nyi fair", "depth": [1, 3]}, {"source": "inference", "target": "fair", "depth": [1, 1]}, {"source": "inference", "target": "r\u00e9nyi", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "lidar surrounding view", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "real-time model", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "model for semantic", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "surrounding view", "depth": [1, 3]}, {"source": "method", "target": "minimizing star-convex function", "depth": [1, 3]}, {"source": "method", "target": "methods for minimizing", "depth": [1, 3]}, {"source": "method", "target": "minimizing star-convex", "depth": [1, 3]}, {"source": "method", "target": "star-convex function", "depth": [1, 3]}, {"source": "method", "target": "minimizing", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "deep convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "robustness and robust", "depth": [1, 3]}, {"source": "function", "target": "evaluation of abramowitz", "depth": [1, 3]}, {"source": "function", "target": "abramowitz function", "depth": [1, 3]}, {"source": "function", "target": "complex plane", "depth": [1, 3]}, {"source": "function", "target": "abramowitz", "depth": [1, 3]}, {"source": "function", "target": "evaluation", "depth": [1, 1]}, {"source": "reinforcement", "target": "two-stream reward", "depth": [1, 3]}, {"source": "reinforcement", "target": "split q learning", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning with two-stream", "depth": [1, 3]}, {"source": "reinforcement", "target": "reward", "depth": [1, 2]}, {"source": "reinforcement", "target": "risk-sensitive reinforcement learning", "depth": [1, 3]}, {"source": "training", "target": "adversarial training", "depth": [1, 1]}, {"source": "training", "target": "neural network training", "depth": [1, 2]}, {"source": "training", "target": "network training", "depth": [1, 2]}, {"source": "training", "target": "worrisome impact", "depth": [1, 3]}, {"source": "training", "target": "inter-rater bia", "depth": [1, 3]}, {"source": "video", "target": "video parsing accessible", "depth": [1, 3]}, {"source": "video", "target": "video parsing", "depth": [1, 3]}, {"source": "video", "target": "cnns for video", "depth": [1, 3]}, {"source": "video", "target": "making cnn", "depth": [1, 3]}, {"source": "video", "target": "unsupervised video interpolation", "depth": [1, 3]}, {"source": "dataset", "target": "synthetic dataset", "depth": [1, 3]}, {"source": "dataset", "target": "dataset for deep", "depth": [1, 3]}, {"source": "dataset", "target": "challenge", "depth": [1, 1]}, {"source": "dataset", "target": "dataset and baseline", "depth": [1, 3]}, {"source": "dataset", "target": "baseline", "depth": [1, 3]}, {"source": "attack", "target": "infty", "depth": [1, 2]}, {"source": "attack", "target": "cope with adversarial", "depth": [1, 3]}, {"source": "attack", "target": "learning to cope", "depth": [1, 3]}, {"source": "attack", "target": "cope", "depth": [1, 3]}, {"source": "attack", "target": "attack on neural", "depth": [1, 3]}, {"source": "performance", "target": "performance analysi", "depth": [1, 2]}, {"source": "performance", "target": "study", "depth": [1, 1]}, {"source": "performance", "target": "pinpointing performance inefficiency", "depth": [1, 3]}, {"source": "performance", "target": "inefficiencies in java", "depth": [1, 3]}, {"source": "performance", "target": "performance inefficiency", "depth": [1, 3]}, {"source": "object", "target": "transforming object", "depth": [1, 3]}, {"source": "object", "target": "objects into word", "depth": [1, 3]}, {"source": "object", "target": "image captioning", "depth": [1, 1]}, {"source": "object", "target": "captioning", "depth": [1, 2]}, {"source": "object", "target": "transforming", "depth": [1, 3]}, {"source": "language", "target": "combinatorial generation", "depth": [1, 3]}, {"source": "language", "target": "permutation language", "depth": [1, 3]}, {"source": "language", "target": "generation via permutation", "depth": [1, 3]}, {"source": "language", "target": "combinatorial", "depth": [1, 3]}, {"source": "language", "target": "armenian language", "depth": [1, 3]}, {"source": "approach", "target": "function learning", "depth": [1, 3]}, {"source": "approach", "target": "approach to model", "depth": [1, 3]}, {"source": "approach", "target": "model exploration", "depth": [1, 3]}, {"source": "approach", "target": "exploration", "depth": [1, 1]}, {"source": "approach", "target": "java generic", "depth": [1, 3]}, {"source": "wireless sensor network", "target": "sensor network", "depth": [1, 1]}, {"source": "wireless sensor network", "target": "wireless sensor", "depth": [1, 2]}, {"source": "wireless sensor network", "target": "autonomous wireless sensor", "depth": [1, 3]}, {"source": "wireless sensor network", "target": "large-scale autonomous wireles", "depth": [1, 3]}, {"source": "wireless sensor network", "target": "autonomous wireles", "depth": [1, 3]}, {"source": "machine", "target": "humans and machine", "depth": [1, 3]}, {"source": "machine", "target": "notion of number", "depth": [1, 3]}, {"source": "machine", "target": "number in human", "depth": [1, 3]}, {"source": "machine", "target": "notion", "depth": [1, 3]}, {"source": "machine", "target": "number", "depth": [1, 2]}, {"source": "point cloud", "target": "point cloud generation", "depth": [1, 3]}, {"source": "point cloud", "target": "continuous normalizing flow", "depth": [1, 3]}, {"source": "point cloud", "target": "normalizing flow", "depth": [1, 2]}, {"source": "point cloud", "target": "cloud generation", "depth": [1, 3]}, {"source": "point cloud", "target": "generation with continuou", "depth": [1, 3]}, {"source": "anomaly detection", "target": "joint representation learning", "depth": [1, 3]}, {"source": "anomaly detection", "target": "content and connection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "detection with joint", "depth": [1, 3]}, {"source": "anomaly detection", "target": "joint representation", "depth": [1, 3]}, {"source": "anomaly detection", "target": "learning of content", "depth": [1, 3]}, {"source": "segmentation", "target": "point", "depth": [1, 2]}, {"source": "segmentation", "target": "instance", "depth": [1, 2]}, {"source": "segmentation", "target": "wireless trajectory datum", "depth": [1, 3]}, {"source": "segmentation", "target": "trajectory datum", "depth": [1, 3]}, {"source": "segmentation", "target": "segmentation of wireles", "depth": [1, 3]}, {"source": "generative adversarial", "target": "video-driven speech reconstruction", "depth": [1, 3]}, {"source": "generative adversarial", "target": "speech reconstruction", "depth": [1, 3]}, {"source": "generative adversarial", "target": "reconstruction using generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "video-driven speech", "depth": [1, 3]}, {"source": "generative adversarial", "target": "graph generative adversarial", "depth": [1, 3]}, {"source": "feature", "target": "deep feature", "depth": [1, 2]}, {"source": "feature", "target": "emotions from walking", "depth": [1, 3]}, {"source": "feature", "target": "walking using affective", "depth": [1, 3]}, {"source": "feature", "target": "affective and deep", "depth": [1, 3]}, {"source": "feature", "target": "identifying emotion", "depth": [1, 3]}, {"source": "policy", "target": "quantile regression", "depth": [1, 3]}, {"source": "policy", "target": "policies through quantile", "depth": [1, 3]}, {"source": "policy", "target": "learning policy", "depth": [1, 2]}, {"source": "policy", "target": "regression", "depth": [1, 1]}, {"source": "policy", "target": "quantile", "depth": [1, 3]}, {"source": "extended version", "target": "extended", "depth": [1, 2]}, {"source": "extended version", "target": "version", "depth": [1, 2]}, {"source": "extended version", "target": "markov decision process", "depth": [1, 2]}, {"source": "extended version", "target": "based learning", "depth": [1, 3]}, {"source": "extended version", "target": "decision process", "depth": [1, 2]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "social media datum", "depth": [1, 2]}, {"source": "social medium", "target": "user portrait", "depth": [1, 3]}, {"source": "social medium", "target": "portrait through social", "depth": [1, 3]}, {"source": "social medium", "target": "modeling of user", "depth": [1, 3]}, {"source": "study", "target": "empirical study", "depth": [1, 2]}, {"source": "study", "target": "professional post-editor", "depth": [1, 3]}, {"source": "study", "target": "user study", "depth": [1, 3]}, {"source": "study", "target": "adaptation of nmt", "depth": [1, 3]}, {"source": "study", "target": "nmt for professional", "depth": [1, 3]}, {"source": "word", "target": "transforming object", "depth": [1, 3]}, {"source": "word", "target": "objects into word", "depth": [1, 3]}, {"source": "word", "target": "image captioning", "depth": [1, 1]}, {"source": "word", "target": "captioning", "depth": [1, 2]}, {"source": "word", "target": "transforming", "depth": [1, 3]}, {"source": "exploration", "target": "generalized linear bandit", "depth": [1, 3]}, {"source": "exploration", "target": "linear bandit", "depth": [1, 2]}, {"source": "exploration", "target": "exploration in generalized", "depth": [1, 3]}, {"source": "exploration", "target": "generalized linear", "depth": [1, 3]}, {"source": "exploration", "target": "randomized exploration", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "adversarial domain adaptation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "generative framework", "depth": [1, 3]}, {"source": "domain adaptation", "target": "learning with adversarial", "depth": [1, 3]}, {"source": "adversarial training", "target": "hurt generalization", "depth": [1, 3]}, {"source": "adversarial training", "target": "training can hurt", "depth": [1, 3]}, {"source": "adversarial training", "target": "generalization", "depth": [1, 1]}, {"source": "adversarial training", "target": "hurt", "depth": [1, 3]}, {"source": "adversarial training", "target": "descent based adversarial", "depth": [1, 3]}, {"source": "translation", "target": "loss and decay", "depth": [1, 3]}, {"source": "translation", "target": "decay of linguistic", "depth": [1, 3]}, {"source": "translation", "target": "linguistic richnes", "depth": [1, 3]}, {"source": "translation", "target": "richness in machine", "depth": [1, 3]}, {"source": "translation", "target": "lost in translation", "depth": [1, 3]}, {"source": "maximization", "target": "edge addition", "depth": [1, 3]}, {"source": "maximization", "target": "maximization through edge", "depth": [1, 3]}, {"source": "maximization", "target": "k-core maximization", "depth": [1, 3]}, {"source": "maximization", "target": "addition", "depth": [1, 3]}, {"source": "maximization", "target": "edge", "depth": [1, 1]}, {"source": "finite element", "target": "finite element method", "depth": [1, 1]}, {"source": "finite element", "target": "element", "depth": [1, 3]}, {"source": "finite element", "target": "element method", "depth": [1, 1]}, {"source": "finite element", "target": "trefftz finite element", "depth": [1, 3]}, {"source": "finite element", "target": "curvilinear polygon", "depth": [1, 3]}, {"source": "challenge", "target": "action recognition challenge", "depth": [1, 3]}, {"source": "challenge", "target": "recognition challenge", "depth": [1, 3]}, {"source": "challenge", "target": "fbk-hupba submission", "depth": [1, 3]}, {"source": "challenge", "target": "action", "depth": [1, 2]}, {"source": "challenge", "target": "submission", "depth": [1, 3]}, {"source": "neural architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "neural architecture", "target": "scalable neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "medical image", "depth": [1, 1]}, {"source": "search", "target": "entropic risk measure", "depth": [1, 3]}, {"source": "search", "target": "policy search", "depth": [1, 3]}, {"source": "search", "target": "risk measure", "depth": [1, 3]}, {"source": "search", "target": "measure in policy", "depth": [1, 3]}, {"source": "search", "target": "entropic risk", "depth": [1, 3]}, {"source": "action recognition", "target": "action recognition challenge", "depth": [1, 3]}, {"source": "action recognition", "target": "recognition challenge", "depth": [1, 3]}, {"source": "action recognition", "target": "fbk-hupba submission", "depth": [1, 3]}, {"source": "action recognition", "target": "action", "depth": [1, 2]}, {"source": "action recognition", "target": "submission", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "solved", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "probing sentiment classification", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "sentiment classification", "depth": [1, 2]}, {"source": "sentiment analysi", "target": "sentiment", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "assessing and probing", "depth": [1, 3]}, {"source": "classifier", "target": "robust", "depth": [1, 1]}, {"source": "classifier", "target": "bias in classifier", "depth": [1, 3]}, {"source": "classifier", "target": "classifiers using generative", "depth": [1, 3]}, {"source": "classifier", "target": "characterizing bia", "depth": [1, 3]}, {"source": "classifier", "target": "bia", "depth": [1, 1]}, {"source": "evaluation", "target": "evaluation of abramowitz", "depth": [1, 3]}, {"source": "evaluation", "target": "abramowitz function", "depth": [1, 3]}, {"source": "evaluation", "target": "complex plane", "depth": [1, 3]}, {"source": "evaluation", "target": "abramowitz", "depth": [1, 3]}, {"source": "evaluation", "target": "plane", "depth": [1, 3]}, {"source": "testing", "target": "angle regression path", "depth": [1, 3]}, {"source": "testing", "target": "testing and variable", "depth": [1, 3]}, {"source": "testing", "target": "variable selection", "depth": [1, 3]}, {"source": "testing", "target": "angle regression", "depth": [1, 3]}, {"source": "testing", "target": "multiple testing", "depth": [1, 3]}, {"source": "graph neural network", "target": "feature-wise linear modulation", "depth": [1, 3]}, {"source": "graph neural network", "target": "linear modulation", "depth": [1, 3]}, {"source": "graph neural network", "target": "networks with feature-wise", "depth": [1, 3]}, {"source": "graph neural network", "target": "coupled graph neural", "depth": [1, 3]}, {"source": "graph neural network", "target": "prediction on social", "depth": [1, 3]}, {"source": "active learning", "target": "reject option classifier", "depth": [1, 3]}, {"source": "active learning", "target": "online active learning", "depth": [1, 3]}, {"source": "active learning", "target": "option classifier", "depth": [1, 3]}, {"source": "active learning", "target": "learning of reject", "depth": [1, 3]}, {"source": "active learning", "target": "reject option", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "noisy speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "noisy", "depth": [1, 2]}, {"source": "speech recognition", "target": "advancing speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "advancing speech", "depth": [1, 3]}, {"source": "bandit", "target": "linear bandit", "depth": [1, 2]}, {"source": "bandit", "target": "generalized linear bandit", "depth": [1, 3]}, {"source": "bandit", "target": "exploration in generalized", "depth": [1, 3]}, {"source": "bandit", "target": "generalized linear", "depth": [1, 3]}, {"source": "bandit", "target": "randomized exploration", "depth": [1, 3]}, {"source": "neural architecture search", "target": "architecture search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "neural architecture search", "target": "scalable neural architecture", "depth": [1, 3]}, {"source": "neural architecture search", "target": "medical image", "depth": [1, 1]}, {"source": "neural architecture search", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "variational inference", "target": "stochastic multi-domain learning", "depth": [1, 3]}, {"source": "variational inference", "target": "semi-supervised stochastic multi-domain", "depth": [1, 3]}, {"source": "variational inference", "target": "learning using variational", "depth": [1, 3]}, {"source": "variational inference", "target": "stochastic multi-domain", "depth": [1, 3]}, {"source": "variational inference", "target": "multi-domain learning", "depth": [1, 3]}, {"source": "protocol", "target": "consensus protocol", "depth": [1, 2]}, {"source": "protocol", "target": "rate control protocol", "depth": [1, 2]}, {"source": "protocol", "target": "control protocol", "depth": [1, 2]}, {"source": "protocol", "target": "rate control", "depth": [1, 2]}, {"source": "protocol", "target": "rcp", "depth": [1, 2]}, {"source": "gradient descent", "target": "secret gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "privacy-preserving distributed learning", "depth": [1, 3]}, {"source": "gradient descent", "target": "distributed learning", "depth": [1, 2]}, {"source": "gradient descent", "target": "learning with secret", "depth": [1, 3]}, {"source": "gradient descent", "target": "secret gradient", "depth": [1, 3]}, {"source": "sensor network", "target": "wireless sensor", "depth": [1, 2]}, {"source": "sensor network", "target": "autonomous wireless sensor", "depth": [1, 3]}, {"source": "sensor network", "target": "large-scale autonomous wireles", "depth": [1, 3]}, {"source": "sensor network", "target": "autonomous wireles", "depth": [1, 3]}, {"source": "sensor network", "target": "large-scale autonomou", "depth": [1, 3]}, {"source": "clustering", "target": "atomic fission", "depth": [1, 3]}, {"source": "clustering", "target": "fission", "depth": [1, 3]}, {"source": "clustering", "target": "deep generative model", "depth": [1, 1]}, {"source": "clustering", "target": "models with clustering", "depth": [1, 3]}, {"source": "clustering", "target": "learning for deep", "depth": [1, 3]}, {"source": "survey", "target": "graph datum", "depth": [1, 3]}, {"source": "survey", "target": "representations of graph", "depth": [1, 3]}, {"source": "survey", "target": "learning representation", "depth": [1, 3]}, {"source": "survey", "target": "blockchain", "depth": [1, 1]}, {"source": "survey", "target": "backhaul network", "depth": [1, 3]}, {"source": "information", "target": "informative image captioning", "depth": [1, 3]}, {"source": "information", "target": "sources of information", "depth": [1, 3]}, {"source": "information", "target": "image captioning", "depth": [1, 1]}, {"source": "information", "target": "captioning with external", "depth": [1, 3]}, {"source": "information", "target": "external source", "depth": [1, 3]}, {"source": "monte carlo", "target": "multilevel monte carlo", "depth": [1, 3]}, {"source": "monte carlo", "target": "monte carlo finite", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo finite volume", "depth": [1, 3]}, {"source": "monte carlo", "target": "finite volume method", "depth": [1, 3]}, {"source": "monte carlo", "target": "random conservation law", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "medical image", "target": "scalable neural architecture", "depth": [1, 3]}, {"source": "medical image", "target": "multi-scale self-guided attention", "depth": [1, 3]}, {"source": "medical image", "target": "self-guided attention", "depth": [1, 3]}, {"source": "medical image", "target": "attention for medical", "depth": [1, 3]}, {"source": "architecture search", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "architecture search", "target": "scalable neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "architecture search", "target": "search for volumetric", "depth": [1, 3]}, {"source": "architecture search", "target": "one-shot neural architecture", "depth": [1, 3]}, {"source": "reasoning", "target": "captioning", "depth": [1, 2]}, {"source": "reasoning", "target": "captioning with reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "figure captioning", "depth": [1, 3]}, {"source": "reasoning", "target": "sequence-level training", "depth": [1, 3]}, {"source": "reasoning", "target": "reasoning and sequence-level", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "non-negative matrix factorisation", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "probabilistic non-negative matrix", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "matrix factorisation", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder for probabilistic", "depth": [1, 3]}, {"source": "time series", "target": "time series merge", "depth": [1, 3]}, {"source": "time series", "target": "series merge tree", "depth": [1, 3]}, {"source": "time series", "target": "horizon visibility graph", "depth": [1, 3]}, {"source": "time series", "target": "trees are dual", "depth": [1, 3]}, {"source": "time series", "target": "visibility graph", "depth": [1, 3]}, {"source": "control", "target": "perception and control", "depth": [1, 3]}, {"source": "control", "target": "learning of object", "depth": [1, 3]}, {"source": "control", "target": "object keypoint", "depth": [1, 3]}, {"source": "control", "target": "keypoints for perception", "depth": [1, 3]}, {"source": "control", "target": "unsupervised learning", "depth": [1, 1]}, {"source": "regression", "target": "quantile regression", "depth": [1, 3]}, {"source": "regression", "target": "policies through quantile", "depth": [1, 3]}, {"source": "regression", "target": "learning policy", "depth": [1, 2]}, {"source": "regression", "target": "quantile", "depth": [1, 3]}, {"source": "regression", "target": "near-optimal statistical estimation", "depth": [1, 3]}, {"source": "data analysi", "target": "topological data analysi", "depth": [1, 2]}, {"source": "data analysi", "target": "big data analysi", "depth": [1, 3]}, {"source": "data analysi", "target": "multivariate big datum", "depth": [1, 3]}, {"source": "data analysi", "target": "intrusion detection", "depth": [1, 2]}, {"source": "data analysi", "target": "big datum", "depth": [1, 2]}, {"source": "case study", "target": "multiple case study", "depth": [1, 3]}, {"source": "case study", "target": "industrial multiple case", "depth": [1, 3]}, {"source": "case study", "target": "initial result", "depth": [1, 3]}, {"source": "case study", "target": "industrial multiple", "depth": [1, 3]}, {"source": "case study", "target": "multiple case", "depth": [1, 3]}, {"source": "process", "target": "neural process", "depth": [1, 3]}, {"source": "process", "target": "network generative process", "depth": [1, 3]}, {"source": "process", "target": "generative process", "depth": [1, 3]}, {"source": "process", "target": "discovery of family", "depth": [1, 3]}, {"source": "process", "target": "families of network", "depth": [1, 3]}, {"source": "blockchain", "target": "blockchain mining", "depth": [1, 3]}, {"source": "blockchain", "target": "speeding up blockchain", "depth": [1, 3]}, {"source": "blockchain", "target": "for-loop for speeding", "depth": [1, 3]}, {"source": "blockchain", "target": "mining", "depth": [1, 2]}, {"source": "blockchain", "target": "speeding", "depth": [1, 3]}, {"source": "optimal transport", "target": "transport", "depth": [1, 1]}, {"source": "optimal transport", "target": "fairness testing", "depth": [1, 3]}, {"source": "optimal transport", "target": "testing via optimal", "depth": [1, 3]}, {"source": "optimal transport", "target": "fliptest", "depth": [1, 3]}, {"source": "optimal transport", "target": "fairnes", "depth": [1, 2]}, {"source": "distributed", "target": "distributed optimization", "depth": [1, 3]}, {"source": "distributed", "target": "over-parameterized learning", "depth": [1, 3]}, {"source": "distributed", "target": "optimization for over-parameterized", "depth": [1, 3]}, {"source": "distributed", "target": "random feature", "depth": [1, 3]}, {"source": "distributed", "target": "learning with random", "depth": [1, 3]}, {"source": "communication", "target": "healthcare network", "depth": [1, 3]}, {"source": "communication", "target": "backscatter communication", "depth": [1, 3]}, {"source": "communication", "target": "communications for healthcare", "depth": [1, 3]}, {"source": "communication", "target": "applications of backscatter", "depth": [1, 3]}, {"source": "communication", "target": "backscatter", "depth": [1, 3]}, {"source": "policy gradient", "target": "discrete action space", "depth": [1, 3]}, {"source": "policy gradient", "target": "direct policy gradient", "depth": [1, 3]}, {"source": "policy gradient", "target": "action space", "depth": [1, 1]}, {"source": "policy gradient", "target": "optimization of policy", "depth": [1, 3]}, {"source": "policy gradient", "target": "policies in discrete", "depth": [1, 3]}, {"source": "language model", "target": "neural language model", "depth": [1, 2]}, {"source": "language model", "target": "neural language", "depth": [1, 2]}, {"source": "language model", "target": "pre-trained language model", "depth": [1, 3]}, {"source": "language model", "target": "transformer language model", "depth": [1, 3]}, {"source": "language model", "target": "transformer language", "depth": [1, 3]}, {"source": "review", "target": "robotic supervised autonomy", "depth": [1, 3]}, {"source": "review", "target": "supervised autonomy", "depth": [1, 3]}, {"source": "review", "target": "robotic supervised", "depth": [1, 3]}, {"source": "review", "target": "autonomy", "depth": [1, 3]}, {"source": "review", "target": "supervised", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "robustness and robust", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "robust training", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "training for graph", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "certifiable robustnes", "depth": [1, 3]}, {"source": "sampling", "target": "adversarial bit prediction", "depth": [1, 3]}, {"source": "sampling", "target": "bit prediction", "depth": [1, 3]}, {"source": "sampling", "target": "sampling for adversarial", "depth": [1, 3]}, {"source": "sampling", "target": "adversarial bit", "depth": [1, 3]}, {"source": "sampling", "target": "thompson sampling", "depth": [1, 3]}, {"source": "autonomous driving", "target": "driving", "depth": [1, 2]}, {"source": "autonomous driving", "target": "autonomou", "depth": [1, 2]}, {"source": "autonomous driving", "target": "accurate depth", "depth": [1, 3]}, {"source": "autonomous driving", "target": "detection in autonomou", "depth": [1, 3]}, {"source": "autonomous driving", "target": "pseudo-lidar", "depth": [1, 3]}, {"source": "generalization", "target": "hurt generalization", "depth": [1, 3]}, {"source": "generalization", "target": "training can hurt", "depth": [1, 3]}, {"source": "generalization", "target": "hurt", "depth": [1, 3]}, {"source": "generalization", "target": "complex belief function", "depth": [1, 3]}, {"source": "generalization", "target": "generalization of dempster-shafer", "depth": [1, 3]}, {"source": "speech", "target": "noisy speech", "depth": [1, 3]}, {"source": "speech", "target": "noisy", "depth": [1, 2]}, {"source": "speech", "target": "advancing speech recognition", "depth": [1, 3]}, {"source": "speech", "target": "advancing speech", "depth": [1, 3]}, {"source": "speech", "target": "speech translation", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "scalable neural architecture", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "search for volumetric", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "multi-scale self-guided attention", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "self-guided attention", "depth": [1, 3]}, {"source": "environment", "target": "unknown cluttered environment", "depth": [1, 3]}, {"source": "environment", "target": "cluttered environment", "depth": [1, 3]}, {"source": "environment", "target": "autonomous navigation", "depth": [1, 3]}, {"source": "environment", "target": "navigation of mav", "depth": [1, 3]}, {"source": "environment", "target": "mavs in unknown", "depth": [1, 3]}, {"source": "bia", "target": "bias in classifier", "depth": [1, 3]}, {"source": "bia", "target": "classifiers using generative", "depth": [1, 3]}, {"source": "bia", "target": "characterizing bia", "depth": [1, 3]}, {"source": "bia", "target": "fighting quantization bia", "depth": [1, 3]}, {"source": "bia", "target": "fighting quantization", "depth": [1, 3]}, {"source": "machine learning approach", "target": "historical register book", "depth": [1, 3]}, {"source": "machine learning approach", "target": "comparing machine learning", "depth": [1, 3]}, {"source": "machine learning approach", "target": "register book", "depth": [1, 3]}, {"source": "machine learning approach", "target": "approaches for table", "depth": [1, 3]}, {"source": "machine learning approach", "target": "crowdsourced live streaming", "depth": [1, 3]}, {"source": "coding", "target": "predictive coding", "depth": [1, 3]}, {"source": "coding", "target": "critical review", "depth": [1, 3]}, {"source": "coding", "target": "prednet and predictive", "depth": [1, 3]}, {"source": "coding", "target": "predictive", "depth": [1, 3]}, {"source": "coding", "target": "arbitrary varying channel", "depth": [1, 3]}, {"source": "program", "target": "neural-based program decompiler", "depth": [1, 3]}, {"source": "program", "target": "program decompiler", "depth": [1, 3]}, {"source": "program", "target": "decompiler", "depth": [1, 3]}, {"source": "program", "target": "faceted dataflow program", "depth": [1, 3]}, {"source": "program", "target": "dataflow program", "depth": [1, 3]}, {"source": "time", "target": "feedback vertex set", "depth": [1, 3]}, {"source": "time", "target": "detecting feedback vertex", "depth": [1, 3]}, {"source": "time", "target": "sets of size", "depth": [1, 3]}, {"source": "time", "target": "feedback vertex", "depth": [1, 3]}, {"source": "time", "target": "vertex set", "depth": [1, 3]}, {"source": "social network", "target": "modeling echo chamber", "depth": [1, 3]}, {"source": "social network", "target": "modeling echo", "depth": [1, 3]}, {"source": "social network", "target": "echo chamber", "depth": [1, 2]}, {"source": "social network", "target": "chambers and polarization", "depth": [1, 3]}, {"source": "social network", "target": "polarization dynamic", "depth": [1, 3]}, {"source": "robust", "target": "multiple classifier", "depth": [1, 3]}, {"source": "robust", "target": "attacks against multiple", "depth": [1, 3]}, {"source": "robust", "target": "robust attack", "depth": [1, 3]}, {"source": "robust", "target": "multiple", "depth": [1, 2]}, {"source": "robust", "target": "linear attitude estimator", "depth": [1, 3]}, {"source": "text", "target": "deep generative model", "depth": [1, 1]}, {"source": "text", "target": "deep generative", "depth": [1, 1]}, {"source": "text", "target": "code-switched text", "depth": [1, 3]}, {"source": "text", "target": "model for code-switched", "depth": [1, 3]}, {"source": "text", "target": "text spotting", "depth": [1, 3]}, {"source": "structure", "target": "related work", "depth": [1, 3]}, {"source": "structure", "target": "structure your related", "depth": [1, 3]}, {"source": "structure", "target": "work", "depth": [1, 3]}, {"source": "structure", "target": "structure learning", "depth": [1, 3]}, {"source": "structure", "target": "covariance query", "depth": [1, 3]}, {"source": "dynamical system", "target": "surrogate-based parameter estimation", "depth": [1, 3]}, {"source": "dynamical system", "target": "parameter estimation", "depth": [1, 2]}, {"source": "dynamical system", "target": "estimation in dynamical", "depth": [1, 3]}, {"source": "dynamical system", "target": "meta-model framework", "depth": [1, 3]}, {"source": "dynamical system", "target": "framework for surrogate-based", "depth": [1, 3]}, {"source": "vision", "target": "computer vision", "depth": [1, 1]}, {"source": "vision", "target": "fourier perspective", "depth": [1, 3]}, {"source": "vision", "target": "perspective on model", "depth": [1, 3]}, {"source": "vision", "target": "model robustnes", "depth": [1, 2]}, {"source": "vision", "target": "robustness in computer", "depth": [1, 3]}, {"source": "community detection", "target": "community", "depth": [1, 2]}, {"source": "community detection", "target": "embeddings for community", "depth": [1, 3]}, {"source": "community detection", "target": "simplicial complex", "depth": [1, 3]}, {"source": "community detection", "target": "detection in simplicial", "depth": [1, 3]}, {"source": "community detection", "target": "hyperbolic space", "depth": [1, 3]}, {"source": "adaptation", "target": "hierarchical reinforcement learning", "depth": [1, 3]}, {"source": "adaptation", "target": "adaptation for hierarchical", "depth": [1, 3]}, {"source": "adaptation", "target": "hierarchical reinforcement", "depth": [1, 3]}, {"source": "adaptation", "target": "sub-policy adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "blstm acoustic model", "depth": [1, 3]}, {"source": "data augmentation", "target": "preliminary study", "depth": [1, 3]}, {"source": "data augmentation", "target": "study on datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation of deep", "depth": [1, 3]}, {"source": "data augmentation", "target": "learning for image", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 3]}, {"source": "fair", "target": "r\u00e9nyi fair inference", "depth": [1, 3]}, {"source": "fair", "target": "fair inference", "depth": [1, 3]}, {"source": "fair", "target": "r\u00e9nyi fair", "depth": [1, 3]}, {"source": "fair", "target": "r\u00e9nyi", "depth": [1, 3]}, {"source": "fair", "target": "disparate impact", "depth": [1, 3]}, {"source": "natural language processing", "target": "language processing", "depth": [1, 2]}, {"source": "natural language processing", "target": "language processing task", "depth": [1, 3]}, {"source": "natural language processing", "target": "supervised contextual embedding", "depth": [1, 3]}, {"source": "natural language processing", "target": "processing task", "depth": [1, 3]}, {"source": "natural language processing", "target": "contextual embedding", "depth": [1, 3]}, {"source": "agent", "target": "agents allowed", "depth": [1, 3]}, {"source": "agent", "target": "cooperate or defect", "depth": [1, 3]}, {"source": "agent", "target": "allowed to cooperate", "depth": [1, 3]}, {"source": "agent", "target": "no-boarding", "depth": [1, 3]}, {"source": "agent", "target": "bus", "depth": [1, 3]}, {"source": "image captioning", "target": "captioning", "depth": [1, 2]}, {"source": "image captioning", "target": "deep decoder structure", "depth": [1, 3]}, {"source": "image captioning", "target": "decoder structure based", "depth": [1, 3]}, {"source": "image captioning", "target": "encoder-decoder based model", "depth": [1, 3]}, {"source": "image captioning", "target": "deep decoder", "depth": [1, 3]}, {"source": "action space", "target": "growing action space", "depth": [1, 3]}, {"source": "action space", "target": "growing action", "depth": [1, 3]}, {"source": "action space", "target": "space", "depth": [1, 1]}, {"source": "action space", "target": "action", "depth": [1, 2]}, {"source": "action space", "target": "growing", "depth": [1, 3]}, {"source": "graph convolutional", "target": "robustness and robust", "depth": [1, 3]}, {"source": "graph convolutional", "target": "robust training", "depth": [1, 3]}, {"source": "graph convolutional", "target": "training for graph", "depth": [1, 3]}, {"source": "graph convolutional", "target": "certifiable robustnes", "depth": [1, 3]}, {"source": "graph convolutional", "target": "guided graph convolutional", "depth": [1, 3]}, {"source": "edge", "target": "edge addition", "depth": [1, 3]}, {"source": "edge", "target": "maximization through edge", "depth": [1, 3]}, {"source": "edge", "target": "k-core maximization", "depth": [1, 3]}, {"source": "edge", "target": "addition", "depth": [1, 3]}, {"source": "edge", "target": "k-core", "depth": [1, 3]}, {"source": "deep generative model", "target": "deep generative", "depth": [1, 1]}, {"source": "deep generative model", "target": "code-switched text", "depth": [1, 3]}, {"source": "deep generative model", "target": "model for code-switched", "depth": [1, 3]}, {"source": "deep generative model", "target": "inputs to deep", "depth": [1, 3]}, {"source": "deep generative model", "target": "models using typicality", "depth": [1, 3]}, {"source": "element method", "target": "finite element method", "depth": [1, 1]}, {"source": "element method", "target": "partitioned finite element", "depth": [1, 3]}, {"source": "element method", "target": "partitioned finite", "depth": [1, 3]}, {"source": "element method", "target": "method for power-preserving", "depth": [1, 3]}, {"source": "element method", "target": "conservation law", "depth": [1, 2]}, {"source": "channel", "target": "timing side channel", "depth": [1, 3]}, {"source": "channel", "target": "side channel", "depth": [1, 3]}, {"source": "channel", "target": "mitigation of timing", "depth": [1, 3]}, {"source": "channel", "target": "timing side", "depth": [1, 3]}, {"source": "channel", "target": "quantitative mitigation", "depth": [1, 3]}, {"source": "deep learning based", "target": "landmark-dependent multi-scale patch", "depth": [1, 3]}, {"source": "deep learning based", "target": "cephalometric landmark identification", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based cephalometric", "depth": [1, 3]}, {"source": "deep learning based", "target": "based cephalometric landmark", "depth": [1, 3]}, {"source": "deep learning based", "target": "multi-scale patch", "depth": [1, 3]}, {"source": "multiple acces", "target": "non-orthogonal multiple acces", "depth": [1, 2]}, {"source": "multiple acces", "target": "vehicular network", "depth": [1, 2]}, {"source": "multiple acces", "target": "cache-aided non-orthogonal multiple", "depth": [1, 3]}, {"source": "multiple acces", "target": "vehicular", "depth": [1, 3]}, {"source": "multiple acces", "target": "code multiple acces", "depth": [1, 3]}, {"source": "deep learning approach", "target": "power flow", "depth": [1, 3]}, {"source": "deep learning approach", "target": "calculation of probabilistic", "depth": [1, 3]}, {"source": "deep learning approach", "target": "probabilistic power flow", "depth": [1, 3]}, {"source": "deep learning approach", "target": "model-based deep learning", "depth": [1, 3]}, {"source": "deep learning approach", "target": "probabilistic power", "depth": [1, 3]}, {"source": "relation extraction", "target": "relation extraction dataset", "depth": [1, 3]}, {"source": "relation extraction", "target": "document-level relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "extraction dataset", "depth": [1, 3]}, {"source": "relation extraction", "target": "large-scale document-level relation", "depth": [1, 3]}, {"source": "relation extraction", "target": "docred", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph construction", "depth": [1, 3]}, {"source": "knowledge graph", "target": "graph construction", "depth": [1, 3]}, {"source": "knowledge graph", "target": "scalable knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "construction from twitter", "depth": [1, 3]}, {"source": "knowledge graph", "target": "scalable knowledge", "depth": [1, 3]}, {"source": "planning", "target": "cyber defence exercise", "depth": [1, 3]}, {"source": "planning", "target": "defence exercise", "depth": [1, 3]}, {"source": "planning", "target": "concept of cyber", "depth": [1, 3]}, {"source": "planning", "target": "cyber defence", "depth": [1, 3]}, {"source": "planning", "target": "cdx", "depth": [1, 3]}, {"source": "solution", "target": "google landmark recognition", "depth": [1, 3]}, {"source": "solution", "target": "landmark recognition", "depth": [1, 3]}, {"source": "solution", "target": "solution to google", "depth": [1, 3]}, {"source": "solution", "target": "google landmark", "depth": [1, 3]}, {"source": "solution", "target": "team jl solution", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "learning of object", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "perception and control", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "object keypoint", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "keypoints for perception", "depth": [1, 3]}, {"source": "unsupervised learning", "target": "classifier parameter estimation", "depth": [1, 3]}, {"source": "tool", "target": "verification tool", "depth": [1, 2]}, {"source": "tool", "target": "program verification tool", "depth": [1, 3]}, {"source": "tool", "target": "detection with program", "depth": [1, 3]}, {"source": "tool", "target": "program verification", "depth": [1, 3]}, {"source": "tool", "target": "invariant detection", "depth": [1, 3]}, {"source": "face", "target": "fisheye image", "depth": [1, 3]}, {"source": "face", "target": "face and object", "depth": [1, 3]}, {"source": "face", "target": "detection in fisheye", "depth": [1, 3]}, {"source": "face", "target": "datasets for face", "depth": [1, 3]}, {"source": "face", "target": "face obscuration", "depth": [1, 3]}, {"source": "user", "target": "smartphone user", "depth": [1, 3]}, {"source": "user", "target": "identifying smartphone user", "depth": [1, 3]}, {"source": "user", "target": "impact of mood", "depth": [1, 3]}, {"source": "user", "target": "mood on identifying", "depth": [1, 3]}, {"source": "user", "target": "identifying smartphone", "depth": [1, 3]}, {"source": "tutorial", "target": "singular value decomposition", "depth": [1, 2]}, {"source": "tutorial", "target": "complexity analysi", "depth": [1, 2]}, {"source": "tutorial", "target": "analysis of singular", "depth": [1, 3]}, {"source": "tutorial", "target": "complexity", "depth": [1, 2]}, {"source": "tutorial", "target": "singular", "depth": [1, 3]}, {"source": "query", "target": "utility-preserving privacy mechanism", "depth": [1, 3]}, {"source": "query", "target": "counting query", "depth": [1, 3]}, {"source": "query", "target": "privacy mechanism", "depth": [1, 3]}, {"source": "query", "target": "mechanisms for counting", "depth": [1, 3]}, {"source": "query", "target": "utility-preserving privacy", "depth": [1, 3]}, {"source": "privacy", "target": "utility-preserving privacy mechanism", "depth": [1, 3]}, {"source": "privacy", "target": "counting query", "depth": [1, 3]}, {"source": "privacy", "target": "privacy mechanism", "depth": [1, 3]}, {"source": "privacy", "target": "mechanisms for counting", "depth": [1, 3]}, {"source": "privacy", "target": "utility-preserving privacy", "depth": [1, 3]}, {"source": "adversarial learning", "target": "visually-guided cognitive representation", "depth": [1, 3]}, {"source": "adversarial learning", "target": "reconstructing perceived image", "depth": [1, 3]}, {"source": "adversarial learning", "target": "perceived image", "depth": [1, 3]}, {"source": "adversarial learning", "target": "images from brain", "depth": [1, 3]}, {"source": "adversarial learning", "target": "brain activity", "depth": [1, 3]}, {"source": "variance reduction", "target": "control variate", "depth": [1, 3]}, {"source": "variance reduction", "target": "weizs\u00e4cker model", "depth": [1, 3]}, {"source": "variance reduction", "target": "weizs\u00e4cker", "depth": [1, 3]}, {"source": "variance reduction", "target": "reduction for effective", "depth": [1, 3]}, {"source": "variance reduction", "target": "effective energy", "depth": [1, 3]}, {"source": "space", "target": "hyperbolic space", "depth": [1, 3]}, {"source": "space", "target": "growing action space", "depth": [1, 3]}, {"source": "space", "target": "growing action", "depth": [1, 3]}, {"source": "space", "target": "action", "depth": [1, 2]}, {"source": "space", "target": "growing", "depth": [1, 3]}, {"source": "multi-task learning", "target": "graph star net", "depth": [1, 3]}, {"source": "multi-task learning", "target": "generalized multi-task learning", "depth": [1, 3]}, {"source": "multi-task learning", "target": "star net", "depth": [1, 3]}, {"source": "multi-task learning", "target": "net for generalized", "depth": [1, 3]}, {"source": "multi-task learning", "target": "graph star", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "making quality assurance", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "quality assurance process", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "assurance processes leaner", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "quality assurance", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence helps making", "depth": [1, 3]}, {"source": "generative", "target": "dependency tree", "depth": [1, 3]}, {"source": "generative", "target": "model for punctuation", "depth": [1, 3]}, {"source": "generative", "target": "punctuation in dependency", "depth": [1, 3]}, {"source": "generative", "target": "tree", "depth": [1, 3]}, {"source": "generative", "target": "generative recursion", "depth": [1, 3]}, {"source": "security", "target": "backhaul network", "depth": [1, 3]}, {"source": "security", "target": "backhaul", "depth": [1, 3]}, {"source": "security", "target": "security assessment", "depth": [1, 3]}, {"source": "security", "target": "assessment of enterprise", "depth": [1, 3]}, {"source": "security", "target": "challenges for security", "depth": [1, 3]}, {"source": "finite element method", "target": "partitioned finite element", "depth": [1, 3]}, {"source": "finite element method", "target": "partitioned finite", "depth": [1, 3]}, {"source": "finite element method", "target": "method for power-preserving", "depth": [1, 3]}, {"source": "finite element method", "target": "conservation law", "depth": [1, 2]}, {"source": "finite element method", "target": "multiscale finite element", "depth": [1, 3]}, {"source": "deep generative", "target": "code-switched text", "depth": [1, 3]}, {"source": "deep generative", "target": "model for code-switched", "depth": [1, 3]}, {"source": "deep generative", "target": "inputs to deep", "depth": [1, 3]}, {"source": "deep generative", "target": "models using typicality", "depth": [1, 3]}, {"source": "deep generative", "target": "detecting", "depth": [1, 2]}, {"source": "efficient", "target": "efficient algorithm", "depth": [1, 3]}, {"source": "efficient", "target": "categorical distribution", "depth": [1, 3]}, {"source": "efficient", "target": "algorithms for modifying", "depth": [1, 3]}, {"source": "efficient", "target": "modifying and sampling", "depth": [1, 3]}, {"source": "efficient", "target": "distribution", "depth": [1, 2]}, {"source": "verification", "target": "verification of neural", "depth": [1, 3]}, {"source": "verification", "target": "automatic verification", "depth": [1, 3]}, {"source": "verification", "target": "heap-manipulating program", "depth": [1, 3]}, {"source": "verification", "target": "verification of heap-manipulating", "depth": [1, 3]}, {"source": "verification", "target": "heap-manipulating", "depth": [1, 3]}, {"source": "transport", "target": "fairness testing", "depth": [1, 3]}, {"source": "transport", "target": "testing via optimal", "depth": [1, 3]}, {"source": "transport", "target": "fliptest", "depth": [1, 3]}, {"source": "transport", "target": "fairnes", "depth": [1, 2]}, {"source": "transport", "target": "transport network", "depth": [1, 3]}, {"source": "matrix", "target": "positive definite matrix", "depth": [1, 3]}, {"source": "matrix", "target": "riemannian optimization", "depth": [1, 3]}, {"source": "matrix", "target": "definite matrix", "depth": [1, 3]}, {"source": "matrix", "target": "simplex of positive", "depth": [1, 3]}, {"source": "matrix", "target": "positive definite", "depth": [1, 3]}, {"source": "sequence", "target": "unsupervised representation learning", "depth": [1, 3]}, {"source": "sequence", "target": "dna sequence", "depth": [1, 3]}, {"source": "sequence", "target": "learning of dna", "depth": [1, 3]}, {"source": "sequence", "target": "unsupervised representation", "depth": [1, 3]}, {"source": "sequence", "target": "sequence generation", "depth": [1, 3]}, {"source": "gradient", "target": "leakage from gradient", "depth": [1, 3]}, {"source": "gradient", "target": "deep leakage", "depth": [1, 3]}, {"source": "gradient", "target": "leakage", "depth": [1, 3]}, {"source": "gradient", "target": "ranking policy gradient", "depth": [1, 3]}, {"source": "gradient", "target": "ranking policy", "depth": [1, 3]}, {"source": "pose estimation", "target": "object pose estimation", "depth": [1, 3]}, {"source": "pose estimation", "target": "robotics revisited", "depth": [1, 3]}, {"source": "pose estimation", "target": "object pose", "depth": [1, 3]}, {"source": "pose estimation", "target": "revisited", "depth": [1, 2]}, {"source": "pose estimation", "target": "pose", "depth": [1, 3]}, {"source": "computer vision", "target": "fourier perspective", "depth": [1, 3]}, {"source": "computer vision", "target": "perspective on model", "depth": [1, 3]}, {"source": "computer vision", "target": "model robustnes", "depth": [1, 2]}, {"source": "computer vision", "target": "robustness in computer", "depth": [1, 3]}, {"source": "computer vision", "target": "fourier", "depth": [1, 3]}, {"source": "style transfer", "target": "image style transfer", "depth": [1, 3]}, {"source": "style transfer", "target": "arbitrary image style", "depth": [1, 3]}, {"source": "style transfer", "target": "peer-regularized feature recombination", "depth": [1, 3]}, {"source": "style transfer", "target": "two-stage peer-regularized feature", "depth": [1, 3]}, {"source": "style transfer", "target": "feature recombination", "depth": [1, 3]}, {"source": "reading comprehension", "target": "comprehension", "depth": [1, 2]}, {"source": "reading comprehension", "target": "machine reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading", "depth": [1, 2]}, {"source": "reading comprehension", "target": "multi-hop reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "multi-hop reading", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised object detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised object", "depth": [1, 3]}, {"source": "weakly supervised", "target": "instability in weakly", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised object", "depth": [1, 3]}, {"source": "weakly supervised", "target": "utilizing the instability", "depth": [1, 3]}]}