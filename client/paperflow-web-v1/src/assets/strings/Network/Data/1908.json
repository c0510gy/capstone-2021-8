{"node": [["neural network", "convolutional neural network", "deep neural network", "network", "learning", "reinforcement learning", "machine learning", "deep learning", "graph", "model"], ["recurrent neural network", "deep", "convolutional network", "reinforcement", "representation", "learning approach", "deep learning based", "deep reinforcement learning", "deep reinforcement", "planar graph", "algorithm", "edge", "machine", "learning model", "graph convolutional", "analysis", "sentiment analysis", "datum", "problem", "system", "graph convolutional network", "image", "single image", "object detection", "object", "detection", "recognition", "action recognition", "speech recognition", "entity recognition", "machine translation", "neural machine translation", "neural machine", "translation", "generation", "semantic segmentation", "segmentation", "representation learning", "pose estimation", "person re-identification", "anomaly detection", "embedding", "generative adversarial network", "adversarial network", "generative adversarial", "game", "gradient method", "point cloud", "point", "cloud", "pose", "estimation", "domain", "domain adaptation", "video", "inference", "function", "survey", "text", "text generation", "language", "question answering", "approach", "classification", "transfer learning", "architecture", "optimization", "modeling", "verification", "action", "social medium", "medium", "computation", "evaluation", "intelligence", "natural language", "quantum", "design", "augmented reality", "knowledge graph", "theory", "structure", "application", "flow", "human", "finite element", "finite element method", "search", "information", "approximation", "clustering", "challenge", "channel", "prediction", "reading comprehension", "complexity", "dataset", "logic", "image registration", "attention", "task", "space", "reasoning", "visualization", "code", "attention network", "power system", "differential privacy", "testing", "multi-task learning", "image captioning", "method", "social network", "entity", "robust", "case study", "study", "tracking", "reconstruction", "recommendation", "named entity recognition", "named entity", "computing", "language model", "efficient", "human motion", "semi-supervised learning", "blockchain", "face", "time", "partial differential equation", "continual learning", "regularization", "massive mimo", "deep network", "decomposition", "benchmark", "bert", "automated", "massive mimo system", "mimo system", "data stream", "constraint", "smart contract", "text summarization", "kernel", "communication", "matching", "theorem", "implementation", "feature selection", "image segmentation", "cellular network", "lower bound", "word embedding", "synthesis", "aggregation network", "time series", "computational", "imaging", "comparison", "bayesian", "environment", "user", "attack", "systematic review", "tree"], ["deep convolutional neural", "graph neural network", "networks for deep", "deep video", "deep learning approach", "reinforcement learning approach", "number", "machine learning model", "automated machine learning", "automated machine", "image generation", "inverse problem", "cyber-physical system", "parameterized algorithm", "approximation algorithm", "fully convolutional network", "convolutional", "network embedding", "point cloud semantic", "cloud semantic segmentation", "navigation", "active learning", "network inference", "neural network inference", "answering", "visual question answering", "visual question", "word sense", "sentiment classification", "artificial intelligence", "language interface", "learning based", "mri reconstruction", "conservation law", "activity recognition", "element method", "multiscale finite element", "multiscale finite", "source separation", "opportunity", "subset space", "logic of subset", "part", "commonsense", "polar code", "privacy", "captioning", "network for image", "speech", "posteriori error estimate", "posteriori error", "error estimate", "network analysis", "case", "fusion", "multi-modal", "learned", "few-shot text classification", "data structure", "designing", "simulation", "partial differential", "differential equation", "cell-free massive mimo", "channel estimation", "technical report", "world", "empirical study", "medical image segmentation", "medical image", "multiple", "word", "regular expression", "data source", "perspective", "bayesian inference", "natural language processing", "language processing"], ["deep video inpainting", "video inpainting", "analysis of image", "systematic analysis", "iot datum", "rewarding high-quality datum", "influence function", "range query problem", "equivalences between triangle", "accurate multi-map system", "orbslam-atla", "multi-map system", "partially colorable graph", "salient object detection", "moving object detection", "disambiguate word sense", "question generation", "learning with language", "language modeling", "modeling for question", "multi-agent deep reinforcement", "real-time localized style", "localized style transfer", "graph representation learning", "aspect category transfer", "information for person", "semi-supervised person re-identification", "cross-camera soft-label learning", "progressive cross-camera soft-label", "clustering wi-fi fingerprint", "indoor-outdoor detection", "adversarial training method", "training method", "generative", "game jam license", "jam license", "game jam", "transferable representation learning", "transferable representation", "learning to grasp", "sparse generative adversarial", "sparse generative", "human pose estimation", "high stakes domain", "stakes domain", "learning in video", "coherence for active", "inference on mobile", "data via influence", "learning in healthcare", "healthcare", "predicting consumer default", "autoregressive text generation", "feedback loop", "cross-lingual topic prediction", "cross-lingual topic", "speech using translation", "revisiting cyclegan", "semi-supervised segmentation", "cyclegan for semi-supervised", "online influence", "offline violence", "youtube surrounding", "rally", "redundancy and synergy", "approach to multivariate", "multivariate redundancy", "synergy", "lyrics and audio", "classification using neural", "lukthung classification", "audio", "autotuning exascale application", "exascale application", "learning for autotuning", "risc-v architecture", "echronos rto", "rtos on risc-v", "disambiguate word", "files to object", "marrying file", "marrying", "file", "bert language model", "language model finetuning", "aspect-target sentiment classification", "pseudo-boolean optimization", "technique of search", "search in pseudo-boolean", "approach to parking", "queuing approach", "cross-enhancement transform two-stream", "cross-enhancement transform", "transform two-stream", "benchmark of visual", "visual storytelling", "storytelling in social", "complex for biomolecule", "computation of alpha", "alpha complex", "parallel computation", "parallel in-memory evaluation", "spatial join", "evaluation of spatial", "analyzing cyber-physical system", "perspective of artificial", "natural language interface", "natural language understanding", "features of quantum", "quantum system", "predicting feature", "augmented reality haploscope", "reality haploscope", "assembly", "based chatbot model", "learning based chatbot", "meta knowledge graph", "knowledge graph information", "adapting meta knowledge", "graph convolutional neural", "recognition in conversation", "field theory", "recurrent mobility", "theory for recurrent", "spatially-distributed multi-agent system", "semantic structure", "multi-agent system", "user dwell time", "user dwell", "dwell time", "immersive environment", "viscoelastic flow", "human activity recognition", "human activity", "skeleton pose", "structural diversity search", "parameter-free structural diversity", "diversity search", "structural diversity", "information extraction", "annotation in information", "weight annotation", "fully factorized approximation", "belief propagation", "factorized approximation", "convolutional recurrent neural", "single-channel source separation", "binarization on recurrent", "autoencoded embedding", "deep clustering", "local manifold", "clustering the local", "animal pose estimation", "adaptation for animal", "animal pose", "cross-domain adaptation", "future challenge", "future direction", "bpsk input", "channel capacity", "capacity of bpsk", "network edge", "distributing intelligence", "distributing", "distributed edge partitioning", "parking", "multi-choice reading comprehension", "dual co-matching network", "network for multi-choice", "multi-choice reading", "sparse graph", "complexity of hedonic", "hedonic game", "games on sparse", "road network", "networks for road", "connected graph convolutional", "evaluating the impact", "behavior in storytelling", "impact of affective", "aerial image registration", "multi-temporal aerial image", "semantic feature", "aerial image", "attention for visual", "learning manipulation task", "manipulation task", "comparison of action", "action space", "abductive commonsense reasoning", "commonsense reasoning", "abductive commonsense", "design by immersion", "transdisciplinary approach", "problem-driven visualization", "analysis and construction", "construction based", "document understanding", "label attention network", "hierarchically-refined label attention", "bus dynamic", "fast scenario reduction", "scenario reduction", "local differential privacy", "shuffler-based differential privacy", "boolean and binary", "property testing", "binary rank", "reflective decoding network", "decoding network", "attribute-aware product network", "representation learning model", "speech spectrum", "recognition using eeg", "decoding of speech", "generalized one-class discriminative", "one-class discriminative subspace", "generalized one-class", "discriminative subspace", "staggered dg method", "social network analysis", "house of common", "queuing", "infer entity", "clinical conversation", "relations from clinical", "robust and accurate", "designing with datum", "rgb-t tracking", "multi-modal fusion", "homothetic triangle representation", "homothetic triangle", "triangle representation", "representations of planar", "learned iterative reconstruction", "multi-scale learned iterative", "iterative reconstruction", "collaborative recommendation", "algorithmic evaluation", "evaluation and comparison", "multi-word entity recognition", "distributed computing", "designs for speeding", "speeding up distributed", "unsupervised language model", "low resource nlp", "efficient computation", "efficient stl-like datum", "stl-like data structure", "high-speed human motion", "event camera", "capture of high-speed", "publish replication study", "anatomy from ultrasound", "learning of fetal", "fetal anatomy", "simulation of blockchain", "agent-based simulation", "dual attention mobdensenet", "face alignment", "dual attention", "simple algorithm", "algorithm for minimum", "minimum cut", "near-linear time", "matrix equation technique", "evolutionary partial differential", "boosting approach", "learning of va", "approach for continual", "tackling algorithmic bia", "algorithmic bia", "bias in neural-network", "neural-network classifier", "fine-grained action retrieval", "retrieval through multiple", "action retrieval", "computing-enabled cell-free massive", "discretely-constrained deep network", "weakly supervised segmentation", "supervised segmentation", "network for weakly", "shadow image decomposition", "image decomposition", "shadow removal", "corpus for named", "open data source", "free open datum", "secrets of bert", "dark secret", "revealing the dark", "dark", "particle energy distribution", "automated classification", "particle energy", "energy distribution", "edge computing-enabled cell-free", "downlink channel prediction", "policy gradient method", "bilinear zero-sum game", "methods on bilinear", "convergence of gradient", "incomplete data stream", "efficient join processing", "machine learning inference", "uncheatable machine learning", "learning inference", "linear stochastic bandit", "safety constraint", "stochastic bandit", "adversarial shape perturbation", "adversarial shape", "shape perturbation", "objects without retraining", "generic", "cornet", "corner", "world model", "learning with world", "deep latent variable", "latent variable model", "implicit deep latent", "deep latent", "listed smart contract", "contracts in ethereum", "success of listed", "extractive text summarization", "exploring domain shift", "domain shift", "lens of kernel", "unified understanding", "transformer dissection", "markovian arrival", "communications with markovian", "energy-efficient communication", "matching with contract", "preferences for matching", "revealed preference", "multimodal sentiment analysis", "fusion for multimodal", "multimodal sentiment", "variational fusion", "basic triangle theorem", "triangle theorem", "localized version", "multi-bernoulli mixture filter", "gaussian implementation", "mixture filter", "exploiting semantic knowledge", "zero-shot feature selection", "semantic knowledge", "robustifying deep network", "robustifying deep", "underlay cellular network", "multicasts in underlay", "probabilistic lower bound", "beating the probabilistic", "perfect hashing", "quantum many-body system", "amazon cloud", "systems on amazon", "simulation of quantum", "synthesis of regular", "multi-modal synthesis", "expression", "pixel aggregation network", "accurate arbitrary-shaped text", "arbitrary-shaped text detection", "time series classification", "accurate time series", "early and accurate", "computational perspective", "fairness in deep", "survey on computational", "ultrasound imaging", "signal recovery", "recovery with application", "applications in ultrasound", "visual cue", "cues in estimation", "cue", "information cascade", "inference of network", "network structure", "soft growing robot", "soft growing", "growing robot", "robot by exploiting", "neuroimaging dataset", "attacks on neuroimaging", "de-anonymization attack", "neuroimaging", "chronic disease", "competitive online search", "online search tree", "online search", "competitive online"]], "link": [{"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 2]}, {"source": "network", "target": "deep", "depth": [0, 1]}, {"source": "network", "target": "networks for deep", "depth": [0, 2]}, {"source": "network", "target": "deep video", "depth": [0, 2]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "convolutional network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "learning", "target": "representation", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 2]}, {"source": "deep learning", "target": "learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "learning approach", "depth": [0, 1]}, {"source": "graph", "target": "planar graph", "depth": [0, 1]}, {"source": "graph", "target": "algorithm", "depth": [0, 1]}, {"source": "graph", "target": "number", "depth": [0, 2]}, {"source": "graph", "target": "edge", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning model", "depth": [0, 2]}, {"source": "machine learning", "target": "learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "automated machine learning", "depth": [0, 2]}, {"source": "machine learning", "target": "automated machine", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "graph convolutional", "depth": [0, 1]}, {"source": "deep neural network", "target": "deep", "depth": [0, 1]}, {"source": "deep", "target": "deep video", "depth": [1, 2]}, {"source": "deep", "target": "deep video inpainting", "depth": [1, 3]}, {"source": "deep", "target": "networks for deep", "depth": [1, 2]}, {"source": "deep", "target": "video inpainting", "depth": [1, 3]}, {"source": "analysis", "target": "sentiment analysis", "depth": [1, 1]}, {"source": "analysis", "target": "analysis of image", "depth": [1, 3]}, {"source": "analysis", "target": "image generation", "depth": [1, 2]}, {"source": "analysis", "target": "systematic analysis", "depth": [1, 3]}, {"source": "datum", "target": "iot datum", "depth": [1, 3]}, {"source": "datum", "target": "rewarding high-quality datum", "depth": [1, 3]}, {"source": "datum", "target": "influence function", "depth": [1, 3]}, {"source": "problem", "target": "algorithm", "depth": [1, 1]}, {"source": "problem", "target": "inverse problem", "depth": [1, 2]}, {"source": "problem", "target": "range query problem", "depth": [1, 3]}, {"source": "problem", "target": "equivalences between triangle", "depth": [1, 3]}, {"source": "system", "target": "cyber-physical system", "depth": [1, 2]}, {"source": "system", "target": "accurate multi-map system", "depth": [1, 3]}, {"source": "system", "target": "orbslam-atla", "depth": [1, 3]}, {"source": "system", "target": "multi-map system", "depth": [1, 3]}, {"source": "algorithm", "target": "parameterized algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "partially colorable graph", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "fully convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "convolutional", "depth": [1, 2]}, {"source": "image", "target": "single image", "depth": [1, 1]}, {"source": "image", "target": "analysis of image", "depth": [1, 3]}, {"source": "image", "target": "image generation", "depth": [1, 2]}, {"source": "image", "target": "systematic analysis", "depth": [1, 3]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "detection", "depth": [1, 1]}, {"source": "object detection", "target": "salient object detection", "depth": [1, 3]}, {"source": "object detection", "target": "moving object detection", "depth": [1, 3]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "translation", "depth": [1, 1]}, {"source": "machine translation", "target": "disambiguate word sense", "depth": [1, 3]}, {"source": "generation", "target": "question generation", "depth": [1, 3]}, {"source": "generation", "target": "learning with language", "depth": [1, 3]}, {"source": "generation", "target": "language modeling", "depth": [1, 3]}, {"source": "generation", "target": "modeling for question", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "multi-agent deep reinforcement", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "real-time localized style", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "localized style transfer", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "disambiguate word sense", "depth": [1, 3]}, {"source": "representation learning", "target": "representation", "depth": [1, 1]}, {"source": "representation learning", "target": "graph representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "pose estimation", "depth": [1, 1]}, {"source": "representation learning", "target": "aspect category transfer", "depth": [1, 3]}, {"source": "person re-identification", "target": "information for person", "depth": [1, 3]}, {"source": "person re-identification", "target": "semi-supervised person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "cross-camera soft-label learning", "depth": [1, 3]}, {"source": "person re-identification", "target": "progressive cross-camera soft-label", "depth": [1, 3]}, {"source": "detection", "target": "anomaly detection", "depth": [1, 1]}, {"source": "detection", "target": "clustering wi-fi fingerprint", "depth": [1, 3]}, {"source": "detection", "target": "indoor-outdoor detection", "depth": [1, 3]}, {"source": "embedding", "target": "network embedding", "depth": [1, 2]}, {"source": "embedding", "target": "adversarial training method", "depth": [1, 3]}, {"source": "embedding", "target": "training method", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "generative", "depth": [1, 3]}, {"source": "game", "target": "gradient method", "depth": [1, 1]}, {"source": "game", "target": "game jam license", "depth": [1, 3]}, {"source": "game", "target": "jam license", "depth": [1, 3]}, {"source": "game", "target": "game jam", "depth": [1, 3]}, {"source": "point cloud", "target": "point cloud semantic", "depth": [1, 2]}, {"source": "point cloud", "target": "cloud semantic segmentation", "depth": [1, 2]}, {"source": "point cloud", "target": "point", "depth": [1, 1]}, {"source": "point cloud", "target": "cloud", "depth": [1, 1]}, {"source": "representation", "target": "transferable representation learning", "depth": [1, 3]}, {"source": "representation", "target": "transferable representation", "depth": [1, 3]}, {"source": "representation", "target": "navigation", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "multi-agent deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "learning to grasp", "depth": [1, 3]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "sparse generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "sparse generative", "depth": [1, 3]}, {"source": "pose estimation", "target": "pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 3]}, {"source": "domain", "target": "domain adaptation", "depth": [1, 1]}, {"source": "domain", "target": "high stakes domain", "depth": [1, 3]}, {"source": "domain", "target": "stakes domain", "depth": [1, 3]}, {"source": "video", "target": "learning in video", "depth": [1, 3]}, {"source": "video", "target": "coherence for active", "depth": [1, 3]}, {"source": "video", "target": "active learning", "depth": [1, 2]}, {"source": "inference", "target": "network inference", "depth": [1, 2]}, {"source": "inference", "target": "neural network inference", "depth": [1, 2]}, {"source": "inference", "target": "inference on mobile", "depth": [1, 3]}, {"source": "function", "target": "rewarding high-quality datum", "depth": [1, 3]}, {"source": "function", "target": "influence function", "depth": [1, 3]}, {"source": "function", "target": "data via influence", "depth": [1, 3]}, {"source": "survey", "target": "learning in healthcare", "depth": [1, 3]}, {"source": "survey", "target": "healthcare", "depth": [1, 3]}, {"source": "survey", "target": "reinforcement", "depth": [1, 1]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "predicting consumer default", "depth": [1, 3]}, {"source": "text", "target": "text generation", "depth": [1, 1]}, {"source": "text", "target": "autoregressive text generation", "depth": [1, 3]}, {"source": "text", "target": "feedback loop", "depth": [1, 3]}, {"source": "translation", "target": "neural machine", "depth": [1, 1]}, {"source": "translation", "target": "cross-lingual topic prediction", "depth": [1, 3]}, {"source": "translation", "target": "cross-lingual topic", "depth": [1, 3]}, {"source": "translation", "target": "speech using translation", "depth": [1, 3]}, {"source": "segmentation", "target": "revisiting cyclegan", "depth": [1, 3]}, {"source": "segmentation", "target": "semi-supervised segmentation", "depth": [1, 3]}, {"source": "segmentation", "target": "cyclegan for semi-supervised", "depth": [1, 3]}, {"source": "language", "target": "online influence", "depth": [1, 3]}, {"source": "language", "target": "offline violence", "depth": [1, 3]}, {"source": "language", "target": "youtube surrounding", "depth": [1, 3]}, {"source": "language", "target": "rally", "depth": [1, 3]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question", "depth": [1, 2]}, {"source": "approach", "target": "redundancy and synergy", "depth": [1, 3]}, {"source": "approach", "target": "approach to multivariate", "depth": [1, 3]}, {"source": "approach", "target": "multivariate redundancy", "depth": [1, 3]}, {"source": "approach", "target": "synergy", "depth": [1, 3]}, {"source": "classification", "target": "lyrics and audio", "depth": [1, 3]}, {"source": "classification", "target": "classification using neural", "depth": [1, 3]}, {"source": "classification", "target": "lukthung classification", "depth": [1, 3]}, {"source": "classification", "target": "audio", "depth": [1, 3]}, {"source": "transfer learning", "target": "autotuning exascale application", "depth": [1, 3]}, {"source": "transfer learning", "target": "exascale application", "depth": [1, 3]}, {"source": "transfer learning", "target": "learning for autotuning", "depth": [1, 3]}, {"source": "architecture", "target": "risc-v architecture", "depth": [1, 3]}, {"source": "architecture", "target": "echronos rto", "depth": [1, 3]}, {"source": "architecture", "target": "rtos on risc-v", "depth": [1, 3]}, {"source": "neural machine", "target": "disambiguate word sense", "depth": [1, 3]}, {"source": "neural machine", "target": "disambiguate word", "depth": [1, 3]}, {"source": "neural machine", "target": "word sense", "depth": [1, 2]}, {"source": "object", "target": "files to object", "depth": [1, 3]}, {"source": "object", "target": "marrying file", "depth": [1, 3]}, {"source": "object", "target": "marrying", "depth": [1, 3]}, {"source": "object", "target": "file", "depth": [1, 3]}, {"source": "domain adaptation", "target": "bert language model", "depth": [1, 3]}, {"source": "domain adaptation", "target": "language model finetuning", "depth": [1, 3]}, {"source": "domain adaptation", "target": "aspect-target sentiment classification", "depth": [1, 3]}, {"source": "domain adaptation", "target": "sentiment classification", "depth": [1, 2]}, {"source": "optimization", "target": "pseudo-boolean optimization", "depth": [1, 3]}, {"source": "optimization", "target": "technique of search", "depth": [1, 3]}, {"source": "optimization", "target": "search in pseudo-boolean", "depth": [1, 3]}, {"source": "modeling", "target": "approach to parking", "depth": [1, 3]}, {"source": "modeling", "target": "queuing approach", "depth": [1, 3]}, {"source": "modeling", "target": "verification", "depth": [1, 1]}, {"source": "action recognition", "target": "action", "depth": [1, 1]}, {"source": "action recognition", "target": "cross-enhancement transform two-stream", "depth": [1, 3]}, {"source": "action recognition", "target": "cross-enhancement transform", "depth": [1, 3]}, {"source": "action recognition", "target": "transform two-stream", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 1]}, {"source": "social medium", "target": "benchmark of visual", "depth": [1, 3]}, {"source": "social medium", "target": "visual storytelling", "depth": [1, 3]}, {"source": "social medium", "target": "storytelling in social", "depth": [1, 3]}, {"source": "computation", "target": "complex for biomolecule", "depth": [1, 3]}, {"source": "computation", "target": "computation of alpha", "depth": [1, 3]}, {"source": "computation", "target": "alpha complex", "depth": [1, 3]}, {"source": "computation", "target": "parallel computation", "depth": [1, 3]}, {"source": "evaluation", "target": "parallel in-memory evaluation", "depth": [1, 3]}, {"source": "evaluation", "target": "spatial join", "depth": [1, 3]}, {"source": "evaluation", "target": "evaluation of spatial", "depth": [1, 3]}, {"source": "intelligence", "target": "edge", "depth": [1, 1]}, {"source": "intelligence", "target": "artificial intelligence", "depth": [1, 2]}, {"source": "intelligence", "target": "analyzing cyber-physical system", "depth": [1, 3]}, {"source": "intelligence", "target": "perspective of artificial", "depth": [1, 3]}, {"source": "natural language", "target": "natural language interface", "depth": [1, 3]}, {"source": "natural language", "target": "language interface", "depth": [1, 2]}, {"source": "natural language", "target": "natural language understanding", "depth": [1, 3]}, {"source": "quantum", "target": "features of quantum", "depth": [1, 3]}, {"source": "quantum", "target": "quantum system", "depth": [1, 3]}, {"source": "quantum", "target": "predicting feature", "depth": [1, 3]}, {"source": "design", "target": "augmented reality haploscope", "depth": [1, 3]}, {"source": "design", "target": "reality haploscope", "depth": [1, 3]}, {"source": "design", "target": "augmented reality", "depth": [1, 1]}, {"source": "design", "target": "assembly", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 2]}, {"source": "deep learning based", "target": "based chatbot model", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based chatbot", "depth": [1, 3]}, {"source": "knowledge graph", "target": "meta knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph information", "depth": [1, 3]}, {"source": "knowledge graph", "target": "adapting meta knowledge", "depth": [1, 3]}, {"source": "graph convolutional", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "graph convolutional", "target": "graph convolutional neural", "depth": [1, 3]}, {"source": "graph convolutional", "target": "recognition in conversation", "depth": [1, 3]}, {"source": "theory", "target": "field theory", "depth": [1, 3]}, {"source": "theory", "target": "recurrent mobility", "depth": [1, 3]}, {"source": "theory", "target": "theory for recurrent", "depth": [1, 3]}, {"source": "structure", "target": "spatially-distributed multi-agent system", "depth": [1, 3]}, {"source": "structure", "target": "semantic structure", "depth": [1, 3]}, {"source": "structure", "target": "multi-agent system", "depth": [1, 3]}, {"source": "application", "target": "user dwell time", "depth": [1, 3]}, {"source": "application", "target": "user dwell", "depth": [1, 3]}, {"source": "application", "target": "dwell time", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "sparse generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "sparse generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "mri reconstruction", "depth": [1, 2]}, {"source": "flow", "target": "immersive environment", "depth": [1, 3]}, {"source": "flow", "target": "viscoelastic flow", "depth": [1, 3]}, {"source": "flow", "target": "conservation law", "depth": [1, 2]}, {"source": "human", "target": "human activity recognition", "depth": [1, 3]}, {"source": "human", "target": "human activity", "depth": [1, 3]}, {"source": "human", "target": "skeleton pose", "depth": [1, 3]}, {"source": "human", "target": "activity recognition", "depth": [1, 2]}, {"source": "finite element", "target": "finite element method", "depth": [1, 1]}, {"source": "finite element", "target": "element method", "depth": [1, 2]}, {"source": "finite element", "target": "multiscale finite element", "depth": [1, 2]}, {"source": "finite element", "target": "multiscale finite", "depth": [1, 2]}, {"source": "search", "target": "structural diversity search", "depth": [1, 3]}, {"source": "search", "target": "parameter-free structural diversity", "depth": [1, 3]}, {"source": "search", "target": "diversity search", "depth": [1, 3]}, {"source": "search", "target": "structural diversity", "depth": [1, 3]}, {"source": "information", "target": "information extraction", "depth": [1, 3]}, {"source": "information", "target": "annotation in information", "depth": [1, 3]}, {"source": "information", "target": "weight annotation", "depth": [1, 3]}, {"source": "approximation", "target": "fully factorized approximation", "depth": [1, 3]}, {"source": "approximation", "target": "belief propagation", "depth": [1, 3]}, {"source": "approximation", "target": "factorized approximation", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "convolutional recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "single-channel source separation", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "source separation", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "binarization on recurrent", "depth": [1, 3]}, {"source": "clustering", "target": "autoencoded embedding", "depth": [1, 3]}, {"source": "clustering", "target": "deep clustering", "depth": [1, 3]}, {"source": "clustering", "target": "local manifold", "depth": [1, 3]}, {"source": "clustering", "target": "clustering the local", "depth": [1, 3]}, {"source": "estimation", "target": "animal pose estimation", "depth": [1, 3]}, {"source": "estimation", "target": "adaptation for animal", "depth": [1, 3]}, {"source": "estimation", "target": "animal pose", "depth": [1, 3]}, {"source": "estimation", "target": "cross-domain adaptation", "depth": [1, 3]}, {"source": "challenge", "target": "opportunity", "depth": [1, 2]}, {"source": "challenge", "target": "future challenge", "depth": [1, 3]}, {"source": "challenge", "target": "future direction", "depth": [1, 3]}, {"source": "channel", "target": "bpsk input", "depth": [1, 3]}, {"source": "channel", "target": "channel capacity", "depth": [1, 3]}, {"source": "channel", "target": "capacity of bpsk", "depth": [1, 3]}, {"source": "edge", "target": "network edge", "depth": [1, 3]}, {"source": "edge", "target": "distributing intelligence", "depth": [1, 3]}, {"source": "edge", "target": "distributing", "depth": [1, 3]}, {"source": "edge", "target": "distributed edge partitioning", "depth": [1, 3]}, {"source": "prediction", "target": "approach to parking", "depth": [1, 3]}, {"source": "prediction", "target": "queuing approach", "depth": [1, 3]}, {"source": "prediction", "target": "verification", "depth": [1, 1]}, {"source": "prediction", "target": "parking", "depth": [1, 3]}, {"source": "reading comprehension", "target": "multi-choice reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "dual co-matching network", "depth": [1, 3]}, {"source": "reading comprehension", "target": "network for multi-choice", "depth": [1, 3]}, {"source": "reading comprehension", "target": "multi-choice reading", "depth": [1, 3]}, {"source": "complexity", "target": "sparse graph", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of hedonic", "depth": [1, 3]}, {"source": "complexity", "target": "hedonic game", "depth": [1, 3]}, {"source": "complexity", "target": "games on sparse", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "road network", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "networks for road", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "convolutional", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "connected graph convolutional", "depth": [1, 3]}, {"source": "dataset", "target": "evaluating the impact", "depth": [1, 3]}, {"source": "dataset", "target": "behavior in storytelling", "depth": [1, 3]}, {"source": "dataset", "target": "impact of affective", "depth": [1, 3]}, {"source": "logic", "target": "subset space", "depth": [1, 2]}, {"source": "logic", "target": "logic of subset", "depth": [1, 2]}, {"source": "logic", "target": "part", "depth": [1, 2]}, {"source": "image registration", "target": "aerial image registration", "depth": [1, 3]}, {"source": "image registration", "target": "multi-temporal aerial image", "depth": [1, 3]}, {"source": "image registration", "target": "semantic feature", "depth": [1, 3]}, {"source": "image registration", "target": "aerial image", "depth": [1, 3]}, {"source": "attention", "target": "visual question answering", "depth": [1, 2]}, {"source": "attention", "target": "attention for visual", "depth": [1, 3]}, {"source": "attention", "target": "visual question", "depth": [1, 2]}, {"source": "task", "target": "learning manipulation task", "depth": [1, 3]}, {"source": "task", "target": "manipulation task", "depth": [1, 3]}, {"source": "task", "target": "comparison of action", "depth": [1, 3]}, {"source": "task", "target": "action space", "depth": [1, 3]}, {"source": "space", "target": "subset space", "depth": [1, 2]}, {"source": "space", "target": "logic of subset", "depth": [1, 2]}, {"source": "space", "target": "part", "depth": [1, 2]}, {"source": "reasoning", "target": "abductive commonsense reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "commonsense reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "abductive commonsense", "depth": [1, 3]}, {"source": "reasoning", "target": "commonsense", "depth": [1, 2]}, {"source": "visualization", "target": "design by immersion", "depth": [1, 3]}, {"source": "visualization", "target": "transdisciplinary approach", "depth": [1, 3]}, {"source": "visualization", "target": "problem-driven visualization", "depth": [1, 3]}, {"source": "code", "target": "analysis and construction", "depth": [1, 3]}, {"source": "code", "target": "construction based", "depth": [1, 3]}, {"source": "code", "target": "polar code", "depth": [1, 2]}, {"source": "attention network", "target": "document understanding", "depth": [1, 3]}, {"source": "attention network", "target": "label attention network", "depth": [1, 3]}, {"source": "attention network", "target": "hierarchically-refined label attention", "depth": [1, 3]}, {"source": "power system", "target": "bus dynamic", "depth": [1, 3]}, {"source": "power system", "target": "fast scenario reduction", "depth": [1, 3]}, {"source": "power system", "target": "scenario reduction", "depth": [1, 3]}, {"source": "differential privacy", "target": "privacy", "depth": [1, 2]}, {"source": "differential privacy", "target": "local differential privacy", "depth": [1, 3]}, {"source": "differential privacy", "target": "shuffler-based differential privacy", "depth": [1, 3]}, {"source": "testing", "target": "boolean and binary", "depth": [1, 3]}, {"source": "testing", "target": "property testing", "depth": [1, 3]}, {"source": "testing", "target": "binary rank", "depth": [1, 3]}, {"source": "multi-task learning", "target": "question generation", "depth": [1, 3]}, {"source": "multi-task learning", "target": "learning with language", "depth": [1, 3]}, {"source": "multi-task learning", "target": "language modeling", "depth": [1, 3]}, {"source": "image captioning", "target": "captioning", "depth": [1, 2]}, {"source": "image captioning", "target": "reflective decoding network", "depth": [1, 3]}, {"source": "image captioning", "target": "decoding network", "depth": [1, 3]}, {"source": "image captioning", "target": "network for image", "depth": [1, 2]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "attribute-aware product network", "depth": [1, 3]}, {"source": "learning model", "target": "representation learning model", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 2]}, {"source": "speech recognition", "target": "speech spectrum", "depth": [1, 3]}, {"source": "speech recognition", "target": "recognition using eeg", "depth": [1, 3]}, {"source": "speech recognition", "target": "decoding of speech", "depth": [1, 3]}, {"source": "anomaly detection", "target": "generalized one-class discriminative", "depth": [1, 3]}, {"source": "anomaly detection", "target": "one-class discriminative subspace", "depth": [1, 3]}, {"source": "anomaly detection", "target": "generalized one-class", "depth": [1, 3]}, {"source": "anomaly detection", "target": "discriminative subspace", "depth": [1, 3]}, {"source": "method", "target": "posteriori error estimate", "depth": [1, 2]}, {"source": "method", "target": "staggered dg method", "depth": [1, 3]}, {"source": "method", "target": "posteriori error", "depth": [1, 2]}, {"source": "method", "target": "error estimate", "depth": [1, 2]}, {"source": "social network", "target": "social network analysis", "depth": [1, 3]}, {"source": "social network", "target": "house of common", "depth": [1, 3]}, {"source": "social network", "target": "network analysis", "depth": [1, 2]}, {"source": "finite element method", "target": "element method", "depth": [1, 2]}, {"source": "finite element method", "target": "multiscale finite element", "depth": [1, 2]}, {"source": "finite element method", "target": "multiscale finite", "depth": [1, 2]}, {"source": "verification", "target": "approach to parking", "depth": [1, 3]}, {"source": "verification", "target": "queuing approach", "depth": [1, 3]}, {"source": "verification", "target": "parking", "depth": [1, 3]}, {"source": "verification", "target": "queuing", "depth": [1, 3]}, {"source": "entity", "target": "infer entity", "depth": [1, 3]}, {"source": "entity", "target": "clinical conversation", "depth": [1, 3]}, {"source": "entity", "target": "relations from clinical", "depth": [1, 3]}, {"source": "robust", "target": "accurate multi-map system", "depth": [1, 3]}, {"source": "robust", "target": "orbslam-atla", "depth": [1, 3]}, {"source": "robust", "target": "multi-map system", "depth": [1, 3]}, {"source": "robust", "target": "robust and accurate", "depth": [1, 3]}, {"source": "case study", "target": "designing with datum", "depth": [1, 3]}, {"source": "case study", "target": "study", "depth": [1, 1]}, {"source": "case study", "target": "case", "depth": [1, 2]}, {"source": "tracking", "target": "rgb-t tracking", "depth": [1, 3]}, {"source": "tracking", "target": "multi-modal fusion", "depth": [1, 3]}, {"source": "tracking", "target": "fusion", "depth": [1, 2]}, {"source": "tracking", "target": "multi-modal", "depth": [1, 2]}, {"source": "planar graph", "target": "homothetic triangle representation", "depth": [1, 3]}, {"source": "planar graph", "target": "homothetic triangle", "depth": [1, 3]}, {"source": "planar graph", "target": "triangle representation", "depth": [1, 3]}, {"source": "planar graph", "target": "representations of planar", "depth": [1, 3]}, {"source": "reconstruction", "target": "learned iterative reconstruction", "depth": [1, 3]}, {"source": "reconstruction", "target": "multi-scale learned iterative", "depth": [1, 3]}, {"source": "reconstruction", "target": "iterative reconstruction", "depth": [1, 3]}, {"source": "reconstruction", "target": "learned", "depth": [1, 2]}, {"source": "recommendation", "target": "collaborative recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "algorithmic evaluation", "depth": [1, 3]}, {"source": "recommendation", "target": "evaluation and comparison", "depth": [1, 3]}, {"source": "entity recognition", "target": "named entity recognition", "depth": [1, 1]}, {"source": "entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "entity recognition", "target": "multi-word entity recognition", "depth": [1, 3]}, {"source": "computing", "target": "distributed computing", "depth": [1, 3]}, {"source": "computing", "target": "designs for speeding", "depth": [1, 3]}, {"source": "computing", "target": "speeding up distributed", "depth": [1, 3]}, {"source": "language model", "target": "unsupervised language model", "depth": [1, 3]}, {"source": "language model", "target": "few-shot text classification", "depth": [1, 2]}, {"source": "language model", "target": "low resource nlp", "depth": [1, 3]}, {"source": "efficient", "target": "efficient computation", "depth": [1, 3]}, {"source": "efficient", "target": "efficient stl-like datum", "depth": [1, 3]}, {"source": "efficient", "target": "stl-like data structure", "depth": [1, 3]}, {"source": "efficient", "target": "data structure", "depth": [1, 2]}, {"source": "human motion", "target": "high-speed human motion", "depth": [1, 3]}, {"source": "human motion", "target": "event camera", "depth": [1, 3]}, {"source": "human motion", "target": "capture of high-speed", "depth": [1, 3]}, {"source": "study", "target": "designing with datum", "depth": [1, 3]}, {"source": "study", "target": "case", "depth": [1, 2]}, {"source": "study", "target": "designing", "depth": [1, 2]}, {"source": "study", "target": "publish replication study", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "anatomy from ultrasound", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "learning of fetal", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "fetal anatomy", "depth": [1, 3]}, {"source": "blockchain", "target": "simulation of blockchain", "depth": [1, 3]}, {"source": "blockchain", "target": "agent-based simulation", "depth": [1, 3]}, {"source": "blockchain", "target": "simulation", "depth": [1, 2]}, {"source": "face", "target": "dual attention mobdensenet", "depth": [1, 3]}, {"source": "face", "target": "face alignment", "depth": [1, 3]}, {"source": "face", "target": "dual attention", "depth": [1, 3]}, {"source": "time", "target": "simple algorithm", "depth": [1, 3]}, {"source": "time", "target": "algorithm for minimum", "depth": [1, 3]}, {"source": "time", "target": "minimum cut", "depth": [1, 3]}, {"source": "time", "target": "near-linear time", "depth": [1, 3]}, {"source": "partial differential equation", "target": "partial differential", "depth": [1, 2]}, {"source": "partial differential equation", "target": "differential equation", "depth": [1, 2]}, {"source": "partial differential equation", "target": "matrix equation technique", "depth": [1, 3]}, {"source": "partial differential equation", "target": "evolutionary partial differential", "depth": [1, 3]}, {"source": "continual learning", "target": "boosting approach", "depth": [1, 3]}, {"source": "continual learning", "target": "learning of va", "depth": [1, 3]}, {"source": "continual learning", "target": "approach for continual", "depth": [1, 3]}, {"source": "regularization", "target": "tackling algorithmic bia", "depth": [1, 3]}, {"source": "regularization", "target": "algorithmic bia", "depth": [1, 3]}, {"source": "regularization", "target": "bias in neural-network", "depth": [1, 3]}, {"source": "regularization", "target": "neural-network classifier", "depth": [1, 3]}, {"source": "action", "target": "fine-grained action retrieval", "depth": [1, 3]}, {"source": "action", "target": "retrieval through multiple", "depth": [1, 3]}, {"source": "action", "target": "action retrieval", "depth": [1, 3]}, {"source": "massive mimo", "target": "cell-free massive mimo", "depth": [1, 2]}, {"source": "massive mimo", "target": "channel estimation", "depth": [1, 2]}, {"source": "massive mimo", "target": "computing-enabled cell-free massive", "depth": [1, 3]}, {"source": "deep network", "target": "discretely-constrained deep network", "depth": [1, 3]}, {"source": "deep network", "target": "weakly supervised segmentation", "depth": [1, 3]}, {"source": "deep network", "target": "supervised segmentation", "depth": [1, 3]}, {"source": "deep network", "target": "network for weakly", "depth": [1, 3]}, {"source": "decomposition", "target": "shadow image decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "image decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "shadow removal", "depth": [1, 3]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "corpus for named", "depth": [1, 3]}, {"source": "named entity recognition", "target": "open data source", "depth": [1, 3]}, {"source": "named entity recognition", "target": "free open datum", "depth": [1, 3]}, {"source": "medium", "target": "benchmark of visual", "depth": [1, 3]}, {"source": "medium", "target": "visual storytelling", "depth": [1, 3]}, {"source": "medium", "target": "storytelling in social", "depth": [1, 3]}, {"source": "medium", "target": "benchmark", "depth": [1, 1]}, {"source": "bert", "target": "secrets of bert", "depth": [1, 3]}, {"source": "bert", "target": "dark secret", "depth": [1, 3]}, {"source": "bert", "target": "revealing the dark", "depth": [1, 3]}, {"source": "bert", "target": "dark", "depth": [1, 3]}, {"source": "automated", "target": "particle energy distribution", "depth": [1, 3]}, {"source": "automated", "target": "automated classification", "depth": [1, 3]}, {"source": "automated", "target": "particle energy", "depth": [1, 3]}, {"source": "automated", "target": "energy distribution", "depth": [1, 3]}, {"source": "massive mimo system", "target": "cell-free massive mimo", "depth": [1, 2]}, {"source": "massive mimo system", "target": "computing-enabled cell-free massive", "depth": [1, 3]}, {"source": "massive mimo system", "target": "edge computing-enabled cell-free", "depth": [1, 3]}, {"source": "massive mimo system", "target": "downlink channel prediction", "depth": [1, 3]}, {"source": "mimo system", "target": "cell-free massive mimo", "depth": [1, 2]}, {"source": "mimo system", "target": "computing-enabled cell-free massive", "depth": [1, 3]}, {"source": "mimo system", "target": "edge computing-enabled cell-free", "depth": [1, 3]}, {"source": "mimo system", "target": "downlink channel prediction", "depth": [1, 3]}, {"source": "gradient method", "target": "policy gradient method", "depth": [1, 3]}, {"source": "gradient method", "target": "bilinear zero-sum game", "depth": [1, 3]}, {"source": "gradient method", "target": "methods on bilinear", "depth": [1, 3]}, {"source": "gradient method", "target": "convergence of gradient", "depth": [1, 3]}, {"source": "data stream", "target": "incomplete data stream", "depth": [1, 3]}, {"source": "data stream", "target": "efficient join processing", "depth": [1, 3]}, {"source": "data stream", "target": "technical report", "depth": [1, 2]}, {"source": "machine", "target": "machine learning inference", "depth": [1, 3]}, {"source": "machine", "target": "uncheatable machine learning", "depth": [1, 3]}, {"source": "machine", "target": "learning inference", "depth": [1, 3]}, {"source": "constraint", "target": "linear stochastic bandit", "depth": [1, 3]}, {"source": "constraint", "target": "safety constraint", "depth": [1, 3]}, {"source": "constraint", "target": "stochastic bandit", "depth": [1, 3]}, {"source": "point", "target": "adversarial shape perturbation", "depth": [1, 3]}, {"source": "point", "target": "adversarial shape", "depth": [1, 3]}, {"source": "point", "target": "shape perturbation", "depth": [1, 3]}, {"source": "pose", "target": "objects without retraining", "depth": [1, 3]}, {"source": "pose", "target": "generic", "depth": [1, 3]}, {"source": "pose", "target": "cornet", "depth": [1, 3]}, {"source": "pose", "target": "corner", "depth": [1, 3]}, {"source": "reinforcement", "target": "world model", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning with world", "depth": [1, 3]}, {"source": "reinforcement", "target": "world", "depth": [1, 2]}, {"source": "reinforcement", "target": "learning in healthcare", "depth": [1, 3]}, {"source": "text generation", "target": "deep latent variable", "depth": [1, 3]}, {"source": "text generation", "target": "latent variable model", "depth": [1, 3]}, {"source": "text generation", "target": "implicit deep latent", "depth": [1, 3]}, {"source": "text generation", "target": "deep latent", "depth": [1, 3]}, {"source": "smart contract", "target": "listed smart contract", "depth": [1, 3]}, {"source": "smart contract", "target": "contracts in ethereum", "depth": [1, 3]}, {"source": "smart contract", "target": "empirical study", "depth": [1, 2]}, {"source": "smart contract", "target": "success of listed", "depth": [1, 3]}, {"source": "text summarization", "target": "extractive text summarization", "depth": [1, 3]}, {"source": "text summarization", "target": "exploring domain shift", "depth": [1, 3]}, {"source": "text summarization", "target": "domain shift", "depth": [1, 3]}, {"source": "kernel", "target": "lens of kernel", "depth": [1, 3]}, {"source": "kernel", "target": "unified understanding", "depth": [1, 3]}, {"source": "kernel", "target": "transformer dissection", "depth": [1, 3]}, {"source": "communication", "target": "markovian arrival", "depth": [1, 3]}, {"source": "communication", "target": "communications with markovian", "depth": [1, 3]}, {"source": "communication", "target": "energy-efficient communication", "depth": [1, 3]}, {"source": "matching", "target": "matching with contract", "depth": [1, 3]}, {"source": "matching", "target": "preferences for matching", "depth": [1, 3]}, {"source": "matching", "target": "revealed preference", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "multimodal sentiment analysis", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "fusion for multimodal", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "multimodal sentiment", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "variational fusion", "depth": [1, 3]}, {"source": "theorem", "target": "basic triangle theorem", "depth": [1, 3]}, {"source": "theorem", "target": "triangle theorem", "depth": [1, 3]}, {"source": "theorem", "target": "localized version", "depth": [1, 3]}, {"source": "implementation", "target": "multi-bernoulli mixture filter", "depth": [1, 3]}, {"source": "implementation", "target": "gaussian implementation", "depth": [1, 3]}, {"source": "implementation", "target": "mixture filter", "depth": [1, 3]}, {"source": "feature selection", "target": "exploiting semantic knowledge", "depth": [1, 3]}, {"source": "feature selection", "target": "zero-shot feature selection", "depth": [1, 3]}, {"source": "feature selection", "target": "semantic knowledge", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 2]}, {"source": "image segmentation", "target": "robustifying deep network", "depth": [1, 3]}, {"source": "image segmentation", "target": "robustifying deep", "depth": [1, 3]}, {"source": "benchmark", "target": "benchmark of visual", "depth": [1, 3]}, {"source": "benchmark", "target": "visual storytelling", "depth": [1, 3]}, {"source": "benchmark", "target": "storytelling in social", "depth": [1, 3]}, {"source": "cellular network", "target": "underlay cellular network", "depth": [1, 3]}, {"source": "cellular network", "target": "multicasts in underlay", "depth": [1, 3]}, {"source": "cellular network", "target": "multiple", "depth": [1, 2]}, {"source": "lower bound", "target": "probabilistic lower bound", "depth": [1, 3]}, {"source": "lower bound", "target": "beating the probabilistic", "depth": [1, 3]}, {"source": "lower bound", "target": "perfect hashing", "depth": [1, 3]}, {"source": "word embedding", "target": "word", "depth": [1, 2]}, {"source": "cloud", "target": "quantum many-body system", "depth": [1, 3]}, {"source": "cloud", "target": "amazon cloud", "depth": [1, 3]}, {"source": "cloud", "target": "systems on amazon", "depth": [1, 3]}, {"source": "cloud", "target": "simulation of quantum", "depth": [1, 3]}, {"source": "synthesis", "target": "regular expression", "depth": [1, 2]}, {"source": "synthesis", "target": "synthesis of regular", "depth": [1, 3]}, {"source": "synthesis", "target": "multi-modal synthesis", "depth": [1, 3]}, {"source": "synthesis", "target": "expression", "depth": [1, 3]}, {"source": "named entity", "target": "corpus for named", "depth": [1, 3]}, {"source": "named entity", "target": "open data source", "depth": [1, 3]}, {"source": "named entity", "target": "free open datum", "depth": [1, 3]}, {"source": "named entity", "target": "data source", "depth": [1, 2]}, {"source": "aggregation network", "target": "pixel aggregation network", "depth": [1, 3]}, {"source": "aggregation network", "target": "accurate arbitrary-shaped text", "depth": [1, 3]}, {"source": "aggregation network", "target": "arbitrary-shaped text detection", "depth": [1, 3]}, {"source": "time series", "target": "time series classification", "depth": [1, 3]}, {"source": "time series", "target": "accurate time series", "depth": [1, 3]}, {"source": "time series", "target": "early and accurate", "depth": [1, 3]}, {"source": "computational", "target": "computational perspective", "depth": [1, 3]}, {"source": "computational", "target": "fairness in deep", "depth": [1, 3]}, {"source": "computational", "target": "perspective", "depth": [1, 2]}, {"source": "computational", "target": "survey on computational", "depth": [1, 3]}, {"source": "imaging", "target": "ultrasound imaging", "depth": [1, 3]}, {"source": "imaging", "target": "signal recovery", "depth": [1, 3]}, {"source": "imaging", "target": "recovery with application", "depth": [1, 3]}, {"source": "imaging", "target": "applications in ultrasound", "depth": [1, 3]}, {"source": "comparison", "target": "visual cue", "depth": [1, 3]}, {"source": "comparison", "target": "cues in estimation", "depth": [1, 3]}, {"source": "comparison", "target": "cue", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian inference", "depth": [1, 2]}, {"source": "bayesian", "target": "information cascade", "depth": [1, 3]}, {"source": "bayesian", "target": "inference of network", "depth": [1, 3]}, {"source": "bayesian", "target": "network structure", "depth": [1, 3]}, {"source": "augmented reality", "target": "augmented reality haploscope", "depth": [1, 3]}, {"source": "augmented reality", "target": "reality haploscope", "depth": [1, 3]}, {"source": "augmented reality", "target": "assembly", "depth": [1, 3]}, {"source": "environment", "target": "soft growing robot", "depth": [1, 3]}, {"source": "environment", "target": "soft growing", "depth": [1, 3]}, {"source": "environment", "target": "growing robot", "depth": [1, 3]}, {"source": "environment", "target": "robot by exploiting", "depth": [1, 3]}, {"source": "user", "target": "user dwell time", "depth": [1, 3]}, {"source": "user", "target": "user dwell", "depth": [1, 3]}, {"source": "user", "target": "dwell time", "depth": [1, 3]}, {"source": "attack", "target": "neuroimaging dataset", "depth": [1, 3]}, {"source": "attack", "target": "attacks on neuroimaging", "depth": [1, 3]}, {"source": "attack", "target": "de-anonymization attack", "depth": [1, 3]}, {"source": "attack", "target": "neuroimaging", "depth": [1, 3]}, {"source": "systematic review", "target": "natural language processing", "depth": [1, 2]}, {"source": "systematic review", "target": "chronic disease", "depth": [1, 3]}, {"source": "systematic review", "target": "language processing", "depth": [1, 2]}, {"source": "tree", "target": "competitive online search", "depth": [1, 3]}, {"source": "tree", "target": "online search tree", "depth": [1, 3]}, {"source": "tree", "target": "online search", "depth": [1, 3]}, {"source": "tree", "target": "competitive online", "depth": [1, 3]}]}