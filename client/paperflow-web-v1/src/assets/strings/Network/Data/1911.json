{"node": [["neural network", "convolutional neural network", "deep neural network", "network", "learning", "reinforcement learning", "machine learning", "graph", "deep reinforcement learning", "deep learning", "system", "model", "machine translation", "algorithm", "detection", "object detection", "generative adversarial network", "datum", "analysi"], ["recurrent neural network", "graph neural network", "machine", "federated learning", "representation", "convolutional network", "graph convolutional network", "deep reinforcement", "inverse reinforcement learning", "reinforcement", "autonomous driving", "deep learning model", "deep", "deep learning approach", "deep learning based", "learning model", "language model", "language", "generative model", "neural machine translation", "neural machine", "translation", "problem", "graph convolutional", "object", "generative adversarial", "adversarial network", "sentiment", "sentiment analysi", "resource allocation", "domain adaptation", "unsupervised domain adaptation", "unsupervised domain", "semantic segmentation", "image", "single image", "distributed", "pretrained language model", "pretrained language", "quantum", "embedding", "word embedding", "generation", "question generation", "text generation", "recognition", "speech recognition", "efficient", "classification", "transfer learning", "dataset", "document", "federated", "privacy", "differential privacy", "optimization", "segmentation", "instance segmentation", "knowledge distillation", "neural architecture search", "architecture search", "neural architecture", "distillation", "knowledge", "representation learning", "question answering", "communication", "knowledge graph", "knowledge graph embedding", "graph embedding", "model predictive control", "predictive control", "model predictive", "lower bound", "bound", "time series", "time series forecasting", "inference", "function", "sparse", "approximation", "speech", "pose estimation", "estimation", "active learning", "code", "polar code", "point cloud", "game", "anomaly detection", "adversarial attack", "security", "search", "survey", "clustering", "program", "approach", "learning approach", "navigation", "multi-task learning", "face recognition", "artificial intelligence", "imaging", "challenge", "social network", "complexity", "training", "framework", "domain", "relation extraction", "case study", "deep network", "online learning", "fast", "deep generative model", "deep generative", "natural language", "natural language processing", "internet of thing", "finite element", "finite element method", "control system", "source separation", "audio source separation", "study", "learn", "polynomial", "bert", "relational", "sampling", "semi-supervised learning", "reasoning", "transformer", "attention network", "type", "person re-identification", "attack", "parsing", "point", "matching", "application", "prediction", "testing", "property", "named entity recognition", "named entity", "entity recognition", "method", "shape", "metric learning", "evaluation", "performance", "synthesi", "text", "gradient", "retrieval", "distribution", "feature", "bayesian", "social medium", "los", "wireless network", "market", "logic", "image segmentation", "medical image segmentation", "task", "perspective", "theory", "question", "reading comprehension", "autonomous vehicle", "information", "relation", "optimal power flow", "optimal power", "power flow", "robustnes", "time", "programming", "recommendation", "adversarial learning", "evolution", "gradient descent", "action recognition", "decision making", "kernel", "emotion recognition", "secure", "decision tree", "document retrieval", "extended version", "smart grid", "computing", "architecture", "artificial neural network", "conjecture", "subspace", "alternative", "length", "smart contract", "supervision", "concept", "communication system", "design", "monte carlo", "convolution network", "graph convolution network", "dynamical system", "image generation", "gaussian proces", "understanding", "linear system", "coding", "minimization", "detection system", "bayesian optimization", "optical flow", "compression", "asr", "supervised learning", "attention", "learning technique", "simulation", "blockchain", "review", "video captioning", "adaptation", "map", "random", "robust", "optimal control", "generalized", "robot", "allocation", "retinal vessel segmentation", "vessel segmentation", "retinal vessel", "consistency", "policy", "path"], ["network flow", "machine learning model", "machine learning based", "model robustnes", "learning system", "multi-agent system", "deep learning system", "deep convolutional neural", "detection using convolutional", "graph convolutional neural", "training deep neural", "training deep", "machine translation evaluation", "experimental", "salient object detection", "bounding box", "salient object", "adversarial domain adaptation", "adversarial domain", "compressed representation", "image synthesi", "distributed representation", "graph representation", "few-shot learning", "deep image", "data generation", "deep transfer learning", "transfer", "comprehensive survey", "comprehensive", "bayesian recurrent neural", "bayesian recurrent", "large-scale dataset", "attacks and defense", "structured", "community question answering", "community question", "answering", "limited datum", "molecular communication", "molecular", "adaptive model predictive", "robust adaptive model", "robust adaptive", "dyck language", "local differential privacy", "bayesian differential privacy", "bayesian differential", "time series analysi", "series analysi", "multi-person pose estimation", "hand pose estimation", "pose", "materials discovery", "subspace code", "network for point", "point cloud classification", "cloud", "parameter", "gaussian process model", "learning in network", "edge computing", "self-supervised learning", "quantum program", "issue", "reinforcement learning approach", "deep multi-task learning", "deep multi-task", "online social network", "monocular", "multiple", "neural relation", "upper bound", "face recognition system", "recognition system", "distributed online learning", "distributed online", "natural language generation", "language generation", "language processing", "neural network inference", "network inference", "element method", "galerkin finite element", "discontinuous galerkin finite", "speech to text", "networked control system", "networked control", "separation", "randomly weighted", "determinant", "graph transformer", "transform", "user experience", "re-identification", "network for person", "defense", "emotion", "semantic parsing", "square", "set", "convex", "group testing", "adaptive group testing", "adaptive group", "e-commerce", "deep metric learning", "deep metric", "learning algorithm", "evaluation of deep", "translation evaluation", "configuration", "normalizing flow", "phase retrieval", "note", "bayesian learning", "efficiency", "packet los", "energy efficiency", "stock market", "view", "medical image", "vehicle", "dynamic environment", "neural text", "submodularity", "adversarial robustnes", "stochastic gradient descent", "making", "dynamic regret", "opportunity", "multimodal emotion recognition", "multimodal emotion", "recognition model", "phase", "knowledge base", "answer", "grid", "trading", "convolution", "neural network approach", "learning dataset", "learning based", "learning based channel", "communication channel", "subspace clustering", "cross entropy", "contract", "smart", "expected", "prototype", "monte carlo method", "graph convolution", "unsupervised learning", "joint learning", "lip reading", "cross-modal", "reading", "delta lense", "transport network", "model selection", "machine learning technique", "linear", "literature review", "summary", "tracking", "random walk", "walk", "control for autonomou", "behavior", "fair allocation", "fully convolutional network", "sensor network"], ["improving model robustnes", "security threat", "threats of deep", "detecting total hip", "total hip replacement", "shift rejection", "statistics or normalization", "train deep neural", "newton-raphson algorithm", "choice of initial", "initial guess", "dual-attention graph convolutional", "dual-attention graph", "tracking and visual", "gravitational finger", "geometry-driven detection", "anchor-point object detection", "sparsity-constrained generative adversarial", "retinal oct image", "oct image", "observational datum", "derivative discontinuity", "discontinuities in observational", "detection of derivative", "discontinuity", "multi-task model", "emotion analysi", "model for sentiment", "reinforcement learning applied", "interactive fiction", "improvements for deep", "remote sensing imagery", "weighted tsetlin machine", "tsetlin machine", "weighted clause", "weighted tsetlin", "layer-wise domain mixing", "adaptive layer-wise domain", "multi-domain neural machine", "metasurface optimization", "networks for metasurface", "semantic region-adaptive normalization", "synthesis with semantic", "region-adaptive normalization", "multi-level and classifier-centric", "common sense knowledge", "masked neural language", "sequential ordering problem", "ordering problem", "tree search algorithm", "sequential ordering", "information-geometric set embedding", "probability distribution", "set embedding", "information-geometric set", "deep autofocu", "consistency constraint", "autofocus with cone-beam", "cone-beam ct consistency", "word-level adaptive layer-wise", "generation for neural", "neural programming", "uncooperative environment", "recognition in uncontrolled", "uncontrolled and uncooperative", "binary labeling problem", "distributed binary labeling", "classification of distributed", "labeling problem", "binary labeling", "survey on transfer", "intermediate dense supervision", "alignment-based process anomaly", "process anomaly correction", "alignment-based proces", "dataset for keyphrase", "keyphrase generation", "kptime", "free-riders in federated", "decomposed structured subset", "structured subset", "subsets for semidefinite", "decomposed structured", "visualisation of environment", "apple orchard", "fruit detection", "cross-modal unsupervised domain", "xmuda", "cover change detection", "time representation learning", "functional time representation", "functional time", "time representation", "self-attention with functional", "adaptation from limited", "leveraging sensing", "mmwave communication", "infrastructure for mmwave", "product knowledge graph", "embedding for e-commerce", "product knowledge", "algorithmic improvement", "learning for trading", "quantum lower bound", "quantum lower", "approximating sensitive attribute", "los angele", "analysis to traffic", "multi-view consistent inference", "shape completion", "consistent inference", "completion with multi-view", "multi-view consistent", "pose-based graph convolutional", "graph language", "word embedding based", "low-resourced language", "corpus for low-resourced", "sindhi", "embedding based", "sparse approximation", "individual function", "approximation of individual", "bayes risk training", "minimum bayes risk", "bayes risk", "risk training", "framework for unconstrained", "multi-objective materials discovery", "model accuracy", "discovery and optimization", "assessing the frontier", "gated hypernet decoder", "gated hypernet", "hypernet decoder", "scene flow estimation", "self-supervised scene flow", "population of parameter", "estimation of change", "optimal estimation", "change", "playing game", "approach for cross-modality", "cross-modality transfer", "transfer in reinforcement", "dark", "economic model predictive", "economic model", "learning-based model predictive", "neuromorphic event-based anomaly", "event-based anomaly detection", "event-based anomaly", "evan", "streaming datum", "network security", "threat of adversarial", "attacks on machine", "personal email search", "email search", "cross-modal audio-video clustering", "audio-video clustering", "learning by cross-modal", "cross-modal audio-video", "oracle knowledge distillation", "oracle knowledge", "distillation with neural", "supervised neural architecture", "dissemination platform", "platform for deep", "modelhub.ai", "runtime of quantum", "expected runtime", "runtime", "joint user association", "heterogeneous network", "user association", "association and resource", "uplink of heterogeneou", "blockwisely supervised neural", "systemic issue", "structural approach", "ethics for systemic", "conquer approach", "mapless navigation", "printable stabilizer system", "efficient deep multi-task", "share for efficient", "dense supervision", "language-independent sentiment analysi", "positional information", "analysis using subjectivity", "subjectivity and positional", "light-weight calibrator", "separable component", "challenges and advance", "glioma imaging", "intelligence in glioma", "multiple social network", "algebraic analysi", "networks with multiplex", "analysis of multiple", "alphabet reordering", "minimization via alphabet", "complexity of bwt-run", "bwt-runs minimization", "reordering", "robust tacotron-based tt", "tacotron-based tt", "training for robust", "teacher-student training", "tt", "unconstrained monocular", "hand pose", "translation across multiple", "multiple domain", "unsupervised", "neural relation extraction", "improving neural relation", "unlabeled learning", "extraction with positive", "spatiotemporal deep learning", "citywide air pollution", "air pollution interpolation", "spatiotemporal deep", "interpolation and prediction", "intelligent transportation system", "regularized deep network", "transportation system", "networks in intelligent", "causal knowledge", "robustness using causal", "empirical upper bound", "bound in object", "empirical upper", "template-based face recognition", "classification-selection approach", "updating of template-based", "adaptive communication bound", "communication bound", "bounds for distributed", "backpropagating learned los", "fast adaptation", "learned los", "adaptation via backpropagating", "backpropagating learned", "learning with bayesian", "context-aware local differential", "multi-modal deep generative", "autoencoders for multi-modal", "variational", "principled regularized optimization", "energy-efficient neural network", "open-source toolkit", "toolkit for energy-efficient", "music source separation", "automatic object removal", "autonomous driving video", "automatic object", "driving video", "object removal", "rosenau equation", "multimodal machine translation", "visuals and speech", "multimodal machine", "improving voice separation", "recognition of graph", "efficient recognition", "embedded mpc", "calibration of embedded", "self-triggered control system", "lipschitz perturbation", "analysis of infinite-dimensional", "randomly weighted u-net", "j-net", "curiosity-driven question generation", "study on curiosity-driven", "curiosity-driven question", "soft anchor-point object", "soft anchor-point", "one-shot object detection", "detection with co-attention", "small formula", "schur", "formula", "computing permutation polynomial", "inducing relational knowledge", "knowledge from bert", "relational knowledge", "lexical semantics task", "probabilistic watershed", "sampling all spanning", "watershed", "spanning forest", "accurate vision-based manipulation", "contact reasoning", "vision-based manipulation", "manipulation through contact", "case-based reasoning", "elsa", "layers during transformer", "freezing layer", "transformer fine-tuning", "coding on cascaded", "multi-modal attention network", "multi-modal attention", "perceive", "price type", "impact on user", "collecting charge", "charge", "video-based person re-identification", "rethinking temporal fusion", "time aspect", "modelling load-changing attack", "sentiment and emotion", "parsing with derivative", "derivatives and zipper", "zipper", "weak and active", "orientation among point", "squares in arbitrary", "arbitrary orientation", "empty square", "self-attention based graph", "based graph neural", "hyper-sagnn", "network for hypergraph", "based graph", "statistical model aggregation", "parameter matching", "model aggregation", "aggregation via parameter", "statistical model", "kruskal-katona for convex", "convex set", "kruskal-katona", "incoming node", "prediction of graph", "graph signal", "signals with incoming", "recursive prediction", "optimal adaptive group", "cross-lingual named entity", "improving scientific named", "scientific named entity", "itlnc-bxe", "method with multiple", "plant lncrna", "multiple feature", "features for identification", "metric learning algorithm", "discourse structure", "structure for machine", "discotk", "software configuration", "silver bullet", "performance of software", "predicting performance", "component for unsupervised", "flows for one-shot", "synthesis of expressive", "expressive speech", "vaes and normalizing", "mixed discontinuous galerkin", "biharmonic equation", "adaptive nystr\u00f6m approximation", "nystr\u00f6m approximation", "networks with adaptive", "adaptive nystr\u00f6m", "presenting an experimental", "experimental dataset", "sorani", "kurdish", "note on douglas-rachford", "douglas-rachford", "hierarchical low-rank structure", "parameterized distribution", "low-rank structure", "structure of parameterized", "hierarchical low-rank", "feature discriminativity estimation", "feature discriminativity", "discriminativity estimation", "estimation in cnn", "cnns for transfer", "improving scientific", "efficiency of bayesian", "aggregative efficiency", "medium", "social media text", "vietnamese social medium", "vietnamese social", "leveraging social medium", "multi-document question generation", "contrastive multi-document question", "multi-document question", "contrastive multi-document", "multi-document", "adversarial inverse reinforcement", "maximum causal entropy", "entropy inverse reinforcement", "compatible reward inverse", "reward inverse reinforcement", "data-imbalanced nlp task", "nlp task", "loss for data-imbalanced", "data-imbalanced nlp", "energy efficiency maximization", "weighted-sum energy efficiency", "efficiency maximization", "maximization in wireles", "serverless seismic imaging", "seismic imaging", "serverles", "universal cnn-based predictor", "predictor for stock", "u-cnnpred", "cnn-based predictor", "geometrical view", "paraconsistent logic", "arguing ecosystem", "ecosystem", "bug detection", "representation of code", "code for bug", "smoothed analysi", "predictive uncertainty estimation", "deep medical image", "calibration and predictive", "testing linear-invariant property", "linear-invariant property", "set invariance property", "data-based guarantee", "invariance property", "dice los", "perspectives on urban", "urban theory", "rating system", "bribery in rating", "questions in movieqa", "movieqa", "answering natural question", "natural question", "strategies for answering", "reducing catastrophic forgetting", "catastrophic forgetting", "forgetting for domain", "adaptation in reading", "interpretable multi-hop reading", "multi-modal deep", "detecting driveable area", "driveable area", "area for autonomou", "neural text generation", "submodularity for neural", "resurrecting submodularity", "language-independent sentiment", "permutation polynomial", "relations for computing", "computing permutation", "equivalence relation", "facilitating grid integration", "stochastic optimal power", "network reconfiguration", "supervised cell instance", "cell instance segmentation", "weakly supervised cell", "detection response", "supervised cell", "robustness in neural", "domain robustnes", "robustness against adversarial", "ultrasound-enhanced multimodal imaging", "real-time ultrasound-enhanced multimodal", "printable stabilizer", "stabilizer system", "block preconditioner", "nonsymmetric problem", "preconditioners for nonsymmetric", "krylov", "fixed-point", "robot behavior", "programming of robot", "protection using adversarial", "privacy-aware recommendation", "recommendation with private-attribute", "private-attribute protection", "iot traffic characterization", "cellular iot traffic", "characterization and evolution", "traffic characterization", "iot traffic", "blocklength polar code", "short blocklength polar", "low latency decoder", "latency decoder", "decoder for short", "adaptive asynchronous parallel", "asynchronous parallel stochastic", "parallel stochastic gradient", "adaptive asynchronou", "unsupervised skeleton based", "based action recognition", "skeleton based action", "unsupervised skeleton", "skeleton based", "improving convolution-based knowledge", "quantization-aware knowledge distillation", "quantization-aware knowledge", "qkd", "quantization-aware", "cross-modal distillation", "keyphrase", "robust federated learning", "noisy communication", "online decision making", "understand dynamic regret", "regret with switching", "advance", "communication-efficient distributed online", "learning with kernel", "svm training", "emotion recognition model", "physiological signal", "secure cross-channel transfer", "channel hub", "transfers via channel", "secure cross-channel", "boro", "congestion management", "distributed optimal power", "longer quantum time", "hybrid decision tree", "longer quantum", "strictly more powerful", "quantum time", "sparql query", "base", "sparql", "admm for distributed", "distributed optimal", "learning-accelerated admm", "power flow analysi", "memory-one strategy", "theory of mind", "mind to find", "future smart grid", "future smart", "blockchain for future", "dissipativity in economic", "steady-state optimality", "real-time model predictive", "goal-oriented agent-based simulation", "agent-based simulation framework", "agent-based simulation", "high-performance computing", "simulation framework", "learn logic program", "forgetting to learn", "control-tutored reinforcement learning", "herding problem", "control-tutored reinforcement", "efficient convolutional architecture", "convolutional architecture", "convolution for efficient", "comb convolution", "integrated mathematical modeling", "limited learning dataset", "mathematical modeling", "turbo autoencoder", "based channel code", "forests for seeded", "zero-resource cross-lingual named", "common entity recognition", "fine-grained science-domain corpu", "corpus for common", "reed conjecture", "local epsilon version", "version of reed", "local epsilon", "epsilon version", "graph embedding method", "neural graph embedding", "embedding method", "methods for natural", "clustering with active", "combining subspace code", "combining subspace", "act", "alternative metric", "alternative cross entropy", "cross entropy los", "alternative cros", "sequences of length", "constructions of complementary", "complementary set", "sets of sequence", "generalized construction", "securing smart contract", "securing smart", "fly", "relational datum", "models over relational", "diverse supervision", "full potential", "potential of small", "small datum", "data with diverse", "weighted u-net", "online spectrogram inversion", "trainable communication system", "concepts and prototype", "trainable communication", "deaf-oriented accessibility", "inclusive design", "accessibility", "concrete", "optimal layout design", "predictive uncertainty", "carlo method", "multilevel monte carlo", "multilevel monte", "neuronal ensemble inference", "driving acceleration", "networks for probabilistic", "probabilistic modeling", "order dynamical system", "coverage of compact", "compact domain", "safe coverage", "modeling dynamical system", "intrinsic image decomposition", "learning for intrinsic", "intrinsic image", "image decomposition", "resistant deep convolutional", "deep convolutional gan", "collapse resistant deep", "multi-object image generation", "resistant deep", "gaussian process dynamic", "learning gaussian proces", "actively learning gaussian", "process dynamic", "actively learning", "long document understanding", "document understanding", "long document", "self-attention for long", "blockwise self-attention", "task-oriented representation", "integer linear system", "reconfiguration problem", "problem of integer", "integer linear", "trichotomy", "cyber security", "sparse coding", "cascaded", "quantum coding", "local testability", "adaption object detection", "object detection system", "model adaption object", "system for robot", "adaption object", "category-specific continuous input", "continuous input", "optimization for categorical", "categorical and category-specific", "category-specific continuou", "legal document retrieval", "topic hierarchies based", "legal document", "retrieval across language", "topic hierarchy", "frame count", "learning of video", "video segmentation", "segmentation and optical", "compression of convolutional", "data-driven compression", "model compression", "pruning for model", "graph pruning", "distillation for lip", "general supervised learning", "general supervised", "learning as change", "change propagation", "collaborative attention network", "collaborative attention", "dense traffic", "scalable time series", "selection for scalable", "scalable time", "backscatter communication system", "real time datum", "short term prediction", "parking area state", "term prediction", "local-ancestry simulation", "class-conditional vae-gan", "vae-gan for local-ancestry", "local-ancestry", "molecular simulation", "linear consistency", "multivocal literature review", "systematic multivocal literature", "review summary", "summary for sentiment", "captioning", "characterizing the impact", "features extracted", "extracted from pre-trained", "quality of video", "style consistency", "adaptation for object", "detection via style", "modeling of driving", "tracking and forecasting", "rich map", "forecasting with rich", "argoverse", "walks on hypergraph", "hypergraph", "neural random", "robust judgement aggregation", "judgement aggregation", "testing and robust", "robust judgement", "aggregation", "vehicles in arbitrary", "arbitrary and dynamic", "time-dependent hybrid-state", "generalized transformation-based gradient", "transformation-based gradient", "generalized speedy q-learning", "speedy q-learning", "generalized speedy", "verbal programming", "verbal", "selective information acquisition", "information acquisition", "allocation through selective", "selective information", "u-net on retinal", "vessel", "vessel segmentation based", "compact hybrid network", "semantic sensor network", "policy editor", "editor for semantic", "semantic sensor", "wide network path", "network path", "wide network", "short and wide", "knowledge base completion", "prior distribution choice", "document-level neural machine", "birds can talk", "misprimed probe", "probes for pretrained", "negated and misprimed"]], "link": [{"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "machine", "depth": [0, 1]}, {"source": "learning", "target": "federated learning", "depth": [0, 1]}, {"source": "learning", "target": "representation", "depth": [0, 1]}, {"source": "network", "target": "convolutional network", "depth": [0, 1]}, {"source": "network", "target": "network flow", "depth": [0, 2]}, {"source": "network", "target": "graph", "depth": [0, 0]}, {"source": "network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "network", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "inverse reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "autonomous driving", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 1]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "system", "depth": [0, 0]}, {"source": "machine learning", "target": "machine learning model", "depth": [0, 2]}, {"source": "machine learning", "target": "learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning based", "depth": [0, 2]}, {"source": "model", "target": "model robustnes", "depth": [0, 2]}, {"source": "model", "target": "language model", "depth": [0, 1]}, {"source": "model", "target": "language", "depth": [0, 1]}, {"source": "model", "target": "generative model", "depth": [0, 1]}, {"source": "model", "target": "improving model robustnes", "depth": [0, 3]}, {"source": "system", "target": "learning system", "depth": [0, 2]}, {"source": "system", "target": "multi-agent system", "depth": [0, 2]}, {"source": "system", "target": "deep learning system", "depth": [0, 2]}, {"source": "system", "target": "security threat", "depth": [0, 3]}, {"source": "system", "target": "threats of deep", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "detection using convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "graph convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "detecting total hip", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "total hip replacement", "depth": [0, 3]}, {"source": "deep neural network", "target": "training deep neural", "depth": [0, 2]}, {"source": "deep neural network", "target": "training deep", "depth": [0, 2]}, {"source": "deep neural network", "target": "shift rejection", "depth": [0, 3]}, {"source": "deep neural network", "target": "statistics or normalization", "depth": [0, 3]}, {"source": "deep neural network", "target": "train deep neural", "depth": [0, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [0, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [0, 1]}, {"source": "machine translation", "target": "translation", "depth": [0, 1]}, {"source": "machine translation", "target": "machine", "depth": [0, 1]}, {"source": "machine translation", "target": "machine translation evaluation", "depth": [0, 2]}, {"source": "algorithm", "target": "problem", "depth": [0, 1]}, {"source": "algorithm", "target": "experimental", "depth": [0, 2]}, {"source": "algorithm", "target": "newton-raphson algorithm", "depth": [0, 3]}, {"source": "algorithm", "target": "choice of initial", "depth": [0, 3]}, {"source": "algorithm", "target": "initial guess", "depth": [0, 3]}, {"source": "graph", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "graph", "target": "dual-attention graph convolutional", "depth": [0, 3]}, {"source": "graph", "target": "convolutional network", "depth": [0, 1]}, {"source": "graph", "target": "graph convolutional", "depth": [0, 1]}, {"source": "graph", "target": "dual-attention graph", "depth": [0, 3]}, {"source": "detection", "target": "object detection", "depth": [0, 0]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "tracking and visual", "depth": [0, 3]}, {"source": "detection", "target": "gravitational finger", "depth": [0, 3]}, {"source": "detection", "target": "geometry-driven detection", "depth": [0, 3]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "salient object detection", "depth": [0, 2]}, {"source": "object detection", "target": "bounding box", "depth": [0, 2]}, {"source": "object detection", "target": "salient object", "depth": [0, 2]}, {"source": "object detection", "target": "anchor-point object detection", "depth": [0, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [0, 1]}, {"source": "generative adversarial network", "target": "sparsity-constrained generative adversarial", "depth": [0, 3]}, {"source": "generative adversarial network", "target": "retinal oct image", "depth": [0, 3]}, {"source": "generative adversarial network", "target": "oct image", "depth": [0, 3]}, {"source": "datum", "target": "observational datum", "depth": [0, 3]}, {"source": "datum", "target": "derivative discontinuity", "depth": [0, 3]}, {"source": "datum", "target": "discontinuities in observational", "depth": [0, 3]}, {"source": "datum", "target": "detection of derivative", "depth": [0, 3]}, {"source": "datum", "target": "discontinuity", "depth": [0, 3]}, {"source": "analysi", "target": "sentiment", "depth": [0, 1]}, {"source": "analysi", "target": "sentiment analysi", "depth": [0, 1]}, {"source": "analysi", "target": "multi-task model", "depth": [0, 3]}, {"source": "analysi", "target": "emotion analysi", "depth": [0, 3]}, {"source": "analysi", "target": "model for sentiment", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "resource allocation", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning applied", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "interactive fiction", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "improvements for deep", "depth": [0, 3]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "sparsity-constrained generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "retinal oct image", "depth": [1, 3]}, {"source": "adversarial network", "target": "oct image", "depth": [1, 3]}, {"source": "adversarial network", "target": "remote sensing imagery", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "adversarial domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adversarial domain", "depth": [1, 2]}, {"source": "machine", "target": "weighted tsetlin machine", "depth": [1, 3]}, {"source": "machine", "target": "tsetlin machine", "depth": [1, 3]}, {"source": "machine", "target": "compressed representation", "depth": [1, 2]}, {"source": "machine", "target": "weighted clause", "depth": [1, 3]}, {"source": "machine", "target": "weighted tsetlin", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "layer-wise domain mixing", "depth": [1, 3]}, {"source": "neural machine translation", "target": "adaptive layer-wise domain", "depth": [1, 3]}, {"source": "neural machine translation", "target": "multi-domain neural machine", "depth": [1, 3]}, {"source": "generative adversarial", "target": "sparsity-constrained generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "retinal oct image", "depth": [1, 3]}, {"source": "generative adversarial", "target": "oct image", "depth": [1, 3]}, {"source": "generative adversarial", "target": "metasurface optimization", "depth": [1, 3]}, {"source": "generative adversarial", "target": "networks for metasurface", "depth": [1, 3]}, {"source": "image", "target": "single image", "depth": [1, 1]}, {"source": "image", "target": "semantic region-adaptive normalization", "depth": [1, 3]}, {"source": "image", "target": "image synthesi", "depth": [1, 2]}, {"source": "image", "target": "synthesis with semantic", "depth": [1, 3]}, {"source": "image", "target": "region-adaptive normalization", "depth": [1, 3]}, {"source": "representation", "target": "distributed representation", "depth": [1, 2]}, {"source": "representation", "target": "distributed", "depth": [1, 1]}, {"source": "representation", "target": "graph representation", "depth": [1, 2]}, {"source": "representation", "target": "few-shot learning", "depth": [1, 2]}, {"source": "representation", "target": "multi-level and classifier-centric", "depth": [1, 3]}, {"source": "language model", "target": "pretrained language model", "depth": [1, 1]}, {"source": "language model", "target": "pretrained language", "depth": [1, 1]}, {"source": "language model", "target": "language", "depth": [1, 1]}, {"source": "language model", "target": "common sense knowledge", "depth": [1, 3]}, {"source": "language model", "target": "masked neural language", "depth": [1, 3]}, {"source": "problem", "target": "quantum", "depth": [1, 1]}, {"source": "problem", "target": "sequential ordering problem", "depth": [1, 3]}, {"source": "problem", "target": "ordering problem", "depth": [1, 3]}, {"source": "problem", "target": "tree search algorithm", "depth": [1, 3]}, {"source": "problem", "target": "sequential ordering", "depth": [1, 3]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "information-geometric set embedding", "depth": [1, 3]}, {"source": "embedding", "target": "probability distribution", "depth": [1, 3]}, {"source": "embedding", "target": "set embedding", "depth": [1, 3]}, {"source": "embedding", "target": "information-geometric set", "depth": [1, 3]}, {"source": "deep", "target": "deep image", "depth": [1, 2]}, {"source": "deep", "target": "deep autofocu", "depth": [1, 3]}, {"source": "deep", "target": "consistency constraint", "depth": [1, 3]}, {"source": "deep", "target": "autofocus with cone-beam", "depth": [1, 3]}, {"source": "deep", "target": "cone-beam ct consistency", "depth": [1, 3]}, {"source": "neural machine", "target": "translation", "depth": [1, 1]}, {"source": "neural machine", "target": "layer-wise domain mixing", "depth": [1, 3]}, {"source": "neural machine", "target": "adaptive layer-wise domain", "depth": [1, 3]}, {"source": "neural machine", "target": "multi-domain neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "word-level adaptive layer-wise", "depth": [1, 3]}, {"source": "generation", "target": "question generation", "depth": [1, 1]}, {"source": "generation", "target": "text generation", "depth": [1, 1]}, {"source": "generation", "target": "generation for neural", "depth": [1, 3]}, {"source": "generation", "target": "neural programming", "depth": [1, 3]}, {"source": "generation", "target": "data generation", "depth": [1, 2]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "efficient", "depth": [1, 1]}, {"source": "recognition", "target": "uncooperative environment", "depth": [1, 3]}, {"source": "recognition", "target": "recognition in uncontrolled", "depth": [1, 3]}, {"source": "recognition", "target": "uncontrolled and uncooperative", "depth": [1, 3]}, {"source": "classification", "target": "binary labeling problem", "depth": [1, 3]}, {"source": "classification", "target": "distributed binary labeling", "depth": [1, 3]}, {"source": "classification", "target": "classification of distributed", "depth": [1, 3]}, {"source": "classification", "target": "labeling problem", "depth": [1, 3]}, {"source": "classification", "target": "binary labeling", "depth": [1, 3]}, {"source": "transfer learning", "target": "deep transfer learning", "depth": [1, 2]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 2]}, {"source": "transfer learning", "target": "comprehensive survey", "depth": [1, 2]}, {"source": "transfer learning", "target": "survey on transfer", "depth": [1, 3]}, {"source": "transfer learning", "target": "comprehensive", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "dual-attention graph convolutional", "depth": [1, 3]}, {"source": "convolutional network", "target": "dual-attention graph", "depth": [1, 3]}, {"source": "convolutional network", "target": "intermediate dense supervision", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "bayesian recurrent neural", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "bayesian recurrent", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "alignment-based process anomaly", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "process anomaly correction", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "alignment-based proces", "depth": [1, 3]}, {"source": "dataset", "target": "dataset for keyphrase", "depth": [1, 3]}, {"source": "dataset", "target": "keyphrase generation", "depth": [1, 3]}, {"source": "dataset", "target": "kptime", "depth": [1, 3]}, {"source": "dataset", "target": "large-scale dataset", "depth": [1, 2]}, {"source": "dataset", "target": "document", "depth": [1, 1]}, {"source": "federated learning", "target": "federated", "depth": [1, 1]}, {"source": "federated learning", "target": "privacy", "depth": [1, 1]}, {"source": "federated learning", "target": "differential privacy", "depth": [1, 1]}, {"source": "federated learning", "target": "attacks and defense", "depth": [1, 2]}, {"source": "federated learning", "target": "free-riders in federated", "depth": [1, 3]}, {"source": "optimization", "target": "decomposed structured subset", "depth": [1, 3]}, {"source": "optimization", "target": "structured subset", "depth": [1, 3]}, {"source": "optimization", "target": "subsets for semidefinite", "depth": [1, 3]}, {"source": "optimization", "target": "decomposed structured", "depth": [1, 3]}, {"source": "optimization", "target": "structured", "depth": [1, 2]}, {"source": "segmentation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "visualisation of environment", "depth": [1, 3]}, {"source": "segmentation", "target": "apple orchard", "depth": [1, 3]}, {"source": "segmentation", "target": "fruit detection", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "neural architecture search", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "architecture search", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "neural architecture", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "distillation", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "knowledge", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "unsupervised domain adaptation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "cross-modal unsupervised domain", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "unsupervised domain", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "xmuda", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "cover change detection", "depth": [1, 3]}, {"source": "representation learning", "target": "time representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "functional time representation", "depth": [1, 3]}, {"source": "representation learning", "target": "functional time", "depth": [1, 3]}, {"source": "representation learning", "target": "time representation", "depth": [1, 3]}, {"source": "representation learning", "target": "self-attention with functional", "depth": [1, 3]}, {"source": "question answering", "target": "community question answering", "depth": [1, 2]}, {"source": "question answering", "target": "community question", "depth": [1, 2]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "adaptation from limited", "depth": [1, 3]}, {"source": "question answering", "target": "limited datum", "depth": [1, 2]}, {"source": "communication", "target": "molecular communication", "depth": [1, 2]}, {"source": "communication", "target": "molecular", "depth": [1, 2]}, {"source": "communication", "target": "leveraging sensing", "depth": [1, 3]}, {"source": "communication", "target": "mmwave communication", "depth": [1, 3]}, {"source": "communication", "target": "infrastructure for mmwave", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "product knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "embedding for e-commerce", "depth": [1, 3]}, {"source": "knowledge graph", "target": "product knowledge", "depth": [1, 3]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 1]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "model predictive control", "target": "adaptive model predictive", "depth": [1, 2]}, {"source": "model predictive control", "target": "robust adaptive model", "depth": [1, 2]}, {"source": "model predictive control", "target": "robust adaptive", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "reinforcement learning applied", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "interactive fiction", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "improvements for deep", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "algorithmic improvement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "learning for trading", "depth": [1, 3]}, {"source": "lower bound", "target": "bound", "depth": [1, 1]}, {"source": "lower bound", "target": "quantum lower bound", "depth": [1, 3]}, {"source": "lower bound", "target": "dyck language", "depth": [1, 2]}, {"source": "lower bound", "target": "quantum lower", "depth": [1, 3]}, {"source": "lower bound", "target": "language", "depth": [1, 1]}, {"source": "differential privacy", "target": "privacy", "depth": [1, 1]}, {"source": "differential privacy", "target": "local differential privacy", "depth": [1, 2]}, {"source": "differential privacy", "target": "bayesian differential privacy", "depth": [1, 2]}, {"source": "differential privacy", "target": "bayesian differential", "depth": [1, 2]}, {"source": "differential privacy", "target": "approximating sensitive attribute", "depth": [1, 3]}, {"source": "time series", "target": "time series forecasting", "depth": [1, 1]}, {"source": "time series", "target": "time series analysi", "depth": [1, 2]}, {"source": "time series", "target": "series analysi", "depth": [1, 2]}, {"source": "time series", "target": "los angele", "depth": [1, 3]}, {"source": "time series", "target": "analysis to traffic", "depth": [1, 3]}, {"source": "inference", "target": "multi-view consistent inference", "depth": [1, 3]}, {"source": "inference", "target": "shape completion", "depth": [1, 3]}, {"source": "inference", "target": "consistent inference", "depth": [1, 3]}, {"source": "inference", "target": "completion with multi-view", "depth": [1, 3]}, {"source": "inference", "target": "multi-view consistent", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "dual-attention graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "dual-attention graph", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "intermediate dense supervision", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "pose-based graph convolutional", "depth": [1, 3]}, {"source": "language", "target": "quantum lower bound", "depth": [1, 3]}, {"source": "language", "target": "dyck language", "depth": [1, 2]}, {"source": "language", "target": "quantum lower", "depth": [1, 3]}, {"source": "language", "target": "bound", "depth": [1, 1]}, {"source": "language", "target": "graph language", "depth": [1, 3]}, {"source": "word embedding", "target": "word embedding based", "depth": [1, 3]}, {"source": "word embedding", "target": "low-resourced language", "depth": [1, 3]}, {"source": "word embedding", "target": "corpus for low-resourced", "depth": [1, 3]}, {"source": "word embedding", "target": "sindhi", "depth": [1, 3]}, {"source": "word embedding", "target": "embedding based", "depth": [1, 3]}, {"source": "function", "target": "sparse approximation", "depth": [1, 3]}, {"source": "function", "target": "individual function", "depth": [1, 3]}, {"source": "function", "target": "approximation of individual", "depth": [1, 3]}, {"source": "function", "target": "sparse", "depth": [1, 1]}, {"source": "function", "target": "approximation", "depth": [1, 1]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "bayes risk training", "depth": [1, 3]}, {"source": "speech recognition", "target": "minimum bayes risk", "depth": [1, 3]}, {"source": "speech recognition", "target": "bayes risk", "depth": [1, 3]}, {"source": "speech recognition", "target": "risk training", "depth": [1, 3]}, {"source": "pose estimation", "target": "estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "multi-person pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "hand pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "framework for unconstrained", "depth": [1, 3]}, {"source": "active learning", "target": "multi-objective materials discovery", "depth": [1, 3]}, {"source": "active learning", "target": "model accuracy", "depth": [1, 3]}, {"source": "active learning", "target": "discovery and optimization", "depth": [1, 3]}, {"source": "active learning", "target": "assessing the frontier", "depth": [1, 3]}, {"source": "active learning", "target": "materials discovery", "depth": [1, 2]}, {"source": "code", "target": "subspace code", "depth": [1, 2]}, {"source": "code", "target": "gated hypernet decoder", "depth": [1, 3]}, {"source": "code", "target": "polar code", "depth": [1, 1]}, {"source": "code", "target": "gated hypernet", "depth": [1, 3]}, {"source": "code", "target": "hypernet decoder", "depth": [1, 3]}, {"source": "point cloud", "target": "network for point", "depth": [1, 2]}, {"source": "point cloud", "target": "point cloud classification", "depth": [1, 2]}, {"source": "point cloud", "target": "cloud", "depth": [1, 2]}, {"source": "point cloud", "target": "scene flow estimation", "depth": [1, 3]}, {"source": "point cloud", "target": "self-supervised scene flow", "depth": [1, 3]}, {"source": "estimation", "target": "population of parameter", "depth": [1, 3]}, {"source": "estimation", "target": "estimation of change", "depth": [1, 3]}, {"source": "estimation", "target": "optimal estimation", "depth": [1, 3]}, {"source": "estimation", "target": "parameter", "depth": [1, 2]}, {"source": "estimation", "target": "change", "depth": [1, 3]}, {"source": "game", "target": "playing game", "depth": [1, 3]}, {"source": "game", "target": "approach for cross-modality", "depth": [1, 3]}, {"source": "game", "target": "cross-modality transfer", "depth": [1, 3]}, {"source": "game", "target": "transfer in reinforcement", "depth": [1, 3]}, {"source": "game", "target": "dark", "depth": [1, 3]}, {"source": "predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "predictive control", "target": "economic model predictive", "depth": [1, 3]}, {"source": "predictive control", "target": "economic model", "depth": [1, 3]}, {"source": "predictive control", "target": "gaussian process model", "depth": [1, 2]}, {"source": "predictive control", "target": "learning-based model predictive", "depth": [1, 3]}, {"source": "anomaly detection", "target": "neuromorphic event-based anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "event-based anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "event-based anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "evan", "depth": [1, 3]}, {"source": "anomaly detection", "target": "streaming datum", "depth": [1, 3]}, {"source": "adversarial attack", "target": "network security", "depth": [1, 3]}, {"source": "adversarial attack", "target": "threat of adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attacks on machine", "depth": [1, 3]}, {"source": "adversarial attack", "target": "learning in network", "depth": [1, 2]}, {"source": "adversarial attack", "target": "security", "depth": [1, 1]}, {"source": "search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "search", "target": "architecture search", "depth": [1, 1]}, {"source": "search", "target": "neural architecture", "depth": [1, 1]}, {"source": "search", "target": "personal email search", "depth": [1, 3]}, {"source": "search", "target": "email search", "depth": [1, 3]}, {"source": "survey", "target": "comprehensive survey", "depth": [1, 2]}, {"source": "survey", "target": "edge computing", "depth": [1, 2]}, {"source": "survey", "target": "deep learning system", "depth": [1, 2]}, {"source": "survey", "target": "learning system", "depth": [1, 2]}, {"source": "survey", "target": "security threat", "depth": [1, 3]}, {"source": "clustering", "target": "cross-modal audio-video clustering", "depth": [1, 3]}, {"source": "clustering", "target": "self-supervised learning", "depth": [1, 2]}, {"source": "clustering", "target": "audio-video clustering", "depth": [1, 3]}, {"source": "clustering", "target": "learning by cross-modal", "depth": [1, 3]}, {"source": "clustering", "target": "cross-modal audio-video", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "oracle knowledge distillation", "depth": [1, 3]}, {"source": "architecture search", "target": "oracle knowledge", "depth": [1, 3]}, {"source": "architecture search", "target": "distillation with neural", "depth": [1, 3]}, {"source": "architecture search", "target": "supervised neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "oracle knowledge distillation", "depth": [1, 3]}, {"source": "neural architecture", "target": "oracle knowledge", "depth": [1, 3]}, {"source": "neural architecture", "target": "distillation with neural", "depth": [1, 3]}, {"source": "neural architecture", "target": "supervised neural architecture", "depth": [1, 3]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 1]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "dissemination platform", "depth": [1, 3]}, {"source": "learning model", "target": "platform for deep", "depth": [1, 3]}, {"source": "learning model", "target": "modelhub.ai", "depth": [1, 3]}, {"source": "quantum", "target": "quantum program", "depth": [1, 2]}, {"source": "quantum", "target": "runtime of quantum", "depth": [1, 3]}, {"source": "quantum", "target": "expected runtime", "depth": [1, 3]}, {"source": "quantum", "target": "program", "depth": [1, 1]}, {"source": "quantum", "target": "runtime", "depth": [1, 3]}, {"source": "resource allocation", "target": "joint user association", "depth": [1, 3]}, {"source": "resource allocation", "target": "heterogeneous network", "depth": [1, 3]}, {"source": "resource allocation", "target": "user association", "depth": [1, 3]}, {"source": "resource allocation", "target": "association and resource", "depth": [1, 3]}, {"source": "resource allocation", "target": "uplink of heterogeneou", "depth": [1, 3]}, {"source": "neural architecture search", "target": "oracle knowledge distillation", "depth": [1, 3]}, {"source": "neural architecture search", "target": "oracle knowledge", "depth": [1, 3]}, {"source": "neural architecture search", "target": "distillation with neural", "depth": [1, 3]}, {"source": "neural architecture search", "target": "supervised neural architecture", "depth": [1, 3]}, {"source": "neural architecture search", "target": "blockwisely supervised neural", "depth": [1, 3]}, {"source": "approach", "target": "systemic issue", "depth": [1, 3]}, {"source": "approach", "target": "structural approach", "depth": [1, 3]}, {"source": "approach", "target": "ethics for systemic", "depth": [1, 3]}, {"source": "approach", "target": "issue", "depth": [1, 2]}, {"source": "approach", "target": "conquer approach", "depth": [1, 3]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "mapless navigation", "depth": [1, 3]}, {"source": "learning approach", "target": "navigation", "depth": [1, 1]}, {"source": "learning approach", "target": "printable stabilizer system", "depth": [1, 3]}, {"source": "multi-task learning", "target": "deep multi-task learning", "depth": [1, 2]}, {"source": "multi-task learning", "target": "deep multi-task", "depth": [1, 2]}, {"source": "multi-task learning", "target": "face recognition", "depth": [1, 1]}, {"source": "multi-task learning", "target": "efficient deep multi-task", "depth": [1, 3]}, {"source": "multi-task learning", "target": "share for efficient", "depth": [1, 3]}, {"source": "graph convolutional", "target": "dual-attention graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional", "target": "dual-attention graph", "depth": [1, 3]}, {"source": "graph convolutional", "target": "intermediate dense supervision", "depth": [1, 3]}, {"source": "graph convolutional", "target": "pose-based graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional", "target": "dense supervision", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "sentiment", "depth": [1, 1]}, {"source": "sentiment analysi", "target": "language-independent sentiment analysi", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "positional information", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "analysis using subjectivity", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "subjectivity and positional", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "unsupervised domain", "depth": [1, 1]}, {"source": "unsupervised domain adaptation", "target": "cross-modal unsupervised domain", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "xmuda", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "light-weight calibrator", "depth": [1, 3]}, {"source": "unsupervised domain adaptation", "target": "separable component", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "challenges and advance", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "glioma imaging", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence in glioma", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "imaging", "depth": [1, 1]}, {"source": "artificial intelligence", "target": "challenge", "depth": [1, 1]}, {"source": "social network", "target": "online social network", "depth": [1, 2]}, {"source": "social network", "target": "multiple social network", "depth": [1, 3]}, {"source": "social network", "target": "algebraic analysi", "depth": [1, 3]}, {"source": "social network", "target": "networks with multiplex", "depth": [1, 3]}, {"source": "social network", "target": "analysis of multiple", "depth": [1, 3]}, {"source": "complexity", "target": "alphabet reordering", "depth": [1, 3]}, {"source": "complexity", "target": "minimization via alphabet", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of bwt-run", "depth": [1, 3]}, {"source": "complexity", "target": "bwt-runs minimization", "depth": [1, 3]}, {"source": "complexity", "target": "reordering", "depth": [1, 3]}, {"source": "training", "target": "robust tacotron-based tt", "depth": [1, 3]}, {"source": "training", "target": "tacotron-based tt", "depth": [1, 3]}, {"source": "training", "target": "training for robust", "depth": [1, 3]}, {"source": "training", "target": "teacher-student training", "depth": [1, 3]}, {"source": "training", "target": "tt", "depth": [1, 3]}, {"source": "framework", "target": "hand pose estimation", "depth": [1, 2]}, {"source": "framework", "target": "framework for unconstrained", "depth": [1, 3]}, {"source": "framework", "target": "unconstrained monocular", "depth": [1, 3]}, {"source": "framework", "target": "hand pose", "depth": [1, 3]}, {"source": "framework", "target": "monocular", "depth": [1, 2]}, {"source": "translation", "target": "translation across multiple", "depth": [1, 3]}, {"source": "translation", "target": "multiple domain", "depth": [1, 3]}, {"source": "translation", "target": "unsupervised", "depth": [1, 3]}, {"source": "translation", "target": "domain", "depth": [1, 1]}, {"source": "translation", "target": "multiple", "depth": [1, 2]}, {"source": "relation extraction", "target": "neural relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "improving neural relation", "depth": [1, 3]}, {"source": "relation extraction", "target": "unlabeled learning", "depth": [1, 3]}, {"source": "relation extraction", "target": "neural relation", "depth": [1, 2]}, {"source": "relation extraction", "target": "extraction with positive", "depth": [1, 3]}, {"source": "deep learning model", "target": "spatiotemporal deep learning", "depth": [1, 3]}, {"source": "deep learning model", "target": "citywide air pollution", "depth": [1, 3]}, {"source": "deep learning model", "target": "air pollution interpolation", "depth": [1, 3]}, {"source": "deep learning model", "target": "spatiotemporal deep", "depth": [1, 3]}, {"source": "deep learning model", "target": "interpolation and prediction", "depth": [1, 3]}, {"source": "case study", "target": "intelligent transportation system", "depth": [1, 3]}, {"source": "case study", "target": "regularized deep network", "depth": [1, 3]}, {"source": "case study", "target": "transportation system", "depth": [1, 3]}, {"source": "case study", "target": "deep network", "depth": [1, 1]}, {"source": "case study", "target": "networks in intelligent", "depth": [1, 3]}, {"source": "knowledge", "target": "distillation", "depth": [1, 1]}, {"source": "knowledge", "target": "improving model robustnes", "depth": [1, 3]}, {"source": "knowledge", "target": "causal knowledge", "depth": [1, 3]}, {"source": "knowledge", "target": "model robustnes", "depth": [1, 2]}, {"source": "knowledge", "target": "robustness using causal", "depth": [1, 3]}, {"source": "bound", "target": "upper bound", "depth": [1, 2]}, {"source": "bound", "target": "empirical upper bound", "depth": [1, 3]}, {"source": "bound", "target": "bound in object", "depth": [1, 3]}, {"source": "bound", "target": "empirical upper", "depth": [1, 3]}, {"source": "bound", "target": "quantum lower bound", "depth": [1, 3]}, {"source": "face recognition", "target": "face recognition system", "depth": [1, 2]}, {"source": "face recognition", "target": "recognition system", "depth": [1, 2]}, {"source": "face recognition", "target": "template-based face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "classification-selection approach", "depth": [1, 3]}, {"source": "face recognition", "target": "updating of template-based", "depth": [1, 3]}, {"source": "online learning", "target": "distributed online learning", "depth": [1, 2]}, {"source": "online learning", "target": "distributed online", "depth": [1, 2]}, {"source": "online learning", "target": "adaptive communication bound", "depth": [1, 3]}, {"source": "online learning", "target": "communication bound", "depth": [1, 3]}, {"source": "online learning", "target": "bounds for distributed", "depth": [1, 3]}, {"source": "fast", "target": "backpropagating learned los", "depth": [1, 3]}, {"source": "fast", "target": "fast adaptation", "depth": [1, 3]}, {"source": "fast", "target": "learned los", "depth": [1, 3]}, {"source": "fast", "target": "adaptation via backpropagating", "depth": [1, 3]}, {"source": "fast", "target": "backpropagating learned", "depth": [1, 3]}, {"source": "privacy", "target": "bayesian differential privacy", "depth": [1, 2]}, {"source": "privacy", "target": "bayesian differential", "depth": [1, 2]}, {"source": "privacy", "target": "learning with bayesian", "depth": [1, 3]}, {"source": "privacy", "target": "local differential privacy", "depth": [1, 2]}, {"source": "privacy", "target": "context-aware local differential", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 1]}, {"source": "generative model", "target": "deep generative", "depth": [1, 1]}, {"source": "generative model", "target": "multi-modal deep generative", "depth": [1, 3]}, {"source": "generative model", "target": "autoencoders for multi-modal", "depth": [1, 3]}, {"source": "generative model", "target": "variational", "depth": [1, 3]}, {"source": "natural language", "target": "natural language generation", "depth": [1, 2]}, {"source": "natural language", "target": "language generation", "depth": [1, 2]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 1]}, {"source": "natural language", "target": "language processing", "depth": [1, 2]}, {"source": "natural language", "target": "principled regularized optimization", "depth": [1, 3]}, {"source": "internet of thing", "target": "neural network inference", "depth": [1, 2]}, {"source": "internet of thing", "target": "energy-efficient neural network", "depth": [1, 3]}, {"source": "internet of thing", "target": "network inference", "depth": [1, 2]}, {"source": "internet of thing", "target": "open-source toolkit", "depth": [1, 3]}, {"source": "internet of thing", "target": "toolkit for energy-efficient", "depth": [1, 3]}, {"source": "domain", "target": "translation across multiple", "depth": [1, 3]}, {"source": "domain", "target": "multiple domain", "depth": [1, 3]}, {"source": "domain", "target": "unsupervised", "depth": [1, 3]}, {"source": "domain", "target": "multiple", "depth": [1, 2]}, {"source": "domain", "target": "music source separation", "depth": [1, 3]}, {"source": "autonomous driving", "target": "automatic object removal", "depth": [1, 3]}, {"source": "autonomous driving", "target": "autonomous driving video", "depth": [1, 3]}, {"source": "autonomous driving", "target": "automatic object", "depth": [1, 3]}, {"source": "autonomous driving", "target": "driving video", "depth": [1, 3]}, {"source": "autonomous driving", "target": "object removal", "depth": [1, 3]}, {"source": "finite element", "target": "finite element method", "depth": [1, 1]}, {"source": "finite element", "target": "element method", "depth": [1, 2]}, {"source": "finite element", "target": "galerkin finite element", "depth": [1, 2]}, {"source": "finite element", "target": "discontinuous galerkin finite", "depth": [1, 2]}, {"source": "finite element", "target": "rosenau equation", "depth": [1, 3]}, {"source": "speech", "target": "speech to text", "depth": [1, 2]}, {"source": "speech", "target": "multimodal machine translation", "depth": [1, 3]}, {"source": "speech", "target": "visuals and speech", "depth": [1, 3]}, {"source": "speech", "target": "multimodal machine", "depth": [1, 3]}, {"source": "speech", "target": "improving voice separation", "depth": [1, 3]}, {"source": "efficient", "target": "graph language", "depth": [1, 3]}, {"source": "efficient", "target": "recognition of graph", "depth": [1, 3]}, {"source": "efficient", "target": "efficient recognition", "depth": [1, 3]}, {"source": "efficient", "target": "embedded mpc", "depth": [1, 3]}, {"source": "efficient", "target": "calibration of embedded", "depth": [1, 3]}, {"source": "control system", "target": "networked control system", "depth": [1, 2]}, {"source": "control system", "target": "networked control", "depth": [1, 2]}, {"source": "control system", "target": "self-triggered control system", "depth": [1, 3]}, {"source": "control system", "target": "lipschitz perturbation", "depth": [1, 3]}, {"source": "control system", "target": "analysis of infinite-dimensional", "depth": [1, 3]}, {"source": "source separation", "target": "audio source separation", "depth": [1, 1]}, {"source": "source separation", "target": "separation", "depth": [1, 2]}, {"source": "source separation", "target": "randomly weighted u-net", "depth": [1, 3]}, {"source": "source separation", "target": "randomly weighted", "depth": [1, 2]}, {"source": "source separation", "target": "j-net", "depth": [1, 3]}, {"source": "study", "target": "curiosity-driven question generation", "depth": [1, 3]}, {"source": "study", "target": "question generation", "depth": [1, 1]}, {"source": "study", "target": "study on curiosity-driven", "depth": [1, 3]}, {"source": "study", "target": "curiosity-driven question", "depth": [1, 3]}, {"source": "study", "target": "learn", "depth": [1, 1]}, {"source": "object", "target": "anchor-point object detection", "depth": [1, 3]}, {"source": "object", "target": "soft anchor-point object", "depth": [1, 3]}, {"source": "object", "target": "soft anchor-point", "depth": [1, 3]}, {"source": "object", "target": "one-shot object detection", "depth": [1, 3]}, {"source": "object", "target": "detection with co-attention", "depth": [1, 3]}, {"source": "polynomial", "target": "small formula", "depth": [1, 3]}, {"source": "polynomial", "target": "determinant", "depth": [1, 2]}, {"source": "polynomial", "target": "schur", "depth": [1, 3]}, {"source": "polynomial", "target": "formula", "depth": [1, 3]}, {"source": "polynomial", "target": "computing permutation polynomial", "depth": [1, 3]}, {"source": "bert", "target": "inducing relational knowledge", "depth": [1, 3]}, {"source": "bert", "target": "knowledge from bert", "depth": [1, 3]}, {"source": "bert", "target": "relational knowledge", "depth": [1, 3]}, {"source": "bert", "target": "relational", "depth": [1, 1]}, {"source": "bert", "target": "lexical semantics task", "depth": [1, 3]}, {"source": "sampling", "target": "semi-supervised learning", "depth": [1, 1]}, {"source": "sampling", "target": "probabilistic watershed", "depth": [1, 3]}, {"source": "sampling", "target": "sampling all spanning", "depth": [1, 3]}, {"source": "sampling", "target": "watershed", "depth": [1, 3]}, {"source": "sampling", "target": "spanning forest", "depth": [1, 3]}, {"source": "reasoning", "target": "accurate vision-based manipulation", "depth": [1, 3]}, {"source": "reasoning", "target": "contact reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "vision-based manipulation", "depth": [1, 3]}, {"source": "reasoning", "target": "manipulation through contact", "depth": [1, 3]}, {"source": "reasoning", "target": "case-based reasoning", "depth": [1, 3]}, {"source": "transformer", "target": "graph transformer", "depth": [1, 2]}, {"source": "transformer", "target": "elsa", "depth": [1, 3]}, {"source": "transformer", "target": "layers during transformer", "depth": [1, 3]}, {"source": "transformer", "target": "freezing layer", "depth": [1, 3]}, {"source": "transformer", "target": "transformer fine-tuning", "depth": [1, 3]}, {"source": "sparse", "target": "sparse approximation", "depth": [1, 3]}, {"source": "sparse", "target": "individual function", "depth": [1, 3]}, {"source": "sparse", "target": "approximation of individual", "depth": [1, 3]}, {"source": "sparse", "target": "approximation", "depth": [1, 1]}, {"source": "sparse", "target": "coding on cascaded", "depth": [1, 3]}, {"source": "attention network", "target": "multi-modal attention network", "depth": [1, 3]}, {"source": "attention network", "target": "multi-modal attention", "depth": [1, 3]}, {"source": "attention network", "target": "transform", "depth": [1, 2]}, {"source": "attention network", "target": "navigation", "depth": [1, 1]}, {"source": "attention network", "target": "perceive", "depth": [1, 3]}, {"source": "type", "target": "price type", "depth": [1, 3]}, {"source": "type", "target": "impact on user", "depth": [1, 3]}, {"source": "type", "target": "user experience", "depth": [1, 2]}, {"source": "type", "target": "collecting charge", "depth": [1, 3]}, {"source": "type", "target": "charge", "depth": [1, 3]}, {"source": "person re-identification", "target": "re-identification", "depth": [1, 2]}, {"source": "person re-identification", "target": "network for person", "depth": [1, 2]}, {"source": "person re-identification", "target": "video-based person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "rethinking temporal fusion", "depth": [1, 3]}, {"source": "person re-identification", "target": "time aspect", "depth": [1, 3]}, {"source": "attack", "target": "attacks and defense", "depth": [1, 2]}, {"source": "attack", "target": "free-riders in federated", "depth": [1, 3]}, {"source": "attack", "target": "defense", "depth": [1, 2]}, {"source": "attack", "target": "federated", "depth": [1, 1]}, {"source": "attack", "target": "modelling load-changing attack", "depth": [1, 3]}, {"source": "sentiment", "target": "multi-task model", "depth": [1, 3]}, {"source": "sentiment", "target": "emotion analysi", "depth": [1, 3]}, {"source": "sentiment", "target": "model for sentiment", "depth": [1, 3]}, {"source": "sentiment", "target": "emotion", "depth": [1, 2]}, {"source": "sentiment", "target": "sentiment and emotion", "depth": [1, 3]}, {"source": "parsing", "target": "semantic parsing", "depth": [1, 2]}, {"source": "parsing", "target": "parsing with derivative", "depth": [1, 3]}, {"source": "parsing", "target": "derivatives and zipper", "depth": [1, 3]}, {"source": "parsing", "target": "zipper", "depth": [1, 3]}, {"source": "parsing", "target": "weak and active", "depth": [1, 3]}, {"source": "point", "target": "orientation among point", "depth": [1, 3]}, {"source": "point", "target": "squares in arbitrary", "depth": [1, 3]}, {"source": "point", "target": "arbitrary orientation", "depth": [1, 3]}, {"source": "point", "target": "empty square", "depth": [1, 3]}, {"source": "point", "target": "square", "depth": [1, 2]}, {"source": "graph neural network", "target": "self-attention based graph", "depth": [1, 3]}, {"source": "graph neural network", "target": "based graph neural", "depth": [1, 3]}, {"source": "graph neural network", "target": "hyper-sagnn", "depth": [1, 3]}, {"source": "graph neural network", "target": "network for hypergraph", "depth": [1, 3]}, {"source": "graph neural network", "target": "based graph", "depth": [1, 3]}, {"source": "matching", "target": "statistical model aggregation", "depth": [1, 3]}, {"source": "matching", "target": "parameter matching", "depth": [1, 3]}, {"source": "matching", "target": "model aggregation", "depth": [1, 3]}, {"source": "matching", "target": "aggregation via parameter", "depth": [1, 3]}, {"source": "matching", "target": "statistical model", "depth": [1, 3]}, {"source": "application", "target": "kruskal-katona for convex", "depth": [1, 3]}, {"source": "application", "target": "convex set", "depth": [1, 3]}, {"source": "application", "target": "kruskal-katona", "depth": [1, 3]}, {"source": "application", "target": "set", "depth": [1, 2]}, {"source": "application", "target": "convex", "depth": [1, 2]}, {"source": "prediction", "target": "incoming node", "depth": [1, 3]}, {"source": "prediction", "target": "prediction of graph", "depth": [1, 3]}, {"source": "prediction", "target": "graph signal", "depth": [1, 3]}, {"source": "prediction", "target": "signals with incoming", "depth": [1, 3]}, {"source": "prediction", "target": "recursive prediction", "depth": [1, 3]}, {"source": "testing", "target": "property", "depth": [1, 1]}, {"source": "testing", "target": "group testing", "depth": [1, 2]}, {"source": "testing", "target": "optimal adaptive group", "depth": [1, 3]}, {"source": "testing", "target": "adaptive group testing", "depth": [1, 2]}, {"source": "testing", "target": "adaptive group", "depth": [1, 2]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity recognition", "target": "cross-lingual named entity", "depth": [1, 3]}, {"source": "named entity recognition", "target": "improving scientific named", "depth": [1, 3]}, {"source": "named entity recognition", "target": "scientific named entity", "depth": [1, 3]}, {"source": "method", "target": "itlnc-bxe", "depth": [1, 3]}, {"source": "method", "target": "method with multiple", "depth": [1, 3]}, {"source": "method", "target": "plant lncrna", "depth": [1, 3]}, {"source": "method", "target": "multiple feature", "depth": [1, 3]}, {"source": "method", "target": "features for identification", "depth": [1, 3]}, {"source": "shape", "target": "multi-view consistent inference", "depth": [1, 3]}, {"source": "shape", "target": "shape completion", "depth": [1, 3]}, {"source": "shape", "target": "consistent inference", "depth": [1, 3]}, {"source": "shape", "target": "completion with multi-view", "depth": [1, 3]}, {"source": "shape", "target": "multi-view consistent", "depth": [1, 3]}, {"source": "graph embedding", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "graph embedding", "target": "product knowledge graph", "depth": [1, 3]}, {"source": "graph embedding", "target": "embedding for e-commerce", "depth": [1, 3]}, {"source": "graph embedding", "target": "product knowledge", "depth": [1, 3]}, {"source": "graph embedding", "target": "e-commerce", "depth": [1, 2]}, {"source": "metric learning", "target": "deep metric learning", "depth": [1, 2]}, {"source": "metric learning", "target": "deep metric", "depth": [1, 2]}, {"source": "metric learning", "target": "metric learning algorithm", "depth": [1, 3]}, {"source": "metric learning", "target": "learning algorithm", "depth": [1, 2]}, {"source": "metric learning", "target": "evaluation of deep", "depth": [1, 2]}, {"source": "evaluation", "target": "machine translation evaluation", "depth": [1, 2]}, {"source": "evaluation", "target": "translation evaluation", "depth": [1, 2]}, {"source": "evaluation", "target": "discourse structure", "depth": [1, 3]}, {"source": "evaluation", "target": "structure for machine", "depth": [1, 3]}, {"source": "evaluation", "target": "discotk", "depth": [1, 3]}, {"source": "performance", "target": "configuration", "depth": [1, 2]}, {"source": "performance", "target": "software configuration", "depth": [1, 3]}, {"source": "performance", "target": "silver bullet", "depth": [1, 3]}, {"source": "performance", "target": "performance of software", "depth": [1, 3]}, {"source": "performance", "target": "predicting performance", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "cross-modal unsupervised domain", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "xmuda", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "light-weight calibrator", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "separable component", "depth": [1, 3]}, {"source": "unsupervised domain", "target": "component for unsupervised", "depth": [1, 3]}, {"source": "synthesi", "target": "flows for one-shot", "depth": [1, 3]}, {"source": "synthesi", "target": "synthesis of expressive", "depth": [1, 3]}, {"source": "synthesi", "target": "expressive speech", "depth": [1, 3]}, {"source": "synthesi", "target": "normalizing flow", "depth": [1, 2]}, {"source": "synthesi", "target": "vaes and normalizing", "depth": [1, 3]}, {"source": "finite element method", "target": "discontinuous galerkin finite", "depth": [1, 2]}, {"source": "finite element method", "target": "galerkin finite element", "depth": [1, 2]}, {"source": "finite element method", "target": "element method", "depth": [1, 2]}, {"source": "finite element method", "target": "mixed discontinuous galerkin", "depth": [1, 3]}, {"source": "finite element method", "target": "biharmonic equation", "depth": [1, 3]}, {"source": "deep network", "target": "adaptive nystr\u00f6m approximation", "depth": [1, 3]}, {"source": "deep network", "target": "nystr\u00f6m approximation", "depth": [1, 3]}, {"source": "deep network", "target": "networks with adaptive", "depth": [1, 3]}, {"source": "deep network", "target": "adaptive nystr\u00f6m", "depth": [1, 3]}, {"source": "deep network", "target": "approximation", "depth": [1, 1]}, {"source": "text", "target": "speech to text", "depth": [1, 2]}, {"source": "text", "target": "presenting an experimental", "depth": [1, 3]}, {"source": "text", "target": "experimental dataset", "depth": [1, 3]}, {"source": "text", "target": "sorani", "depth": [1, 3]}, {"source": "text", "target": "kurdish", "depth": [1, 3]}, {"source": "gradient", "target": "note on douglas-rachford", "depth": [1, 3]}, {"source": "gradient", "target": "phase retrieval", "depth": [1, 2]}, {"source": "gradient", "target": "douglas-rachford", "depth": [1, 3]}, {"source": "gradient", "target": "retrieval", "depth": [1, 1]}, {"source": "gradient", "target": "note", "depth": [1, 2]}, {"source": "distribution", "target": "hierarchical low-rank structure", "depth": [1, 3]}, {"source": "distribution", "target": "parameterized distribution", "depth": [1, 3]}, {"source": "distribution", "target": "low-rank structure", "depth": [1, 3]}, {"source": "distribution", "target": "structure of parameterized", "depth": [1, 3]}, {"source": "distribution", "target": "hierarchical low-rank", "depth": [1, 3]}, {"source": "feature", "target": "feature discriminativity estimation", "depth": [1, 3]}, {"source": "feature", "target": "feature discriminativity", "depth": [1, 3]}, {"source": "feature", "target": "discriminativity estimation", "depth": [1, 3]}, {"source": "feature", "target": "estimation in cnn", "depth": [1, 3]}, {"source": "feature", "target": "cnns for transfer", "depth": [1, 3]}, {"source": "named entity", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity", "target": "cross-lingual named entity", "depth": [1, 3]}, {"source": "named entity", "target": "improving scientific named", "depth": [1, 3]}, {"source": "named entity", "target": "scientific named entity", "depth": [1, 3]}, {"source": "named entity", "target": "improving scientific", "depth": [1, 3]}, {"source": "bayesian", "target": "learning in network", "depth": [1, 2]}, {"source": "bayesian", "target": "efficiency of bayesian", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian learning", "depth": [1, 2]}, {"source": "bayesian", "target": "aggregative efficiency", "depth": [1, 3]}, {"source": "bayesian", "target": "efficiency", "depth": [1, 2]}, {"source": "social medium", "target": "medium", "depth": [1, 3]}, {"source": "social medium", "target": "social media text", "depth": [1, 3]}, {"source": "social medium", "target": "vietnamese social medium", "depth": [1, 3]}, {"source": "social medium", "target": "vietnamese social", "depth": [1, 3]}, {"source": "social medium", "target": "leveraging social medium", "depth": [1, 3]}, {"source": "question generation", "target": "multi-document question generation", "depth": [1, 3]}, {"source": "question generation", "target": "contrastive multi-document question", "depth": [1, 3]}, {"source": "question generation", "target": "multi-document question", "depth": [1, 3]}, {"source": "question generation", "target": "contrastive multi-document", "depth": [1, 3]}, {"source": "question generation", "target": "multi-document", "depth": [1, 3]}, {"source": "inverse reinforcement learning", "target": "adversarial inverse reinforcement", "depth": [1, 3]}, {"source": "inverse reinforcement learning", "target": "maximum causal entropy", "depth": [1, 3]}, {"source": "inverse reinforcement learning", "target": "entropy inverse reinforcement", "depth": [1, 3]}, {"source": "inverse reinforcement learning", "target": "compatible reward inverse", "depth": [1, 3]}, {"source": "inverse reinforcement learning", "target": "reward inverse reinforcement", "depth": [1, 3]}, {"source": "los", "target": "packet los", "depth": [1, 2]}, {"source": "los", "target": "data-imbalanced nlp task", "depth": [1, 3]}, {"source": "los", "target": "nlp task", "depth": [1, 3]}, {"source": "los", "target": "loss for data-imbalanced", "depth": [1, 3]}, {"source": "los", "target": "data-imbalanced nlp", "depth": [1, 3]}, {"source": "wireless network", "target": "energy efficiency maximization", "depth": [1, 3]}, {"source": "wireless network", "target": "weighted-sum energy efficiency", "depth": [1, 3]}, {"source": "wireless network", "target": "energy efficiency", "depth": [1, 2]}, {"source": "wireless network", "target": "efficiency maximization", "depth": [1, 3]}, {"source": "wireless network", "target": "maximization in wireles", "depth": [1, 3]}, {"source": "imaging", "target": "serverless seismic imaging", "depth": [1, 3]}, {"source": "imaging", "target": "seismic imaging", "depth": [1, 3]}, {"source": "imaging", "target": "serverles", "depth": [1, 3]}, {"source": "imaging", "target": "cloud", "depth": [1, 2]}, {"source": "imaging", "target": "challenges and advance", "depth": [1, 3]}, {"source": "market", "target": "universal cnn-based predictor", "depth": [1, 3]}, {"source": "market", "target": "stock market", "depth": [1, 2]}, {"source": "market", "target": "predictor for stock", "depth": [1, 3]}, {"source": "market", "target": "u-cnnpred", "depth": [1, 3]}, {"source": "market", "target": "cnn-based predictor", "depth": [1, 3]}, {"source": "logic", "target": "geometrical view", "depth": [1, 3]}, {"source": "logic", "target": "view", "depth": [1, 2]}, {"source": "logic", "target": "paraconsistent logic", "depth": [1, 3]}, {"source": "logic", "target": "arguing ecosystem", "depth": [1, 3]}, {"source": "logic", "target": "ecosystem", "depth": [1, 3]}, {"source": "distributed", "target": "distributed representation", "depth": [1, 2]}, {"source": "distributed", "target": "bug detection", "depth": [1, 3]}, {"source": "distributed", "target": "representation of code", "depth": [1, 3]}, {"source": "distributed", "target": "code for bug", "depth": [1, 3]}, {"source": "distributed", "target": "smoothed analysi", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 2]}, {"source": "image segmentation", "target": "predictive uncertainty estimation", "depth": [1, 3]}, {"source": "image segmentation", "target": "deep medical image", "depth": [1, 3]}, {"source": "image segmentation", "target": "calibration and predictive", "depth": [1, 3]}, {"source": "property", "target": "testing linear-invariant property", "depth": [1, 3]}, {"source": "property", "target": "linear-invariant property", "depth": [1, 3]}, {"source": "property", "target": "set invariance property", "depth": [1, 3]}, {"source": "property", "target": "data-based guarantee", "depth": [1, 3]}, {"source": "property", "target": "invariance property", "depth": [1, 3]}, {"source": "task", "target": "data-imbalanced nlp task", "depth": [1, 3]}, {"source": "task", "target": "nlp task", "depth": [1, 3]}, {"source": "task", "target": "loss for data-imbalanced", "depth": [1, 3]}, {"source": "task", "target": "data-imbalanced nlp", "depth": [1, 3]}, {"source": "task", "target": "dice los", "depth": [1, 3]}, {"source": "perspective", "target": "perspectives on urban", "depth": [1, 3]}, {"source": "perspective", "target": "urban theory", "depth": [1, 3]}, {"source": "perspective", "target": "theory", "depth": [1, 1]}, {"source": "perspective", "target": "rating system", "depth": [1, 3]}, {"source": "perspective", "target": "bribery in rating", "depth": [1, 3]}, {"source": "question", "target": "questions in movieqa", "depth": [1, 3]}, {"source": "question", "target": "movieqa", "depth": [1, 3]}, {"source": "question", "target": "answering natural question", "depth": [1, 3]}, {"source": "question", "target": "natural question", "depth": [1, 3]}, {"source": "question", "target": "strategies for answering", "depth": [1, 3]}, {"source": "reading comprehension", "target": "reducing catastrophic forgetting", "depth": [1, 3]}, {"source": "reading comprehension", "target": "catastrophic forgetting", "depth": [1, 3]}, {"source": "reading comprehension", "target": "forgetting for domain", "depth": [1, 3]}, {"source": "reading comprehension", "target": "adaptation in reading", "depth": [1, 3]}, {"source": "reading comprehension", "target": "interpretable multi-hop reading", "depth": [1, 3]}, {"source": "deep generative", "target": "deep generative model", "depth": [1, 1]}, {"source": "deep generative", "target": "multi-modal deep generative", "depth": [1, 3]}, {"source": "deep generative", "target": "autoencoders for multi-modal", "depth": [1, 3]}, {"source": "deep generative", "target": "variational", "depth": [1, 3]}, {"source": "deep generative", "target": "multi-modal deep", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "vehicle", "depth": [1, 2]}, {"source": "autonomous vehicle", "target": "detecting driveable area", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "driveable area", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "area for autonomou", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "dynamic environment", "depth": [1, 2]}, {"source": "text generation", "target": "neural text generation", "depth": [1, 3]}, {"source": "text generation", "target": "submodularity for neural", "depth": [1, 3]}, {"source": "text generation", "target": "neural text", "depth": [1, 2]}, {"source": "text generation", "target": "resurrecting submodularity", "depth": [1, 3]}, {"source": "text generation", "target": "submodularity", "depth": [1, 2]}, {"source": "information", "target": "language-independent sentiment analysi", "depth": [1, 3]}, {"source": "information", "target": "positional information", "depth": [1, 3]}, {"source": "information", "target": "analysis using subjectivity", "depth": [1, 3]}, {"source": "information", "target": "subjectivity and positional", "depth": [1, 3]}, {"source": "information", "target": "language-independent sentiment", "depth": [1, 3]}, {"source": "relation", "target": "computing permutation polynomial", "depth": [1, 3]}, {"source": "relation", "target": "permutation polynomial", "depth": [1, 3]}, {"source": "relation", "target": "relations for computing", "depth": [1, 3]}, {"source": "relation", "target": "computing permutation", "depth": [1, 3]}, {"source": "relation", "target": "equivalence relation", "depth": [1, 3]}, {"source": "optimal power flow", "target": "optimal power", "depth": [1, 1]}, {"source": "optimal power flow", "target": "power flow", "depth": [1, 1]}, {"source": "optimal power flow", "target": "facilitating grid integration", "depth": [1, 3]}, {"source": "optimal power flow", "target": "stochastic optimal power", "depth": [1, 3]}, {"source": "optimal power flow", "target": "network reconfiguration", "depth": [1, 3]}, {"source": "instance segmentation", "target": "supervised cell instance", "depth": [1, 3]}, {"source": "instance segmentation", "target": "cell instance segmentation", "depth": [1, 3]}, {"source": "instance segmentation", "target": "weakly supervised cell", "depth": [1, 3]}, {"source": "instance segmentation", "target": "detection response", "depth": [1, 3]}, {"source": "instance segmentation", "target": "supervised cell", "depth": [1, 3]}, {"source": "robustnes", "target": "robustness in neural", "depth": [1, 3]}, {"source": "robustnes", "target": "domain robustnes", "depth": [1, 3]}, {"source": "robustnes", "target": "model robustnes", "depth": [1, 2]}, {"source": "robustnes", "target": "robustness against adversarial", "depth": [1, 3]}, {"source": "robustnes", "target": "adversarial robustnes", "depth": [1, 2]}, {"source": "deep learning approach", "target": "printable stabilizer system", "depth": [1, 3]}, {"source": "deep learning approach", "target": "ultrasound-enhanced multimodal imaging", "depth": [1, 3]}, {"source": "deep learning approach", "target": "real-time ultrasound-enhanced multimodal", "depth": [1, 3]}, {"source": "deep learning approach", "target": "printable stabilizer", "depth": [1, 3]}, {"source": "deep learning approach", "target": "stabilizer system", "depth": [1, 3]}, {"source": "time", "target": "block preconditioner", "depth": [1, 3]}, {"source": "time", "target": "nonsymmetric problem", "depth": [1, 3]}, {"source": "time", "target": "preconditioners for nonsymmetric", "depth": [1, 3]}, {"source": "time", "target": "krylov", "depth": [1, 3]}, {"source": "time", "target": "fixed-point", "depth": [1, 3]}, {"source": "programming", "target": "generation for neural", "depth": [1, 3]}, {"source": "programming", "target": "neural programming", "depth": [1, 3]}, {"source": "programming", "target": "data generation", "depth": [1, 2]}, {"source": "programming", "target": "robot behavior", "depth": [1, 3]}, {"source": "programming", "target": "programming of robot", "depth": [1, 3]}, {"source": "recommendation", "target": "adversarial learning", "depth": [1, 1]}, {"source": "recommendation", "target": "protection using adversarial", "depth": [1, 3]}, {"source": "recommendation", "target": "privacy-aware recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "recommendation with private-attribute", "depth": [1, 3]}, {"source": "recommendation", "target": "private-attribute protection", "depth": [1, 3]}, {"source": "evolution", "target": "iot traffic characterization", "depth": [1, 3]}, {"source": "evolution", "target": "cellular iot traffic", "depth": [1, 3]}, {"source": "evolution", "target": "characterization and evolution", "depth": [1, 3]}, {"source": "evolution", "target": "traffic characterization", "depth": [1, 3]}, {"source": "evolution", "target": "iot traffic", "depth": [1, 3]}, {"source": "polar code", "target": "blocklength polar code", "depth": [1, 3]}, {"source": "polar code", "target": "short blocklength polar", "depth": [1, 3]}, {"source": "polar code", "target": "low latency decoder", "depth": [1, 3]}, {"source": "polar code", "target": "latency decoder", "depth": [1, 3]}, {"source": "polar code", "target": "decoder for short", "depth": [1, 3]}, {"source": "gradient descent", "target": "stochastic gradient descent", "depth": [1, 2]}, {"source": "gradient descent", "target": "adaptive asynchronous parallel", "depth": [1, 3]}, {"source": "gradient descent", "target": "asynchronous parallel stochastic", "depth": [1, 3]}, {"source": "gradient descent", "target": "parallel stochastic gradient", "depth": [1, 3]}, {"source": "gradient descent", "target": "adaptive asynchronou", "depth": [1, 3]}, {"source": "action recognition", "target": "unsupervised skeleton based", "depth": [1, 3]}, {"source": "action recognition", "target": "based action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "skeleton based action", "depth": [1, 3]}, {"source": "action recognition", "target": "unsupervised skeleton", "depth": [1, 3]}, {"source": "action recognition", "target": "skeleton based", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "product knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "embedding for e-commerce", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "product knowledge", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "e-commerce", "depth": [1, 2]}, {"source": "knowledge graph embedding", "target": "improving convolution-based knowledge", "depth": [1, 3]}, {"source": "distillation", "target": "quantization-aware knowledge distillation", "depth": [1, 3]}, {"source": "distillation", "target": "quantization-aware knowledge", "depth": [1, 3]}, {"source": "distillation", "target": "qkd", "depth": [1, 3]}, {"source": "distillation", "target": "quantization-aware", "depth": [1, 3]}, {"source": "distillation", "target": "cross-modal distillation", "depth": [1, 3]}, {"source": "document", "target": "dataset for keyphrase", "depth": [1, 3]}, {"source": "document", "target": "keyphrase generation", "depth": [1, 3]}, {"source": "document", "target": "kptime", "depth": [1, 3]}, {"source": "document", "target": "large-scale dataset", "depth": [1, 2]}, {"source": "document", "target": "keyphrase", "depth": [1, 3]}, {"source": "federated", "target": "attacks and defense", "depth": [1, 2]}, {"source": "federated", "target": "free-riders in federated", "depth": [1, 3]}, {"source": "federated", "target": "defense", "depth": [1, 2]}, {"source": "federated", "target": "robust federated learning", "depth": [1, 3]}, {"source": "federated", "target": "noisy communication", "depth": [1, 3]}, {"source": "decision making", "target": "making", "depth": [1, 2]}, {"source": "decision making", "target": "online decision making", "depth": [1, 3]}, {"source": "decision making", "target": "understand dynamic regret", "depth": [1, 3]}, {"source": "decision making", "target": "dynamic regret", "depth": [1, 2]}, {"source": "decision making", "target": "regret with switching", "depth": [1, 3]}, {"source": "challenge", "target": "challenges and advance", "depth": [1, 3]}, {"source": "challenge", "target": "glioma imaging", "depth": [1, 3]}, {"source": "challenge", "target": "intelligence in glioma", "depth": [1, 3]}, {"source": "challenge", "target": "advance", "depth": [1, 3]}, {"source": "challenge", "target": "opportunity", "depth": [1, 2]}, {"source": "kernel", "target": "distributed online learning", "depth": [1, 2]}, {"source": "kernel", "target": "communication-efficient distributed online", "depth": [1, 3]}, {"source": "kernel", "target": "learning with kernel", "depth": [1, 3]}, {"source": "kernel", "target": "distributed online", "depth": [1, 2]}, {"source": "kernel", "target": "svm training", "depth": [1, 3]}, {"source": "emotion recognition", "target": "multimodal emotion recognition", "depth": [1, 2]}, {"source": "emotion recognition", "target": "multimodal emotion", "depth": [1, 2]}, {"source": "emotion recognition", "target": "emotion recognition model", "depth": [1, 3]}, {"source": "emotion recognition", "target": "physiological signal", "depth": [1, 3]}, {"source": "emotion recognition", "target": "recognition model", "depth": [1, 2]}, {"source": "secure", "target": "secure cross-channel transfer", "depth": [1, 3]}, {"source": "secure", "target": "channel hub", "depth": [1, 3]}, {"source": "secure", "target": "transfers via channel", "depth": [1, 3]}, {"source": "secure", "target": "secure cross-channel", "depth": [1, 3]}, {"source": "secure", "target": "boro", "depth": [1, 3]}, {"source": "optimal power", "target": "facilitating grid integration", "depth": [1, 3]}, {"source": "optimal power", "target": "stochastic optimal power", "depth": [1, 3]}, {"source": "optimal power", "target": "network reconfiguration", "depth": [1, 3]}, {"source": "optimal power", "target": "congestion management", "depth": [1, 3]}, {"source": "optimal power", "target": "distributed optimal power", "depth": [1, 3]}, {"source": "decision tree", "target": "longer quantum time", "depth": [1, 3]}, {"source": "decision tree", "target": "hybrid decision tree", "depth": [1, 3]}, {"source": "decision tree", "target": "longer quantum", "depth": [1, 3]}, {"source": "decision tree", "target": "strictly more powerful", "depth": [1, 3]}, {"source": "decision tree", "target": "quantum time", "depth": [1, 3]}, {"source": "retrieval", "target": "phase retrieval", "depth": [1, 2]}, {"source": "retrieval", "target": "phase", "depth": [1, 2]}, {"source": "retrieval", "target": "document retrieval", "depth": [1, 1]}, {"source": "retrieval", "target": "note on douglas-rachford", "depth": [1, 3]}, {"source": "retrieval", "target": "douglas-rachford", "depth": [1, 3]}, {"source": "extended version", "target": "knowledge base", "depth": [1, 2]}, {"source": "extended version", "target": "sparql query", "depth": [1, 3]}, {"source": "extended version", "target": "base", "depth": [1, 3]}, {"source": "extended version", "target": "answer", "depth": [1, 2]}, {"source": "extended version", "target": "sparql", "depth": [1, 3]}, {"source": "power flow", "target": "distributed optimal power", "depth": [1, 3]}, {"source": "power flow", "target": "admm for distributed", "depth": [1, 3]}, {"source": "power flow", "target": "distributed optimal", "depth": [1, 3]}, {"source": "power flow", "target": "learning-accelerated admm", "depth": [1, 3]}, {"source": "power flow", "target": "power flow analysi", "depth": [1, 3]}, {"source": "theory", "target": "perspectives on urban", "depth": [1, 3]}, {"source": "theory", "target": "urban theory", "depth": [1, 3]}, {"source": "theory", "target": "memory-one strategy", "depth": [1, 3]}, {"source": "theory", "target": "theory of mind", "depth": [1, 3]}, {"source": "theory", "target": "mind to find", "depth": [1, 3]}, {"source": "smart grid", "target": "grid", "depth": [1, 2]}, {"source": "smart grid", "target": "future smart grid", "depth": [1, 3]}, {"source": "smart grid", "target": "comprehensive survey", "depth": [1, 2]}, {"source": "smart grid", "target": "future smart", "depth": [1, 3]}, {"source": "smart grid", "target": "blockchain for future", "depth": [1, 3]}, {"source": "model predictive", "target": "economic model predictive", "depth": [1, 3]}, {"source": "model predictive", "target": "economic model", "depth": [1, 3]}, {"source": "model predictive", "target": "dissipativity in economic", "depth": [1, 3]}, {"source": "model predictive", "target": "steady-state optimality", "depth": [1, 3]}, {"source": "model predictive", "target": "real-time model predictive", "depth": [1, 3]}, {"source": "computing", "target": "goal-oriented agent-based simulation", "depth": [1, 3]}, {"source": "computing", "target": "agent-based simulation framework", "depth": [1, 3]}, {"source": "computing", "target": "agent-based simulation", "depth": [1, 3]}, {"source": "computing", "target": "high-performance computing", "depth": [1, 3]}, {"source": "computing", "target": "simulation framework", "depth": [1, 3]}, {"source": "learn", "target": "curiosity-driven question generation", "depth": [1, 3]}, {"source": "learn", "target": "study on curiosity-driven", "depth": [1, 3]}, {"source": "learn", "target": "curiosity-driven question", "depth": [1, 3]}, {"source": "learn", "target": "learn logic program", "depth": [1, 3]}, {"source": "learn", "target": "forgetting to learn", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning for trading", "depth": [1, 3]}, {"source": "reinforcement", "target": "trading", "depth": [1, 2]}, {"source": "reinforcement", "target": "control-tutored reinforcement learning", "depth": [1, 3]}, {"source": "reinforcement", "target": "herding problem", "depth": [1, 3]}, {"source": "reinforcement", "target": "control-tutored reinforcement", "depth": [1, 3]}, {"source": "architecture", "target": "efficient convolutional architecture", "depth": [1, 3]}, {"source": "architecture", "target": "convolutional architecture", "depth": [1, 3]}, {"source": "architecture", "target": "convolution for efficient", "depth": [1, 3]}, {"source": "architecture", "target": "comb convolution", "depth": [1, 3]}, {"source": "architecture", "target": "convolution", "depth": [1, 2]}, {"source": "artificial neural network", "target": "integrated mathematical modeling", "depth": [1, 3]}, {"source": "artificial neural network", "target": "limited learning dataset", "depth": [1, 3]}, {"source": "artificial neural network", "target": "neural network approach", "depth": [1, 2]}, {"source": "artificial neural network", "target": "mathematical modeling", "depth": [1, 3]}, {"source": "artificial neural network", "target": "learning dataset", "depth": [1, 2]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 2]}, {"source": "deep learning based", "target": "turbo autoencoder", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based channel", "depth": [1, 2]}, {"source": "deep learning based", "target": "based channel code", "depth": [1, 3]}, {"source": "deep learning based", "target": "communication channel", "depth": [1, 2]}, {"source": "semi-supervised learning", "target": "probabilistic watershed", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "sampling all spanning", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "watershed", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "spanning forest", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "forests for seeded", "depth": [1, 3]}, {"source": "entity recognition", "target": "cross-lingual named entity", "depth": [1, 3]}, {"source": "entity recognition", "target": "zero-resource cross-lingual named", "depth": [1, 3]}, {"source": "entity recognition", "target": "common entity recognition", "depth": [1, 3]}, {"source": "entity recognition", "target": "fine-grained science-domain corpu", "depth": [1, 3]}, {"source": "entity recognition", "target": "corpus for common", "depth": [1, 3]}, {"source": "conjecture", "target": "reed conjecture", "depth": [1, 3]}, {"source": "conjecture", "target": "local epsilon version", "depth": [1, 3]}, {"source": "conjecture", "target": "version of reed", "depth": [1, 3]}, {"source": "conjecture", "target": "local epsilon", "depth": [1, 3]}, {"source": "conjecture", "target": "epsilon version", "depth": [1, 3]}, {"source": "natural language processing", "target": "language processing", "depth": [1, 2]}, {"source": "natural language processing", "target": "graph embedding method", "depth": [1, 3]}, {"source": "natural language processing", "target": "neural graph embedding", "depth": [1, 3]}, {"source": "natural language processing", "target": "embedding method", "depth": [1, 3]}, {"source": "natural language processing", "target": "methods for natural", "depth": [1, 3]}, {"source": "subspace", "target": "clustering with active", "depth": [1, 3]}, {"source": "subspace", "target": "subspace clustering", "depth": [1, 2]}, {"source": "subspace", "target": "combining subspace code", "depth": [1, 3]}, {"source": "subspace", "target": "combining subspace", "depth": [1, 3]}, {"source": "subspace", "target": "subspace code", "depth": [1, 2]}, {"source": "navigation", "target": "multi-modal attention network", "depth": [1, 3]}, {"source": "navigation", "target": "multi-modal attention", "depth": [1, 3]}, {"source": "navigation", "target": "transform", "depth": [1, 2]}, {"source": "navigation", "target": "perceive", "depth": [1, 3]}, {"source": "navigation", "target": "act", "depth": [1, 3]}, {"source": "alternative", "target": "alternative metric", "depth": [1, 3]}, {"source": "alternative", "target": "alternative cross entropy", "depth": [1, 3]}, {"source": "alternative", "target": "cross entropy los", "depth": [1, 3]}, {"source": "alternative", "target": "alternative cros", "depth": [1, 3]}, {"source": "alternative", "target": "cross entropy", "depth": [1, 2]}, {"source": "length", "target": "sequences of length", "depth": [1, 3]}, {"source": "length", "target": "constructions of complementary", "depth": [1, 3]}, {"source": "length", "target": "complementary set", "depth": [1, 3]}, {"source": "length", "target": "sets of sequence", "depth": [1, 3]}, {"source": "length", "target": "generalized construction", "depth": [1, 3]}, {"source": "smart contract", "target": "contract", "depth": [1, 2]}, {"source": "smart contract", "target": "securing smart contract", "depth": [1, 3]}, {"source": "smart contract", "target": "securing smart", "depth": [1, 3]}, {"source": "smart contract", "target": "fly", "depth": [1, 3]}, {"source": "smart contract", "target": "smart", "depth": [1, 2]}, {"source": "program", "target": "quantum program", "depth": [1, 2]}, {"source": "program", "target": "runtime of quantum", "depth": [1, 3]}, {"source": "program", "target": "expected runtime", "depth": [1, 3]}, {"source": "program", "target": "runtime", "depth": [1, 3]}, {"source": "program", "target": "expected", "depth": [1, 2]}, {"source": "relational", "target": "inducing relational knowledge", "depth": [1, 3]}, {"source": "relational", "target": "knowledge from bert", "depth": [1, 3]}, {"source": "relational", "target": "relational knowledge", "depth": [1, 3]}, {"source": "relational", "target": "relational datum", "depth": [1, 3]}, {"source": "relational", "target": "models over relational", "depth": [1, 3]}, {"source": "supervision", "target": "diverse supervision", "depth": [1, 3]}, {"source": "supervision", "target": "full potential", "depth": [1, 3]}, {"source": "supervision", "target": "potential of small", "depth": [1, 3]}, {"source": "supervision", "target": "small datum", "depth": [1, 3]}, {"source": "supervision", "target": "data with diverse", "depth": [1, 3]}, {"source": "audio source separation", "target": "randomly weighted u-net", "depth": [1, 3]}, {"source": "audio source separation", "target": "randomly weighted", "depth": [1, 2]}, {"source": "audio source separation", "target": "j-net", "depth": [1, 3]}, {"source": "audio source separation", "target": "weighted u-net", "depth": [1, 3]}, {"source": "audio source separation", "target": "online spectrogram inversion", "depth": [1, 3]}, {"source": "approximation", "target": "adaptive nystr\u00f6m approximation", "depth": [1, 3]}, {"source": "approximation", "target": "nystr\u00f6m approximation", "depth": [1, 3]}, {"source": "approximation", "target": "networks with adaptive", "depth": [1, 3]}, {"source": "approximation", "target": "adaptive nystr\u00f6m", "depth": [1, 3]}, {"source": "approximation", "target": "sparse approximation", "depth": [1, 3]}, {"source": "concept", "target": "trainable communication system", "depth": [1, 3]}, {"source": "concept", "target": "concepts and prototype", "depth": [1, 3]}, {"source": "concept", "target": "communication system", "depth": [1, 1]}, {"source": "concept", "target": "trainable communication", "depth": [1, 3]}, {"source": "concept", "target": "prototype", "depth": [1, 2]}, {"source": "design", "target": "deaf-oriented accessibility", "depth": [1, 3]}, {"source": "design", "target": "inclusive design", "depth": [1, 3]}, {"source": "design", "target": "accessibility", "depth": [1, 3]}, {"source": "design", "target": "concrete", "depth": [1, 3]}, {"source": "design", "target": "optimal layout design", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "medical image", "depth": [1, 2]}, {"source": "medical image segmentation", "target": "predictive uncertainty estimation", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "deep medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "calibration and predictive", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "predictive uncertainty", "depth": [1, 3]}, {"source": "monte carlo", "target": "monte carlo method", "depth": [1, 2]}, {"source": "monte carlo", "target": "carlo method", "depth": [1, 3]}, {"source": "monte carlo", "target": "multilevel monte carlo", "depth": [1, 3]}, {"source": "monte carlo", "target": "multilevel monte", "depth": [1, 3]}, {"source": "monte carlo", "target": "neuronal ensemble inference", "depth": [1, 3]}, {"source": "convolution network", "target": "graph convolution network", "depth": [1, 1]}, {"source": "convolution network", "target": "graph convolution", "depth": [1, 2]}, {"source": "convolution network", "target": "driving acceleration", "depth": [1, 3]}, {"source": "convolution network", "target": "networks for probabilistic", "depth": [1, 3]}, {"source": "convolution network", "target": "probabilistic modeling", "depth": [1, 3]}, {"source": "dynamical system", "target": "order dynamical system", "depth": [1, 3]}, {"source": "dynamical system", "target": "coverage of compact", "depth": [1, 3]}, {"source": "dynamical system", "target": "compact domain", "depth": [1, 3]}, {"source": "dynamical system", "target": "safe coverage", "depth": [1, 3]}, {"source": "dynamical system", "target": "modeling dynamical system", "depth": [1, 3]}, {"source": "single image", "target": "unsupervised learning", "depth": [1, 2]}, {"source": "single image", "target": "intrinsic image decomposition", "depth": [1, 3]}, {"source": "single image", "target": "learning for intrinsic", "depth": [1, 3]}, {"source": "single image", "target": "intrinsic image", "depth": [1, 3]}, {"source": "single image", "target": "image decomposition", "depth": [1, 3]}, {"source": "image generation", "target": "resistant deep convolutional", "depth": [1, 3]}, {"source": "image generation", "target": "deep convolutional gan", "depth": [1, 3]}, {"source": "image generation", "target": "collapse resistant deep", "depth": [1, 3]}, {"source": "image generation", "target": "multi-object image generation", "depth": [1, 3]}, {"source": "image generation", "target": "resistant deep", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process dynamic", "depth": [1, 3]}, {"source": "gaussian proces", "target": "learning gaussian proces", "depth": [1, 3]}, {"source": "gaussian proces", "target": "actively learning gaussian", "depth": [1, 3]}, {"source": "gaussian proces", "target": "process dynamic", "depth": [1, 3]}, {"source": "gaussian proces", "target": "actively learning", "depth": [1, 3]}, {"source": "understanding", "target": "long document understanding", "depth": [1, 3]}, {"source": "understanding", "target": "document understanding", "depth": [1, 3]}, {"source": "understanding", "target": "long document", "depth": [1, 3]}, {"source": "understanding", "target": "self-attention for long", "depth": [1, 3]}, {"source": "understanding", "target": "blockwise self-attention", "depth": [1, 3]}, {"source": "adversarial learning", "target": "protection using adversarial", "depth": [1, 3]}, {"source": "adversarial learning", "target": "privacy-aware recommendation", "depth": [1, 3]}, {"source": "adversarial learning", "target": "recommendation with private-attribute", "depth": [1, 3]}, {"source": "adversarial learning", "target": "private-attribute protection", "depth": [1, 3]}, {"source": "adversarial learning", "target": "task-oriented representation", "depth": [1, 3]}, {"source": "linear system", "target": "integer linear system", "depth": [1, 3]}, {"source": "linear system", "target": "reconfiguration problem", "depth": [1, 3]}, {"source": "linear system", "target": "problem of integer", "depth": [1, 3]}, {"source": "linear system", "target": "integer linear", "depth": [1, 3]}, {"source": "linear system", "target": "trichotomy", "depth": [1, 3]}, {"source": "security", "target": "network security", "depth": [1, 3]}, {"source": "security", "target": "threat of adversarial", "depth": [1, 3]}, {"source": "security", "target": "attacks on machine", "depth": [1, 3]}, {"source": "security", "target": "learning in network", "depth": [1, 2]}, {"source": "security", "target": "cyber security", "depth": [1, 3]}, {"source": "coding", "target": "coding on cascaded", "depth": [1, 3]}, {"source": "coding", "target": "sparse coding", "depth": [1, 3]}, {"source": "coding", "target": "cascaded", "depth": [1, 3]}, {"source": "coding", "target": "quantum coding", "depth": [1, 3]}, {"source": "coding", "target": "local testability", "depth": [1, 3]}, {"source": "minimization", "target": "alphabet reordering", "depth": [1, 3]}, {"source": "minimization", "target": "minimization via alphabet", "depth": [1, 3]}, {"source": "minimization", "target": "complexity of bwt-run", "depth": [1, 3]}, {"source": "minimization", "target": "bwt-runs minimization", "depth": [1, 3]}, {"source": "minimization", "target": "reordering", "depth": [1, 3]}, {"source": "detection system", "target": "adaption object detection", "depth": [1, 3]}, {"source": "detection system", "target": "object detection system", "depth": [1, 3]}, {"source": "detection system", "target": "model adaption object", "depth": [1, 3]}, {"source": "detection system", "target": "system for robot", "depth": [1, 3]}, {"source": "detection system", "target": "adaption object", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "category-specific continuous input", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "continuous input", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "optimization for categorical", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "categorical and category-specific", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "category-specific continuou", "depth": [1, 3]}, {"source": "document retrieval", "target": "legal document retrieval", "depth": [1, 3]}, {"source": "document retrieval", "target": "topic hierarchies based", "depth": [1, 3]}, {"source": "document retrieval", "target": "legal document", "depth": [1, 3]}, {"source": "document retrieval", "target": "retrieval across language", "depth": [1, 3]}, {"source": "document retrieval", "target": "topic hierarchy", "depth": [1, 3]}, {"source": "optical flow", "target": "frame count", "depth": [1, 3]}, {"source": "optical flow", "target": "joint learning", "depth": [1, 2]}, {"source": "optical flow", "target": "learning of video", "depth": [1, 3]}, {"source": "optical flow", "target": "video segmentation", "depth": [1, 3]}, {"source": "optical flow", "target": "segmentation and optical", "depth": [1, 3]}, {"source": "compression", "target": "compression of convolutional", "depth": [1, 3]}, {"source": "compression", "target": "data-driven compression", "depth": [1, 3]}, {"source": "compression", "target": "model compression", "depth": [1, 3]}, {"source": "compression", "target": "pruning for model", "depth": [1, 3]}, {"source": "compression", "target": "graph pruning", "depth": [1, 3]}, {"source": "asr", "target": "cross-modal distillation", "depth": [1, 3]}, {"source": "asr", "target": "lip reading", "depth": [1, 2]}, {"source": "asr", "target": "distillation for lip", "depth": [1, 3]}, {"source": "asr", "target": "cross-modal", "depth": [1, 2]}, {"source": "asr", "target": "reading", "depth": [1, 2]}, {"source": "supervised learning", "target": "general supervised learning", "depth": [1, 3]}, {"source": "supervised learning", "target": "general supervised", "depth": [1, 3]}, {"source": "supervised learning", "target": "delta lense", "depth": [1, 2]}, {"source": "supervised learning", "target": "learning as change", "depth": [1, 3]}, {"source": "supervised learning", "target": "change propagation", "depth": [1, 3]}, {"source": "attention", "target": "collaborative attention network", "depth": [1, 3]}, {"source": "attention", "target": "network for person", "depth": [1, 2]}, {"source": "attention", "target": "collaborative attention", "depth": [1, 3]}, {"source": "attention", "target": "re-identification", "depth": [1, 2]}, {"source": "attention", "target": "dense traffic", "depth": [1, 3]}, {"source": "time series forecasting", "target": "scalable time series", "depth": [1, 3]}, {"source": "time series forecasting", "target": "transport network", "depth": [1, 2]}, {"source": "time series forecasting", "target": "model selection", "depth": [1, 2]}, {"source": "time series forecasting", "target": "selection for scalable", "depth": [1, 3]}, {"source": "time series forecasting", "target": "scalable time", "depth": [1, 3]}, {"source": "communication system", "target": "trainable communication system", "depth": [1, 3]}, {"source": "communication system", "target": "concepts and prototype", "depth": [1, 3]}, {"source": "communication system", "target": "trainable communication", "depth": [1, 3]}, {"source": "communication system", "target": "prototype", "depth": [1, 2]}, {"source": "communication system", "target": "backscatter communication system", "depth": [1, 3]}, {"source": "learning technique", "target": "machine learning technique", "depth": [1, 2]}, {"source": "learning technique", "target": "real time datum", "depth": [1, 3]}, {"source": "learning technique", "target": "short term prediction", "depth": [1, 3]}, {"source": "learning technique", "target": "parking area state", "depth": [1, 3]}, {"source": "learning technique", "target": "term prediction", "depth": [1, 3]}, {"source": "simulation", "target": "local-ancestry simulation", "depth": [1, 3]}, {"source": "simulation", "target": "class-conditional vae-gan", "depth": [1, 3]}, {"source": "simulation", "target": "vae-gan for local-ancestry", "depth": [1, 3]}, {"source": "simulation", "target": "local-ancestry", "depth": [1, 3]}, {"source": "simulation", "target": "molecular simulation", "depth": [1, 3]}, {"source": "blockchain", "target": "linear consistency", "depth": [1, 3]}, {"source": "blockchain", "target": "linear", "depth": [1, 2]}, {"source": "blockchain", "target": "multivocal literature review", "depth": [1, 3]}, {"source": "blockchain", "target": "systematic multivocal literature", "depth": [1, 3]}, {"source": "blockchain", "target": "literature review", "depth": [1, 2]}, {"source": "review", "target": "review summary", "depth": [1, 3]}, {"source": "review", "target": "summary for sentiment", "depth": [1, 3]}, {"source": "review", "target": "summary", "depth": [1, 2]}, {"source": "review", "target": "literature review", "depth": [1, 2]}, {"source": "review", "target": "multivocal literature review", "depth": [1, 3]}, {"source": "video captioning", "target": "captioning", "depth": [1, 3]}, {"source": "video captioning", "target": "characterizing the impact", "depth": [1, 3]}, {"source": "video captioning", "target": "features extracted", "depth": [1, 3]}, {"source": "video captioning", "target": "extracted from pre-trained", "depth": [1, 3]}, {"source": "video captioning", "target": "quality of video", "depth": [1, 3]}, {"source": "adaptation", "target": "style consistency", "depth": [1, 3]}, {"source": "adaptation", "target": "adaptation for object", "depth": [1, 3]}, {"source": "adaptation", "target": "detection via style", "depth": [1, 3]}, {"source": "adaptation", "target": "adversarial domain adaptation", "depth": [1, 2]}, {"source": "adaptation", "target": "adversarial domain", "depth": [1, 2]}, {"source": "graph convolution network", "target": "graph convolution", "depth": [1, 2]}, {"source": "graph convolution network", "target": "driving acceleration", "depth": [1, 3]}, {"source": "graph convolution network", "target": "networks for probabilistic", "depth": [1, 3]}, {"source": "graph convolution network", "target": "probabilistic modeling", "depth": [1, 3]}, {"source": "graph convolution network", "target": "modeling of driving", "depth": [1, 3]}, {"source": "map", "target": "tracking and forecasting", "depth": [1, 3]}, {"source": "map", "target": "rich map", "depth": [1, 3]}, {"source": "map", "target": "forecasting with rich", "depth": [1, 3]}, {"source": "map", "target": "argoverse", "depth": [1, 3]}, {"source": "map", "target": "tracking", "depth": [1, 2]}, {"source": "random", "target": "random walk", "depth": [1, 2]}, {"source": "random", "target": "walk", "depth": [1, 2]}, {"source": "random", "target": "walks on hypergraph", "depth": [1, 3]}, {"source": "random", "target": "hypergraph", "depth": [1, 3]}, {"source": "random", "target": "neural random", "depth": [1, 3]}, {"source": "robust", "target": "robust judgement aggregation", "depth": [1, 3]}, {"source": "robust", "target": "judgement aggregation", "depth": [1, 3]}, {"source": "robust", "target": "testing and robust", "depth": [1, 3]}, {"source": "robust", "target": "robust judgement", "depth": [1, 3]}, {"source": "robust", "target": "aggregation", "depth": [1, 3]}, {"source": "optimal control", "target": "dynamic environment", "depth": [1, 2]}, {"source": "optimal control", "target": "control for autonomou", "depth": [1, 2]}, {"source": "optimal control", "target": "vehicles in arbitrary", "depth": [1, 3]}, {"source": "optimal control", "target": "arbitrary and dynamic", "depth": [1, 3]}, {"source": "optimal control", "target": "time-dependent hybrid-state", "depth": [1, 3]}, {"source": "generalized", "target": "generalized transformation-based gradient", "depth": [1, 3]}, {"source": "generalized", "target": "transformation-based gradient", "depth": [1, 3]}, {"source": "generalized", "target": "generalized speedy q-learning", "depth": [1, 3]}, {"source": "generalized", "target": "speedy q-learning", "depth": [1, 3]}, {"source": "generalized", "target": "generalized speedy", "depth": [1, 3]}, {"source": "robot", "target": "robot behavior", "depth": [1, 3]}, {"source": "robot", "target": "programming of robot", "depth": [1, 3]}, {"source": "robot", "target": "verbal programming", "depth": [1, 3]}, {"source": "robot", "target": "behavior", "depth": [1, 2]}, {"source": "robot", "target": "verbal", "depth": [1, 3]}, {"source": "allocation", "target": "fair allocation", "depth": [1, 2]}, {"source": "allocation", "target": "selective information acquisition", "depth": [1, 3]}, {"source": "allocation", "target": "information acquisition", "depth": [1, 3]}, {"source": "allocation", "target": "allocation through selective", "depth": [1, 3]}, {"source": "allocation", "target": "selective information", "depth": [1, 3]}, {"source": "retinal vessel segmentation", "target": "u-net on retinal", "depth": [1, 3]}, {"source": "retinal vessel segmentation", "target": "vessel", "depth": [1, 3]}, {"source": "retinal vessel segmentation", "target": "fully convolutional network", "depth": [1, 2]}, {"source": "retinal vessel segmentation", "target": "vessel segmentation based", "depth": [1, 3]}, {"source": "retinal vessel segmentation", "target": "compact hybrid network", "depth": [1, 3]}, {"source": "vessel segmentation", "target": "u-net on retinal", "depth": [1, 3]}, {"source": "vessel segmentation", "target": "vessel", "depth": [1, 3]}, {"source": "vessel segmentation", "target": "fully convolutional network", "depth": [1, 2]}, {"source": "vessel segmentation", "target": "vessel segmentation based", "depth": [1, 3]}, {"source": "vessel segmentation", "target": "compact hybrid network", "depth": [1, 3]}, {"source": "retinal vessel", "target": "u-net on retinal", "depth": [1, 3]}, {"source": "retinal vessel", "target": "vessel", "depth": [1, 3]}, {"source": "retinal vessel", "target": "fully convolutional network", "depth": [1, 2]}, {"source": "retinal vessel", "target": "vessel segmentation based", "depth": [1, 3]}, {"source": "retinal vessel", "target": "compact hybrid network", "depth": [1, 3]}, {"source": "consistency", "target": "style consistency", "depth": [1, 3]}, {"source": "consistency", "target": "adaptation for object", "depth": [1, 3]}, {"source": "consistency", "target": "detection via style", "depth": [1, 3]}, {"source": "consistency", "target": "linear consistency", "depth": [1, 3]}, {"source": "consistency", "target": "linear", "depth": [1, 2]}, {"source": "policy", "target": "semantic sensor network", "depth": [1, 3]}, {"source": "policy", "target": "sensor network", "depth": [1, 2]}, {"source": "policy", "target": "policy editor", "depth": [1, 3]}, {"source": "policy", "target": "editor for semantic", "depth": [1, 3]}, {"source": "policy", "target": "semantic sensor", "depth": [1, 3]}, {"source": "path", "target": "wide network path", "depth": [1, 3]}, {"source": "path", "target": "network path", "depth": [1, 3]}, {"source": "path", "target": "wide network", "depth": [1, 3]}, {"source": "path", "target": "short and wide", "depth": [1, 3]}, {"source": "path", "target": "knowledge base completion", "depth": [1, 3]}, {"source": "deep generative model", "target": "multi-modal deep generative", "depth": [1, 3]}, {"source": "deep generative model", "target": "autoencoders for multi-modal", "depth": [1, 3]}, {"source": "deep generative model", "target": "variational", "depth": [1, 3]}, {"source": "deep generative model", "target": "multi-modal deep", "depth": [1, 3]}, {"source": "deep generative model", "target": "prior distribution choice", "depth": [1, 3]}, {"source": "pretrained language model", "target": "document-level neural machine", "depth": [1, 3]}, {"source": "pretrained language model", "target": "birds can talk", "depth": [1, 3]}, {"source": "pretrained language model", "target": "misprimed probe", "depth": [1, 3]}, {"source": "pretrained language model", "target": "probes for pretrained", "depth": [1, 3]}, {"source": "pretrained language model", "target": "negated and misprimed", "depth": [1, 3]}, {"source": "pretrained language", "target": "document-level neural machine", "depth": [1, 3]}, {"source": "pretrained language", "target": "birds can talk", "depth": [1, 3]}, {"source": "pretrained language", "target": "misprimed probe", "depth": [1, 3]}, {"source": "pretrained language", "target": "probes for pretrained", "depth": [1, 3]}, {"source": "pretrained language", "target": "negated and misprimed", "depth": [1, 3]}]}