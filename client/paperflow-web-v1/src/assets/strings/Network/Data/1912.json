{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "reinforcement learning", "deep learning", "machine learning", "generative adversarial network", "adversarial network", "model", "point cloud", "system", "object detection", "object", "image", "algorithm"], ["graph neural network", "recurrent neural network", "survey", "federated learning", "active learning", "generative adversarial", "bitcoin network", "social network", "deep reinforcement learning", "deep reinforcement", "reinforcement", "reinforcement learning approach", "deep", "learning model", "deep learning method", "machine learning algorithm", "learning algorithm", "point", "cloud", "space", "deep convolutional neural", "image segmentation", "detection", "single image", "analysis", "sentiment analysis", "task", "dataset", "graph", "knowledge graph", "application", "optimization", "semantic segmentation", "model for semantic", "machine translation", "neural machine translation", "neural machine", "translation", "recognition", "speech", "speech recognition", "graph convolutional network", "convolutional network", "graph convolutional", "action recognition", "representation", "classification method", "efficient", "datum", "representation learning", "method", "problem", "pose estimation", "object pose estimation", "object pose", "learning approach", "classification", "prediction", "artificial intelligence", "intelligence", "theory", "transfer learning", "legal document review", "document review", "anomaly detection", "domain adaptation", "adaptation", "text", "training", "approach", "clustering", "wasserstein barycenter", "attention", "segmentation", "information", "architecture search", "neural architecture search", "neural architecture", "search", "image classification", "hyperspectral image classification", "language model", "estimation", "tree", "code", "finite element", "massive mimo", "generation", "approximation", "robustness", "adversarial robustness", "set", "dynamical system", "complexity", "game", "case study", "data augmentation", "attention network", "transformer", "variational autoencoder", "twitter", "structure", "testing", "intelligent reflecting surface", "reflecting surface", "mining", "improving", "synthesis", "communication", "intelligent surface", "video", "computing", "nonlinear system", "disentangled representation", "challenge", "cognitive radio system", "analysis on interaction", "interactions among secondary", "markov decision proces", "bound", "embedding", "wireless network", "architecture", "language", "control", "sequence", "domain", "feature learning", "vision and language", "vision", "differential equation", "equation", "study", "empirical study", "face recognition", "tracking", "imitation learning", "sensor datum", "programming", "linear", "software engineering", "blockchain", "construction", "binary self-dual code", "self-dual code", "robot", "smart contract", "simulation", "adversarial attack", "query", "natural language", "instance segmentation", "edge computing", "big datum", "function", "generalization", "doa enlargement", "random number", "hybrid", "gaussian proces", "time", "gaussian mixture", "learning method", "fast", "attack", "question answering", "reconstruction", "agent", "large scale", "few-shot learning", "kernel", "environment", "detection framework", "online", "modeling", "recovery", "zero-shot", "human", "navigation", "feedback control", "hybrid representation", "multi-view stereo", "planning", "policy optimization", "attention model", "compressed sensing", "element method", "face", "deep network", "kalman filter", "internet of thing", "robust", "emotion recognition", "test", "proof", "error analysis", "selection", "extractive summarization", "omniscience", "streaming over http", "detector", "convolution", "deep learning based", "load monitoring", "wireless sensor network", "reconfigurable intelligent surface"], ["neural network based", "multi-agent reinforcement learning", "random number generation", "deep learning model", "model counting meet", "meets machine learning", "counting meets machine", "relational property", "finite", "autoregressive model", "finite automatum", "models of finite", "neural network model", "network model", "neural network architecture", "network architectures based", "lipschitz constant", "expressiveness of deep", "lidar point cloud", "lidar point", "time-efficient storage", "recommendation system", "drug recommendation system", "cancer cell line", "drug recommendation", "cell line", "deep convolutional", "neural networks architecture", "pruning deep convolutional", "evolution strategy", "self-ensembling semi-supervised", "ses", "self-ensembling", "infrastructure sensor", "spatially varying reflectance", "recovery of spatially", "spatially varying", "varying reflectance", "efficient algorithm", "related consequence", "linear complexity", "complexity of sequence", "object shape recovery", "object shape", "shape recovery", "generative", "based on generative", "single target tracking", "target tracking algorithm", "analysis in twitter", "sentiment", "dataset for text", "detection and recognition", "text detection", "answer ambiguous question", "ambiguous question", "high performance computing", "geospatial application", "performance computing", "computing for geospatial", "network information-theoretic approach", "topology optimization", "information-theoretic approach", "attention-based fusion model", "multi-modal attention-based fusion", "attention-based fusion", "multilingual neural machine", "skeleton-based action recognition", "concise representation", "representation and classification", "inspherenet", "heterogeneous fpga-cpu platform", "efficient rowhammer", "rowhammer on heterogeneous", "efficient processing", "vector datum", "processing of raster", "unsupervised representation learning", "network representation learning", "convolutional network representation", "multi-label graph convolutional", "saliency detection method", "detection method", "general framework", "framework for saliency", "level set", "segmentation with level", "odes for image", "neural ode", "twinless articulation point", "twinless articulation", "related problem", "articulation point", "articulated object pose", "noise resilient learning", "feature-attention graph convolutional", "resilient learning", "machine learning approach", "apricot variety classification", "apricot variety", "study of multilingual", "use-specific high performance", "high performance cyber-nanomaterial", "performance cyber-nanomaterial optical", "ensembles of regression", "one-class classification", "regression model", "detailed study", "distributed least square", "prediction theory", "theory of distributed", "learning and prediction", "users in social", "networks with motif-based", "ranking user", "motif-based pagerank", "morality of artificial", "morality", "object into part", "clouds by decomposing", "decomposing the object", "transfer learning approach", "analytics for legal", "unsupervised anomaly detection", "unsupervised anomaly", "history-based anomaly detector", "explicit sentence compression", "domain adaptation regularization", "spectral pruning", "adaptation regularization", "efficient adversarial training", "training with transferable", "adversarial training", "transferable adversarial", "bidirectional attentive graph", "attentive graph convolutional", "graph similarity learning", "deep graph similarity", "similarity learning", "graph similarity", "clustering measure-valued datum", "data with wasserstein", "measure-valued datum", "augmented graph neural", "memory augmented graph", "sequential recommendation", "augmented graph", "gan for unpaired", "asymmetric gan", "empirical investigation", "active memory", "convolution-based active memory", "neutrosophic domain", "segmentation in neutrosophic", "fluid segmentation", "fluid", "extending multi-object tracking", "multi-object tracking system", "multi-object tracking", "tracking system", "multi-class image classification", "discriminative multi-class image", "competing ratio loss", "federated", "energy-recycling consensus algorithm", "consensus algorithm", "energy-recycling consensu", "product rating prediction", "quantum-like language model", "convolutional quantum-like language", "object segmentation", "simultaneous", "pose", "cycles in partial", "trees and chordal", "chordal graph", "polar code", "polar", "finite element method", "monotonicity-preserving finite element", "finite element scheme", "adaptive mesh refinement", "mmwave massive mimo", "all-digital mmwave massive", "mimo with per-antenna", "singing voice generation", "lyrics-free singing voice", "voice generation", "approximation algorithm", "benchmarking adversarial robustness", "benchmarking adversarial", "linear dynamical system", "input sparsity constraint", "sparsity constraint", "systems under input", "nash equilibrium", "mobile app", "small case study", "mobile app usage", "persistent biometric", "medical image segmentation", "medical image", "effective data augmentation", "effective datum", "learning gan", "augmentation with multi-domain", "graph attention network", "graph attention", "informed attention network", "mixture variational autoencoder", "gaussian mixture variational", "embeddings from molecular", "molecular simulation", "cyber-nanomaterial optical detector", "network structure", "attributes of node", "nodes using network", "risk-based testing", "taxonomy of risk-based", "taxonomy", "object detection system", "explicit sparse transformer", "sparse transformer", "concentrated attention", "intelligent reflecting", "multi-user massive mimo", "terahertz multi-user massive", "intelligent system", "mining of trend", "trend information", "questions with knowledge", "improving computational efficiency", "communication for omniscience", "computational efficiency", "dynamic adaptive streaming", "unconventional computing", "systems for unconventional", "controllable disentangled representation", "learning controllable disentangled", "decorrelation regularization", "controllable disentangled", "exemplary achievement", "automated reasoning", "international workshop", "workshop on automated", "regularization for spectral", "decision process approach", "lower bound", "network embedding", "allocation in wireless", "crowd labelling", "networks for crowd", "deeper network architecture", "resnetx", "network architecture", "content creation", "visual perception", "perception to content", "creation", "high utility", "high utility episode", "discovering high utility", "classification driven feature", "driven feature learning", "learning for person", "ranking and classification", "identification of explicit", "explicit solution", "solutions to overdetermined", "principal component", "storage of lidar", "crowdfunding dynamics tracking", "dynamics tracking", "crowdfunding dynamic", "heterogeneous sensor datum", "federated imitation learning", "cloud robotic system", "path planning", "state space", "engineering", "evolution of empirical", "empirical method", "methods in software", "fee-free pooled mining", "mining in blockchain", "pooled mining", "circulant construction", "wall following robot", "comparative study", "study on machine", "category-level articulated object", "ethereum smart contract", "gas analysis", "analysis and optimization", "independent sentiment analysis", "improving the initial", "time-dependent simulation", "initial gues", "newton-raphson protocol", "federation access control", "big data federation", "data federation access", "next-generation big datum", "robust doa enlargement", "data-driven robust stabilization", "enlargement for nonlinear", "pseudo random number", "number generation", "quantum computer control", "computer control", "quantum computer", "hybrid semiconductor-superconductor", "characterizing orphan transaction", "orphan transaction", "characterizing orphan", "concise", "gaussian process regression", "scalable gaussian proces", "process regression", "regression for kernel", "articulated object", "linear time", "coresets for subspace", "subspace approximation", "strong coreset", "projection pursuit based", "based on gaussian", "projection pursuit", "evolutionary algorithm", "augmented reality calibration", "depth sensor datum", "reality calibration method", "augmented reality", "multi-coil cine mrus", "unsupervised deep learning", "adversarial sample", "community question answering", "unsupervised few-shot learning", "self-supervised training", "learning via self-supervised", "kernel transform learning", "transform learning", "kernel transform", "transform", "dynamic environment", "anytime planning", "motion planner", "planner for dynamic", "transaction detection framework", "fraud transaction detection", "attention based fraud", "boundary cue", "make lead bia", "zero-shot abstractive", "abstractive news summarization", "human modeling", "orthogonal silhouette", "effective network", "audio-visual embodied navigation", "embodied navigation", "listen", "act", "measurement-based feedback control", "linear quantum stochastic", "quantum stochastic system", "measurement-based feedback", "relative pose network", "extreme relative pose", "relative pose", "planar prior assisted", "prior assisted patchmatch", "patchmatch multi-view stereo", "region policy optimization", "trust region policy", "quasi-newton trust region", "acoustic event classification", "cross-scale attention model", "event classification", "derandomized compressed sensing", "ell", "derandomized compressed", "sensing with nonuniform", "text classification", "classification in legal", "virtual element method", "virtual element", "challenging new task", "task for exploring", "abstractions learned", "cubature kalman filter", "monocular visual inertial", "visual inertial odometry", "invariant cubature kalman", "internet", "robust stabilization", "pseudo random", "constrained wasserstein barycenter", "constrained wasserstein", "image morphing", "speech emotion recognition", "speech emotion", "learning transferable feature", "transferable feature", "zipf-mandelbrot law", "statistical test", "test for correspondence", "correspondence of text", "pspace", "quantum-inspired proof", "stochastic homogenization method", "priori error analysis", "numerical stochastic homogenization", "homogenization method", "support intersection", "selection via support", "confounder selection", "intersection", "beam training", "hybrid beamforming", "learning distributed heterogeneous", "distributed heterogeneous sentence", "heterogeneous sentence representation", "fusion model", "binary", "group induced four-circulant", "induced four-circulant construction", "efficiency of communication", "ensemble rate adaptation", "rate adaptation framework", "ensemble rate", "anomaly detector", "adversarial approach", "history-based anomaly", "benchmarking", "colorectal polyp segmentation", "dilation convolution", "polyp segmentation", "logic gate synthesis", "quantum logic gate", "decision proces", "chilean bills classification", "bills classification", "malware detection framework", "learning based android", "based android malware", "android malware detection", "non-intrusive load monitoring", "deep sparse coding", "sparse coding", "coordinated jamming attack", "radio system", "secondary and malicious", "malicious user", "cine mrus", "wireless sensor", "hybrid intrusion detection", "intrusion detection system", "detection system based", "surface"], ["exploiting the potential", "unstructured datum", "deep curvature suite", "curvature suite", "potential of deep", "differentiable architecture search", "representation active learning", "adversarial representation active", "representation active", "pre-transformed polar code", "multivariate", "edge-connected dominating set", "edge-connected dominating", "verifying population protocol", "population protocol", "complexity of verifying", "verifying population", "blockchain game", "synthesis of byzantine", "synchronous transformer", "mask for transformer", "semantic mask", "atomna", "byzantine system", "large intelligent surface", "communication model", "model for large", "temporal consistency-aware dynamic", "consistency-aware dynamic adaptive", "fine-grained", "binary search tree", "strong wilber", "convergence rate abstraction", "weakly-hard real-time control", "rate abstraction", "information privacy opinion", "opinions on twitter", "principal component analysis", "two-dimensional principal component", "component analysis", "multi-robot path planning", "genetic programming", "alphago actually play", "recognition adversarial attack", "face recognition adversarial", "recognition adversarial", "extracting clinical concept", "user query", "clinical concept", "concepts from user", "natural language processing", "language processing", "real-time instance segmentation", "real-time instance", "yolact", "mobile edge computing", "leveraging contextual-combinatorial bandit", "bandit and coded", "coded computing", "universal", "measuring compositional generalization", "compositional generalization", "realistic datum", "comprehensive method", "fast single-shot line-segment", "single-shot line-segment detector", "line-segment detector", "potential adversarial sample", "potential adversarial", "white-box attack", "translation evaluation meet", "evaluation meets community", "geometric reconstruction", "reconstruction of metric", "metric graph", "topological and geometric", "upside-down reinforcement learning", "training agent", "agents using upside-down", "scale", "distributed online optimization", "online optimization", "distributed online", "long-term constraint", "modeling in poiesis", "applications in software", "poiesis", "minimal surface problem", "controllable face aging", "face aging", "controllable face", "overfitting in reinforcement", "observational overfitting", "overfitting", "hyperspectral image", "localized residual connection", "cnn with localized", "privacy of sgd", "intrinsic privacy", "sgd", "thing", "designing edge-based middleware", "challenges in designing", "formal proof", "explainability and adversarial", "reconfigurable intelligent", "large intelligent", "language with localized", "connecting vision", "language agent navigation", "agent navigation"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "neural network based", "depth": [0, 2]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "survey", "depth": [0, 1]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "federated learning", "depth": [0, 1]}, {"source": "learning", "target": "active learning", "depth": [0, 1]}, {"source": "network", "target": "generative adversarial network", "depth": [0, 0]}, {"source": "network", "target": "adversarial network", "depth": [0, 0]}, {"source": "network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "network", "target": "bitcoin network", "depth": [0, 1]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "random number generation", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "survey", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 2]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning method", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning algorithm", "depth": [0, 1]}, {"source": "machine learning", "target": "learning algorithm", "depth": [0, 1]}, {"source": "machine learning", "target": "model counting meet", "depth": [0, 2]}, {"source": "machine learning", "target": "meets machine learning", "depth": [0, 2]}, {"source": "machine learning", "target": "counting meets machine", "depth": [0, 2]}, {"source": "machine learning", "target": "relational property", "depth": [0, 2]}, {"source": "model", "target": "finite", "depth": [0, 2]}, {"source": "model", "target": "autoregressive model", "depth": [0, 2]}, {"source": "model", "target": "finite automatum", "depth": [0, 2]}, {"source": "model", "target": "models of finite", "depth": [0, 2]}, {"source": "deep neural network", "target": "neural network model", "depth": [0, 2]}, {"source": "deep neural network", "target": "network model", "depth": [0, 2]}, {"source": "deep neural network", "target": "neural network architecture", "depth": [0, 2]}, {"source": "deep neural network", "target": "network architectures based", "depth": [0, 2]}, {"source": "deep neural network", "target": "lipschitz constant", "depth": [0, 2]}, {"source": "deep neural network", "target": "expressiveness of deep", "depth": [0, 2]}, {"source": "point cloud", "target": "point", "depth": [0, 1]}, {"source": "point cloud", "target": "cloud", "depth": [0, 1]}, {"source": "point cloud", "target": "lidar point cloud", "depth": [0, 2]}, {"source": "point cloud", "target": "lidar point", "depth": [0, 2]}, {"source": "point cloud", "target": "space", "depth": [0, 1]}, {"source": "point cloud", "target": "time-efficient storage", "depth": [0, 2]}, {"source": "system", "target": "recommendation system", "depth": [0, 2]}, {"source": "system", "target": "drug recommendation system", "depth": [0, 2]}, {"source": "system", "target": "cancer cell line", "depth": [0, 2]}, {"source": "system", "target": "drug recommendation", "depth": [0, 2]}, {"source": "system", "target": "cell line", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "image segmentation", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "neural networks architecture", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "pruning deep convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "evolution strategy", "depth": [0, 2]}, {"source": "object detection", "target": "object", "depth": [0, 0]}, {"source": "object detection", "target": "detection", "depth": [0, 1]}, {"source": "object detection", "target": "self-ensembling semi-supervised", "depth": [0, 2]}, {"source": "object detection", "target": "ses", "depth": [0, 2]}, {"source": "object detection", "target": "self-ensembling", "depth": [0, 2]}, {"source": "object detection", "target": "infrastructure sensor", "depth": [0, 2]}, {"source": "image", "target": "single image", "depth": [0, 1]}, {"source": "image", "target": "image segmentation", "depth": [0, 1]}, {"source": "image", "target": "spatially varying reflectance", "depth": [0, 2]}, {"source": "image", "target": "recovery of spatially", "depth": [0, 2]}, {"source": "image", "target": "spatially varying", "depth": [0, 2]}, {"source": "image", "target": "varying reflectance", "depth": [0, 2]}, {"source": "algorithm", "target": "efficient algorithm", "depth": [0, 2]}, {"source": "algorithm", "target": "related consequence", "depth": [0, 2]}, {"source": "algorithm", "target": "linear complexity", "depth": [0, 2]}, {"source": "algorithm", "target": "complexity of sequence", "depth": [0, 2]}, {"source": "object", "target": "detection", "depth": [0, 1]}, {"source": "object", "target": "object shape recovery", "depth": [0, 2]}, {"source": "object", "target": "object shape", "depth": [0, 2]}, {"source": "object", "target": "shape recovery", "depth": [0, 2]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [0, 0]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "adversarial network", "target": "generative", "depth": [0, 2]}, {"source": "adversarial network", "target": "based on generative", "depth": [0, 2]}, {"source": "adversarial network", "target": "single target tracking", "depth": [0, 2]}, {"source": "adversarial network", "target": "target tracking algorithm", "depth": [0, 2]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [0, 1]}, {"source": "generative adversarial network", "target": "generative", "depth": [0, 2]}, {"source": "generative adversarial network", "target": "based on generative", "depth": [0, 2]}, {"source": "generative adversarial network", "target": "single target tracking", "depth": [0, 2]}, {"source": "analysis", "target": "sentiment analysis", "depth": [1, 1]}, {"source": "analysis", "target": "analysis in twitter", "depth": [1, 2]}, {"source": "analysis", "target": "task", "depth": [1, 1]}, {"source": "analysis", "target": "sentiment", "depth": [1, 2]}, {"source": "detection", "target": "dataset for text", "depth": [1, 2]}, {"source": "detection", "target": "detection and recognition", "depth": [1, 2]}, {"source": "detection", "target": "text detection", "depth": [1, 2]}, {"source": "detection", "target": "dataset", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "exploiting the potential", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "unstructured datum", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative", "depth": [1, 2]}, {"source": "generative adversarial", "target": "based on generative", "depth": [1, 2]}, {"source": "generative adversarial", "target": "single target tracking", "depth": [1, 2]}, {"source": "graph", "target": "answer ambiguous question", "depth": [1, 2]}, {"source": "graph", "target": "knowledge graph", "depth": [1, 1]}, {"source": "graph", "target": "ambiguous question", "depth": [1, 2]}, {"source": "application", "target": "high performance computing", "depth": [1, 2]}, {"source": "application", "target": "geospatial application", "depth": [1, 2]}, {"source": "application", "target": "performance computing", "depth": [1, 2]}, {"source": "application", "target": "computing for geospatial", "depth": [1, 2]}, {"source": "optimization", "target": "network information-theoretic approach", "depth": [1, 2]}, {"source": "optimization", "target": "topology optimization", "depth": [1, 2]}, {"source": "optimization", "target": "information-theoretic approach", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "model for semantic", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "attention-based fusion model", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "multi-modal attention-based fusion", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "attention-based fusion", "depth": [1, 2]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "translation", "depth": [1, 1]}, {"source": "machine translation", "target": "multilingual neural machine", "depth": [1, 2]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "dataset for text", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "convolutional network", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "action recognition", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "representation", "target": "concise representation", "depth": [1, 2]}, {"source": "representation", "target": "representation and classification", "depth": [1, 2]}, {"source": "representation", "target": "classification method", "depth": [1, 1]}, {"source": "representation", "target": "inspherenet", "depth": [1, 2]}, {"source": "efficient", "target": "heterogeneous fpga-cpu platform", "depth": [1, 2]}, {"source": "efficient", "target": "efficient rowhammer", "depth": [1, 2]}, {"source": "efficient", "target": "rowhammer on heterogeneous", "depth": [1, 2]}, {"source": "datum", "target": "efficient processing", "depth": [1, 2]}, {"source": "datum", "target": "vector datum", "depth": [1, 2]}, {"source": "datum", "target": "processing of raster", "depth": [1, 2]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [1, 2]}, {"source": "representation learning", "target": "network representation learning", "depth": [1, 2]}, {"source": "representation learning", "target": "convolutional network representation", "depth": [1, 2]}, {"source": "representation learning", "target": "multi-label graph convolutional", "depth": [1, 2]}, {"source": "method", "target": "saliency detection method", "depth": [1, 2]}, {"source": "method", "target": "detection method", "depth": [1, 2]}, {"source": "method", "target": "general framework", "depth": [1, 2]}, {"source": "method", "target": "framework for saliency", "depth": [1, 2]}, {"source": "image segmentation", "target": "level set", "depth": [1, 2]}, {"source": "image segmentation", "target": "segmentation with level", "depth": [1, 2]}, {"source": "image segmentation", "target": "odes for image", "depth": [1, 2]}, {"source": "image segmentation", "target": "neural ode", "depth": [1, 2]}, {"source": "problem", "target": "twinless articulation point", "depth": [1, 2]}, {"source": "problem", "target": "twinless articulation", "depth": [1, 2]}, {"source": "problem", "target": "related problem", "depth": [1, 2]}, {"source": "problem", "target": "articulation point", "depth": [1, 2]}, {"source": "pose estimation", "target": "object pose estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "object pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "articulated object pose", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "noise resilient learning", "depth": [1, 2]}, {"source": "convolutional network", "target": "feature-attention graph convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "resilient learning", "depth": [1, 2]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "apricot variety classification", "depth": [1, 2]}, {"source": "learning approach", "target": "apricot variety", "depth": [1, 2]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "multilingual neural machine", "depth": [1, 2]}, {"source": "neural machine translation", "target": "study of multilingual", "depth": [1, 2]}, {"source": "learning algorithm", "target": "machine learning algorithm", "depth": [1, 1]}, {"source": "learning algorithm", "target": "use-specific high performance", "depth": [1, 2]}, {"source": "learning algorithm", "target": "high performance cyber-nanomaterial", "depth": [1, 2]}, {"source": "learning algorithm", "target": "performance cyber-nanomaterial optical", "depth": [1, 2]}, {"source": "classification", "target": "ensembles of regression", "depth": [1, 2]}, {"source": "classification", "target": "one-class classification", "depth": [1, 2]}, {"source": "classification", "target": "regression model", "depth": [1, 2]}, {"source": "classification", "target": "detailed study", "depth": [1, 2]}, {"source": "prediction", "target": "distributed least square", "depth": [1, 2]}, {"source": "prediction", "target": "prediction theory", "depth": [1, 2]}, {"source": "prediction", "target": "theory of distributed", "depth": [1, 2]}, {"source": "prediction", "target": "learning and prediction", "depth": [1, 2]}, {"source": "deep", "target": "survey", "depth": [1, 1]}, {"source": "deep", "target": "cloud", "depth": [1, 1]}, {"source": "deep", "target": "deep curvature suite", "depth": [1, 3]}, {"source": "deep", "target": "curvature suite", "depth": [1, 3]}, {"source": "social network", "target": "users in social", "depth": [1, 2]}, {"source": "social network", "target": "networks with motif-based", "depth": [1, 2]}, {"source": "social network", "target": "ranking user", "depth": [1, 2]}, {"source": "social network", "target": "motif-based pagerank", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 1]}, {"source": "artificial intelligence", "target": "morality of artificial", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "morality", "depth": [1, 2]}, {"source": "point", "target": "cloud", "depth": [1, 1]}, {"source": "point", "target": "object into part", "depth": [1, 2]}, {"source": "point", "target": "clouds by decomposing", "depth": [1, 2]}, {"source": "point", "target": "decomposing the object", "depth": [1, 2]}, {"source": "theory", "target": "distributed least square", "depth": [1, 2]}, {"source": "theory", "target": "prediction theory", "depth": [1, 2]}, {"source": "theory", "target": "theory of distributed", "depth": [1, 2]}, {"source": "theory", "target": "learning and prediction", "depth": [1, 2]}, {"source": "transfer learning", "target": "legal document review", "depth": [1, 1]}, {"source": "transfer learning", "target": "transfer learning approach", "depth": [1, 2]}, {"source": "transfer learning", "target": "document review", "depth": [1, 1]}, {"source": "transfer learning", "target": "analytics for legal", "depth": [1, 2]}, {"source": "anomaly detection", "target": "unsupervised anomaly detection", "depth": [1, 2]}, {"source": "anomaly detection", "target": "unsupervised anomaly", "depth": [1, 2]}, {"source": "anomaly detection", "target": "history-based anomaly detector", "depth": [1, 2]}, {"source": "neural machine", "target": "translation", "depth": [1, 1]}, {"source": "neural machine", "target": "multilingual neural machine", "depth": [1, 2]}, {"source": "neural machine", "target": "study of multilingual", "depth": [1, 2]}, {"source": "neural machine", "target": "explicit sentence compression", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "domain adaptation regularization", "depth": [1, 2]}, {"source": "domain adaptation", "target": "spectral pruning", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation regularization", "depth": [1, 2]}, {"source": "dataset", "target": "dataset for text", "depth": [1, 2]}, {"source": "dataset", "target": "detection and recognition", "depth": [1, 2]}, {"source": "dataset", "target": "text detection", "depth": [1, 2]}, {"source": "dataset", "target": "text", "depth": [1, 1]}, {"source": "training", "target": "efficient adversarial training", "depth": [1, 2]}, {"source": "training", "target": "training with transferable", "depth": [1, 2]}, {"source": "training", "target": "adversarial training", "depth": [1, 2]}, {"source": "training", "target": "transferable adversarial", "depth": [1, 2]}, {"source": "approach", "target": "network information-theoretic approach", "depth": [1, 2]}, {"source": "approach", "target": "topology optimization", "depth": [1, 2]}, {"source": "approach", "target": "information-theoretic approach", "depth": [1, 2]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "bidirectional attentive graph", "depth": [1, 2]}, {"source": "action recognition", "target": "attentive graph convolutional", "depth": [1, 2]}, {"source": "survey", "target": "graph similarity learning", "depth": [1, 2]}, {"source": "survey", "target": "deep graph similarity", "depth": [1, 2]}, {"source": "survey", "target": "similarity learning", "depth": [1, 2]}, {"source": "survey", "target": "graph similarity", "depth": [1, 2]}, {"source": "clustering", "target": "clustering measure-valued datum", "depth": [1, 2]}, {"source": "clustering", "target": "wasserstein barycenter", "depth": [1, 1]}, {"source": "clustering", "target": "data with wasserstein", "depth": [1, 2]}, {"source": "clustering", "target": "measure-valued datum", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "exploiting the potential", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "unstructured datum", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "potential of deep", "depth": [1, 3]}, {"source": "graph neural network", "target": "augmented graph neural", "depth": [1, 2]}, {"source": "graph neural network", "target": "memory augmented graph", "depth": [1, 2]}, {"source": "graph neural network", "target": "sequential recommendation", "depth": [1, 2]}, {"source": "graph neural network", "target": "augmented graph", "depth": [1, 2]}, {"source": "translation", "target": "multilingual neural machine", "depth": [1, 2]}, {"source": "translation", "target": "study of multilingual", "depth": [1, 2]}, {"source": "translation", "target": "gan for unpaired", "depth": [1, 2]}, {"source": "translation", "target": "asymmetric gan", "depth": [1, 2]}, {"source": "attention", "target": "empirical investigation", "depth": [1, 2]}, {"source": "attention", "target": "active memory", "depth": [1, 2]}, {"source": "attention", "target": "convolution-based active memory", "depth": [1, 2]}, {"source": "segmentation", "target": "neutrosophic domain", "depth": [1, 2]}, {"source": "segmentation", "target": "segmentation in neutrosophic", "depth": [1, 2]}, {"source": "segmentation", "target": "fluid segmentation", "depth": [1, 2]}, {"source": "segmentation", "target": "fluid", "depth": [1, 2]}, {"source": "graph convolutional", "target": "noise resilient learning", "depth": [1, 2]}, {"source": "graph convolutional", "target": "feature-attention graph convolutional", "depth": [1, 2]}, {"source": "graph convolutional", "target": "resilient learning", "depth": [1, 2]}, {"source": "information", "target": "extending multi-object tracking", "depth": [1, 2]}, {"source": "information", "target": "multi-object tracking system", "depth": [1, 2]}, {"source": "information", "target": "multi-object tracking", "depth": [1, 2]}, {"source": "information", "target": "tracking system", "depth": [1, 2]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "search", "depth": [1, 1]}, {"source": "architecture search", "target": "differentiable architecture search", "depth": [1, 3]}, {"source": "image classification", "target": "hyperspectral image classification", "depth": [1, 1]}, {"source": "image classification", "target": "multi-class image classification", "depth": [1, 2]}, {"source": "image classification", "target": "discriminative multi-class image", "depth": [1, 2]}, {"source": "image classification", "target": "competing ratio loss", "depth": [1, 2]}, {"source": "federated learning", "target": "federated", "depth": [1, 2]}, {"source": "federated learning", "target": "energy-recycling consensus algorithm", "depth": [1, 2]}, {"source": "federated learning", "target": "consensus algorithm", "depth": [1, 2]}, {"source": "federated learning", "target": "energy-recycling consensu", "depth": [1, 2]}, {"source": "language model", "target": "product rating prediction", "depth": [1, 2]}, {"source": "language model", "target": "quantum-like language model", "depth": [1, 2]}, {"source": "language model", "target": "convolutional quantum-like language", "depth": [1, 2]}, {"source": "active learning", "target": "representation active learning", "depth": [1, 3]}, {"source": "active learning", "target": "adversarial representation active", "depth": [1, 3]}, {"source": "active learning", "target": "representation active", "depth": [1, 3]}, {"source": "estimation", "target": "object segmentation", "depth": [1, 2]}, {"source": "estimation", "target": "simultaneous", "depth": [1, 2]}, {"source": "estimation", "target": "pose", "depth": [1, 2]}, {"source": "tree", "target": "cycles in partial", "depth": [1, 2]}, {"source": "tree", "target": "trees and chordal", "depth": [1, 2]}, {"source": "tree", "target": "chordal graph", "depth": [1, 2]}, {"source": "code", "target": "polar code", "depth": [1, 2]}, {"source": "code", "target": "polar", "depth": [1, 2]}, {"source": "code", "target": "pre-transformed polar code", "depth": [1, 3]}, {"source": "finite element", "target": "finite element method", "depth": [1, 2]}, {"source": "finite element", "target": "monotonicity-preserving finite element", "depth": [1, 2]}, {"source": "finite element", "target": "finite element scheme", "depth": [1, 2]}, {"source": "finite element", "target": "adaptive mesh refinement", "depth": [1, 2]}, {"source": "massive mimo", "target": "mmwave massive mimo", "depth": [1, 2]}, {"source": "massive mimo", "target": "all-digital mmwave massive", "depth": [1, 2]}, {"source": "massive mimo", "target": "mimo with per-antenna", "depth": [1, 2]}, {"source": "generation", "target": "singing voice generation", "depth": [1, 2]}, {"source": "generation", "target": "lyrics-free singing voice", "depth": [1, 2]}, {"source": "generation", "target": "voice generation", "depth": [1, 2]}, {"source": "approximation", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "approximation", "target": "multivariate", "depth": [1, 3]}, {"source": "approximation", "target": "edge-connected dominating set", "depth": [1, 3]}, {"source": "approximation", "target": "edge-connected dominating", "depth": [1, 3]}, {"source": "robustness", "target": "adversarial robustness", "depth": [1, 1]}, {"source": "robustness", "target": "benchmarking adversarial robustness", "depth": [1, 2]}, {"source": "robustness", "target": "benchmarking adversarial", "depth": [1, 2]}, {"source": "set", "target": "level set", "depth": [1, 2]}, {"source": "set", "target": "segmentation with level", "depth": [1, 2]}, {"source": "set", "target": "odes for image", "depth": [1, 2]}, {"source": "dynamical system", "target": "linear dynamical system", "depth": [1, 2]}, {"source": "dynamical system", "target": "input sparsity constraint", "depth": [1, 2]}, {"source": "dynamical system", "target": "sparsity constraint", "depth": [1, 2]}, {"source": "dynamical system", "target": "systems under input", "depth": [1, 2]}, {"source": "complexity", "target": "verifying population protocol", "depth": [1, 3]}, {"source": "complexity", "target": "population protocol", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of verifying", "depth": [1, 3]}, {"source": "complexity", "target": "verifying population", "depth": [1, 3]}, {"source": "cloud", "target": "lidar point cloud", "depth": [1, 2]}, {"source": "cloud", "target": "space", "depth": [1, 1]}, {"source": "cloud", "target": "time-efficient storage", "depth": [1, 2]}, {"source": "game", "target": "blockchain game", "depth": [1, 3]}, {"source": "game", "target": "synthesis of byzantine", "depth": [1, 3]}, {"source": "game", "target": "nash equilibrium", "depth": [1, 2]}, {"source": "case study", "target": "mobile app", "depth": [1, 2]}, {"source": "case study", "target": "small case study", "depth": [1, 2]}, {"source": "case study", "target": "mobile app usage", "depth": [1, 2]}, {"source": "case study", "target": "persistent biometric", "depth": [1, 2]}, {"source": "neural architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "neural architecture search", "target": "search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "neural architecture search", "target": "medical image", "depth": [1, 2]}, {"source": "data augmentation", "target": "effective data augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "effective datum", "depth": [1, 2]}, {"source": "data augmentation", "target": "learning gan", "depth": [1, 2]}, {"source": "data augmentation", "target": "augmentation with multi-domain", "depth": [1, 2]}, {"source": "single image", "target": "spatially varying reflectance", "depth": [1, 2]}, {"source": "single image", "target": "recovery of spatially", "depth": [1, 2]}, {"source": "single image", "target": "spatially varying", "depth": [1, 2]}, {"source": "single image", "target": "varying reflectance", "depth": [1, 2]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 2]}, {"source": "attention network", "target": "graph attention", "depth": [1, 2]}, {"source": "attention network", "target": "informed attention network", "depth": [1, 2]}, {"source": "speech recognition", "target": "synchronous transformer", "depth": [1, 3]}, {"source": "speech recognition", "target": "transformer", "depth": [1, 1]}, {"source": "speech recognition", "target": "mask for transformer", "depth": [1, 3]}, {"source": "speech", "target": "synchronous transformer", "depth": [1, 3]}, {"source": "speech", "target": "transformer", "depth": [1, 1]}, {"source": "speech", "target": "mask for transformer", "depth": [1, 3]}, {"source": "speech", "target": "semantic mask", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "mixture variational autoencoder", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "gaussian mixture variational", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "embeddings from molecular", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "molecular simulation", "depth": [1, 2]}, {"source": "task", "target": "sentiment analysis", "depth": [1, 1]}, {"source": "task", "target": "analysis in twitter", "depth": [1, 2]}, {"source": "task", "target": "sentiment", "depth": [1, 2]}, {"source": "task", "target": "twitter", "depth": [1, 1]}, {"source": "neural architecture", "target": "search", "depth": [1, 1]}, {"source": "neural architecture", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "neural architecture", "target": "medical image", "depth": [1, 2]}, {"source": "neural architecture", "target": "atomna", "depth": [1, 3]}, {"source": "machine learning algorithm", "target": "use-specific high performance", "depth": [1, 2]}, {"source": "machine learning algorithm", "target": "high performance cyber-nanomaterial", "depth": [1, 2]}, {"source": "machine learning algorithm", "target": "performance cyber-nanomaterial optical", "depth": [1, 2]}, {"source": "machine learning algorithm", "target": "cyber-nanomaterial optical detector", "depth": [1, 2]}, {"source": "structure", "target": "network structure", "depth": [1, 2]}, {"source": "structure", "target": "attributes of node", "depth": [1, 2]}, {"source": "structure", "target": "nodes using network", "depth": [1, 2]}, {"source": "testing", "target": "risk-based testing", "depth": [1, 2]}, {"source": "testing", "target": "taxonomy of risk-based", "depth": [1, 2]}, {"source": "testing", "target": "taxonomy", "depth": [1, 2]}, {"source": "testing", "target": "object detection system", "depth": [1, 2]}, {"source": "transformer", "target": "explicit sparse transformer", "depth": [1, 2]}, {"source": "transformer", "target": "sparse transformer", "depth": [1, 2]}, {"source": "transformer", "target": "concentrated attention", "depth": [1, 2]}, {"source": "intelligent reflecting surface", "target": "reflecting surface", "depth": [1, 1]}, {"source": "intelligent reflecting surface", "target": "intelligent reflecting", "depth": [1, 2]}, {"source": "intelligent reflecting surface", "target": "multi-user massive mimo", "depth": [1, 2]}, {"source": "intelligent reflecting surface", "target": "terahertz multi-user massive", "depth": [1, 2]}, {"source": "mining", "target": "intelligent system", "depth": [1, 2]}, {"source": "mining", "target": "mining of trend", "depth": [1, 2]}, {"source": "mining", "target": "trend information", "depth": [1, 2]}, {"source": "knowledge graph", "target": "answer ambiguous question", "depth": [1, 2]}, {"source": "knowledge graph", "target": "ambiguous question", "depth": [1, 2]}, {"source": "knowledge graph", "target": "questions with knowledge", "depth": [1, 2]}, {"source": "improving", "target": "improving computational efficiency", "depth": [1, 2]}, {"source": "improving", "target": "communication for omniscience", "depth": [1, 2]}, {"source": "improving", "target": "computational efficiency", "depth": [1, 2]}, {"source": "synthesis", "target": "blockchain game", "depth": [1, 3]}, {"source": "synthesis", "target": "synthesis of byzantine", "depth": [1, 3]}, {"source": "synthesis", "target": "nash equilibrium", "depth": [1, 2]}, {"source": "synthesis", "target": "byzantine system", "depth": [1, 3]}, {"source": "communication", "target": "large intelligent surface", "depth": [1, 3]}, {"source": "communication", "target": "intelligent surface", "depth": [1, 1]}, {"source": "communication", "target": "communication model", "depth": [1, 3]}, {"source": "communication", "target": "model for large", "depth": [1, 3]}, {"source": "video", "target": "dynamic adaptive streaming", "depth": [1, 2]}, {"source": "video", "target": "temporal consistency-aware dynamic", "depth": [1, 3]}, {"source": "video", "target": "consistency-aware dynamic adaptive", "depth": [1, 3]}, {"source": "computing", "target": "nonlinear system", "depth": [1, 1]}, {"source": "computing", "target": "unconventional computing", "depth": [1, 2]}, {"source": "computing", "target": "systems for unconventional", "depth": [1, 2]}, {"source": "disentangled representation", "target": "controllable disentangled representation", "depth": [1, 2]}, {"source": "disentangled representation", "target": "learning controllable disentangled", "depth": [1, 2]}, {"source": "disentangled representation", "target": "decorrelation regularization", "depth": [1, 2]}, {"source": "disentangled representation", "target": "controllable disentangled", "depth": [1, 2]}, {"source": "search", "target": "atomna", "depth": [1, 3]}, {"source": "search", "target": "fine-grained", "depth": [1, 3]}, {"source": "challenge", "target": "exemplary achievement", "depth": [1, 2]}, {"source": "challenge", "target": "automated reasoning", "depth": [1, 2]}, {"source": "challenge", "target": "international workshop", "depth": [1, 2]}, {"source": "challenge", "target": "workshop on automated", "depth": [1, 2]}, {"source": "adaptation", "target": "domain adaptation regularization", "depth": [1, 2]}, {"source": "adaptation", "target": "spectral pruning", "depth": [1, 2]}, {"source": "adaptation", "target": "adaptation regularization", "depth": [1, 2]}, {"source": "adaptation", "target": "regularization for spectral", "depth": [1, 2]}, {"source": "cognitive radio system", "target": "analysis on interaction", "depth": [1, 1]}, {"source": "cognitive radio system", "target": "interactions among secondary", "depth": [1, 1]}, {"source": "cognitive radio system", "target": "decision process approach", "depth": [1, 2]}, {"source": "cognitive radio system", "target": "markov decision proces", "depth": [1, 1]}, {"source": "bound", "target": "lower bound", "depth": [1, 2]}, {"source": "bound", "target": "binary search tree", "depth": [1, 3]}, {"source": "bound", "target": "strong wilber", "depth": [1, 3]}, {"source": "embedding", "target": "network embedding", "depth": [1, 2]}, {"source": "wireless network", "target": "allocation in wireless", "depth": [1, 2]}, {"source": "wireless network", "target": "crowd labelling", "depth": [1, 2]}, {"source": "wireless network", "target": "networks for crowd", "depth": [1, 2]}, {"source": "architecture", "target": "deeper network architecture", "depth": [1, 2]}, {"source": "architecture", "target": "resnetx", "depth": [1, 2]}, {"source": "architecture", "target": "network architecture", "depth": [1, 2]}, {"source": "language", "target": "content creation", "depth": [1, 2]}, {"source": "language", "target": "visual perception", "depth": [1, 2]}, {"source": "language", "target": "perception to content", "depth": [1, 2]}, {"source": "language", "target": "creation", "depth": [1, 2]}, {"source": "control", "target": "convergence rate abstraction", "depth": [1, 3]}, {"source": "control", "target": "weakly-hard real-time control", "depth": [1, 3]}, {"source": "control", "target": "rate abstraction", "depth": [1, 3]}, {"source": "sequence", "target": "high utility", "depth": [1, 2]}, {"source": "sequence", "target": "high utility episode", "depth": [1, 2]}, {"source": "sequence", "target": "discovering high utility", "depth": [1, 2]}, {"source": "domain", "target": "neutrosophic domain", "depth": [1, 2]}, {"source": "domain", "target": "segmentation in neutrosophic", "depth": [1, 2]}, {"source": "domain", "target": "fluid segmentation", "depth": [1, 2]}, {"source": "domain", "target": "fluid", "depth": [1, 2]}, {"source": "feature learning", "target": "classification driven feature", "depth": [1, 2]}, {"source": "feature learning", "target": "driven feature learning", "depth": [1, 2]}, {"source": "feature learning", "target": "learning for person", "depth": [1, 2]}, {"source": "feature learning", "target": "ranking and classification", "depth": [1, 2]}, {"source": "vision and language", "target": "vision", "depth": [1, 1]}, {"source": "vision and language", "target": "content creation", "depth": [1, 2]}, {"source": "vision and language", "target": "visual perception", "depth": [1, 2]}, {"source": "vision and language", "target": "perception to content", "depth": [1, 2]}, {"source": "differential equation", "target": "equation", "depth": [1, 1]}, {"source": "differential equation", "target": "identification of explicit", "depth": [1, 2]}, {"source": "differential equation", "target": "explicit solution", "depth": [1, 2]}, {"source": "differential equation", "target": "solutions to overdetermined", "depth": [1, 2]}, {"source": "study", "target": "empirical study", "depth": [1, 1]}, {"source": "study", "target": "information privacy opinion", "depth": [1, 3]}, {"source": "study", "target": "opinions on twitter", "depth": [1, 3]}, {"source": "face recognition", "target": "principal component analysis", "depth": [1, 3]}, {"source": "face recognition", "target": "two-dimensional principal component", "depth": [1, 3]}, {"source": "face recognition", "target": "principal component", "depth": [1, 2]}, {"source": "face recognition", "target": "component analysis", "depth": [1, 3]}, {"source": "space", "target": "lidar point cloud", "depth": [1, 2]}, {"source": "space", "target": "time-efficient storage", "depth": [1, 2]}, {"source": "space", "target": "storage of lidar", "depth": [1, 2]}, {"source": "space", "target": "lidar point", "depth": [1, 2]}, {"source": "tracking", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "tracking", "target": "crowdfunding dynamics tracking", "depth": [1, 2]}, {"source": "tracking", "target": "dynamics tracking", "depth": [1, 2]}, {"source": "tracking", "target": "crowdfunding dynamic", "depth": [1, 2]}, {"source": "imitation learning", "target": "heterogeneous sensor datum", "depth": [1, 2]}, {"source": "imitation learning", "target": "federated imitation learning", "depth": [1, 2]}, {"source": "imitation learning", "target": "cloud robotic system", "depth": [1, 2]}, {"source": "imitation learning", "target": "sensor datum", "depth": [1, 1]}, {"source": "programming", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "programming", "target": "genetic programming", "depth": [1, 3]}, {"source": "programming", "target": "path planning", "depth": [1, 2]}, {"source": "linear", "target": "related consequence", "depth": [1, 2]}, {"source": "linear", "target": "linear complexity", "depth": [1, 2]}, {"source": "linear", "target": "complexity of sequence", "depth": [1, 2]}, {"source": "intelligence", "target": "morality of artificial", "depth": [1, 2]}, {"source": "intelligence", "target": "morality", "depth": [1, 2]}, {"source": "intelligence", "target": "alphago actually play", "depth": [1, 3]}, {"source": "intelligence", "target": "state space", "depth": [1, 2]}, {"source": "software engineering", "target": "engineering", "depth": [1, 2]}, {"source": "software engineering", "target": "evolution of empirical", "depth": [1, 2]}, {"source": "software engineering", "target": "empirical method", "depth": [1, 2]}, {"source": "software engineering", "target": "methods in software", "depth": [1, 2]}, {"source": "blockchain", "target": "fee-free pooled mining", "depth": [1, 2]}, {"source": "blockchain", "target": "mining in blockchain", "depth": [1, 2]}, {"source": "blockchain", "target": "pooled mining", "depth": [1, 2]}, {"source": "construction", "target": "binary self-dual code", "depth": [1, 1]}, {"source": "construction", "target": "circulant construction", "depth": [1, 2]}, {"source": "construction", "target": "self-dual code", "depth": [1, 1]}, {"source": "robot", "target": "wall following robot", "depth": [1, 2]}, {"source": "robot", "target": "comparative study", "depth": [1, 2]}, {"source": "robot", "target": "study on machine", "depth": [1, 2]}, {"source": "object pose estimation", "target": "object pose", "depth": [1, 1]}, {"source": "object pose estimation", "target": "articulated object pose", "depth": [1, 2]}, {"source": "object pose estimation", "target": "category-level articulated object", "depth": [1, 2]}, {"source": "smart contract", "target": "ethereum smart contract", "depth": [1, 2]}, {"source": "smart contract", "target": "gas analysis", "depth": [1, 2]}, {"source": "smart contract", "target": "analysis and optimization", "depth": [1, 2]}, {"source": "sentiment analysis", "target": "analysis in twitter", "depth": [1, 2]}, {"source": "sentiment analysis", "target": "sentiment", "depth": [1, 2]}, {"source": "sentiment analysis", "target": "twitter", "depth": [1, 1]}, {"source": "sentiment analysis", "target": "independent sentiment analysis", "depth": [1, 2]}, {"source": "simulation", "target": "improving the initial", "depth": [1, 2]}, {"source": "simulation", "target": "time-dependent simulation", "depth": [1, 2]}, {"source": "simulation", "target": "initial gues", "depth": [1, 2]}, {"source": "simulation", "target": "newton-raphson protocol", "depth": [1, 2]}, {"source": "adversarial attack", "target": "recognition adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "face recognition adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "recognition adversarial", "depth": [1, 3]}, {"source": "query", "target": "extracting clinical concept", "depth": [1, 3]}, {"source": "query", "target": "user query", "depth": [1, 3]}, {"source": "query", "target": "clinical concept", "depth": [1, 3]}, {"source": "query", "target": "concepts from user", "depth": [1, 3]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 3]}, {"source": "natural language", "target": "language processing", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "deep convolutional", "depth": [1, 2]}, {"source": "deep convolutional neural", "target": "neural networks architecture", "depth": [1, 2]}, {"source": "deep convolutional neural", "target": "pruning deep convolutional", "depth": [1, 2]}, {"source": "instance segmentation", "target": "real-time instance segmentation", "depth": [1, 3]}, {"source": "instance segmentation", "target": "real-time instance", "depth": [1, 3]}, {"source": "instance segmentation", "target": "yolact", "depth": [1, 3]}, {"source": "edge computing", "target": "mobile edge computing", "depth": [1, 3]}, {"source": "edge computing", "target": "leveraging contextual-combinatorial bandit", "depth": [1, 3]}, {"source": "edge computing", "target": "bandit and coded", "depth": [1, 3]}, {"source": "edge computing", "target": "coded computing", "depth": [1, 3]}, {"source": "big datum", "target": "federation access control", "depth": [1, 2]}, {"source": "big datum", "target": "big data federation", "depth": [1, 2]}, {"source": "big datum", "target": "data federation access", "depth": [1, 2]}, {"source": "big datum", "target": "next-generation big datum", "depth": [1, 2]}, {"source": "function", "target": "universal", "depth": [1, 3]}, {"source": "generalization", "target": "measuring compositional generalization", "depth": [1, 3]}, {"source": "generalization", "target": "compositional generalization", "depth": [1, 3]}, {"source": "generalization", "target": "realistic datum", "depth": [1, 3]}, {"source": "generalization", "target": "comprehensive method", "depth": [1, 3]}, {"source": "nonlinear system", "target": "robust doa enlargement", "depth": [1, 2]}, {"source": "nonlinear system", "target": "data-driven robust stabilization", "depth": [1, 2]}, {"source": "nonlinear system", "target": "doa enlargement", "depth": [1, 1]}, {"source": "nonlinear system", "target": "enlargement for nonlinear", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "random number generation", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "pseudo random number", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "number generation", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "random number", "depth": [1, 1]}, {"source": "hybrid", "target": "quantum computer control", "depth": [1, 2]}, {"source": "hybrid", "target": "computer control", "depth": [1, 2]}, {"source": "hybrid", "target": "quantum computer", "depth": [1, 2]}, {"source": "hybrid", "target": "hybrid semiconductor-superconductor", "depth": [1, 2]}, {"source": "bitcoin network", "target": "characterizing orphan transaction", "depth": [1, 2]}, {"source": "bitcoin network", "target": "orphan transaction", "depth": [1, 2]}, {"source": "bitcoin network", "target": "characterizing orphan", "depth": [1, 2]}, {"source": "classification method", "target": "concise representation", "depth": [1, 2]}, {"source": "classification method", "target": "representation and classification", "depth": [1, 2]}, {"source": "classification method", "target": "inspherenet", "depth": [1, 2]}, {"source": "classification method", "target": "concise", "depth": [1, 2]}, {"source": "gaussian proces", "target": "gaussian process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "scalable gaussian proces", "depth": [1, 2]}, {"source": "gaussian proces", "target": "process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "regression for kernel", "depth": [1, 2]}, {"source": "object pose", "target": "articulated object pose", "depth": [1, 2]}, {"source": "object pose", "target": "category-level articulated object", "depth": [1, 2]}, {"source": "object pose", "target": "articulated object", "depth": [1, 2]}, {"source": "time", "target": "linear time", "depth": [1, 2]}, {"source": "time", "target": "coresets for subspace", "depth": [1, 2]}, {"source": "time", "target": "subspace approximation", "depth": [1, 2]}, {"source": "time", "target": "strong coreset", "depth": [1, 2]}, {"source": "gaussian mixture", "target": "projection pursuit based", "depth": [1, 2]}, {"source": "gaussian mixture", "target": "based on gaussian", "depth": [1, 2]}, {"source": "gaussian mixture", "target": "projection pursuit", "depth": [1, 2]}, {"source": "gaussian mixture", "target": "evolutionary algorithm", "depth": [1, 2]}, {"source": "sensor datum", "target": "augmented reality calibration", "depth": [1, 2]}, {"source": "sensor datum", "target": "depth sensor datum", "depth": [1, 2]}, {"source": "sensor datum", "target": "reality calibration method", "depth": [1, 2]}, {"source": "sensor datum", "target": "augmented reality", "depth": [1, 2]}, {"source": "learning method", "target": "deep learning method", "depth": [1, 1]}, {"source": "learning method", "target": "multi-coil cine mrus", "depth": [1, 2]}, {"source": "learning method", "target": "unsupervised deep learning", "depth": [1, 2]}, {"source": "fast", "target": "fast single-shot line-segment", "depth": [1, 3]}, {"source": "fast", "target": "single-shot line-segment detector", "depth": [1, 3]}, {"source": "fast", "target": "line-segment detector", "depth": [1, 3]}, {"source": "attack", "target": "potential adversarial sample", "depth": [1, 3]}, {"source": "attack", "target": "potential adversarial", "depth": [1, 3]}, {"source": "attack", "target": "white-box attack", "depth": [1, 3]}, {"source": "attack", "target": "adversarial sample", "depth": [1, 2]}, {"source": "question answering", "target": "community question answering", "depth": [1, 2]}, {"source": "question answering", "target": "translation evaluation meet", "depth": [1, 3]}, {"source": "question answering", "target": "evaluation meets community", "depth": [1, 3]}, {"source": "reconstruction", "target": "geometric reconstruction", "depth": [1, 3]}, {"source": "reconstruction", "target": "reconstruction of metric", "depth": [1, 3]}, {"source": "reconstruction", "target": "metric graph", "depth": [1, 3]}, {"source": "reconstruction", "target": "topological and geometric", "depth": [1, 3]}, {"source": "text", "target": "dataset for text", "depth": [1, 2]}, {"source": "text", "target": "detection and recognition", "depth": [1, 2]}, {"source": "text", "target": "text detection", "depth": [1, 2]}, {"source": "agent", "target": "upside-down reinforcement learning", "depth": [1, 3]}, {"source": "agent", "target": "training agent", "depth": [1, 3]}, {"source": "agent", "target": "agents using upside-down", "depth": [1, 3]}, {"source": "large scale", "target": "scale", "depth": [1, 3]}, {"source": "few-shot learning", "target": "unsupervised few-shot learning", "depth": [1, 2]}, {"source": "few-shot learning", "target": "self-supervised training", "depth": [1, 2]}, {"source": "few-shot learning", "target": "learning via self-supervised", "depth": [1, 2]}, {"source": "kernel", "target": "kernel transform learning", "depth": [1, 2]}, {"source": "kernel", "target": "transform learning", "depth": [1, 2]}, {"source": "kernel", "target": "kernel transform", "depth": [1, 2]}, {"source": "kernel", "target": "transform", "depth": [1, 2]}, {"source": "environment", "target": "dynamic environment", "depth": [1, 2]}, {"source": "environment", "target": "anytime planning", "depth": [1, 2]}, {"source": "environment", "target": "motion planner", "depth": [1, 2]}, {"source": "environment", "target": "planner for dynamic", "depth": [1, 2]}, {"source": "detection framework", "target": "transaction detection framework", "depth": [1, 2]}, {"source": "detection framework", "target": "fraud transaction detection", "depth": [1, 2]}, {"source": "detection framework", "target": "attention based fraud", "depth": [1, 2]}, {"source": "online", "target": "distributed online optimization", "depth": [1, 3]}, {"source": "online", "target": "online optimization", "depth": [1, 3]}, {"source": "online", "target": "distributed online", "depth": [1, 3]}, {"source": "online", "target": "long-term constraint", "depth": [1, 3]}, {"source": "modeling", "target": "modeling in poiesis", "depth": [1, 3]}, {"source": "modeling", "target": "applications in software", "depth": [1, 3]}, {"source": "modeling", "target": "poiesis", "depth": [1, 3]}, {"source": "recovery", "target": "shape recovery", "depth": [1, 2]}, {"source": "recovery", "target": "object shape recovery", "depth": [1, 2]}, {"source": "recovery", "target": "object shape", "depth": [1, 2]}, {"source": "recovery", "target": "boundary cue", "depth": [1, 2]}, {"source": "zero-shot", "target": "make lead bia", "depth": [1, 2]}, {"source": "zero-shot", "target": "zero-shot abstractive", "depth": [1, 2]}, {"source": "zero-shot", "target": "abstractive news summarization", "depth": [1, 2]}, {"source": "human", "target": "human modeling", "depth": [1, 2]}, {"source": "human", "target": "orthogonal silhouette", "depth": [1, 2]}, {"source": "human", "target": "effective network", "depth": [1, 2]}, {"source": "navigation", "target": "audio-visual embodied navigation", "depth": [1, 2]}, {"source": "navigation", "target": "embodied navigation", "depth": [1, 2]}, {"source": "navigation", "target": "listen", "depth": [1, 2]}, {"source": "navigation", "target": "act", "depth": [1, 2]}, {"source": "feedback control", "target": "measurement-based feedback control", "depth": [1, 2]}, {"source": "feedback control", "target": "linear quantum stochastic", "depth": [1, 2]}, {"source": "feedback control", "target": "quantum stochastic system", "depth": [1, 2]}, {"source": "feedback control", "target": "measurement-based feedback", "depth": [1, 2]}, {"source": "hybrid representation", "target": "relative pose network", "depth": [1, 2]}, {"source": "hybrid representation", "target": "extreme relative pose", "depth": [1, 2]}, {"source": "hybrid representation", "target": "relative pose", "depth": [1, 2]}, {"source": "multi-view stereo", "target": "planar prior assisted", "depth": [1, 2]}, {"source": "multi-view stereo", "target": "prior assisted patchmatch", "depth": [1, 2]}, {"source": "multi-view stereo", "target": "patchmatch multi-view stereo", "depth": [1, 2]}, {"source": "planning", "target": "dynamic environment", "depth": [1, 2]}, {"source": "planning", "target": "anytime planning", "depth": [1, 2]}, {"source": "planning", "target": "motion planner", "depth": [1, 2]}, {"source": "policy optimization", "target": "region policy optimization", "depth": [1, 2]}, {"source": "policy optimization", "target": "trust region policy", "depth": [1, 2]}, {"source": "policy optimization", "target": "quasi-newton trust region", "depth": [1, 2]}, {"source": "attention model", "target": "acoustic event classification", "depth": [1, 2]}, {"source": "attention model", "target": "cross-scale attention model", "depth": [1, 2]}, {"source": "attention model", "target": "event classification", "depth": [1, 2]}, {"source": "compressed sensing", "target": "derandomized compressed sensing", "depth": [1, 2]}, {"source": "compressed sensing", "target": "ell", "depth": [1, 2]}, {"source": "compressed sensing", "target": "derandomized compressed", "depth": [1, 2]}, {"source": "compressed sensing", "target": "sensing with nonuniform", "depth": [1, 2]}, {"source": "equation", "target": "identification of explicit", "depth": [1, 2]}, {"source": "equation", "target": "explicit solution", "depth": [1, 2]}, {"source": "equation", "target": "solutions to overdetermined", "depth": [1, 2]}, {"source": "legal document review", "target": "text classification", "depth": [1, 2]}, {"source": "legal document review", "target": "classification in legal", "depth": [1, 2]}, {"source": "legal document review", "target": "transfer learning approach", "depth": [1, 2]}, {"source": "legal document review", "target": "analytics for legal", "depth": [1, 2]}, {"source": "document review", "target": "text classification", "depth": [1, 2]}, {"source": "document review", "target": "classification in legal", "depth": [1, 2]}, {"source": "document review", "target": "transfer learning approach", "depth": [1, 2]}, {"source": "document review", "target": "analytics for legal", "depth": [1, 2]}, {"source": "element method", "target": "virtual element method", "depth": [1, 2]}, {"source": "element method", "target": "virtual element", "depth": [1, 2]}, {"source": "element method", "target": "minimal surface problem", "depth": [1, 3]}, {"source": "face", "target": "controllable face aging", "depth": [1, 3]}, {"source": "face", "target": "face aging", "depth": [1, 3]}, {"source": "face", "target": "controllable face", "depth": [1, 3]}, {"source": "reinforcement", "target": "overfitting in reinforcement", "depth": [1, 3]}, {"source": "reinforcement", "target": "observational overfitting", "depth": [1, 3]}, {"source": "reinforcement", "target": "overfitting", "depth": [1, 3]}, {"source": "deep network", "target": "challenging new task", "depth": [1, 2]}, {"source": "deep network", "target": "task for exploring", "depth": [1, 2]}, {"source": "deep network", "target": "abstractions learned", "depth": [1, 2]}, {"source": "hyperspectral image classification", "target": "hyperspectral image", "depth": [1, 3]}, {"source": "hyperspectral image classification", "target": "localized residual connection", "depth": [1, 3]}, {"source": "hyperspectral image classification", "target": "cnn with localized", "depth": [1, 3]}, {"source": "kalman filter", "target": "cubature kalman filter", "depth": [1, 2]}, {"source": "kalman filter", "target": "monocular visual inertial", "depth": [1, 2]}, {"source": "kalman filter", "target": "visual inertial odometry", "depth": [1, 2]}, {"source": "kalman filter", "target": "invariant cubature kalman", "depth": [1, 2]}, {"source": "empirical study", "target": "privacy of sgd", "depth": [1, 3]}, {"source": "empirical study", "target": "intrinsic privacy", "depth": [1, 3]}, {"source": "empirical study", "target": "sgd", "depth": [1, 3]}, {"source": "internet of thing", "target": "internet", "depth": [1, 2]}, {"source": "internet of thing", "target": "thing", "depth": [1, 3]}, {"source": "internet of thing", "target": "designing edge-based middleware", "depth": [1, 3]}, {"source": "internet of thing", "target": "challenges in designing", "depth": [1, 3]}, {"source": "robust", "target": "federated", "depth": [1, 2]}, {"source": "doa enlargement", "target": "robust doa enlargement", "depth": [1, 2]}, {"source": "doa enlargement", "target": "data-driven robust stabilization", "depth": [1, 2]}, {"source": "doa enlargement", "target": "enlargement for nonlinear", "depth": [1, 2]}, {"source": "doa enlargement", "target": "robust stabilization", "depth": [1, 2]}, {"source": "random number", "target": "random number generation", "depth": [1, 2]}, {"source": "random number", "target": "number generation", "depth": [1, 2]}, {"source": "random number", "target": "pseudo random number", "depth": [1, 2]}, {"source": "random number", "target": "pseudo random", "depth": [1, 2]}, {"source": "wasserstein barycenter", "target": "constrained wasserstein barycenter", "depth": [1, 2]}, {"source": "wasserstein barycenter", "target": "constrained wasserstein", "depth": [1, 2]}, {"source": "wasserstein barycenter", "target": "image morphing", "depth": [1, 2]}, {"source": "emotion recognition", "target": "speech emotion recognition", "depth": [1, 2]}, {"source": "emotion recognition", "target": "speech emotion", "depth": [1, 2]}, {"source": "emotion recognition", "target": "learning transferable feature", "depth": [1, 2]}, {"source": "emotion recognition", "target": "transferable feature", "depth": [1, 2]}, {"source": "test", "target": "zipf-mandelbrot law", "depth": [1, 2]}, {"source": "test", "target": "statistical test", "depth": [1, 2]}, {"source": "test", "target": "test for correspondence", "depth": [1, 2]}, {"source": "test", "target": "correspondence of text", "depth": [1, 2]}, {"source": "proof", "target": "pspace", "depth": [1, 2]}, {"source": "proof", "target": "quantum-inspired proof", "depth": [1, 2]}, {"source": "proof", "target": "formal proof", "depth": [1, 3]}, {"source": "error analysis", "target": "stochastic homogenization method", "depth": [1, 2]}, {"source": "error analysis", "target": "priori error analysis", "depth": [1, 2]}, {"source": "error analysis", "target": "numerical stochastic homogenization", "depth": [1, 2]}, {"source": "error analysis", "target": "homogenization method", "depth": [1, 2]}, {"source": "selection", "target": "support intersection", "depth": [1, 2]}, {"source": "selection", "target": "selection via support", "depth": [1, 2]}, {"source": "selection", "target": "confounder selection", "depth": [1, 2]}, {"source": "selection", "target": "intersection", "depth": [1, 2]}, {"source": "reflecting surface", "target": "multi-user massive mimo", "depth": [1, 2]}, {"source": "reflecting surface", "target": "terahertz multi-user massive", "depth": [1, 2]}, {"source": "reflecting surface", "target": "beam training", "depth": [1, 2]}, {"source": "reflecting surface", "target": "hybrid beamforming", "depth": [1, 2]}, {"source": "extractive summarization", "target": "learning distributed heterogeneous", "depth": [1, 2]}, {"source": "extractive summarization", "target": "distributed heterogeneous sentence", "depth": [1, 2]}, {"source": "extractive summarization", "target": "heterogeneous sentence representation", "depth": [1, 2]}, {"source": "model for semantic", "target": "attention-based fusion model", "depth": [1, 2]}, {"source": "model for semantic", "target": "multi-modal attention-based fusion", "depth": [1, 2]}, {"source": "model for semantic", "target": "attention-based fusion", "depth": [1, 2]}, {"source": "model for semantic", "target": "fusion model", "depth": [1, 2]}, {"source": "binary self-dual code", "target": "circulant construction", "depth": [1, 2]}, {"source": "binary self-dual code", "target": "binary", "depth": [1, 2]}, {"source": "binary self-dual code", "target": "group induced four-circulant", "depth": [1, 2]}, {"source": "self-dual code", "target": "circulant construction", "depth": [1, 2]}, {"source": "self-dual code", "target": "binary", "depth": [1, 2]}, {"source": "self-dual code", "target": "group induced four-circulant", "depth": [1, 2]}, {"source": "self-dual code", "target": "induced four-circulant construction", "depth": [1, 2]}, {"source": "omniscience", "target": "improving computational efficiency", "depth": [1, 2]}, {"source": "omniscience", "target": "communication for omniscience", "depth": [1, 2]}, {"source": "omniscience", "target": "computational efficiency", "depth": [1, 2]}, {"source": "omniscience", "target": "efficiency of communication", "depth": [1, 2]}, {"source": "streaming over http", "target": "ensemble rate adaptation", "depth": [1, 2]}, {"source": "streaming over http", "target": "rate adaptation framework", "depth": [1, 2]}, {"source": "streaming over http", "target": "dynamic adaptive streaming", "depth": [1, 2]}, {"source": "streaming over http", "target": "ensemble rate", "depth": [1, 2]}, {"source": "detector", "target": "history-based anomaly detector", "depth": [1, 2]}, {"source": "detector", "target": "anomaly detector", "depth": [1, 2]}, {"source": "detector", "target": "adversarial approach", "depth": [1, 2]}, {"source": "detector", "target": "history-based anomaly", "depth": [1, 2]}, {"source": "adversarial robustness", "target": "benchmarking adversarial robustness", "depth": [1, 2]}, {"source": "adversarial robustness", "target": "benchmarking adversarial", "depth": [1, 2]}, {"source": "adversarial robustness", "target": "benchmarking", "depth": [1, 2]}, {"source": "adversarial robustness", "target": "explainability and adversarial", "depth": [1, 3]}, {"source": "convolution", "target": "colorectal polyp segmentation", "depth": [1, 2]}, {"source": "convolution", "target": "dilation convolution", "depth": [1, 2]}, {"source": "convolution", "target": "polyp segmentation", "depth": [1, 2]}, {"source": "markov decision proces", "target": "logic gate synthesis", "depth": [1, 2]}, {"source": "markov decision proces", "target": "quantum logic gate", "depth": [1, 2]}, {"source": "markov decision proces", "target": "decision proces", "depth": [1, 2]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 2]}, {"source": "learning model", "target": "chilean bills classification", "depth": [1, 2]}, {"source": "learning model", "target": "bills classification", "depth": [1, 2]}, {"source": "deep learning based", "target": "malware detection framework", "depth": [1, 2]}, {"source": "deep learning based", "target": "learning based android", "depth": [1, 2]}, {"source": "deep learning based", "target": "based android malware", "depth": [1, 2]}, {"source": "deep learning based", "target": "android malware detection", "depth": [1, 2]}, {"source": "load monitoring", "target": "non-intrusive load monitoring", "depth": [1, 2]}, {"source": "load monitoring", "target": "deep sparse coding", "depth": [1, 2]}, {"source": "load monitoring", "target": "sparse coding", "depth": [1, 2]}, {"source": "analysis on interaction", "target": "coordinated jamming attack", "depth": [1, 2]}, {"source": "analysis on interaction", "target": "radio system", "depth": [1, 2]}, {"source": "analysis on interaction", "target": "secondary and malicious", "depth": [1, 2]}, {"source": "analysis on interaction", "target": "malicious user", "depth": [1, 2]}, {"source": "interactions among secondary", "target": "coordinated jamming attack", "depth": [1, 2]}, {"source": "interactions among secondary", "target": "radio system", "depth": [1, 2]}, {"source": "interactions among secondary", "target": "secondary and malicious", "depth": [1, 2]}, {"source": "interactions among secondary", "target": "malicious user", "depth": [1, 2]}, {"source": "deep learning method", "target": "multi-coil cine mrus", "depth": [1, 2]}, {"source": "deep learning method", "target": "unsupervised deep learning", "depth": [1, 2]}, {"source": "deep learning method", "target": "cine mrus", "depth": [1, 2]}, {"source": "wireless sensor network", "target": "wireless sensor", "depth": [1, 2]}, {"source": "wireless sensor network", "target": "hybrid intrusion detection", "depth": [1, 2]}, {"source": "wireless sensor network", "target": "intrusion detection system", "depth": [1, 2]}, {"source": "wireless sensor network", "target": "detection system based", "depth": [1, 2]}, {"source": "reconfigurable intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 3]}, {"source": "intelligent surface", "target": "surface", "depth": [1, 2]}, {"source": "intelligent surface", "target": "large intelligent surface", "depth": [1, 3]}, {"source": "intelligent surface", "target": "large intelligent", "depth": [1, 3]}, {"source": "intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 3]}, {"source": "vision", "target": "language with localized", "depth": [1, 3]}, {"source": "vision", "target": "connecting vision", "depth": [1, 3]}, {"source": "vision", "target": "language agent navigation", "depth": [1, 3]}, {"source": "vision", "target": "agent navigation", "depth": [1, 3]}, {"source": "twitter", "target": "analysis in twitter", "depth": [1, 2]}, {"source": "twitter", "target": "sentiment", "depth": [1, 2]}, {"source": "twitter", "target": "information privacy opinion", "depth": [1, 3]}, {"source": "twitter", "target": "opinions on twitter", "depth": [1, 3]}]}