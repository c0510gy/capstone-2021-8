{"node": [["neural network", "deep neural network", "network", "learning", "reinforcement learning", "deep learning", "deep", "machine learning", "graph", "system", "model", "object detection", "detection"], ["convolutional neural network", "graph neural network", "recurrent neural network", "spiking neural network", "reinforcement", "deep reinforcement learning", "deep reinforcement", "multi-agent reinforcement learning", "learning model", "convolutional network", "graph convolutional network", "machine learning model", "machine", "knowledge graph", "knowledge", "graph convolutional", "recognition", "object", "survey", "image", "inverse problem", "information", "anomaly detection", "reinforcement learning approach", "learning approach", "algorithm", "optimization", "method", "computation", "datum", "image generation", "generation", "problem", "solution", "prediction", "face recognition", "speech recognition", "point cloud", "point", "semantic segmentation", "analysis", "domain adaptation", "domain", "pose estimation", "human pose estimation", "human pose", "estimation", "representation learning", "action recognition", "bayesian optimization", "application", "architecture", "challenge", "framework", "adversarial network", "generative adversarial network", "generative adversarial", "representation", "driving", "function", "approximation", "approach", "classification", "time series", "dataset", "game", "federated learning", "named entity recognition", "adversarial attack", "attack", "communication", "transfer learning", "architecture search", "neural architecture search", "neural architecture", "generalization", "segmentation", "instance segmentation", "fast", "object detector", "named entity", "entity recognition", "autonomous driving", "training", "semi-supervised learning", "translation", "neural machine translation", "neural machine", "machine translation", "control", "complexity", "case study", "task", "dynamical system", "object tracking", "social medium", "video", "modeling", "shape", "tree", "inference", "massive mimo", "computing", "camera", "monte carlo", "metric learning", "latent space", "variational autoencoder", "online", "activity recognition", "learning framework", "human", "distributed", "robustness", "weakly supervised", "word embedding", "embedding", "regression", "active learning", "sequence", "tracking", "space", "image segmentation", "few-shot learning", "constraint", "recommendation", "online learning", "identification", "resource allocation", "code", "artificial intelligence", "recognition system", "mutual information", "remote sensing", "scene", "finite element method", "transformer", "flow", "study", "theory", "system identification", "light field", "real-time", "person re-identification", "motion planning", "continual learning", "design", "distribution", "agent", "data augmentation", "perspective", "autonomous vehicle", "planning", "channel", "robust", "detector", "discontinuous galerkin", "expansion", "pattern", "social network", "bayesian", "question answering", "label", "efficient", "uncertainty", "model order reduction", "mobile robot", "alignment", "stochastic gradient descent", "gaussian proces", "software", "gan", "big datum", "control system", "transfer", "concept", "topology", "generative model", "manipulation", "optimal control"], ["deep learning model", "deep learning based", "deep learning approach", "complex network", "cyber-physical system", "time-delay system", "production system", "h-infinity", "entity", "adaptive object detection", "salient object detection", "symmetry breaking", "pedestrian detection", "deep convolutional neural", "optimization algorithm", "deep convolutional", "single image", "crowded scene", "speech", "cloud", "privacy", "unsupervised domain adaptation", "skeleton-based action recognition", "side information", "simulation", "state estimation", "state", "few-shot classification", "image classification", "time series forecasting", "reading comprehension", "image captioning", "mean-field game", "intelligence", "edge", "efficient neural architecture", "instance", "deep spiking neural", "feature extraction", "fast and accurate", "medical image", "search", "knowledge distillation", "computational complexity", "computational", "chest x-ray image", "medium", "learning with weighted", "invariant", "gap", "human activity recognition", "human activity", "activity", "distributed optimization", "weak supervision", "supervised", "visual tracking", "medical image segmentation", "geometric", "vocabulary expansion", "gradient flow", "wild", "mobile text entry", "nonlinear system identification", "prior knowledge", "arrangement", "entanglement", "graph embedding", "autoencoder", "memory network", "edge crossing", "constraint satisfaction", "discontinuous galerkin method", "galerkin method", "disentangled representation", "bayesian approach", "visual question answering", "visual question", "noisy label", "sample efficient", "order reduction", "graph alignment", "gradient descent", "stochastic gradient", "multi-agent reinforcement", "gaussian process regression", "software framework", "framework for quantum", "cycle", "bert", "style transfer", "generative", "program synthesis", "visual navigation"], ["algorithm-based fault tolerance", "fault tolerance", "cognitive routing based", "point detection algorithm", "change point detection", "computation of eigenvalue", "eigenvalue", "crime prediction", "spatio-temporal datum", "prediction using spatio-temporal", "deep convolutional network", "pyramid for image", "multiple prediction", "detection in crowded", "recognition on coprocessor", "parametric surface fitting", "lightning network", "empirical analysis", "analysis of privacy", "string edit distance", "unstructured multilingual text", "audio representation learning", "cross-modal audio representation", "unsupervised cross-modal audio", "generalizable semantic segmentation", "target-specific normalization", "segmentation via model-agnostic", "model-agnostic learning", "cognitive routing", "routing based", "structure and optimization", "paths in complex", "edge intelligence", "information hiding", "detection of information", "hiding at anti-copying", "simulation framework", "system-level domain-specific", "overcome microphone variability", "air quality inference", "representation invariant", "inference of representation", "data-driven inference", "progressive graph convolutional", "semi-supervised node classification", "cycle-consistent generative adversarial", "speech system", "architectures and training", "training method", "gauss sum", "repartition of gaus", "carlet-feng function", "health state estimation", "health state", "execution and prioritization", "set-theoretic approach", "approach to multi-task", "multi-task execution", "selecting relevant feature", "relevant feature", "series forecasting", "financial time series", "dataset for image", "automating botnet detection", "botnet detection", "detection with graph", "regularized mean-field game", "regularized mean-field", "privacy-preserving medical named", "medical named entity", "countermeasures of asv", "defense against adversarial", "kernel ridge regression", "distributed kernel ridge", "regression with communication", "inter-capillary area quantification", "deep vascular complex", "segmentation and inter-capillary", "networks to overcome", "mixed-level reformulation", "bias explain generalization", "implicit bias explain", "explain generalization", "implicit bia", "point-based instance segmentation", "convolutional spiking neural", "spatio-temporal feature extraction", "milena", "predicting the number", "coauthors for researcher", "accurate object detector", "comprehensive named entity", "decentralized runtime protection", "runtime protection system", "decentralized runtime", "runtime protection", "training for speech", "coprocessor", "medical image detection", "image detection", "fon-french neural machine", "ffr", "teaching an algorithm", "model for cultural", "cultural learning", "control of complex", "data-driven control", "data-free knowledge amalgamation", "knowledge amalgamation", "data-free knowledge", "ham-sandwich problem", "simulated annealing", "few-shot time series", "ordinal regression recurrent", "industrial case study", "role of software", "software architecture", "ner", "named", "performance via reverse", "reconfiguration of dynamical", "systems for improved", "viral pneumonia screening", "confidence-aware anomaly detection", "pneumonia screening", "real-time object tracking", "real-time object", "extremely small matrix", "analyzing misinformation", "twitter conversation", "conspiracy video", "longitudinal analysis", "promotion of conspiracy", "analysis of youtube", "shapes by reinforcement", "random binary tree", "binary tree", "collection of fringe", "sequential uplink processing", "cell-free massive mimo", "uplink processing", "mimo with radio", "proportional veto core", "computing the proportional", "veto core", "gap for event", "event camera", "carlo", "pose and shape", "metric-scale truncation-robust heatmap", "face recognition dataset", "masked face recognition", "dataset and application", "unifying mutual information", "mutual information view", "cross-entropy vs. pairwise", "pairwise loss", "diffusion variational autoencoder", "hyperspherical latent space", "method preference", "dis-empowerment online", "privacy-sharing perception", "investigation of privacy-sharing", "temporal extension module", "extension module", "boost gnn expressiveness", "collective learning framework", "gnn expressiveness", "navigation among human", "humans with optimal", "byzantine-resilient distributed optimization", "multi-dimensional function", "optimization of multi-dimensional", "learning stl task", "stl task", "robustness metric", "metrics for learning", "voice activity detection", "weakly supervised sound", "co-occurrence text network", "text network", "embeddings to improve", "regression for visual", "probabilistic regression", "events from tweet", "crowdsourcing and active", "learning for classification", "integrating crowdsourcing", "leech sequence", "squarefree term", "term not occurring", "leech", "optimize non-rigid tracking", "learning to optimize", "non-rigid tracking", "breaking", "bayesian inverse problem", "generalized parallel tempering", "high quality software", "science from space", "quality software", "semantic image segmentation", "semantic image", "geometric constraint", "learning with geometric", "attribute-aware attentive gcn", "attentive gcn model", "model for recommendation", "networks via online", "training small", "altitude balloon network", "wireless high altitude", "high altitude balloon", "balloon network", "semantic pyramid", "pyramid", "distant or weak", "commit code", "characterizing bot", "bots that commit", "comments on sejnowski", "sejnowski", "speech recognition system", "hybrid speech recognition", "remote sensing image", "detection in remote", "sensing image", "implicit grid representation", "local implicit grid", "space-time finite element", "adaptive space-time finite", "adaptive space-time", "point-based instance", "convex nonparametric formulation", "nonparametric formulation", "text entry behavimy", "text entry", "entry behavimy", "region of attraction", "identification with prior", "camera arrangement", "chiral domain", "identification without entanglement", "quantum identification", "contextual embedding", "surface light field", "implicit surface light", "learning implicit surface", "implicit surface", "real-time information retrieval", "identity card", "retrieval from identity", "video-based person re-identification", "attentive feature aggregation", "reference-aided attentive feature", "task and motion", "hyperspherical latent", "ionic liquid", "ammonia capture", "capture of ionic", "online continual learning", "learning on sequence", "triple memory network", "reappraising the distribution", "number of edge", "stubborn agent", "majority dynamic", "dynamics with biased", "biased and stubborn", "models for neural", "augmentation", "two-way perspective", "detection with wearable", "wearable camera", "object-induced action decision", "explainable object-induced action", "object-induced action", "planning with brain-inspired", "sparse graphical memory", "robust planning", "vector poisson channel", "poisson channel", "conditional mean estimator", "non-parametric methods robust", "methods robust", "adapting object detector", "adapting object", "categorical variables informed", "algorithm for bayesian", "applications to chemistry", "optimization for categorical", "urban air quality", "quality inference", "method for incompressible", "incompressible two-phase", "singular euler-maclaurin expansion", "singular euler-maclaurin", "euler-maclaurin expansion", "autonomous car", "driving for intervention", "intervention in autonomous", "maneuver-based driving", "scientific elite revisited", "patterns of productivity", "authorship and impact", "online social network", "topological prior", "approach to inverse", "question answering dataset", "practical annotation strategy", "nonlinear spde", "approximation of nonlinear", "numerical approximation", "domain-adversarial image generation", "deep domain-adversarial image", "domain generalisation", "generation for domain", "truncation-robust heatmap", "metric-scale truncation-robust", "regret sample selection", "regret sample", "sample selection", "ensemble learning", "safe mission planning", "dynamical uncertainty", "mission planning", "planning under dynamical", "based model order", "model order", "resource-constrained mobile robot", "learning-based bias correction", "bias correction", "correction for ultra-wideband", "wasserstein-based graph alignment", "wasserstein-based graph", "difficult combinatorial problem", "combinatorial problem", "predict the solution", "deep multi-agent reinforcement", "gaussian process bandit", "process bandit", "quantum network", "qunetsim", "accurate object", "saccadenet", "gan with bert", "sorting big datum", "college ranking", "data by revealed", "graph limit", "onsager-machlup functional", "event-triggered control system", "homogeneous event-triggered control", "nonlinear homogeneous event-triggered", "blockchain meets biometric", "application to template", "template protection", "combinatorial topology", "set-agreement bound", "bounds in round-based", "round-based model", "tensor manipulation", "synthesis for tensor"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 1]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "spiking neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "deep", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 0]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 2]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 2]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 2]}, {"source": "network", "target": "convolutional network", "depth": [0, 1]}, {"source": "network", "target": "complex network", "depth": [0, 2]}, {"source": "network", "target": "graph", "depth": [0, 0]}, {"source": "network", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "system", "target": "cyber-physical system", "depth": [0, 2]}, {"source": "system", "target": "time-delay system", "depth": [0, 2]}, {"source": "system", "target": "production system", "depth": [0, 2]}, {"source": "system", "target": "h-infinity", "depth": [0, 2]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "knowledge", "depth": [0, 1]}, {"source": "graph", "target": "entity", "depth": [0, 2]}, {"source": "graph", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "graph", "target": "convolutional network", "depth": [0, 1]}, {"source": "graph", "target": "graph convolutional", "depth": [0, 1]}, {"source": "model", "target": "recognition", "depth": [0, 1]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "adaptive object detection", "depth": [0, 2]}, {"source": "object detection", "target": "salient object detection", "depth": [0, 2]}, {"source": "object detection", "target": "detection", "depth": [0, 0]}, {"source": "deep", "target": "survey", "depth": [0, 1]}, {"source": "deep", "target": "image", "depth": [0, 1]}, {"source": "deep", "target": "symmetry breaking", "depth": [0, 2]}, {"source": "deep", "target": "inverse problem", "depth": [0, 1]}, {"source": "detection", "target": "pedestrian detection", "depth": [0, 2]}, {"source": "detection", "target": "information", "depth": [0, 1]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "anomaly detection", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [1, 2]}, {"source": "convolutional neural network", "target": "algorithm-based fault tolerance", "depth": [1, 3]}, {"source": "convolutional neural network", "target": "fault tolerance", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "cognitive routing based", "depth": [1, 3]}, {"source": "algorithm", "target": "optimization algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "optimization", "depth": [1, 1]}, {"source": "algorithm", "target": "point detection algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "change point detection", "depth": [1, 3]}, {"source": "method", "target": "survey", "depth": [1, 1]}, {"source": "method", "target": "computation of eigenvalue", "depth": [1, 3]}, {"source": "method", "target": "eigenvalue", "depth": [1, 3]}, {"source": "method", "target": "computation", "depth": [1, 1]}, {"source": "datum", "target": "crime prediction", "depth": [1, 3]}, {"source": "datum", "target": "spatio-temporal datum", "depth": [1, 3]}, {"source": "datum", "target": "prediction using spatio-temporal", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "deep convolutional", "depth": [1, 2]}, {"source": "image", "target": "image generation", "depth": [1, 1]}, {"source": "image", "target": "generation", "depth": [1, 1]}, {"source": "image", "target": "single image", "depth": [1, 2]}, {"source": "image", "target": "pyramid for image", "depth": [1, 3]}, {"source": "problem", "target": "solution", "depth": [1, 1]}, {"source": "problem", "target": "inverse problem", "depth": [1, 1]}, {"source": "problem", "target": "symmetry breaking", "depth": [1, 2]}, {"source": "prediction", "target": "multiple prediction", "depth": [1, 3]}, {"source": "prediction", "target": "crowded scene", "depth": [1, 2]}, {"source": "prediction", "target": "detection in crowded", "depth": [1, 3]}, {"source": "recognition", "target": "face recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 2]}, {"source": "recognition", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "point cloud", "target": "point", "depth": [1, 1]}, {"source": "point cloud", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "point cloud", "target": "cloud", "depth": [1, 2]}, {"source": "point cloud", "target": "parametric surface fitting", "depth": [1, 3]}, {"source": "analysis", "target": "lightning network", "depth": [1, 3]}, {"source": "analysis", "target": "empirical analysis", "depth": [1, 3]}, {"source": "analysis", "target": "analysis of privacy", "depth": [1, 3]}, {"source": "analysis", "target": "privacy", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "knowledge graph", "target": "entity", "depth": [1, 2]}, {"source": "knowledge graph", "target": "knowledge", "depth": [1, 1]}, {"source": "knowledge graph", "target": "string edit distance", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "estimation", "depth": [1, 1]}, {"source": "representation learning", "target": "unstructured multilingual text", "depth": [1, 3]}, {"source": "representation learning", "target": "audio representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "cross-modal audio representation", "depth": [1, 3]}, {"source": "representation learning", "target": "unsupervised cross-modal audio", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "generalizable semantic segmentation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "target-specific normalization", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation via model-agnostic", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "model-agnostic learning", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "cognitive routing based", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "cognitive routing", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "routing based", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "action recognition", "depth": [1, 1]}, {"source": "optimization", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "optimization", "target": "structure and optimization", "depth": [1, 3]}, {"source": "optimization", "target": "complex network", "depth": [1, 2]}, {"source": "optimization", "target": "paths in complex", "depth": [1, 3]}, {"source": "application", "target": "edge intelligence", "depth": [1, 3]}, {"source": "application", "target": "architecture", "depth": [1, 1]}, {"source": "application", "target": "challenge", "depth": [1, 1]}, {"source": "information", "target": "side information", "depth": [1, 2]}, {"source": "information", "target": "information hiding", "depth": [1, 3]}, {"source": "information", "target": "detection of information", "depth": [1, 3]}, {"source": "information", "target": "hiding at anti-copying", "depth": [1, 3]}, {"source": "framework", "target": "simulation framework", "depth": [1, 3]}, {"source": "framework", "target": "system-level domain-specific", "depth": [1, 3]}, {"source": "framework", "target": "simulation", "depth": [1, 2]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "air quality inference", "depth": [1, 3]}, {"source": "representation", "target": "representation invariant", "depth": [1, 3]}, {"source": "representation", "target": "inference of representation", "depth": [1, 3]}, {"source": "representation", "target": "data-driven inference", "depth": [1, 3]}, {"source": "graph convolutional", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "graph convolutional", "target": "action recognition", "depth": [1, 1]}, {"source": "graph convolutional", "target": "progressive graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional", "target": "semi-supervised node classification", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "cycle-consistent generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "speech system", "depth": [1, 3]}, {"source": "survey", "target": "architectures and training", "depth": [1, 3]}, {"source": "survey", "target": "training method", "depth": [1, 3]}, {"source": "survey", "target": "driving", "depth": [1, 1]}, {"source": "function", "target": "approximation", "depth": [1, 1]}, {"source": "function", "target": "gauss sum", "depth": [1, 3]}, {"source": "function", "target": "repartition of gaus", "depth": [1, 3]}, {"source": "function", "target": "carlet-feng function", "depth": [1, 3]}, {"source": "estimation", "target": "health state estimation", "depth": [1, 3]}, {"source": "estimation", "target": "state estimation", "depth": [1, 2]}, {"source": "estimation", "target": "health state", "depth": [1, 3]}, {"source": "estimation", "target": "state", "depth": [1, 2]}, {"source": "approach", "target": "execution and prioritization", "depth": [1, 3]}, {"source": "approach", "target": "set-theoretic approach", "depth": [1, 3]}, {"source": "approach", "target": "approach to multi-task", "depth": [1, 3]}, {"source": "approach", "target": "multi-task execution", "depth": [1, 3]}, {"source": "classification", "target": "few-shot classification", "depth": [1, 2]}, {"source": "classification", "target": "image classification", "depth": [1, 2]}, {"source": "classification", "target": "selecting relevant feature", "depth": [1, 3]}, {"source": "classification", "target": "relevant feature", "depth": [1, 3]}, {"source": "time series", "target": "time series forecasting", "depth": [1, 2]}, {"source": "time series", "target": "series forecasting", "depth": [1, 3]}, {"source": "time series", "target": "financial time series", "depth": [1, 3]}, {"source": "dataset", "target": "reading comprehension", "depth": [1, 2]}, {"source": "dataset", "target": "dataset for image", "depth": [1, 3]}, {"source": "dataset", "target": "image captioning", "depth": [1, 2]}, {"source": "graph neural network", "target": "automating botnet detection", "depth": [1, 3]}, {"source": "graph neural network", "target": "botnet detection", "depth": [1, 3]}, {"source": "graph neural network", "target": "detection with graph", "depth": [1, 3]}, {"source": "game", "target": "mean-field game", "depth": [1, 2]}, {"source": "game", "target": "regularized mean-field game", "depth": [1, 3]}, {"source": "game", "target": "regularized mean-field", "depth": [1, 3]}, {"source": "federated learning", "target": "privacy-preserving medical named", "depth": [1, 3]}, {"source": "federated learning", "target": "medical named entity", "depth": [1, 3]}, {"source": "federated learning", "target": "named entity recognition", "depth": [1, 1]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "countermeasures of asv", "depth": [1, 3]}, {"source": "adversarial attack", "target": "defense against adversarial", "depth": [1, 3]}, {"source": "communication", "target": "kernel ridge regression", "depth": [1, 3]}, {"source": "communication", "target": "distributed kernel ridge", "depth": [1, 3]}, {"source": "communication", "target": "regression with communication", "depth": [1, 3]}, {"source": "transfer learning", "target": "inter-capillary area quantification", "depth": [1, 3]}, {"source": "transfer learning", "target": "deep vascular complex", "depth": [1, 3]}, {"source": "transfer learning", "target": "segmentation and inter-capillary", "depth": [1, 3]}, {"source": "challenge", "target": "edge intelligence", "depth": [1, 3]}, {"source": "challenge", "target": "architecture", "depth": [1, 1]}, {"source": "challenge", "target": "intelligence", "depth": [1, 2]}, {"source": "challenge", "target": "edge", "depth": [1, 2]}, {"source": "generative adversarial", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "generative adversarial", "target": "cycle-consistent generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "speech system", "depth": [1, 3]}, {"source": "generative adversarial", "target": "networks to overcome", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "architecture search", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "generalization", "target": "bias explain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "implicit bias explain", "depth": [1, 3]}, {"source": "generalization", "target": "explain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "implicit bia", "depth": [1, 3]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "instance", "depth": [1, 2]}, {"source": "segmentation", "target": "point-based instance segmentation", "depth": [1, 3]}, {"source": "spiking neural network", "target": "deep spiking neural", "depth": [1, 2]}, {"source": "spiking neural network", "target": "convolutional spiking neural", "depth": [1, 3]}, {"source": "spiking neural network", "target": "spatio-temporal feature extraction", "depth": [1, 3]}, {"source": "spiking neural network", "target": "feature extraction", "depth": [1, 2]}, {"source": "neural architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "neural architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture search", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "neural architecture search", "target": "milena", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 1]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 2]}, {"source": "learning model", "target": "predicting the number", "depth": [1, 3]}, {"source": "learning model", "target": "coauthors for researcher", "depth": [1, 3]}, {"source": "fast", "target": "fast and accurate", "depth": [1, 2]}, {"source": "fast", "target": "accurate object detector", "depth": [1, 3]}, {"source": "fast", "target": "object detector", "depth": [1, 1]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity recognition", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "autonomous driving", "target": "decentralized runtime protection", "depth": [1, 3]}, {"source": "autonomous driving", "target": "runtime protection system", "depth": [1, 3]}, {"source": "autonomous driving", "target": "decentralized runtime", "depth": [1, 3]}, {"source": "autonomous driving", "target": "runtime protection", "depth": [1, 3]}, {"source": "training", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "training", "target": "speech recognition", "depth": [1, 1]}, {"source": "training", "target": "training for speech", "depth": [1, 3]}, {"source": "training", "target": "coprocessor", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "medical image detection", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "medical image", "depth": [1, 2]}, {"source": "semi-supervised learning", "target": "image detection", "depth": [1, 3]}, {"source": "translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "translation", "target": "neural machine", "depth": [1, 1]}, {"source": "translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "translation", "target": "ffr", "depth": [1, 3]}, {"source": "machine", "target": "teaching an algorithm", "depth": [1, 3]}, {"source": "machine", "target": "model for cultural", "depth": [1, 3]}, {"source": "machine", "target": "cultural learning", "depth": [1, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 2]}, {"source": "speech recognition", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "speech recognition", "target": "training for speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "coprocessor", "depth": [1, 3]}, {"source": "architecture", "target": "edge intelligence", "depth": [1, 3]}, {"source": "architecture", "target": "intelligence", "depth": [1, 2]}, {"source": "architecture", "target": "edge", "depth": [1, 2]}, {"source": "architecture", "target": "search", "depth": [1, 2]}, {"source": "control", "target": "complex network", "depth": [1, 2]}, {"source": "control", "target": "control of complex", "depth": [1, 3]}, {"source": "control", "target": "data-driven control", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge distillation", "depth": [1, 2]}, {"source": "knowledge", "target": "data-free knowledge amalgamation", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge amalgamation", "depth": [1, 3]}, {"source": "knowledge", "target": "data-free knowledge", "depth": [1, 3]}, {"source": "complexity", "target": "computational complexity", "depth": [1, 2]}, {"source": "complexity", "target": "computational", "depth": [1, 2]}, {"source": "complexity", "target": "ham-sandwich problem", "depth": [1, 3]}, {"source": "complexity", "target": "simulated annealing", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "few-shot time series", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "time series forecasting", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "ordinal regression recurrent", "depth": [1, 3]}, {"source": "case study", "target": "industrial case study", "depth": [1, 3]}, {"source": "case study", "target": "role of software", "depth": [1, 3]}, {"source": "case study", "target": "software architecture", "depth": [1, 3]}, {"source": "task", "target": "named entity", "depth": [1, 1]}, {"source": "task", "target": "entity recognition", "depth": [1, 1]}, {"source": "task", "target": "ner", "depth": [1, 3]}, {"source": "task", "target": "named", "depth": [1, 3]}, {"source": "dynamical system", "target": "performance via reverse", "depth": [1, 3]}, {"source": "dynamical system", "target": "reconfiguration of dynamical", "depth": [1, 3]}, {"source": "dynamical system", "target": "systems for improved", "depth": [1, 3]}, {"source": "anomaly detection", "target": "chest x-ray image", "depth": [1, 2]}, {"source": "anomaly detection", "target": "viral pneumonia screening", "depth": [1, 3]}, {"source": "anomaly detection", "target": "confidence-aware anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "pneumonia screening", "depth": [1, 3]}, {"source": "object tracking", "target": "real-time object tracking", "depth": [1, 3]}, {"source": "object tracking", "target": "real-time object", "depth": [1, 3]}, {"source": "object tracking", "target": "extremely small matrix", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "analyzing misinformation", "depth": [1, 3]}, {"source": "social medium", "target": "twitter conversation", "depth": [1, 3]}, {"source": "video", "target": "conspiracy video", "depth": [1, 3]}, {"source": "video", "target": "longitudinal analysis", "depth": [1, 3]}, {"source": "video", "target": "promotion of conspiracy", "depth": [1, 3]}, {"source": "video", "target": "analysis of youtube", "depth": [1, 3]}, {"source": "neural architecture", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "neural architecture", "target": "milena", "depth": [1, 3]}, {"source": "neural architecture", "target": "search", "depth": [1, 2]}, {"source": "reinforcement", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "reinforcement", "target": "modeling", "depth": [1, 1]}, {"source": "reinforcement", "target": "shape", "depth": [1, 1]}, {"source": "reinforcement", "target": "learning with weighted", "depth": [1, 2]}, {"source": "tree", "target": "random binary tree", "depth": [1, 3]}, {"source": "tree", "target": "binary tree", "depth": [1, 3]}, {"source": "tree", "target": "collection of fringe", "depth": [1, 3]}, {"source": "inference", "target": "representation invariant", "depth": [1, 3]}, {"source": "inference", "target": "inference of representation", "depth": [1, 3]}, {"source": "inference", "target": "data-driven inference", "depth": [1, 3]}, {"source": "inference", "target": "invariant", "depth": [1, 2]}, {"source": "massive mimo", "target": "sequential uplink processing", "depth": [1, 3]}, {"source": "massive mimo", "target": "cell-free massive mimo", "depth": [1, 3]}, {"source": "massive mimo", "target": "uplink processing", "depth": [1, 3]}, {"source": "massive mimo", "target": "mimo with radio", "depth": [1, 3]}, {"source": "computing", "target": "proportional veto core", "depth": [1, 3]}, {"source": "computing", "target": "computing the proportional", "depth": [1, 3]}, {"source": "computing", "target": "veto core", "depth": [1, 3]}, {"source": "camera", "target": "gap for event", "depth": [1, 3]}, {"source": "camera", "target": "event camera", "depth": [1, 3]}, {"source": "camera", "target": "gap", "depth": [1, 2]}, {"source": "monte carlo", "target": "carlo", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human pose", "target": "pose and shape", "depth": [1, 3]}, {"source": "human pose", "target": "metric-scale truncation-robust heatmap", "depth": [1, 3]}, {"source": "face recognition", "target": "face recognition dataset", "depth": [1, 3]}, {"source": "face recognition", "target": "masked face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "dataset and application", "depth": [1, 3]}, {"source": "metric learning", "target": "unifying mutual information", "depth": [1, 3]}, {"source": "metric learning", "target": "mutual information view", "depth": [1, 3]}, {"source": "metric learning", "target": "cross-entropy vs. pairwise", "depth": [1, 3]}, {"source": "metric learning", "target": "pairwise loss", "depth": [1, 3]}, {"source": "latent space", "target": "diffusion variational autoencoder", "depth": [1, 3]}, {"source": "latent space", "target": "hyperspherical latent space", "depth": [1, 3]}, {"source": "latent space", "target": "variational autoencoder", "depth": [1, 1]}, {"source": "online", "target": "method preference", "depth": [1, 3]}, {"source": "online", "target": "dis-empowerment online", "depth": [1, 3]}, {"source": "online", "target": "privacy-sharing perception", "depth": [1, 3]}, {"source": "online", "target": "investigation of privacy-sharing", "depth": [1, 3]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "temporal extension module", "depth": [1, 3]}, {"source": "action recognition", "target": "extension module", "depth": [1, 3]}, {"source": "activity recognition", "target": "human activity recognition", "depth": [1, 2]}, {"source": "activity recognition", "target": "human activity", "depth": [1, 2]}, {"source": "activity recognition", "target": "activity", "depth": [1, 2]}, {"source": "learning framework", "target": "boost gnn expressiveness", "depth": [1, 3]}, {"source": "learning framework", "target": "collective learning framework", "depth": [1, 3]}, {"source": "learning framework", "target": "gnn expressiveness", "depth": [1, 3]}, {"source": "human", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human", "target": "navigation among human", "depth": [1, 3]}, {"source": "human", "target": "humans with optimal", "depth": [1, 3]}, {"source": "distributed", "target": "byzantine-resilient distributed optimization", "depth": [1, 3]}, {"source": "distributed", "target": "distributed optimization", "depth": [1, 2]}, {"source": "distributed", "target": "multi-dimensional function", "depth": [1, 3]}, {"source": "distributed", "target": "optimization of multi-dimensional", "depth": [1, 3]}, {"source": "robustness", "target": "learning stl task", "depth": [1, 3]}, {"source": "robustness", "target": "stl task", "depth": [1, 3]}, {"source": "robustness", "target": "robustness metric", "depth": [1, 3]}, {"source": "robustness", "target": "metrics for learning", "depth": [1, 3]}, {"source": "named entity", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "named entity", "target": "weak supervision", "depth": [1, 2]}, {"source": "weakly supervised", "target": "supervised", "depth": [1, 2]}, {"source": "weakly supervised", "target": "voice activity detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised sound", "depth": [1, 3]}, {"source": "word embedding", "target": "embedding", "depth": [1, 1]}, {"source": "word embedding", "target": "co-occurrence text network", "depth": [1, 3]}, {"source": "word embedding", "target": "text network", "depth": [1, 3]}, {"source": "word embedding", "target": "embeddings to improve", "depth": [1, 3]}, {"source": "regression", "target": "visual tracking", "depth": [1, 2]}, {"source": "regression", "target": "regression for visual", "depth": [1, 3]}, {"source": "regression", "target": "probabilistic regression", "depth": [1, 3]}, {"source": "active learning", "target": "events from tweet", "depth": [1, 3]}, {"source": "active learning", "target": "crowdsourcing and active", "depth": [1, 3]}, {"source": "active learning", "target": "learning for classification", "depth": [1, 3]}, {"source": "active learning", "target": "integrating crowdsourcing", "depth": [1, 3]}, {"source": "sequence", "target": "leech sequence", "depth": [1, 3]}, {"source": "sequence", "target": "squarefree term", "depth": [1, 3]}, {"source": "sequence", "target": "term not occurring", "depth": [1, 3]}, {"source": "sequence", "target": "leech", "depth": [1, 3]}, {"source": "tracking", "target": "optimize non-rigid tracking", "depth": [1, 3]}, {"source": "tracking", "target": "learning to optimize", "depth": [1, 3]}, {"source": "tracking", "target": "non-rigid tracking", "depth": [1, 3]}, {"source": "inverse problem", "target": "symmetry breaking", "depth": [1, 2]}, {"source": "inverse problem", "target": "breaking", "depth": [1, 3]}, {"source": "inverse problem", "target": "bayesian inverse problem", "depth": [1, 3]}, {"source": "inverse problem", "target": "generalized parallel tempering", "depth": [1, 3]}, {"source": "space", "target": "high quality software", "depth": [1, 3]}, {"source": "space", "target": "science from space", "depth": [1, 3]}, {"source": "space", "target": "quality software", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "image segmentation", "target": "semantic image segmentation", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 2]}, {"source": "image segmentation", "target": "semantic image", "depth": [1, 3]}, {"source": "few-shot learning", "target": "geometric constraint", "depth": [1, 3]}, {"source": "few-shot learning", "target": "learning with geometric", "depth": [1, 3]}, {"source": "few-shot learning", "target": "constraint", "depth": [1, 1]}, {"source": "few-shot learning", "target": "geometric", "depth": [1, 2]}, {"source": "recommendation", "target": "attribute-aware attentive gcn", "depth": [1, 3]}, {"source": "recommendation", "target": "attentive gcn model", "depth": [1, 3]}, {"source": "recommendation", "target": "model for recommendation", "depth": [1, 3]}, {"source": "online learning", "target": "networks via online", "depth": [1, 3]}, {"source": "online learning", "target": "identification", "depth": [1, 1]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "neural machine translation", "target": "ffr", "depth": [1, 3]}, {"source": "neural machine translation", "target": "training small", "depth": [1, 3]}, {"source": "resource allocation", "target": "altitude balloon network", "depth": [1, 3]}, {"source": "resource allocation", "target": "wireless high altitude", "depth": [1, 3]}, {"source": "resource allocation", "target": "high altitude balloon", "depth": [1, 3]}, {"source": "resource allocation", "target": "balloon network", "depth": [1, 3]}, {"source": "generation", "target": "image generation", "depth": [1, 1]}, {"source": "generation", "target": "pyramid for image", "depth": [1, 3]}, {"source": "generation", "target": "semantic pyramid", "depth": [1, 3]}, {"source": "generation", "target": "pyramid", "depth": [1, 3]}, {"source": "entity recognition", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "entity recognition", "target": "weak supervision", "depth": [1, 2]}, {"source": "entity recognition", "target": "distant or weak", "depth": [1, 3]}, {"source": "modeling", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "modeling", "target": "shape", "depth": [1, 1]}, {"source": "code", "target": "commit code", "depth": [1, 3]}, {"source": "code", "target": "characterizing bot", "depth": [1, 3]}, {"source": "code", "target": "bots that commit", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "comments on sejnowski", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "sejnowski", "depth": [1, 3]}, {"source": "recognition system", "target": "speech recognition system", "depth": [1, 3]}, {"source": "recognition system", "target": "hybrid speech recognition", "depth": [1, 3]}, {"source": "recognition system", "target": "vocabulary expansion", "depth": [1, 2]}, {"source": "mutual information", "target": "unifying mutual information", "depth": [1, 3]}, {"source": "mutual information", "target": "mutual information view", "depth": [1, 3]}, {"source": "mutual information", "target": "cross-entropy vs. pairwise", "depth": [1, 3]}, {"source": "mutual information", "target": "pairwise loss", "depth": [1, 3]}, {"source": "remote sensing", "target": "remote sensing image", "depth": [1, 3]}, {"source": "remote sensing", "target": "detection in remote", "depth": [1, 3]}, {"source": "remote sensing", "target": "sensing image", "depth": [1, 3]}, {"source": "scene", "target": "crowded scene", "depth": [1, 2]}, {"source": "scene", "target": "implicit grid representation", "depth": [1, 3]}, {"source": "scene", "target": "local implicit grid", "depth": [1, 3]}, {"source": "finite element method", "target": "space-time finite element", "depth": [1, 3]}, {"source": "finite element method", "target": "adaptive space-time finite", "depth": [1, 3]}, {"source": "finite element method", "target": "adaptive space-time", "depth": [1, 3]}, {"source": "instance segmentation", "target": "instance", "depth": [1, 2]}, {"source": "instance segmentation", "target": "point-based instance segmentation", "depth": [1, 3]}, {"source": "instance segmentation", "target": "point-based instance", "depth": [1, 3]}, {"source": "flow", "target": "convex nonparametric formulation", "depth": [1, 3]}, {"source": "flow", "target": "gradient flow", "depth": [1, 2]}, {"source": "flow", "target": "nonparametric formulation", "depth": [1, 3]}, {"source": "object", "target": "wild", "depth": [1, 2]}, {"source": "study", "target": "text entry behavimy", "depth": [1, 3]}, {"source": "study", "target": "mobile text entry", "depth": [1, 2]}, {"source": "study", "target": "text entry", "depth": [1, 3]}, {"source": "study", "target": "entry behavimy", "depth": [1, 3]}, {"source": "system identification", "target": "nonlinear system identification", "depth": [1, 2]}, {"source": "system identification", "target": "region of attraction", "depth": [1, 3]}, {"source": "system identification", "target": "identification with prior", "depth": [1, 3]}, {"source": "system identification", "target": "prior knowledge", "depth": [1, 2]}, {"source": "domain", "target": "camera arrangement", "depth": [1, 3]}, {"source": "domain", "target": "chiral domain", "depth": [1, 3]}, {"source": "domain", "target": "arrangement", "depth": [1, 2]}, {"source": "identification", "target": "identification without entanglement", "depth": [1, 3]}, {"source": "identification", "target": "quantum identification", "depth": [1, 3]}, {"source": "identification", "target": "entanglement", "depth": [1, 2]}, {"source": "embedding", "target": "contextual embedding", "depth": [1, 3]}, {"source": "embedding", "target": "graph embedding", "depth": [1, 2]}, {"source": "light field", "target": "surface light field", "depth": [1, 3]}, {"source": "light field", "target": "implicit surface light", "depth": [1, 3]}, {"source": "light field", "target": "learning implicit surface", "depth": [1, 3]}, {"source": "light field", "target": "implicit surface", "depth": [1, 3]}, {"source": "real-time", "target": "real-time information retrieval", "depth": [1, 3]}, {"source": "real-time", "target": "identity card", "depth": [1, 3]}, {"source": "real-time", "target": "retrieval from identity", "depth": [1, 3]}, {"source": "person re-identification", "target": "video-based person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "attentive feature aggregation", "depth": [1, 3]}, {"source": "person re-identification", "target": "reference-aided attentive feature", "depth": [1, 3]}, {"source": "motion planning", "target": "task and motion", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "diffusion variational autoencoder", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "hyperspherical latent space", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "hyperspherical latent", "depth": [1, 3]}, {"source": "machine learning model", "target": "ionic liquid", "depth": [1, 3]}, {"source": "machine learning model", "target": "ammonia capture", "depth": [1, 3]}, {"source": "machine learning model", "target": "capture of ionic", "depth": [1, 3]}, {"source": "continual learning", "target": "online continual learning", "depth": [1, 3]}, {"source": "continual learning", "target": "learning on sequence", "depth": [1, 3]}, {"source": "continual learning", "target": "triple memory network", "depth": [1, 3]}, {"source": "continual learning", "target": "memory network", "depth": [1, 2]}, {"source": "distribution", "target": "reappraising the distribution", "depth": [1, 3]}, {"source": "distribution", "target": "number of edge", "depth": [1, 3]}, {"source": "distribution", "target": "edge crossing", "depth": [1, 2]}, {"source": "agent", "target": "stubborn agent", "depth": [1, 3]}, {"source": "agent", "target": "majority dynamic", "depth": [1, 3]}, {"source": "agent", "target": "dynamics with biased", "depth": [1, 3]}, {"source": "agent", "target": "biased and stubborn", "depth": [1, 3]}, {"source": "neural machine", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "ffr", "depth": [1, 3]}, {"source": "neural machine", "target": "training small", "depth": [1, 3]}, {"source": "neural machine", "target": "models for neural", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 3]}, {"source": "perspective", "target": "two-way perspective", "depth": [1, 3]}, {"source": "perspective", "target": "detection with wearable", "depth": [1, 3]}, {"source": "perspective", "target": "wearable camera", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "object-induced action decision", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "explainable object-induced action", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "object-induced action", "depth": [1, 3]}, {"source": "constraint", "target": "constraint satisfaction", "depth": [1, 2]}, {"source": "constraint", "target": "geometric constraint", "depth": [1, 3]}, {"source": "constraint", "target": "learning with geometric", "depth": [1, 3]}, {"source": "constraint", "target": "geometric", "depth": [1, 2]}, {"source": "planning", "target": "planning with brain-inspired", "depth": [1, 3]}, {"source": "planning", "target": "sparse graphical memory", "depth": [1, 3]}, {"source": "planning", "target": "robust planning", "depth": [1, 3]}, {"source": "channel", "target": "vector poisson channel", "depth": [1, 3]}, {"source": "channel", "target": "poisson channel", "depth": [1, 3]}, {"source": "channel", "target": "conditional mean estimator", "depth": [1, 3]}, {"source": "robust", "target": "non-parametric methods robust", "depth": [1, 3]}, {"source": "robust", "target": "methods robust", "depth": [1, 3]}, {"source": "object detector", "target": "detector", "depth": [1, 1]}, {"source": "object detector", "target": "adapting object detector", "depth": [1, 3]}, {"source": "object detector", "target": "adapting object", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "categorical variables informed", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "algorithm for bayesian", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "applications to chemistry", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "optimization for categorical", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "air quality inference", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "urban air quality", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "quality inference", "depth": [1, 3]}, {"source": "discontinuous galerkin", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "discontinuous galerkin", "target": "galerkin method", "depth": [1, 2]}, {"source": "discontinuous galerkin", "target": "method for incompressible", "depth": [1, 3]}, {"source": "discontinuous galerkin", "target": "incompressible two-phase", "depth": [1, 3]}, {"source": "shape", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "shape", "target": "disentangled representation", "depth": [1, 2]}, {"source": "expansion", "target": "singular euler-maclaurin expansion", "depth": [1, 3]}, {"source": "expansion", "target": "singular euler-maclaurin", "depth": [1, 3]}, {"source": "expansion", "target": "euler-maclaurin expansion", "depth": [1, 3]}, {"source": "driving", "target": "autonomous car", "depth": [1, 3]}, {"source": "driving", "target": "driving for intervention", "depth": [1, 3]}, {"source": "driving", "target": "intervention in autonomous", "depth": [1, 3]}, {"source": "driving", "target": "maneuver-based driving", "depth": [1, 3]}, {"source": "pattern", "target": "scientific elite revisited", "depth": [1, 3]}, {"source": "pattern", "target": "patterns of productivity", "depth": [1, 3]}, {"source": "pattern", "target": "authorship and impact", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian approach", "depth": [1, 2]}, {"source": "bayesian", "target": "topological prior", "depth": [1, 3]}, {"source": "bayesian", "target": "approach to inverse", "depth": [1, 3]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question", "depth": [1, 2]}, {"source": "question answering", "target": "question answering dataset", "depth": [1, 3]}, {"source": "question answering", "target": "practical annotation strategy", "depth": [1, 3]}, {"source": "approximation", "target": "nonlinear spde", "depth": [1, 3]}, {"source": "approximation", "target": "approximation of nonlinear", "depth": [1, 3]}, {"source": "approximation", "target": "numerical approximation", "depth": [1, 3]}, {"source": "image generation", "target": "domain-adversarial image generation", "depth": [1, 3]}, {"source": "image generation", "target": "deep domain-adversarial image", "depth": [1, 3]}, {"source": "image generation", "target": "domain generalisation", "depth": [1, 3]}, {"source": "image generation", "target": "generation for domain", "depth": [1, 3]}, {"source": "human pose estimation", "target": "metric-scale truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose estimation", "target": "truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose estimation", "target": "metric-scale truncation-robust", "depth": [1, 3]}, {"source": "label", "target": "noisy label", "depth": [1, 2]}, {"source": "label", "target": "regret sample selection", "depth": [1, 3]}, {"source": "label", "target": "regret sample", "depth": [1, 3]}, {"source": "label", "target": "sample selection", "depth": [1, 3]}, {"source": "efficient", "target": "ensemble learning", "depth": [1, 3]}, {"source": "efficient", "target": "sample efficient", "depth": [1, 2]}, {"source": "uncertainty", "target": "safe mission planning", "depth": [1, 3]}, {"source": "uncertainty", "target": "dynamical uncertainty", "depth": [1, 3]}, {"source": "uncertainty", "target": "mission planning", "depth": [1, 3]}, {"source": "uncertainty", "target": "planning under dynamical", "depth": [1, 3]}, {"source": "model order reduction", "target": "order reduction", "depth": [1, 2]}, {"source": "model order reduction", "target": "based model order", "depth": [1, 3]}, {"source": "model order reduction", "target": "model order", "depth": [1, 3]}, {"source": "mobile robot", "target": "resource-constrained mobile robot", "depth": [1, 3]}, {"source": "mobile robot", "target": "learning-based bias correction", "depth": [1, 3]}, {"source": "mobile robot", "target": "bias correction", "depth": [1, 3]}, {"source": "mobile robot", "target": "correction for ultra-wideband", "depth": [1, 3]}, {"source": "alignment", "target": "wasserstein-based graph alignment", "depth": [1, 3]}, {"source": "alignment", "target": "graph alignment", "depth": [1, 2]}, {"source": "alignment", "target": "wasserstein-based graph", "depth": [1, 3]}, {"source": "stochastic gradient descent", "target": "gradient descent", "depth": [1, 2]}, {"source": "stochastic gradient descent", "target": "stochastic gradient", "depth": [1, 2]}, {"source": "solution", "target": "difficult combinatorial problem", "depth": [1, 3]}, {"source": "solution", "target": "combinatorial problem", "depth": [1, 3]}, {"source": "solution", "target": "predict the solution", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "multi-agent reinforcement", "depth": [1, 2]}, {"source": "multi-agent reinforcement learning", "target": "deep multi-agent reinforcement", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "gaussian process bandit", "depth": [1, 3]}, {"source": "gaussian proces", "target": "process bandit", "depth": [1, 3]}, {"source": "software", "target": "quantum network", "depth": [1, 3]}, {"source": "software", "target": "software framework", "depth": [1, 2]}, {"source": "software", "target": "framework for quantum", "depth": [1, 2]}, {"source": "software", "target": "qunetsim", "depth": [1, 3]}, {"source": "detector", "target": "accurate object detector", "depth": [1, 3]}, {"source": "detector", "target": "fast and accurate", "depth": [1, 2]}, {"source": "detector", "target": "accurate object", "depth": [1, 3]}, {"source": "detector", "target": "saccadenet", "depth": [1, 3]}, {"source": "gan", "target": "gan with bert", "depth": [1, 3]}, {"source": "gan", "target": "cycle", "depth": [1, 2]}, {"source": "gan", "target": "bert", "depth": [1, 2]}, {"source": "big datum", "target": "sorting big datum", "depth": [1, 3]}, {"source": "big datum", "target": "college ranking", "depth": [1, 3]}, {"source": "big datum", "target": "data by revealed", "depth": [1, 3]}, {"source": "computation", "target": "computation of eigenvalue", "depth": [1, 3]}, {"source": "computation", "target": "eigenvalue", "depth": [1, 3]}, {"source": "computation", "target": "graph limit", "depth": [1, 3]}, {"source": "computation", "target": "onsager-machlup functional", "depth": [1, 3]}, {"source": "control system", "target": "event-triggered control system", "depth": [1, 3]}, {"source": "control system", "target": "homogeneous event-triggered control", "depth": [1, 3]}, {"source": "control system", "target": "nonlinear homogeneous event-triggered", "depth": [1, 3]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "concept", "target": "blockchain meets biometric", "depth": [1, 3]}, {"source": "concept", "target": "application to template", "depth": [1, 3]}, {"source": "concept", "target": "template protection", "depth": [1, 3]}, {"source": "topology", "target": "combinatorial topology", "depth": [1, 3]}, {"source": "topology", "target": "set-agreement bound", "depth": [1, 3]}, {"source": "topology", "target": "bounds in round-based", "depth": [1, 3]}, {"source": "topology", "target": "round-based model", "depth": [1, 3]}, {"source": "generative model", "target": "generative", "depth": [1, 2]}, {"source": "manipulation", "target": "program synthesis", "depth": [1, 2]}, {"source": "manipulation", "target": "tensor manipulation", "depth": [1, 3]}, {"source": "manipulation", "target": "synthesis for tensor", "depth": [1, 3]}, {"source": "optimal control", "target": "navigation among human", "depth": [1, 3]}, {"source": "optimal control", "target": "humans with optimal", "depth": [1, 3]}, {"source": "optimal control", "target": "visual navigation", "depth": [1, 2]}]}