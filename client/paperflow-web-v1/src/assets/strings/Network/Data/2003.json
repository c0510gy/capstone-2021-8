{"node": [["neural network", "deep neural network", "network", "learning", "reinforcement learning", "deep learning", "deep", "machine learning", "graph", "system", "model", "object detection", "detection"], ["convolutional neural network", "graph neural network", "recurrent neural network", "reinforcement", "deep reinforcement learning", "deep reinforcement", "multi-agent reinforcement learning", "learning model", "convolutional network", "graph convolutional network", "graph convolutional", "machine learning model", "machine", "knowledge graph", "knowledge", "recognition", "object", "survey", "image", "inverse problem", "problem", "information", "anomaly detection", "reinforcement learning approach", "learning approach", "algorithm", "optimization", "method", "computation", "datum", "prediction", "image generation", "generation", "solution", "scene", "face recognition", "speech recognition", "point cloud", "point", "semantic segmentation", "domain adaptation", "domain", "analysi", "application", "pose estimation", "human pose estimation", "human pose", "estimation", "representation learning", "action recognition", "bayesian optimization", "architecture", "challenge", "framework", "adversarial network", "generative adversarial network", "generative adversarial", "representation", "inference", "driving", "training", "function", "approximation", "approach", "classification", "time series", "dataset", "game", "federated learning", "named entity recognition", "named entity", "adversarial attack", "attack", "communication", "transfer learning", "architecture search", "neural architecture search", "neural architecture", "generalization", "segmentation", "instance segmentation", "spiking neural network", "fast", "object detector", "entity recognition", "autonomous driving", "semi-supervised learning", "translation", "neural machine translation", "neural machine", "machine translation", "control", "complexity", "case study", "task", "dynamical system", "object tracking", "social medium", "video", "modeling", "shape", "tree", "massive mimo", "computing", "camera", "monte carlo", "metric learning", "mutual information", "latent space", "variational autoencoder", "online", "activity recognition", "learning framework", "human", "optimal control", "distributed", "robustnes", "weakly supervised", "word embedding", "embedding", "regression", "active learning", "sequence", "tracking", "space", "image segmentation", "few-shot learning", "constraint", "recommendation", "online learning", "identification", "resource allocation", "code", "artificial intelligence", "recognition system", "remote sensing", "finite element method", "transformer", "flow", "study", "theory", "system identification", "light field", "real-time", "person re-identification", "motion planning", "continual learning", "design", "distribution", "agent", "data augmentation", "perspective", "autonomous vehicle", "planning", "channel", "robust", "detector", "discontinuous galerkin", "expansion", "pattern", "social network", "bayesian", "question answering", "label", "efficient", "uncertainty", "model order reduction", "mobile robot", "alignment", "stochastic gradient descent", "gaussian proces", "software", "gan", "big datum", "control system", "transfer", "concept", "topology", "generative model", "manipulation"], ["multi-agent reinforcement", "deep learning model", "deep learning based", "deep learning approach", "complex network", "cyber-physical system", "time-delay system", "production system", "h-infinity", "entity", "time delay", "adaptive object detection", "salient object detection", "symmetry breaking", "pedestrian detection", "deep convolutional neural", "optimization algorithm", "deep convolutional", "skeleton-based action recognition", "single image", "crowded scene", "speech", "cloud", "unsupervised domain adaptation", "adaptation", "privacy", "based on deep", "shortest path", "intelligence", "edge", "side information", "simulation", "invariant", "state estimation", "state", "few-shot classification", "image classification", "time series forecasting", "reading comprehension", "image captioning", "mean-field game", "ridge regression", "efficient neural architecture", "instance", "deep spiking neural", "feature extraction", "fast and accurate", "weak supervision", "medical image", "search", "knowledge distillation", "computational complexity", "computational", "chest x-ray image", "medium", "learning with weighted", "gap", "perception", "human activity recognition", "human activity", "activity", "visual navigation", "distributed optimization", "supervised", "sound event detection", "visual tracking", "medical image segmentation", "geometric", "vocabulary expansion", "finite element", "parsing", "gradient flow", "wild", "mobile text entry", "text", "nonlinear system identification", "prior knowledge", "nonlinear system", "arrangement", "entanglement", "quantum", "graph embedding", "information retrieval", "autoencoder", "memory network", "edge crossing", "blind", "constraint satisfaction", "discontinuous galerkin method", "galerkin method", "disentangled representation", "collaboration", "bayesian approach", "inverse scattering", "visual question answering", "visual question", "noisy label", "sample efficient", "order reduction", "graph alignment", "gradient descent", "stochastic gradient", "gaussian process regression", "software framework", "framework for quantum", "engineering", "cycle", "bert", "limit", "style transfer", "generative", "program synthesi", "program", "navigation"], ["quantum machine learning", "representations of molecule", "resilient cyber-physical system", "time-series model", "hybrid model", "lwr model", "breast histopathology image", "histopathology image analysi", "comprehensive review", "review for breast", "breast histopathology", "domain adaptive object", "two-way perspective", "algorithm-based fault tolerance", "fault tolerance", "tolerance for convolutional", "algorithm-based fault", "cognitive routing based", "cognitive routing", "point detection algorithm", "change point detection", "detection algorithm", "computation of eigenvalue", "eigenvalue", "method preference", "crime prediction", "spatio-temporal datum", "prediction using spatio-temporal", "crime", "deep convolutional network", "pyramid for image", "semantic pyramid", "breaking", "ham-sandwich problem", "multiple prediction", "detection in crowded", "proposal", "recognition on coprocessor", "training for speech", "parametric surface fitting", "surface fitting network", "adversarial domain adaptation", "string edit distance", "knowledge graph alignment", "edit distance", "lightning network", "empirical analysi", "analysis of privacy", "hand pose estimation", "hand pose", "unstructured multilingual text", "audio representation learning", "cross-modal audio representation", "unsupervised cross-modal audio", "multilingual text", "generalizable semantic segmentation", "target-specific normalization", "segmentation via model-agnostic", "model-agnostic learning", "learning and target-specific", "routing based", "progressive graph convolutional", "semi-supervised node classification", "structure and optimization", "paths in complex", "edge intelligence", "information hiding", "detection of information", "hiding at anti-copying", "barcode", "simulation framework", "system-level domain-specific", "domain-specific", "system-level", "overcome microphone variability", "cycle-consistent generative adversarial", "speech system", "air quality inference", "urban air quality", "quality inference", "representation invariant", "inference of representation", "data-driven inference", "node classification", "networks to overcome", "architectures and training", "training method", "gauss sum", "repartition of gaus", "carlet-feng function", "gaus", "health state estimation", "health state", "health", "execution and prioritization", "set-theoretic approach", "approach to multi-task", "multi-task execution", "prioritization", "selecting relevant feature", "relevant feature", "multi-domain representation", "series forecasting", "financial time series", "adaptive neural network", "spatiotemporal adaptive neural", "dataset for image", "captioning with reading", "textcap", "automating botnet detection", "botnet detection", "detection with graph", "automating botnet", "multi-modal graph neural", "regularized mean-field game", "regularized mean-field", "q-learning in regularized", "regularized", "privacy-preserving medical named", "medical named entity", "medical named", "countermeasures of asv", "defense against adversarial", "asv", "attacks on spoofing", "kernel ridge regression", "distributed kernel ridge", "regression with communication", "kernel ridge", "inter-capillary area quantification", "deep vascular complex", "segmentation and inter-capillary", "inter-capillary area", "area quantification", "current challenge", "evaluating generative adversarial", "mixed-level reformulation", "milena", "bias explain generalization", "implicit bias explain", "explain generalization", "implicit bia", "bias explain", "point-based instance segmentation", "point-based instance", "pointin", "convolutional spiking neural", "spatio-temporal feature extraction", "convolutional spiking", "data adapted pruning", "predicting the number", "coauthors for researcher", "number of coauthor", "accurate object detector", "accurate object", "saccadenet", "comprehensive named entity", "distant or weak", "decentralized runtime protection", "runtime protection system", "decentralized runtime", "runtime protection", "protection system", "coprocessor", "medical image detection", "image detection", "focalmix", "deep semi-supervised learning", "fon-french neural machine", "ffr", "generating embroidery pattern", "teaching an algorithm", "model for cultural", "cultural learning", "teaching", "fat", "training small", "speech recognition system", "cyber-physical production system", "control of complex", "data-driven control", "reinforcement learning agent", "neurons as reinforcement", "data-free knowledge amalgamation", "knowledge amalgamation", "data-free knowledge", "amalgamation via group-stack", "simulated annealing", "complexity of simulated", "few-shot time series", "ordinal regression recurrent", "regression recurrent neural", "zero-shot and few-shot", "industrial case study", "role of software", "software architecture", "industrial case", "devops transformation", "ner", "named", "learning stl task", "performance via reverse", "reconfiguration of dynamical", "systems for improved", "improved performance", "control reconfiguration", "viral pneumonia screening", "confidence-aware anomaly detection", "pneumonia screening", "screening on chest", "real-time object tracking", "real-time object", "extremely small matrix", "object tracking algorithm", "small matrix", "analyzing misinformation", "twitter conversation", "misinformation in twitter", "analyzing", "conspiracy video", "longitudinal analysi", "promotion of conspiracy", "analysis of youtube", "youtube promotion", "task-agnostic neural architecture", "shapes by reinforcement", "weighted q-learning", "adaptive reward-poisoning attack", "attacks against reinforcement", "reward-poisoning attack", "adaptive reward-poisoning", "adversarial imitation attack", "random binary tree", "binary tree", "collection of fringe", "fringe subtree", "subtrees in random", "visual inference", "sequential uplink processing", "cell-free massive mimo", "uplink processing", "mimo with radio", "radio stripe", "proportional veto core", "computing the proportional", "veto core", "proportional veto", "core", "gap for event", "event camera", "event", "reducing", "carlo", "monte carlo tree", "carlo tree search", "carlo tree", "markov chain monte", "pose and shape", "metric-scale truncation-robust heatmap", "truncation-robust heatmap", "metric-scale truncation-robust", "face recognition dataset", "masked face recognition", "dataset and application", "recognition dataset", "masked face", "unifying mutual information", "mutual information view", "cross-entropy vs. pairwise", "pairwise loss", "diffusion variational autoencoder", "hyperspherical latent space", "hyperspherical latent", "spaces using diffusion", "dis-empowerment online", "privacy-sharing perception", "investigation of privacy-sharing", "temporal extension module", "extension module", "temporal extension", "module for skeleton-based", "wearable sensor datum", "recognition from wearable", "boost gnn expressivenes", "collective learning framework", "gnn expressivenes", "collective learning", "framework to boost", "navigation among human", "humans with optimal", "byzantine-resilient distributed optimization", "multi-dimensional function", "optimization of multi-dimensional", "resilient distributed diffusion", "stl task", "robustness metric", "metrics for learning", "learning stl", "comprehensive named", "voice activity detection", "weakly supervised sound", "supervised sound event", "co-occurrence text network", "text network", "embeddings to improve", "improve the discriminability", "regression for visual", "probabilistic regression", "localized sketching", "events from tweet", "crowdsourcing and active", "learning for classification", "integrating crowdsourcing", "classification of work-life", "leech sequence", "squarefree term", "term not occurring", "leech", "squarefree", "optimize non-rigid tracking", "learning to optimize", "non-rigid tracking", "optimize", "bayesian inverse problem", "generalized parallel tempering", "parallel tempering", "high quality software", "science from space", "quality software", "software for planetary", "planetary science", "semantic image segmentation", "semantic image", "deep image segmentation", "geometric constraint", "learning with geometric", "distribution propagation graph", "attribute-aware attentive gcn", "attentive gcn model", "model for recommendation", "attentive gcn", "gcn model", "networks via online", "online learning framework", "congestion level prediction", "traffic datum", "models for neural", "altitude balloon network", "wireless high altitude", "high altitude balloon", "balloon network", "learning for task", "pyramid", "interpreting malware classifier", "generic object anti-spoofing", "synthesis and classification", "noise modeling", "commit code", "characterizing bot", "bots that commit", "detecting and characterizing", "characterizing", "comments on sejnowski", "sejnowski", "unreasonable effectivenes", "effectiveness of deep", "hybrid speech recognition", "expansion in hybrid", "hybrid speech", "bayesian experimental design", "remote sensing image", "detection in remote", "sensing image", "object detector network", "detector network", "implicit grid representation", "local implicit grid", "implicit grid", "grid representation", "space-time finite element", "adaptive space-time finite", "adaptive space-time", "distributional source", "unsupervised parsing", "hierarchical transformer", "transformer for unsupervised", "trees to transformer", "semantic instance segmentation", "convex nonparametric formulation", "nonparametric formulation", "formulation for identification", "identification of gradient", "segmenting transparent object", "transparent object", "segmenting transparent", "transparent", "text entry behavimy", "text entry", "entry behavimy", "behaviour in lab", "classification in text", "theories for emotion", "emotion classification", "appraisal theory", "region of attraction", "identification with prior", "camera arrangement", "chiral domain", "scholarly knowledge domain", "knowledge domain", "identification without entanglement", "quantum identification", "historical manuscript", "contextual embedding", "extracting topological feature", "method of extracting", "topological feature", "surface light field", "implicit surface light", "learning implicit surface", "implicit surface", "surface light", "real-time information retrieval", "identity card", "retrieval from identity", "real-time information", "video-based person re-identification", "attentive feature aggregation", "reference-aided attentive feature", "multi-granularity reference-aided attentive", "attentive feature", "task and motion", "integrating combined task", "compliant control", "combined task", "planning with compliant", "ionic liquid", "ammonia capture", "capture of ionic", "models for ammonium", "comparative analysi", "online continual learning", "learning on sequence", "triple memory network", "method for continual", "designs for assessing", "assessing response", "response on social", "media to policy", "quasi-experimental design", "reappraising the distribution", "number of edge", "crossings of graph", "reappraising", "stubborn agent", "majority dynamic", "dynamics with biased", "biased and stubborn", "voter and majority", "in-domain model", "augmentation", "data augmentation approach", "search-free probabilistic datum", "probabilistic data augmentation", "augmentation approach", "detection with wearable", "wearable camera", "object-induced action decision", "explainable object-induced action", "object-induced action", "action decision", "decision for autonomou", "constraint satisfaction problem", "planning with brain-inspired", "sparse graphical memory", "robust planning", "graphical memory", "memory for robust", "vector poisson channel", "poisson channel", "conditional mean estimator", "vector poisson", "estimator", "non-parametric methods robust", "methods robust", "robust point matching", "robust point", "learned feature", "adapting object detector", "adapting object", "categorical variables informed", "algorithm for bayesian", "applications to chemistry", "optimization for categorical", "variables informed", "approach to urban", "uav navigation", "method for incompressible", "incompressible two-phase", "discontinuous galerkin scheme", "shape translation", "translation with disentangled", "self-supervised", "singular euler-maclaurin expansion", "singular euler-maclaurin", "euler-maclaurin expansion", "singular", "euler-maclaurin", "autonomous car", "driving for intervention", "intervention in autonomou", "maneuver-based driving", "car", "scientific elite revisited", "patterns of productivity", "authorship and impact", "scientific elite", "online social network", "deep agent", "dynamics of information", "information spread", "spread and evolution", "topological prior", "approach to inverse", "scattering with topological", "question answering dataset", "practical annotation strategy", "answering dataset", "nonlinear spde", "approximation of nonlinear", "numerical approximation", "spde", "matrix-valued function", "domain-adversarial image generation", "deep domain-adversarial image", "domain generalisation", "generation for domain", "domain-adversarial image", "estimation in video", "combining detection", "regret sample selection", "regret sample", "sample selection", "selection with noisy", "efficient ensemble learning", "sample efficient ensemble", "ensemble learning", "learning with catalyst.rl", "fast-forwarding video", "textual datum", "videos via reinforcement", "learning using textual", "fast-forwarding", "safe mission planning", "dynamical uncertainty", "mission planning", "planning under dynamical", "safe mission", "based model order", "model order", "parametric model order", "gramian based model", "resource-constrained mobile robot", "learning-based bias correction", "bias correction", "correction for ultra-wideband", "ultra-wideband localization", "wasserstein-based graph alignment", "wasserstein-based graph", "noisy oracle", "alignment from pairwise", "directed roadmap graph", "optimized directed roadmap", "multi-agent path finding", "difficult combinatorial problem", "combinatorial problem", "predict the solution", "difficult combinatorial", "predict", "deep multi-agent reinforcement", "cooperative multi-agent reinforcement", "cooperative multi-agent", "parallel knowledge transfer", "gaussian process bandit", "process bandit", "process bandit optimization", "gaussian process modeling", "quantum network", "qunetsim", "gan with bert", "profile face recognition", "dual-discriminator gan", "sorting big datum", "college ranking", "data by revealed", "revealed preference", "preference with application", "graph limit", "onsager-machlup functional", "event-triggered control system", "homogeneous event-triggered control", "nonlinear homogeneous event-triggered", "abstractions of nonlinear", "nonlinear homogeneou", "style", "memory using conceptor", "transfer between long-term", "conceptor", "blockchain meets biometric", "application to template", "template protection", "meets biometric", "blockchain meet", "combinatorial topology", "set-agreement bound", "bounds in round-based", "round-based model", "models through combinatorial", "discriminative viewer identification", "eye gaze", "viewer identification", "identification using generative", "tensor manipulation", "synthesis for tensor", "tf-coder", "supervisor"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 1]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "deep", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 0]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 2]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 2]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 2]}, {"source": "network", "target": "convolutional network", "depth": [0, 1]}, {"source": "network", "target": "complex network", "depth": [0, 2]}, {"source": "network", "target": "graph", "depth": [0, 0]}, {"source": "network", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "network", "target": "graph convolutional", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "learning model", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "quantum machine learning", "depth": [0, 3]}, {"source": "machine learning", "target": "representations of molecule", "depth": [0, 3]}, {"source": "system", "target": "cyber-physical system", "depth": [0, 2]}, {"source": "system", "target": "time-delay system", "depth": [0, 2]}, {"source": "system", "target": "production system", "depth": [0, 2]}, {"source": "system", "target": "h-infinity", "depth": [0, 2]}, {"source": "system", "target": "resilient cyber-physical system", "depth": [0, 3]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "knowledge", "depth": [0, 1]}, {"source": "graph", "target": "entity", "depth": [0, 2]}, {"source": "graph", "target": "graph convolutional network", "depth": [0, 1]}, {"source": "graph", "target": "convolutional network", "depth": [0, 1]}, {"source": "model", "target": "time-series model", "depth": [0, 3]}, {"source": "model", "target": "hybrid model", "depth": [0, 3]}, {"source": "model", "target": "recognition", "depth": [0, 1]}, {"source": "model", "target": "lwr model", "depth": [0, 3]}, {"source": "model", "target": "time delay", "depth": [0, 2]}, {"source": "deep neural network", "target": "breast histopathology image", "depth": [0, 3]}, {"source": "deep neural network", "target": "histopathology image analysi", "depth": [0, 3]}, {"source": "deep neural network", "target": "comprehensive review", "depth": [0, 3]}, {"source": "deep neural network", "target": "review for breast", "depth": [0, 3]}, {"source": "deep neural network", "target": "breast histopathology", "depth": [0, 3]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "adaptive object detection", "depth": [0, 2]}, {"source": "object detection", "target": "salient object detection", "depth": [0, 2]}, {"source": "object detection", "target": "detection", "depth": [0, 0]}, {"source": "object detection", "target": "domain adaptive object", "depth": [0, 3]}, {"source": "deep", "target": "survey", "depth": [0, 1]}, {"source": "deep", "target": "image", "depth": [0, 1]}, {"source": "deep", "target": "symmetry breaking", "depth": [0, 2]}, {"source": "deep", "target": "inverse problem", "depth": [0, 1]}, {"source": "deep", "target": "problem", "depth": [0, 1]}, {"source": "detection", "target": "pedestrian detection", "depth": [0, 2]}, {"source": "detection", "target": "information", "depth": [0, 1]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "anomaly detection", "depth": [0, 1]}, {"source": "detection", "target": "two-way perspective", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [1, 2]}, {"source": "convolutional neural network", "target": "algorithm-based fault tolerance", "depth": [1, 3]}, {"source": "convolutional neural network", "target": "fault tolerance", "depth": [1, 3]}, {"source": "convolutional neural network", "target": "tolerance for convolutional", "depth": [1, 3]}, {"source": "convolutional neural network", "target": "algorithm-based fault", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "cognitive routing based", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "cognitive routing", "depth": [1, 3]}, {"source": "algorithm", "target": "optimization algorithm", "depth": [1, 2]}, {"source": "algorithm", "target": "optimization", "depth": [1, 1]}, {"source": "algorithm", "target": "point detection algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "change point detection", "depth": [1, 3]}, {"source": "algorithm", "target": "detection algorithm", "depth": [1, 3]}, {"source": "method", "target": "survey", "depth": [1, 1]}, {"source": "method", "target": "computation of eigenvalue", "depth": [1, 3]}, {"source": "method", "target": "eigenvalue", "depth": [1, 3]}, {"source": "method", "target": "computation", "depth": [1, 1]}, {"source": "method", "target": "method preference", "depth": [1, 3]}, {"source": "datum", "target": "crime prediction", "depth": [1, 3]}, {"source": "datum", "target": "spatio-temporal datum", "depth": [1, 3]}, {"source": "datum", "target": "prediction using spatio-temporal", "depth": [1, 3]}, {"source": "datum", "target": "prediction", "depth": [1, 1]}, {"source": "datum", "target": "crime", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "deep convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "image", "target": "image generation", "depth": [1, 1]}, {"source": "image", "target": "generation", "depth": [1, 1]}, {"source": "image", "target": "single image", "depth": [1, 2]}, {"source": "image", "target": "pyramid for image", "depth": [1, 3]}, {"source": "image", "target": "semantic pyramid", "depth": [1, 3]}, {"source": "problem", "target": "solution", "depth": [1, 1]}, {"source": "problem", "target": "inverse problem", "depth": [1, 1]}, {"source": "problem", "target": "symmetry breaking", "depth": [1, 2]}, {"source": "problem", "target": "breaking", "depth": [1, 3]}, {"source": "problem", "target": "ham-sandwich problem", "depth": [1, 3]}, {"source": "prediction", "target": "multiple prediction", "depth": [1, 3]}, {"source": "prediction", "target": "crowded scene", "depth": [1, 2]}, {"source": "prediction", "target": "detection in crowded", "depth": [1, 3]}, {"source": "prediction", "target": "scene", "depth": [1, 1]}, {"source": "prediction", "target": "proposal", "depth": [1, 3]}, {"source": "recognition", "target": "face recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 2]}, {"source": "recognition", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "recognition", "target": "training for speech", "depth": [1, 3]}, {"source": "point cloud", "target": "point", "depth": [1, 1]}, {"source": "point cloud", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "point cloud", "target": "cloud", "depth": [1, 2]}, {"source": "point cloud", "target": "parametric surface fitting", "depth": [1, 3]}, {"source": "point cloud", "target": "surface fitting network", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adversarial domain adaptation", "depth": [1, 3]}, {"source": "knowledge graph", "target": "entity", "depth": [1, 2]}, {"source": "knowledge graph", "target": "knowledge", "depth": [1, 1]}, {"source": "knowledge graph", "target": "string edit distance", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph alignment", "depth": [1, 3]}, {"source": "knowledge graph", "target": "edit distance", "depth": [1, 3]}, {"source": "analysi", "target": "lightning network", "depth": [1, 3]}, {"source": "analysi", "target": "empirical analysi", "depth": [1, 3]}, {"source": "analysi", "target": "analysis of privacy", "depth": [1, 3]}, {"source": "analysi", "target": "privacy", "depth": [1, 2]}, {"source": "analysi", "target": "application", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "hand pose estimation", "depth": [1, 3]}, {"source": "pose estimation", "target": "hand pose", "depth": [1, 3]}, {"source": "representation learning", "target": "unstructured multilingual text", "depth": [1, 3]}, {"source": "representation learning", "target": "audio representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "cross-modal audio representation", "depth": [1, 3]}, {"source": "representation learning", "target": "unsupervised cross-modal audio", "depth": [1, 3]}, {"source": "representation learning", "target": "multilingual text", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "generalizable semantic segmentation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "target-specific normalization", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation via model-agnostic", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "model-agnostic learning", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "learning and target-specific", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "cognitive routing based", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "cognitive routing", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "routing based", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "based on deep", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "action recognition", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "progressive graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "semi-supervised node classification", "depth": [1, 3]}, {"source": "optimization", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "optimization", "target": "structure and optimization", "depth": [1, 3]}, {"source": "optimization", "target": "complex network", "depth": [1, 2]}, {"source": "optimization", "target": "paths in complex", "depth": [1, 3]}, {"source": "optimization", "target": "shortest path", "depth": [1, 2]}, {"source": "application", "target": "edge intelligence", "depth": [1, 3]}, {"source": "application", "target": "architecture", "depth": [1, 1]}, {"source": "application", "target": "challenge", "depth": [1, 1]}, {"source": "application", "target": "intelligence", "depth": [1, 2]}, {"source": "application", "target": "edge", "depth": [1, 2]}, {"source": "information", "target": "side information", "depth": [1, 2]}, {"source": "information", "target": "information hiding", "depth": [1, 3]}, {"source": "information", "target": "detection of information", "depth": [1, 3]}, {"source": "information", "target": "hiding at anti-copying", "depth": [1, 3]}, {"source": "information", "target": "barcode", "depth": [1, 3]}, {"source": "framework", "target": "simulation framework", "depth": [1, 3]}, {"source": "framework", "target": "system-level domain-specific", "depth": [1, 3]}, {"source": "framework", "target": "simulation", "depth": [1, 2]}, {"source": "framework", "target": "domain-specific", "depth": [1, 3]}, {"source": "framework", "target": "system-level", "depth": [1, 3]}, {"source": "adversarial network", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "adversarial network", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "adversarial network", "target": "cycle-consistent generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "speech system", "depth": [1, 3]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "air quality inference", "depth": [1, 3]}, {"source": "learning approach", "target": "urban air quality", "depth": [1, 3]}, {"source": "learning approach", "target": "quality inference", "depth": [1, 3]}, {"source": "representation", "target": "representation invariant", "depth": [1, 3]}, {"source": "representation", "target": "inference of representation", "depth": [1, 3]}, {"source": "representation", "target": "data-driven inference", "depth": [1, 3]}, {"source": "representation", "target": "invariant", "depth": [1, 2]}, {"source": "representation", "target": "inference", "depth": [1, 1]}, {"source": "graph convolutional", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "graph convolutional", "target": "action recognition", "depth": [1, 1]}, {"source": "graph convolutional", "target": "progressive graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional", "target": "semi-supervised node classification", "depth": [1, 3]}, {"source": "graph convolutional", "target": "node classification", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "cycle-consistent generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "speech system", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "networks to overcome", "depth": [1, 3]}, {"source": "survey", "target": "architectures and training", "depth": [1, 3]}, {"source": "survey", "target": "training method", "depth": [1, 3]}, {"source": "survey", "target": "driving", "depth": [1, 1]}, {"source": "survey", "target": "architecture", "depth": [1, 1]}, {"source": "survey", "target": "training", "depth": [1, 1]}, {"source": "function", "target": "approximation", "depth": [1, 1]}, {"source": "function", "target": "gauss sum", "depth": [1, 3]}, {"source": "function", "target": "repartition of gaus", "depth": [1, 3]}, {"source": "function", "target": "carlet-feng function", "depth": [1, 3]}, {"source": "function", "target": "gaus", "depth": [1, 3]}, {"source": "estimation", "target": "health state estimation", "depth": [1, 3]}, {"source": "estimation", "target": "state estimation", "depth": [1, 2]}, {"source": "estimation", "target": "health state", "depth": [1, 3]}, {"source": "estimation", "target": "state", "depth": [1, 2]}, {"source": "estimation", "target": "health", "depth": [1, 3]}, {"source": "approach", "target": "execution and prioritization", "depth": [1, 3]}, {"source": "approach", "target": "set-theoretic approach", "depth": [1, 3]}, {"source": "approach", "target": "approach to multi-task", "depth": [1, 3]}, {"source": "approach", "target": "multi-task execution", "depth": [1, 3]}, {"source": "approach", "target": "prioritization", "depth": [1, 3]}, {"source": "classification", "target": "few-shot classification", "depth": [1, 2]}, {"source": "classification", "target": "image classification", "depth": [1, 2]}, {"source": "classification", "target": "selecting relevant feature", "depth": [1, 3]}, {"source": "classification", "target": "relevant feature", "depth": [1, 3]}, {"source": "classification", "target": "multi-domain representation", "depth": [1, 3]}, {"source": "time series", "target": "time series forecasting", "depth": [1, 2]}, {"source": "time series", "target": "series forecasting", "depth": [1, 3]}, {"source": "time series", "target": "financial time series", "depth": [1, 3]}, {"source": "time series", "target": "adaptive neural network", "depth": [1, 3]}, {"source": "time series", "target": "spatiotemporal adaptive neural", "depth": [1, 3]}, {"source": "dataset", "target": "reading comprehension", "depth": [1, 2]}, {"source": "dataset", "target": "dataset for image", "depth": [1, 3]}, {"source": "dataset", "target": "image captioning", "depth": [1, 2]}, {"source": "dataset", "target": "captioning with reading", "depth": [1, 3]}, {"source": "dataset", "target": "textcap", "depth": [1, 3]}, {"source": "graph neural network", "target": "automating botnet detection", "depth": [1, 3]}, {"source": "graph neural network", "target": "botnet detection", "depth": [1, 3]}, {"source": "graph neural network", "target": "detection with graph", "depth": [1, 3]}, {"source": "graph neural network", "target": "automating botnet", "depth": [1, 3]}, {"source": "graph neural network", "target": "multi-modal graph neural", "depth": [1, 3]}, {"source": "game", "target": "mean-field game", "depth": [1, 2]}, {"source": "game", "target": "regularized mean-field game", "depth": [1, 3]}, {"source": "game", "target": "regularized mean-field", "depth": [1, 3]}, {"source": "game", "target": "q-learning in regularized", "depth": [1, 3]}, {"source": "game", "target": "regularized", "depth": [1, 3]}, {"source": "federated learning", "target": "privacy-preserving medical named", "depth": [1, 3]}, {"source": "federated learning", "target": "medical named entity", "depth": [1, 3]}, {"source": "federated learning", "target": "named entity recognition", "depth": [1, 1]}, {"source": "federated learning", "target": "medical named", "depth": [1, 3]}, {"source": "federated learning", "target": "named entity", "depth": [1, 1]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "countermeasures of asv", "depth": [1, 3]}, {"source": "adversarial attack", "target": "defense against adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "asv", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attacks on spoofing", "depth": [1, 3]}, {"source": "communication", "target": "kernel ridge regression", "depth": [1, 3]}, {"source": "communication", "target": "distributed kernel ridge", "depth": [1, 3]}, {"source": "communication", "target": "regression with communication", "depth": [1, 3]}, {"source": "communication", "target": "kernel ridge", "depth": [1, 3]}, {"source": "communication", "target": "ridge regression", "depth": [1, 2]}, {"source": "transfer learning", "target": "inter-capillary area quantification", "depth": [1, 3]}, {"source": "transfer learning", "target": "deep vascular complex", "depth": [1, 3]}, {"source": "transfer learning", "target": "segmentation and inter-capillary", "depth": [1, 3]}, {"source": "transfer learning", "target": "inter-capillary area", "depth": [1, 3]}, {"source": "transfer learning", "target": "area quantification", "depth": [1, 3]}, {"source": "challenge", "target": "edge intelligence", "depth": [1, 3]}, {"source": "challenge", "target": "architecture", "depth": [1, 1]}, {"source": "challenge", "target": "intelligence", "depth": [1, 2]}, {"source": "challenge", "target": "edge", "depth": [1, 2]}, {"source": "challenge", "target": "current challenge", "depth": [1, 3]}, {"source": "generative adversarial", "target": "overcome microphone variability", "depth": [1, 3]}, {"source": "generative adversarial", "target": "cycle-consistent generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "speech system", "depth": [1, 3]}, {"source": "generative adversarial", "target": "networks to overcome", "depth": [1, 3]}, {"source": "generative adversarial", "target": "evaluating generative adversarial", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "architecture search", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "architecture search", "target": "milena", "depth": [1, 3]}, {"source": "generalization", "target": "bias explain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "implicit bias explain", "depth": [1, 3]}, {"source": "generalization", "target": "explain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "implicit bia", "depth": [1, 3]}, {"source": "generalization", "target": "bias explain", "depth": [1, 3]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "instance", "depth": [1, 2]}, {"source": "segmentation", "target": "point-based instance segmentation", "depth": [1, 3]}, {"source": "segmentation", "target": "point-based instance", "depth": [1, 3]}, {"source": "segmentation", "target": "pointin", "depth": [1, 3]}, {"source": "spiking neural network", "target": "deep spiking neural", "depth": [1, 2]}, {"source": "spiking neural network", "target": "convolutional spiking neural", "depth": [1, 3]}, {"source": "spiking neural network", "target": "spatio-temporal feature extraction", "depth": [1, 3]}, {"source": "spiking neural network", "target": "feature extraction", "depth": [1, 2]}, {"source": "spiking neural network", "target": "convolutional spiking", "depth": [1, 3]}, {"source": "neural architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "neural architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture search", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "neural architecture search", "target": "milena", "depth": [1, 3]}, {"source": "neural architecture search", "target": "data adapted pruning", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 1]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 2]}, {"source": "learning model", "target": "predicting the number", "depth": [1, 3]}, {"source": "learning model", "target": "coauthors for researcher", "depth": [1, 3]}, {"source": "learning model", "target": "number of coauthor", "depth": [1, 3]}, {"source": "fast", "target": "fast and accurate", "depth": [1, 2]}, {"source": "fast", "target": "accurate object detector", "depth": [1, 3]}, {"source": "fast", "target": "object detector", "depth": [1, 1]}, {"source": "fast", "target": "accurate object", "depth": [1, 3]}, {"source": "fast", "target": "saccadenet", "depth": [1, 3]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity recognition", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "named entity recognition", "target": "weak supervision", "depth": [1, 2]}, {"source": "named entity recognition", "target": "distant or weak", "depth": [1, 3]}, {"source": "autonomous driving", "target": "decentralized runtime protection", "depth": [1, 3]}, {"source": "autonomous driving", "target": "runtime protection system", "depth": [1, 3]}, {"source": "autonomous driving", "target": "decentralized runtime", "depth": [1, 3]}, {"source": "autonomous driving", "target": "runtime protection", "depth": [1, 3]}, {"source": "autonomous driving", "target": "protection system", "depth": [1, 3]}, {"source": "training", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "training", "target": "speech recognition", "depth": [1, 1]}, {"source": "training", "target": "training for speech", "depth": [1, 3]}, {"source": "training", "target": "coprocessor", "depth": [1, 3]}, {"source": "training", "target": "speech", "depth": [1, 2]}, {"source": "semi-supervised learning", "target": "medical image detection", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "medical image", "depth": [1, 2]}, {"source": "semi-supervised learning", "target": "image detection", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "focalmix", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "deep semi-supervised learning", "depth": [1, 3]}, {"source": "translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "translation", "target": "neural machine", "depth": [1, 1]}, {"source": "translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "translation", "target": "ffr", "depth": [1, 3]}, {"source": "translation", "target": "generating embroidery pattern", "depth": [1, 3]}, {"source": "machine", "target": "teaching an algorithm", "depth": [1, 3]}, {"source": "machine", "target": "model for cultural", "depth": [1, 3]}, {"source": "machine", "target": "cultural learning", "depth": [1, 3]}, {"source": "machine", "target": "teaching", "depth": [1, 3]}, {"source": "machine", "target": "fat", "depth": [1, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "machine translation", "target": "ffr", "depth": [1, 3]}, {"source": "machine translation", "target": "training small", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 2]}, {"source": "speech recognition", "target": "recognition on coprocessor", "depth": [1, 3]}, {"source": "speech recognition", "target": "training for speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "coprocessor", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech recognition system", "depth": [1, 3]}, {"source": "architecture", "target": "edge intelligence", "depth": [1, 3]}, {"source": "architecture", "target": "intelligence", "depth": [1, 2]}, {"source": "architecture", "target": "edge", "depth": [1, 2]}, {"source": "architecture", "target": "search", "depth": [1, 2]}, {"source": "architecture", "target": "cyber-physical production system", "depth": [1, 3]}, {"source": "control", "target": "complex network", "depth": [1, 2]}, {"source": "control", "target": "control of complex", "depth": [1, 3]}, {"source": "control", "target": "data-driven control", "depth": [1, 3]}, {"source": "control", "target": "reinforcement learning agent", "depth": [1, 3]}, {"source": "control", "target": "neurons as reinforcement", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge distillation", "depth": [1, 2]}, {"source": "knowledge", "target": "data-free knowledge amalgamation", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge amalgamation", "depth": [1, 3]}, {"source": "knowledge", "target": "data-free knowledge", "depth": [1, 3]}, {"source": "knowledge", "target": "amalgamation via group-stack", "depth": [1, 3]}, {"source": "complexity", "target": "computational complexity", "depth": [1, 2]}, {"source": "complexity", "target": "computational", "depth": [1, 2]}, {"source": "complexity", "target": "ham-sandwich problem", "depth": [1, 3]}, {"source": "complexity", "target": "simulated annealing", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of simulated", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "few-shot time series", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "time series forecasting", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "ordinal regression recurrent", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "regression recurrent neural", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "zero-shot and few-shot", "depth": [1, 3]}, {"source": "case study", "target": "industrial case study", "depth": [1, 3]}, {"source": "case study", "target": "role of software", "depth": [1, 3]}, {"source": "case study", "target": "software architecture", "depth": [1, 3]}, {"source": "case study", "target": "industrial case", "depth": [1, 3]}, {"source": "case study", "target": "devops transformation", "depth": [1, 3]}, {"source": "task", "target": "named entity", "depth": [1, 1]}, {"source": "task", "target": "entity recognition", "depth": [1, 1]}, {"source": "task", "target": "ner", "depth": [1, 3]}, {"source": "task", "target": "named", "depth": [1, 3]}, {"source": "task", "target": "learning stl task", "depth": [1, 3]}, {"source": "dynamical system", "target": "performance via reverse", "depth": [1, 3]}, {"source": "dynamical system", "target": "reconfiguration of dynamical", "depth": [1, 3]}, {"source": "dynamical system", "target": "systems for improved", "depth": [1, 3]}, {"source": "dynamical system", "target": "improved performance", "depth": [1, 3]}, {"source": "dynamical system", "target": "control reconfiguration", "depth": [1, 3]}, {"source": "anomaly detection", "target": "chest x-ray image", "depth": [1, 2]}, {"source": "anomaly detection", "target": "viral pneumonia screening", "depth": [1, 3]}, {"source": "anomaly detection", "target": "confidence-aware anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "pneumonia screening", "depth": [1, 3]}, {"source": "anomaly detection", "target": "screening on chest", "depth": [1, 3]}, {"source": "object tracking", "target": "real-time object tracking", "depth": [1, 3]}, {"source": "object tracking", "target": "real-time object", "depth": [1, 3]}, {"source": "object tracking", "target": "extremely small matrix", "depth": [1, 3]}, {"source": "object tracking", "target": "object tracking algorithm", "depth": [1, 3]}, {"source": "object tracking", "target": "small matrix", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "analyzing misinformation", "depth": [1, 3]}, {"source": "social medium", "target": "twitter conversation", "depth": [1, 3]}, {"source": "social medium", "target": "misinformation in twitter", "depth": [1, 3]}, {"source": "social medium", "target": "analyzing", "depth": [1, 3]}, {"source": "video", "target": "conspiracy video", "depth": [1, 3]}, {"source": "video", "target": "longitudinal analysi", "depth": [1, 3]}, {"source": "video", "target": "promotion of conspiracy", "depth": [1, 3]}, {"source": "video", "target": "analysis of youtube", "depth": [1, 3]}, {"source": "video", "target": "youtube promotion", "depth": [1, 3]}, {"source": "neural architecture", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture", "target": "mixed-level reformulation", "depth": [1, 3]}, {"source": "neural architecture", "target": "milena", "depth": [1, 3]}, {"source": "neural architecture", "target": "search", "depth": [1, 2]}, {"source": "neural architecture", "target": "task-agnostic neural architecture", "depth": [1, 3]}, {"source": "reinforcement", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "reinforcement", "target": "modeling", "depth": [1, 1]}, {"source": "reinforcement", "target": "shape", "depth": [1, 1]}, {"source": "reinforcement", "target": "learning with weighted", "depth": [1, 2]}, {"source": "reinforcement", "target": "weighted q-learning", "depth": [1, 3]}, {"source": "attack", "target": "adaptive reward-poisoning attack", "depth": [1, 3]}, {"source": "attack", "target": "attacks against reinforcement", "depth": [1, 3]}, {"source": "attack", "target": "reward-poisoning attack", "depth": [1, 3]}, {"source": "attack", "target": "adaptive reward-poisoning", "depth": [1, 3]}, {"source": "attack", "target": "adversarial imitation attack", "depth": [1, 3]}, {"source": "tree", "target": "random binary tree", "depth": [1, 3]}, {"source": "tree", "target": "binary tree", "depth": [1, 3]}, {"source": "tree", "target": "collection of fringe", "depth": [1, 3]}, {"source": "tree", "target": "fringe subtree", "depth": [1, 3]}, {"source": "tree", "target": "subtrees in random", "depth": [1, 3]}, {"source": "inference", "target": "representation invariant", "depth": [1, 3]}, {"source": "inference", "target": "inference of representation", "depth": [1, 3]}, {"source": "inference", "target": "data-driven inference", "depth": [1, 3]}, {"source": "inference", "target": "invariant", "depth": [1, 2]}, {"source": "inference", "target": "visual inference", "depth": [1, 3]}, {"source": "massive mimo", "target": "sequential uplink processing", "depth": [1, 3]}, {"source": "massive mimo", "target": "cell-free massive mimo", "depth": [1, 3]}, {"source": "massive mimo", "target": "uplink processing", "depth": [1, 3]}, {"source": "massive mimo", "target": "mimo with radio", "depth": [1, 3]}, {"source": "massive mimo", "target": "radio stripe", "depth": [1, 3]}, {"source": "computing", "target": "proportional veto core", "depth": [1, 3]}, {"source": "computing", "target": "computing the proportional", "depth": [1, 3]}, {"source": "computing", "target": "veto core", "depth": [1, 3]}, {"source": "computing", "target": "proportional veto", "depth": [1, 3]}, {"source": "computing", "target": "core", "depth": [1, 3]}, {"source": "camera", "target": "gap for event", "depth": [1, 3]}, {"source": "camera", "target": "event camera", "depth": [1, 3]}, {"source": "camera", "target": "gap", "depth": [1, 2]}, {"source": "camera", "target": "event", "depth": [1, 3]}, {"source": "camera", "target": "reducing", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo", "depth": [1, 3]}, {"source": "monte carlo", "target": "monte carlo tree", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo tree search", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo tree", "depth": [1, 3]}, {"source": "monte carlo", "target": "markov chain monte", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human pose", "target": "pose and shape", "depth": [1, 3]}, {"source": "human pose", "target": "metric-scale truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose", "target": "truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose", "target": "metric-scale truncation-robust", "depth": [1, 3]}, {"source": "face recognition", "target": "face recognition dataset", "depth": [1, 3]}, {"source": "face recognition", "target": "masked face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "dataset and application", "depth": [1, 3]}, {"source": "face recognition", "target": "recognition dataset", "depth": [1, 3]}, {"source": "face recognition", "target": "masked face", "depth": [1, 3]}, {"source": "metric learning", "target": "unifying mutual information", "depth": [1, 3]}, {"source": "metric learning", "target": "mutual information view", "depth": [1, 3]}, {"source": "metric learning", "target": "cross-entropy vs. pairwise", "depth": [1, 3]}, {"source": "metric learning", "target": "pairwise loss", "depth": [1, 3]}, {"source": "metric learning", "target": "mutual information", "depth": [1, 1]}, {"source": "latent space", "target": "diffusion variational autoencoder", "depth": [1, 3]}, {"source": "latent space", "target": "hyperspherical latent space", "depth": [1, 3]}, {"source": "latent space", "target": "variational autoencoder", "depth": [1, 1]}, {"source": "latent space", "target": "hyperspherical latent", "depth": [1, 3]}, {"source": "latent space", "target": "spaces using diffusion", "depth": [1, 3]}, {"source": "online", "target": "method preference", "depth": [1, 3]}, {"source": "online", "target": "dis-empowerment online", "depth": [1, 3]}, {"source": "online", "target": "privacy-sharing perception", "depth": [1, 3]}, {"source": "online", "target": "investigation of privacy-sharing", "depth": [1, 3]}, {"source": "online", "target": "perception", "depth": [1, 2]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "temporal extension module", "depth": [1, 3]}, {"source": "action recognition", "target": "extension module", "depth": [1, 3]}, {"source": "action recognition", "target": "temporal extension", "depth": [1, 3]}, {"source": "action recognition", "target": "module for skeleton-based", "depth": [1, 3]}, {"source": "activity recognition", "target": "human activity recognition", "depth": [1, 2]}, {"source": "activity recognition", "target": "human activity", "depth": [1, 2]}, {"source": "activity recognition", "target": "activity", "depth": [1, 2]}, {"source": "activity recognition", "target": "wearable sensor datum", "depth": [1, 3]}, {"source": "activity recognition", "target": "recognition from wearable", "depth": [1, 3]}, {"source": "learning framework", "target": "boost gnn expressivenes", "depth": [1, 3]}, {"source": "learning framework", "target": "collective learning framework", "depth": [1, 3]}, {"source": "learning framework", "target": "gnn expressivenes", "depth": [1, 3]}, {"source": "learning framework", "target": "collective learning", "depth": [1, 3]}, {"source": "learning framework", "target": "framework to boost", "depth": [1, 3]}, {"source": "human", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human", "target": "navigation among human", "depth": [1, 3]}, {"source": "human", "target": "humans with optimal", "depth": [1, 3]}, {"source": "human", "target": "optimal control", "depth": [1, 1]}, {"source": "human", "target": "visual navigation", "depth": [1, 2]}, {"source": "distributed", "target": "byzantine-resilient distributed optimization", "depth": [1, 3]}, {"source": "distributed", "target": "distributed optimization", "depth": [1, 2]}, {"source": "distributed", "target": "multi-dimensional function", "depth": [1, 3]}, {"source": "distributed", "target": "optimization of multi-dimensional", "depth": [1, 3]}, {"source": "distributed", "target": "resilient distributed diffusion", "depth": [1, 3]}, {"source": "robustnes", "target": "learning stl task", "depth": [1, 3]}, {"source": "robustnes", "target": "stl task", "depth": [1, 3]}, {"source": "robustnes", "target": "robustness metric", "depth": [1, 3]}, {"source": "robustnes", "target": "metrics for learning", "depth": [1, 3]}, {"source": "robustnes", "target": "learning stl", "depth": [1, 3]}, {"source": "named entity", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "named entity", "target": "weak supervision", "depth": [1, 2]}, {"source": "named entity", "target": "distant or weak", "depth": [1, 3]}, {"source": "named entity", "target": "comprehensive named", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised", "depth": [1, 2]}, {"source": "weakly supervised", "target": "voice activity detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised sound", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised sound event", "depth": [1, 3]}, {"source": "weakly supervised", "target": "sound event detection", "depth": [1, 2]}, {"source": "word embedding", "target": "embedding", "depth": [1, 1]}, {"source": "word embedding", "target": "co-occurrence text network", "depth": [1, 3]}, {"source": "word embedding", "target": "text network", "depth": [1, 3]}, {"source": "word embedding", "target": "embeddings to improve", "depth": [1, 3]}, {"source": "word embedding", "target": "improve the discriminability", "depth": [1, 3]}, {"source": "regression", "target": "visual tracking", "depth": [1, 2]}, {"source": "regression", "target": "regression for visual", "depth": [1, 3]}, {"source": "regression", "target": "probabilistic regression", "depth": [1, 3]}, {"source": "regression", "target": "localized sketching", "depth": [1, 3]}, {"source": "regression", "target": "ridge regression", "depth": [1, 2]}, {"source": "active learning", "target": "events from tweet", "depth": [1, 3]}, {"source": "active learning", "target": "crowdsourcing and active", "depth": [1, 3]}, {"source": "active learning", "target": "learning for classification", "depth": [1, 3]}, {"source": "active learning", "target": "integrating crowdsourcing", "depth": [1, 3]}, {"source": "active learning", "target": "classification of work-life", "depth": [1, 3]}, {"source": "sequence", "target": "leech sequence", "depth": [1, 3]}, {"source": "sequence", "target": "squarefree term", "depth": [1, 3]}, {"source": "sequence", "target": "term not occurring", "depth": [1, 3]}, {"source": "sequence", "target": "leech", "depth": [1, 3]}, {"source": "sequence", "target": "squarefree", "depth": [1, 3]}, {"source": "tracking", "target": "optimize non-rigid tracking", "depth": [1, 3]}, {"source": "tracking", "target": "learning to optimize", "depth": [1, 3]}, {"source": "tracking", "target": "non-rigid tracking", "depth": [1, 3]}, {"source": "tracking", "target": "optimize", "depth": [1, 3]}, {"source": "tracking", "target": "visual tracking", "depth": [1, 2]}, {"source": "inverse problem", "target": "symmetry breaking", "depth": [1, 2]}, {"source": "inverse problem", "target": "breaking", "depth": [1, 3]}, {"source": "inverse problem", "target": "bayesian inverse problem", "depth": [1, 3]}, {"source": "inverse problem", "target": "generalized parallel tempering", "depth": [1, 3]}, {"source": "inverse problem", "target": "parallel tempering", "depth": [1, 3]}, {"source": "space", "target": "high quality software", "depth": [1, 3]}, {"source": "space", "target": "science from space", "depth": [1, 3]}, {"source": "space", "target": "quality software", "depth": [1, 3]}, {"source": "space", "target": "software for planetary", "depth": [1, 3]}, {"source": "space", "target": "planetary science", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "image segmentation", "target": "semantic image segmentation", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 2]}, {"source": "image segmentation", "target": "semantic image", "depth": [1, 3]}, {"source": "image segmentation", "target": "deep image segmentation", "depth": [1, 3]}, {"source": "few-shot learning", "target": "geometric constraint", "depth": [1, 3]}, {"source": "few-shot learning", "target": "learning with geometric", "depth": [1, 3]}, {"source": "few-shot learning", "target": "constraint", "depth": [1, 1]}, {"source": "few-shot learning", "target": "geometric", "depth": [1, 2]}, {"source": "few-shot learning", "target": "distribution propagation graph", "depth": [1, 3]}, {"source": "recommendation", "target": "attribute-aware attentive gcn", "depth": [1, 3]}, {"source": "recommendation", "target": "attentive gcn model", "depth": [1, 3]}, {"source": "recommendation", "target": "model for recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "attentive gcn", "depth": [1, 3]}, {"source": "recommendation", "target": "gcn model", "depth": [1, 3]}, {"source": "online learning", "target": "networks via online", "depth": [1, 3]}, {"source": "online learning", "target": "identification", "depth": [1, 1]}, {"source": "online learning", "target": "online learning framework", "depth": [1, 3]}, {"source": "online learning", "target": "congestion level prediction", "depth": [1, 3]}, {"source": "online learning", "target": "traffic datum", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "neural machine translation", "target": "ffr", "depth": [1, 3]}, {"source": "neural machine translation", "target": "training small", "depth": [1, 3]}, {"source": "neural machine translation", "target": "models for neural", "depth": [1, 3]}, {"source": "resource allocation", "target": "altitude balloon network", "depth": [1, 3]}, {"source": "resource allocation", "target": "wireless high altitude", "depth": [1, 3]}, {"source": "resource allocation", "target": "high altitude balloon", "depth": [1, 3]}, {"source": "resource allocation", "target": "balloon network", "depth": [1, 3]}, {"source": "resource allocation", "target": "learning for task", "depth": [1, 3]}, {"source": "generation", "target": "image generation", "depth": [1, 1]}, {"source": "generation", "target": "pyramid for image", "depth": [1, 3]}, {"source": "generation", "target": "semantic pyramid", "depth": [1, 3]}, {"source": "generation", "target": "pyramid", "depth": [1, 3]}, {"source": "generation", "target": "interpreting malware classifier", "depth": [1, 3]}, {"source": "entity recognition", "target": "comprehensive named entity", "depth": [1, 3]}, {"source": "entity recognition", "target": "weak supervision", "depth": [1, 2]}, {"source": "entity recognition", "target": "distant or weak", "depth": [1, 3]}, {"source": "entity recognition", "target": "comprehensive named", "depth": [1, 3]}, {"source": "entity recognition", "target": "ner", "depth": [1, 3]}, {"source": "modeling", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "modeling", "target": "shape", "depth": [1, 1]}, {"source": "modeling", "target": "generic object anti-spoofing", "depth": [1, 3]}, {"source": "modeling", "target": "synthesis and classification", "depth": [1, 3]}, {"source": "modeling", "target": "noise modeling", "depth": [1, 3]}, {"source": "code", "target": "commit code", "depth": [1, 3]}, {"source": "code", "target": "characterizing bot", "depth": [1, 3]}, {"source": "code", "target": "bots that commit", "depth": [1, 3]}, {"source": "code", "target": "detecting and characterizing", "depth": [1, 3]}, {"source": "code", "target": "characterizing", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "comments on sejnowski", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "sejnowski", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "unreasonable effectivenes", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "effectiveness of deep", "depth": [1, 3]}, {"source": "recognition system", "target": "speech recognition system", "depth": [1, 3]}, {"source": "recognition system", "target": "hybrid speech recognition", "depth": [1, 3]}, {"source": "recognition system", "target": "vocabulary expansion", "depth": [1, 2]}, {"source": "recognition system", "target": "expansion in hybrid", "depth": [1, 3]}, {"source": "recognition system", "target": "hybrid speech", "depth": [1, 3]}, {"source": "mutual information", "target": "unifying mutual information", "depth": [1, 3]}, {"source": "mutual information", "target": "mutual information view", "depth": [1, 3]}, {"source": "mutual information", "target": "cross-entropy vs. pairwise", "depth": [1, 3]}, {"source": "mutual information", "target": "pairwise loss", "depth": [1, 3]}, {"source": "mutual information", "target": "bayesian experimental design", "depth": [1, 3]}, {"source": "remote sensing", "target": "remote sensing image", "depth": [1, 3]}, {"source": "remote sensing", "target": "detection in remote", "depth": [1, 3]}, {"source": "remote sensing", "target": "sensing image", "depth": [1, 3]}, {"source": "remote sensing", "target": "object detector network", "depth": [1, 3]}, {"source": "remote sensing", "target": "detector network", "depth": [1, 3]}, {"source": "scene", "target": "crowded scene", "depth": [1, 2]}, {"source": "scene", "target": "implicit grid representation", "depth": [1, 3]}, {"source": "scene", "target": "local implicit grid", "depth": [1, 3]}, {"source": "scene", "target": "implicit grid", "depth": [1, 3]}, {"source": "scene", "target": "grid representation", "depth": [1, 3]}, {"source": "finite element method", "target": "space-time finite element", "depth": [1, 3]}, {"source": "finite element method", "target": "adaptive space-time finite", "depth": [1, 3]}, {"source": "finite element method", "target": "adaptive space-time", "depth": [1, 3]}, {"source": "finite element method", "target": "distributional source", "depth": [1, 3]}, {"source": "finite element method", "target": "finite element", "depth": [1, 2]}, {"source": "transformer", "target": "unsupervised parsing", "depth": [1, 3]}, {"source": "transformer", "target": "hierarchical transformer", "depth": [1, 3]}, {"source": "transformer", "target": "transformer for unsupervised", "depth": [1, 3]}, {"source": "transformer", "target": "parsing", "depth": [1, 2]}, {"source": "transformer", "target": "trees to transformer", "depth": [1, 3]}, {"source": "instance segmentation", "target": "instance", "depth": [1, 2]}, {"source": "instance segmentation", "target": "point-based instance segmentation", "depth": [1, 3]}, {"source": "instance segmentation", "target": "point-based instance", "depth": [1, 3]}, {"source": "instance segmentation", "target": "pointin", "depth": [1, 3]}, {"source": "instance segmentation", "target": "semantic instance segmentation", "depth": [1, 3]}, {"source": "flow", "target": "convex nonparametric formulation", "depth": [1, 3]}, {"source": "flow", "target": "gradient flow", "depth": [1, 2]}, {"source": "flow", "target": "nonparametric formulation", "depth": [1, 3]}, {"source": "flow", "target": "formulation for identification", "depth": [1, 3]}, {"source": "flow", "target": "identification of gradient", "depth": [1, 3]}, {"source": "object", "target": "segmenting transparent object", "depth": [1, 3]}, {"source": "object", "target": "transparent object", "depth": [1, 3]}, {"source": "object", "target": "segmenting transparent", "depth": [1, 3]}, {"source": "object", "target": "wild", "depth": [1, 2]}, {"source": "object", "target": "transparent", "depth": [1, 3]}, {"source": "study", "target": "text entry behavimy", "depth": [1, 3]}, {"source": "study", "target": "mobile text entry", "depth": [1, 2]}, {"source": "study", "target": "text entry", "depth": [1, 3]}, {"source": "study", "target": "entry behavimy", "depth": [1, 3]}, {"source": "study", "target": "behaviour in lab", "depth": [1, 3]}, {"source": "theory", "target": "classification in text", "depth": [1, 3]}, {"source": "theory", "target": "theories for emotion", "depth": [1, 3]}, {"source": "theory", "target": "emotion classification", "depth": [1, 3]}, {"source": "theory", "target": "appraisal theory", "depth": [1, 3]}, {"source": "theory", "target": "text", "depth": [1, 2]}, {"source": "system identification", "target": "nonlinear system identification", "depth": [1, 2]}, {"source": "system identification", "target": "region of attraction", "depth": [1, 3]}, {"source": "system identification", "target": "identification with prior", "depth": [1, 3]}, {"source": "system identification", "target": "prior knowledge", "depth": [1, 2]}, {"source": "system identification", "target": "nonlinear system", "depth": [1, 2]}, {"source": "domain", "target": "camera arrangement", "depth": [1, 3]}, {"source": "domain", "target": "chiral domain", "depth": [1, 3]}, {"source": "domain", "target": "arrangement", "depth": [1, 2]}, {"source": "domain", "target": "scholarly knowledge domain", "depth": [1, 3]}, {"source": "domain", "target": "knowledge domain", "depth": [1, 3]}, {"source": "identification", "target": "identification without entanglement", "depth": [1, 3]}, {"source": "identification", "target": "quantum identification", "depth": [1, 3]}, {"source": "identification", "target": "entanglement", "depth": [1, 2]}, {"source": "identification", "target": "quantum", "depth": [1, 2]}, {"source": "identification", "target": "historical manuscript", "depth": [1, 3]}, {"source": "embedding", "target": "contextual embedding", "depth": [1, 3]}, {"source": "embedding", "target": "graph embedding", "depth": [1, 2]}, {"source": "embedding", "target": "extracting topological feature", "depth": [1, 3]}, {"source": "embedding", "target": "method of extracting", "depth": [1, 3]}, {"source": "embedding", "target": "topological feature", "depth": [1, 3]}, {"source": "light field", "target": "surface light field", "depth": [1, 3]}, {"source": "light field", "target": "implicit surface light", "depth": [1, 3]}, {"source": "light field", "target": "learning implicit surface", "depth": [1, 3]}, {"source": "light field", "target": "implicit surface", "depth": [1, 3]}, {"source": "light field", "target": "surface light", "depth": [1, 3]}, {"source": "real-time", "target": "real-time information retrieval", "depth": [1, 3]}, {"source": "real-time", "target": "identity card", "depth": [1, 3]}, {"source": "real-time", "target": "retrieval from identity", "depth": [1, 3]}, {"source": "real-time", "target": "real-time information", "depth": [1, 3]}, {"source": "real-time", "target": "information retrieval", "depth": [1, 2]}, {"source": "person re-identification", "target": "video-based person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "attentive feature aggregation", "depth": [1, 3]}, {"source": "person re-identification", "target": "reference-aided attentive feature", "depth": [1, 3]}, {"source": "person re-identification", "target": "multi-granularity reference-aided attentive", "depth": [1, 3]}, {"source": "person re-identification", "target": "attentive feature", "depth": [1, 3]}, {"source": "motion planning", "target": "task and motion", "depth": [1, 3]}, {"source": "motion planning", "target": "integrating combined task", "depth": [1, 3]}, {"source": "motion planning", "target": "compliant control", "depth": [1, 3]}, {"source": "motion planning", "target": "combined task", "depth": [1, 3]}, {"source": "motion planning", "target": "planning with compliant", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "diffusion variational autoencoder", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "hyperspherical latent space", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "hyperspherical latent", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "spaces using diffusion", "depth": [1, 3]}, {"source": "machine learning model", "target": "ionic liquid", "depth": [1, 3]}, {"source": "machine learning model", "target": "ammonia capture", "depth": [1, 3]}, {"source": "machine learning model", "target": "capture of ionic", "depth": [1, 3]}, {"source": "machine learning model", "target": "models for ammonium", "depth": [1, 3]}, {"source": "machine learning model", "target": "comparative analysi", "depth": [1, 3]}, {"source": "continual learning", "target": "online continual learning", "depth": [1, 3]}, {"source": "continual learning", "target": "learning on sequence", "depth": [1, 3]}, {"source": "continual learning", "target": "triple memory network", "depth": [1, 3]}, {"source": "continual learning", "target": "memory network", "depth": [1, 2]}, {"source": "continual learning", "target": "method for continual", "depth": [1, 3]}, {"source": "design", "target": "designs for assessing", "depth": [1, 3]}, {"source": "design", "target": "assessing response", "depth": [1, 3]}, {"source": "design", "target": "response on social", "depth": [1, 3]}, {"source": "design", "target": "media to policy", "depth": [1, 3]}, {"source": "design", "target": "quasi-experimental design", "depth": [1, 3]}, {"source": "distribution", "target": "reappraising the distribution", "depth": [1, 3]}, {"source": "distribution", "target": "number of edge", "depth": [1, 3]}, {"source": "distribution", "target": "edge crossing", "depth": [1, 2]}, {"source": "distribution", "target": "crossings of graph", "depth": [1, 3]}, {"source": "distribution", "target": "reappraising", "depth": [1, 3]}, {"source": "agent", "target": "stubborn agent", "depth": [1, 3]}, {"source": "agent", "target": "majority dynamic", "depth": [1, 3]}, {"source": "agent", "target": "dynamics with biased", "depth": [1, 3]}, {"source": "agent", "target": "biased and stubborn", "depth": [1, 3]}, {"source": "agent", "target": "voter and majority", "depth": [1, 3]}, {"source": "neural machine", "target": "fon-french neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "ffr", "depth": [1, 3]}, {"source": "neural machine", "target": "training small", "depth": [1, 3]}, {"source": "neural machine", "target": "models for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "in-domain model", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "data augmentation approach", "depth": [1, 3]}, {"source": "data augmentation", "target": "search-free probabilistic datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "probabilistic data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation approach", "depth": [1, 3]}, {"source": "perspective", "target": "two-way perspective", "depth": [1, 3]}, {"source": "perspective", "target": "detection with wearable", "depth": [1, 3]}, {"source": "perspective", "target": "wearable camera", "depth": [1, 3]}, {"source": "perspective", "target": "pedestrian detection", "depth": [1, 2]}, {"source": "perspective", "target": "blind", "depth": [1, 2]}, {"source": "autonomous vehicle", "target": "object-induced action decision", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "explainable object-induced action", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "object-induced action", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "action decision", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "decision for autonomou", "depth": [1, 3]}, {"source": "constraint", "target": "constraint satisfaction", "depth": [1, 2]}, {"source": "constraint", "target": "geometric constraint", "depth": [1, 3]}, {"source": "constraint", "target": "learning with geometric", "depth": [1, 3]}, {"source": "constraint", "target": "geometric", "depth": [1, 2]}, {"source": "constraint", "target": "constraint satisfaction problem", "depth": [1, 3]}, {"source": "planning", "target": "planning with brain-inspired", "depth": [1, 3]}, {"source": "planning", "target": "sparse graphical memory", "depth": [1, 3]}, {"source": "planning", "target": "robust planning", "depth": [1, 3]}, {"source": "planning", "target": "graphical memory", "depth": [1, 3]}, {"source": "planning", "target": "memory for robust", "depth": [1, 3]}, {"source": "channel", "target": "vector poisson channel", "depth": [1, 3]}, {"source": "channel", "target": "poisson channel", "depth": [1, 3]}, {"source": "channel", "target": "conditional mean estimator", "depth": [1, 3]}, {"source": "channel", "target": "vector poisson", "depth": [1, 3]}, {"source": "channel", "target": "estimator", "depth": [1, 3]}, {"source": "robust", "target": "non-parametric methods robust", "depth": [1, 3]}, {"source": "robust", "target": "methods robust", "depth": [1, 3]}, {"source": "robust", "target": "robust point matching", "depth": [1, 3]}, {"source": "robust", "target": "robust point", "depth": [1, 3]}, {"source": "robust", "target": "learned feature", "depth": [1, 3]}, {"source": "object detector", "target": "detector", "depth": [1, 1]}, {"source": "object detector", "target": "adapting object detector", "depth": [1, 3]}, {"source": "object detector", "target": "adapting object", "depth": [1, 3]}, {"source": "object detector", "target": "accurate object detector", "depth": [1, 3]}, {"source": "object detector", "target": "fast and accurate", "depth": [1, 2]}, {"source": "bayesian optimization", "target": "categorical variables informed", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "algorithm for bayesian", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "applications to chemistry", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "optimization for categorical", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "variables informed", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "air quality inference", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "urban air quality", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "quality inference", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "approach to urban", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "uav navigation", "depth": [1, 3]}, {"source": "discontinuous galerkin", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "discontinuous galerkin", "target": "galerkin method", "depth": [1, 2]}, {"source": "discontinuous galerkin", "target": "method for incompressible", "depth": [1, 3]}, {"source": "discontinuous galerkin", "target": "incompressible two-phase", "depth": [1, 3]}, {"source": "discontinuous galerkin", "target": "discontinuous galerkin scheme", "depth": [1, 3]}, {"source": "shape", "target": "shapes by reinforcement", "depth": [1, 3]}, {"source": "shape", "target": "shape translation", "depth": [1, 3]}, {"source": "shape", "target": "disentangled representation", "depth": [1, 2]}, {"source": "shape", "target": "translation with disentangled", "depth": [1, 3]}, {"source": "shape", "target": "self-supervised", "depth": [1, 3]}, {"source": "expansion", "target": "singular euler-maclaurin expansion", "depth": [1, 3]}, {"source": "expansion", "target": "singular euler-maclaurin", "depth": [1, 3]}, {"source": "expansion", "target": "euler-maclaurin expansion", "depth": [1, 3]}, {"source": "expansion", "target": "singular", "depth": [1, 3]}, {"source": "expansion", "target": "euler-maclaurin", "depth": [1, 3]}, {"source": "driving", "target": "autonomous car", "depth": [1, 3]}, {"source": "driving", "target": "driving for intervention", "depth": [1, 3]}, {"source": "driving", "target": "intervention in autonomou", "depth": [1, 3]}, {"source": "driving", "target": "maneuver-based driving", "depth": [1, 3]}, {"source": "driving", "target": "car", "depth": [1, 3]}, {"source": "pattern", "target": "scientific elite revisited", "depth": [1, 3]}, {"source": "pattern", "target": "patterns of productivity", "depth": [1, 3]}, {"source": "pattern", "target": "authorship and impact", "depth": [1, 3]}, {"source": "pattern", "target": "collaboration", "depth": [1, 2]}, {"source": "pattern", "target": "scientific elite", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "social network", "target": "deep agent", "depth": [1, 3]}, {"source": "social network", "target": "dynamics of information", "depth": [1, 3]}, {"source": "social network", "target": "information spread", "depth": [1, 3]}, {"source": "social network", "target": "spread and evolution", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian approach", "depth": [1, 2]}, {"source": "bayesian", "target": "topological prior", "depth": [1, 3]}, {"source": "bayesian", "target": "approach to inverse", "depth": [1, 3]}, {"source": "bayesian", "target": "inverse scattering", "depth": [1, 2]}, {"source": "bayesian", "target": "scattering with topological", "depth": [1, 3]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 2]}, {"source": "question answering", "target": "visual question", "depth": [1, 2]}, {"source": "question answering", "target": "question answering dataset", "depth": [1, 3]}, {"source": "question answering", "target": "practical annotation strategy", "depth": [1, 3]}, {"source": "question answering", "target": "answering dataset", "depth": [1, 3]}, {"source": "approximation", "target": "nonlinear spde", "depth": [1, 3]}, {"source": "approximation", "target": "approximation of nonlinear", "depth": [1, 3]}, {"source": "approximation", "target": "numerical approximation", "depth": [1, 3]}, {"source": "approximation", "target": "spde", "depth": [1, 3]}, {"source": "approximation", "target": "matrix-valued function", "depth": [1, 3]}, {"source": "image generation", "target": "domain-adversarial image generation", "depth": [1, 3]}, {"source": "image generation", "target": "deep domain-adversarial image", "depth": [1, 3]}, {"source": "image generation", "target": "domain generalisation", "depth": [1, 3]}, {"source": "image generation", "target": "generation for domain", "depth": [1, 3]}, {"source": "image generation", "target": "domain-adversarial image", "depth": [1, 3]}, {"source": "human pose estimation", "target": "metric-scale truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose estimation", "target": "truncation-robust heatmap", "depth": [1, 3]}, {"source": "human pose estimation", "target": "metric-scale truncation-robust", "depth": [1, 3]}, {"source": "human pose estimation", "target": "estimation in video", "depth": [1, 3]}, {"source": "human pose estimation", "target": "combining detection", "depth": [1, 3]}, {"source": "label", "target": "noisy label", "depth": [1, 2]}, {"source": "label", "target": "regret sample selection", "depth": [1, 3]}, {"source": "label", "target": "regret sample", "depth": [1, 3]}, {"source": "label", "target": "sample selection", "depth": [1, 3]}, {"source": "label", "target": "selection with noisy", "depth": [1, 3]}, {"source": "efficient", "target": "efficient ensemble learning", "depth": [1, 3]}, {"source": "efficient", "target": "sample efficient ensemble", "depth": [1, 3]}, {"source": "efficient", "target": "ensemble learning", "depth": [1, 3]}, {"source": "efficient", "target": "sample efficient", "depth": [1, 2]}, {"source": "efficient", "target": "learning with catalyst.rl", "depth": [1, 3]}, {"source": "point", "target": "fast-forwarding video", "depth": [1, 3]}, {"source": "point", "target": "textual datum", "depth": [1, 3]}, {"source": "point", "target": "videos via reinforcement", "depth": [1, 3]}, {"source": "point", "target": "learning using textual", "depth": [1, 3]}, {"source": "point", "target": "fast-forwarding", "depth": [1, 3]}, {"source": "uncertainty", "target": "safe mission planning", "depth": [1, 3]}, {"source": "uncertainty", "target": "dynamical uncertainty", "depth": [1, 3]}, {"source": "uncertainty", "target": "mission planning", "depth": [1, 3]}, {"source": "uncertainty", "target": "planning under dynamical", "depth": [1, 3]}, {"source": "uncertainty", "target": "safe mission", "depth": [1, 3]}, {"source": "model order reduction", "target": "order reduction", "depth": [1, 2]}, {"source": "model order reduction", "target": "based model order", "depth": [1, 3]}, {"source": "model order reduction", "target": "model order", "depth": [1, 3]}, {"source": "model order reduction", "target": "parametric model order", "depth": [1, 3]}, {"source": "model order reduction", "target": "gramian based model", "depth": [1, 3]}, {"source": "mobile robot", "target": "resource-constrained mobile robot", "depth": [1, 3]}, {"source": "mobile robot", "target": "learning-based bias correction", "depth": [1, 3]}, {"source": "mobile robot", "target": "bias correction", "depth": [1, 3]}, {"source": "mobile robot", "target": "correction for ultra-wideband", "depth": [1, 3]}, {"source": "mobile robot", "target": "ultra-wideband localization", "depth": [1, 3]}, {"source": "alignment", "target": "wasserstein-based graph alignment", "depth": [1, 3]}, {"source": "alignment", "target": "graph alignment", "depth": [1, 2]}, {"source": "alignment", "target": "wasserstein-based graph", "depth": [1, 3]}, {"source": "alignment", "target": "noisy oracle", "depth": [1, 3]}, {"source": "alignment", "target": "alignment from pairwise", "depth": [1, 3]}, {"source": "stochastic gradient descent", "target": "gradient descent", "depth": [1, 2]}, {"source": "stochastic gradient descent", "target": "stochastic gradient", "depth": [1, 2]}, {"source": "stochastic gradient descent", "target": "directed roadmap graph", "depth": [1, 3]}, {"source": "stochastic gradient descent", "target": "optimized directed roadmap", "depth": [1, 3]}, {"source": "stochastic gradient descent", "target": "multi-agent path finding", "depth": [1, 3]}, {"source": "solution", "target": "difficult combinatorial problem", "depth": [1, 3]}, {"source": "solution", "target": "combinatorial problem", "depth": [1, 3]}, {"source": "solution", "target": "predict the solution", "depth": [1, 3]}, {"source": "solution", "target": "difficult combinatorial", "depth": [1, 3]}, {"source": "solution", "target": "predict", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "multi-agent reinforcement", "depth": [1, 2]}, {"source": "multi-agent reinforcement learning", "target": "deep multi-agent reinforcement", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "cooperative multi-agent reinforcement", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "cooperative multi-agent", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "parallel knowledge transfer", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "gaussian process bandit", "depth": [1, 3]}, {"source": "gaussian proces", "target": "process bandit", "depth": [1, 3]}, {"source": "gaussian proces", "target": "process bandit optimization", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process modeling", "depth": [1, 3]}, {"source": "software", "target": "quantum network", "depth": [1, 3]}, {"source": "software", "target": "software framework", "depth": [1, 2]}, {"source": "software", "target": "framework for quantum", "depth": [1, 2]}, {"source": "software", "target": "qunetsim", "depth": [1, 3]}, {"source": "software", "target": "engineering", "depth": [1, 2]}, {"source": "detector", "target": "accurate object detector", "depth": [1, 3]}, {"source": "detector", "target": "fast and accurate", "depth": [1, 2]}, {"source": "detector", "target": "accurate object", "depth": [1, 3]}, {"source": "detector", "target": "saccadenet", "depth": [1, 3]}, {"source": "detector", "target": "adapting object detector", "depth": [1, 3]}, {"source": "gan", "target": "gan with bert", "depth": [1, 3]}, {"source": "gan", "target": "cycle", "depth": [1, 2]}, {"source": "gan", "target": "bert", "depth": [1, 2]}, {"source": "gan", "target": "profile face recognition", "depth": [1, 3]}, {"source": "gan", "target": "dual-discriminator gan", "depth": [1, 3]}, {"source": "big datum", "target": "sorting big datum", "depth": [1, 3]}, {"source": "big datum", "target": "college ranking", "depth": [1, 3]}, {"source": "big datum", "target": "data by revealed", "depth": [1, 3]}, {"source": "big datum", "target": "revealed preference", "depth": [1, 3]}, {"source": "big datum", "target": "preference with application", "depth": [1, 3]}, {"source": "computation", "target": "computation of eigenvalue", "depth": [1, 3]}, {"source": "computation", "target": "eigenvalue", "depth": [1, 3]}, {"source": "computation", "target": "graph limit", "depth": [1, 3]}, {"source": "computation", "target": "onsager-machlup functional", "depth": [1, 3]}, {"source": "computation", "target": "limit", "depth": [1, 2]}, {"source": "control system", "target": "event-triggered control system", "depth": [1, 3]}, {"source": "control system", "target": "homogeneous event-triggered control", "depth": [1, 3]}, {"source": "control system", "target": "nonlinear homogeneous event-triggered", "depth": [1, 3]}, {"source": "control system", "target": "abstractions of nonlinear", "depth": [1, 3]}, {"source": "control system", "target": "nonlinear homogeneou", "depth": [1, 3]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "transfer", "target": "style", "depth": [1, 3]}, {"source": "transfer", "target": "memory using conceptor", "depth": [1, 3]}, {"source": "transfer", "target": "transfer between long-term", "depth": [1, 3]}, {"source": "transfer", "target": "conceptor", "depth": [1, 3]}, {"source": "concept", "target": "blockchain meets biometric", "depth": [1, 3]}, {"source": "concept", "target": "application to template", "depth": [1, 3]}, {"source": "concept", "target": "template protection", "depth": [1, 3]}, {"source": "concept", "target": "meets biometric", "depth": [1, 3]}, {"source": "concept", "target": "blockchain meet", "depth": [1, 3]}, {"source": "topology", "target": "combinatorial topology", "depth": [1, 3]}, {"source": "topology", "target": "set-agreement bound", "depth": [1, 3]}, {"source": "topology", "target": "bounds in round-based", "depth": [1, 3]}, {"source": "topology", "target": "round-based model", "depth": [1, 3]}, {"source": "topology", "target": "models through combinatorial", "depth": [1, 3]}, {"source": "generative model", "target": "generative", "depth": [1, 2]}, {"source": "generative model", "target": "discriminative viewer identification", "depth": [1, 3]}, {"source": "generative model", "target": "eye gaze", "depth": [1, 3]}, {"source": "generative model", "target": "viewer identification", "depth": [1, 3]}, {"source": "generative model", "target": "identification using generative", "depth": [1, 3]}, {"source": "manipulation", "target": "program synthesi", "depth": [1, 2]}, {"source": "manipulation", "target": "tensor manipulation", "depth": [1, 3]}, {"source": "manipulation", "target": "synthesis for tensor", "depth": [1, 3]}, {"source": "manipulation", "target": "tf-coder", "depth": [1, 3]}, {"source": "manipulation", "target": "program", "depth": [1, 2]}, {"source": "optimal control", "target": "navigation among human", "depth": [1, 3]}, {"source": "optimal control", "target": "humans with optimal", "depth": [1, 3]}, {"source": "optimal control", "target": "visual navigation", "depth": [1, 2]}, {"source": "optimal control", "target": "supervisor", "depth": [1, 3]}, {"source": "optimal control", "target": "navigation", "depth": [1, 2]}]}