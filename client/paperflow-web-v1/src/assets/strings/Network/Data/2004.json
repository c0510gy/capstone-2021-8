{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "reinforcement learning", "machine learning", "deep learning", "graph", "model", "system", "detection", "image", "machine translation"], ["recurrent neural network", "graph neural network", "deep", "machine", "deep reinforcement learning", "deep reinforcement", "multi-agent reinforcement learning", "reinforcement", "deep learning based", "deep learning model", "deep learning approach", "learning approach", "social network", "generative adversarial network", "adversarial network", "machine learning approach", "chest x-ray image", "x-ray image", "language model", "deep convolutional neural", "image segmentation", "medical image segmentation", "dynamical system", "recommender system", "knowledge graph", "representation", "object detection", "anomaly detection", "object", "single image", "neural machine translation", "neural machine", "translation", "vehicle", "point cloud", "dataset", "understanding", "domain adaptation", "adaptation", "domain", "deep network", "question answering", "answering", "recognition", "action recognition", "speech recognition", "datum", "data augmentation", "analysi", "generative adversarial", "neural language model", "classification", "image classification", "hyperspectral image", "cnn", "text classification", "segmentation", "semantic segmentation", "transfer learning", "deep transfer learning", "transfer", "generation", "text generation", "social medium", "medium", "algorithm", "natural language", "natural language processing", "language processing", "pose estimation", "human pose estimation", "human pose", "pose", "estimation", "video", "time series", "optimization", "speech", "transformer", "federated learning", "reasoning", "method", "approach", "medical image", "problem", "survey", "representation learning", "label", "embedding", "word embedding", "application", "streaming", "learning model", "language", "review", "neural architecture", "neural architecture search", "architecture search", "architecture", "synthesi", "feature", "case study", "quantum", "clustering", "information", "modeling", "sentiment analysi", "chest x-ray", "resource allocation", "code", "communication", "design", "task", "attack", "adversarial attack", "perspective", "continual learning", "text", "prediction", "challenge", "autonomous vehicle", "learning based", "efficient", "relation extraction", "training", "blockchain", "control", "game", "generative model", "artificial intelligence", "robust", "function", "testing", "group testing", "edge computing", "convolutional network", "generalization", "matching", "autoencoder", "variational autoencoder", "lower bound", "search", "theory", "big datum", "pandemic", "set", "platform", "interaction", "contact tracing", "environment", "model predictive control", "predictive control", "inference", "internet of thing", "control system", "power system", "person re-identification", "twitter", "reading comprehension", "machine reading comprehension", "attention", "attention network", "space", "evolution", "privacy", "extended version", "time", "technical report", "benchmark", "bert", "path", "feature extraction", "empirical study", "tensor", "research", "structure", "solution", "approximation", "online", "complexity", "active learning", "block model", "knowledge distillation", "knowledge", "language understanding", "question", "sign language", "performance", "nonlinear system", "learning framework", "motion planning", "massive mimo", "study", "tool", "action", "trajectory prediction", "tree", "named entity recognition", "named entity", "adversarial training", "bia", "dialogue generation", "error", "metric learning", "summarization", "zero-shot learning", "spiking neural network", "depth estimation", "strategy", "fast", "policy", "data analysi", "sensor network", "feature selection", "automatum", "evaluation", "gaussian process", "market", "clinical text", "sampling", "computation", "inverse problem", "manipulation", "learning algorithm", "linear system"], ["multi-agent reinforcement", "capsule network", "machine learning based", "machine learning model", "energy-based model", "stochastic block model", "deep convolutional", "graph representation", "detection and prevention", "action detection", "image captioning", "captioning", "microscopy image", "non-autoregressive machine translation", "salient object detection", "scene", "unsupervised domain adaptation", "unsupervised domain", "reinforcement learning approach", "registration", "unsupervised neural machine", "speaker recognition", "commonsense reasoning", "extended", "generative", "neural language", "pretrained language model", "pretrained language", "pre-trained language model", "hyperspectral image classification", "instance segmentation", "deep transfer", "natural language inference", "language inference", "natural language generation", "lidar point cloud", "shape and pose", "object detector", "anomaly", "distributed optimization", "federated", "hierarchical clustering", "slot filling", "biomedical image", "eigenvalue problem", "knowledge graph embedding", "graph embedding", "benchmarking", "neural network architecture", "detection method", "word", "quantum walk", "batch", "level", "aspect-based sentiment analysi", "cellular network", "transformer network", "offensive language", "attacks and defense", "defense", "interpretability", "learning based framework", "extraction", "dnn", "network analysi", "deep generative model", "deep generative", "nearest neighbor", "causal", "group", "mobile edge computing", "mobile edge", "energy harvesting", "graph convolutional network", "graph convolutional", "domain generalization", "unified approach", "algebraic", "forecasting", "point set", "human-object interaction", "transaction", "tracing", "model predictive", "sparse", "industrial control system", "nonlinear control", "graph attention network", "simulation", "predictive", "differential privacy", "commitment", "mining", "imagery", "evaluation benchmark", "fine-tuning", "white paper", "research challenge", "boolean", "rank", "stochastic block", "distillation", "los", "sign language recognition", "language recognition", "sign", "detection and recognition", "vehicle re-identification", "multiple instance learning", "cell-free massive mimo", "outbreak", "human", "entity recognition", "fine-grained named entity", "gender bia", "dialogue", "bounds and algorithm", "deep metric learning", "deep metric", "document", "monocular depth estimation", "graph learning", "parsing", "lightweight network", "sentence embedding", "wireless sensor network", "process", "discrimination", "clinical text mining", "mining in russian", "text mining", "evolutionary computation", "sample", "model reduction", "machine learning algorithm", "intrusion detection"], ["neural network laundering", "removing black-box backdoor", "black-box backdoor watermark", "residual energy-based model", "models for text", "polynomial-delay enumeration algorithm", "enumeration algorithm", "polynomial-delay enumeration", "planar graph", "mat\u00e9rn field", "object detection method", "dialogue dataset", "scene understanding", "datasets for scene", "learning bound", "interactive recommendation", "self-paced deep reinforcement", "deep global registration", "global registration", "deep global", "robust question answering", "robust question", "multi-hop question answering", "visual question answering", "multilingual neural machine", "machine translation model", "video recognition", "nonlinear feature", "generative data augmentation", "augmentation for commonsense", "generative datum", "extended analysi", "overlapping co-clustering", "non-exhaustive", "overlapping", "conditional generative adversarial", "graph learning approach", "soft color segmentation", "fast soft color", "adversarial transfer learning", "adversarial transfer", "dynamic contents caching", "approach for dynamic", "playlist generation", "comparison of method", "methods for treatment", "treatment assignment", "social media datum", "media datum", "events in social", "override critical topic", "precedence constrained scheduling", "combinatorial algorithm", "ptas for precedence", "precedence constrained", "constrained scheduling", "segmentations of thai", "thai sentence", "sentences for neural", "scan-based semantic segmentation", "experimental study", "segmentation of lidar", "object reconstruction", "iou guided", "detector for point", "clustering small dataset", "surveillance video", "detection in surveillance", "preserving statistical privacy", "statistical privacy", "privacy in distributed", "architecture generator optimization", "speech translation", "in-depth walkthrough", "walkthrough on evolution", "chinese ner", "flat-lattice transformer", "ner using flat-lattice", "ner", "non-iid datum", "learning with hierarchical", "clustering of local", "acoustical classification", "nonlinear method", "speech act", "acts using nonlinear", "generating typology", "cross-domain slot filling", "approach for cross-domain", "cross-domain slot", "coach", "biomedical image segmentation", "crossing aggregation network", "laplacian eigenvalue problem", "laplacian eigenvalue", "numerical scheme", "reformulation", "event-centric question answering", "answering over knowledge", "event-qa", "texts into arabic", "arabic script", "script using recurrent", "judeo-arabic text", "medication information extraction", "edge performance benchmarking", "performance benchmarking", "survey on edge", "edge performance", "cosmological mass map", "spde approach", "screening chest radiograph", "chest radiograph", "image and point", "method on image", "tree embedding", "deadlines or delay", "deterministic framework", "streaming network", "smart fish farming", "opportunities and challenge", "fish farming", "indian patient", "model and mobile", "state complexity bound", "group language", "complexity bound", "commutative closure", "closure of group", "object pose estimation", "object pose", "density estimation", "density", "geometry-aware domain adaptation", "adaptation for unsupervised", "unsupervised alignment", "alignment of word", "geometry-aware domain", "dilemma", "demosaicking", "denoising", "efficient neural architecture", "series", "unsupervised anomaly detection", "anomaly detection method", "find a unicorn", "combination of feature", "based on combination", "features for automatic", "automatic news retrieval", "approach based", "data science approach", "quora case study", "semantically duplicate question", "identifying semantically duplicate", "science approach", "controlled text generation", "formats controlled text", "self-supervised representation learning", "self-supervised representation", "disentangled representation learning", "graph representation learning", "topological quantum compiling", "quantum compiling", "compiling with reinforcement", "topological quantum", "multilingual news streaming", "clustering for multilingual", "batch clustering", "chest radiograph screening", "comorbidity aware chest", "aware chest radiograph", "learning decision ensemble", "radiograph screening", "ground terrain recognition", "information for ground", "terrain recognition", "ground terrain", "analysis for machine", "levels of analysi", "diagnose cough", "recognize and diagnose", "visual sentiment analysi", "visual sentiment", "survey on visual", "sentiment", "posteroanterior chest x-ray", "limited posteroanterior chest", "fine-tuned deep neural", "large cellular network", "coordinated transmission scheme", "allocation and coordinated", "coordinated transmission", "impact of datum", "data partitioning", "partitioning for approximate", "approximate memory", "assessing impact", "spatial transformer network", "understanding when spatial", "support invariance", "spatial transformer", "periodic broadcast", "combining of directional", "directional antenna", "antennas for periodic", "hybrid combining", "user-space emulation framework", "domain-specific soc design", "emulation framework", "user-space emulation", "soc design", "offensive language detection", "language detection", "pre-trained transformer network", "few-shot image classification", "divergent search", "search for few-shot", "interpretation perspective", "learning for anomaly", "video frame", "cnn for text", "light-weighted cnn", "bilingual text extraction", "stock market prediction", "market prediction", "stock market", "learning for stock", "stock", "industry practice", "model interpretability", "factors in model", "human factor", "reinforced cooperative autonomou", "cooperative autonomous vehicle", "autonomous vehicle collision", "vehicle collision avoidance", "multilingual wikipedium", "wikipedium", "learning based packet", "based packet detection", "carrier frequency offset", "efficient video action", "video action modeling", "efficient video", "detection in chest", "neural relation extraction", "neural relation", "dialogue-based relation extraction", "dialogue-based relation", "fat separation", "supervised training", "training transformer", "difficulty of training", "blockchain metatransaction", "metatransaction", "transactions over ethereum", "ethereum blockchain", "adaptive control", "bayesian learning", "control with bayesian", "mathcal", "multi-attribute text generation", "cops and robber", "robbers game", "general cop", "games with randomnes", "cop", "linking generative model", "nearest neighbor retrieval", "multi-label text classification", "gun audio sample", "meets artificial intelligence", "audio samples meet", "samples meets artificial", "digital forensic", "stock price prediction", "time series analysis-based", "series analysis-based stock", "analysis-based stock price", "understanding deep learning", "robust testing", "low-dimensional function", "testing of low-dimensional", "algebra-based loop synthesi", "loop synthesi", "algebra-based loop", "loop", "model extraction library", "reinforcement learning model", "learning model extraction", "networked system control", "crossing aggregation", "aggregation network", "network for medical", "multi-lingual social network", "characterising user content", "user content", "characterising user", "modern social network", "stochastic confounder", "modeling with stochastic", "causal modeling", "confounder", "interpretation", "heterogeneous mobile edge", "offloading in heterogeneou", "recurrent convolutional network", "long-term recurrent convolutional", "detecting driver distraction", "continuous domain", "sampling in continuou", "approximate pattern matching", "faster approximate pattern", "pattern matching", "approximate pattern", "state machine design", "liquid state machine", "search based framework", "architecture search based", "graph variational autoencoder", "representation of molecule", "molecules using graph", "graph variational", "continuous representation", "tight lower bound", "related contraction problem", "contraction problem", "tight lower", "hadwiger number", "hip replacement dislocation", "adverse event detection", "detecting total hip", "total hip replacement", "arbitrary sensor geometry", "sparse array selection", "array selection", "selection across arbitrary", "few-shot image", "search via parallel", "implicit gating mechanism", "implicit gating", "gating mechanism", "mechanism for continual", "implicit", "algebraic datatype", "theory of algebraic", "datatype", "politenes", "enabling big datum", "farplas automotive", "analytics at manufacturing", "manufacturing field", "analytics architecture design", "forecast and forecasting", "forecasting to learn", "learning to forecast", "forecast", "labelled point set", "paths on labelled", "labelled point", "compatible path", "universal audio adversarial", "imbalanced satellite datum", "reliably predicting", "satellite datum", "climate adaptation", "predicting from imbalanced", "molecular inverse-design platform", "material industry", "platform for material", "inverse-design platform", "molecular inverse-design", "business transaction", "interactions or busines", "social interaction", "frequency offset estimation", "blind contact tracing", "note on blind", "blind contact", "tracing at scale", "skid-steering kinematic model", "subarctic environment", "kinematic model", "models for subarctic", "evaluation of skid-steering", "learning model predictive", "nonlinear model predictive", "nonlinear model", "quantized communication", "inference with sparse", "sparse and quantized", "distributed inference", "bayesian optimisation", "function in bayesian", "thing", "mobile agent framework", "localized mobile agent", "mobile agent", "agent framework", "nonlinear control system", "testbed for teaching", "teaching cybersecurity", "transmission capacity allocation", "wind-dominated power system", "reserve and transmission", "transmission capacity", "capacity allocation", "explicit occlusion training", "occlusion training", "networks with explicit", "explicit occlusion", "hard sample mining", "active hard sample", "sample mining", "active hard", "hard sample", "dynamic topic modeling", "twitter narrative", "dynamic topic", "governors and cabinet", "cabinet executive", "machine reading", "comprehension", "requiring reasoning process", "reading comprehension benchmark", "long-short range attention", "range attention", "lite transformer", "transformer with long-short", "long-short range", "item knowledge graph", "contextualized graph attention", "network for recommendation", "recommendation with item", "linear dynamical system", "continuous linear dynamical", "continuous linear", "invariants for continuou", "learning nonlinear dynamical", "pay attention", "visual modality", "modality in speech", "teach dnn", "dnns to pay", "scientific text", "space of meaning", "meaning for scientific", "informational space", "meaning", "epidemic evolution", "models really predictive", "compartmental model", "joint depth-pose learning", "learning without posenet", "joint depth-pose", "depth-pose learning", "differential", "tailbiting convolutional code", "nested tailbiting convolutional", "codes for secrecy", "cqe in description", "instance indistinguishability", "description logic", "logics through instance", "cqe", "commitment toward time", "intention as commitment", "intention", "multi-layered cake cutting", "generic ensemble based", "ensemble based deep", "based deep convolutional", "semi-supervised medical image", "mining self-similarity", "label super-resolution", "epitomic representation", "super-resolution with epitomic", "extended technical report", "approximate quantile computation", "large-scale datum", "survey of approximate", "approximate quantile", "coronet", "network for detection", "noisy ecg", "rpnet", "robust r peak", "peak detection", "oct datum", "dataset and benchmark", "underwater imagery", "segmentation of underwater", "embeddings during fine-tuning", "bert embedding", "universal dependency", "dependency", "discriminative feature extraction", "discriminative feature", "dfnet", "discriminative", "speech synthesi", "advancing speech synthesi", "synthesis using eeg", "advancing speech", "market impact conditional", "study of market", "market impact", "order-flow imbalance", "conditional on order-flow", "driven representation", "driven", "augmented datum", "learning with augmented", "augmented", "tensor ring completion", "hierarchical tensor ring", "ring completion", "tensor ring", "hierarchical tensor", "evolutionary-based approach", "approach for natural", "processing", "chinese natural language", "revisiting pre-trained model", "security and privacy", "challenges for trust", "trust", "categorization of crisi", "crisis event", "multimodal categorization", "categorization", "stable tournament solution", "tournament solution", "structure of stable", "stable tournament", "optimal streaming approximation", "streaming approximation", "optimal streaming", "enhance spatiotemporal", "mega-scale dataset", "datasets further enhance", "sarcasm communication online", "communication online", "effect of sociocultural", "variables on sarcasm", "sarcasm communication", "rank and complexity", "tensor rank", "subgraph isomorphism", "formula complexity", "halfspaces almost optimally", "location and active", "point location", "learning halfspace", "adversarial active learning", "knowledge-inherited neural architecture", "modulenet", "multimodal neural architecture", "deep multimodal neural", "deep multimodal", "assortative-constrained stochastic block", "permuted striped block", "striped block model", "loss for knowledge", "triplet los", "natural language understanding", "dual learning", "virtual adversarial training", "token-aware virtual adversarial", "virtual adversarial", "sub-part alignment", "answering through sub-part", "neural network array", "network array", "multi-camera rgb-d dataset", "dataset for object", "object recognition", "ycb-m", "rgb-d dataset", "application to commonsense", "decentralized learning model", "nonlinear multi-agent system", "optimization for nonlinear", "steel defects detection", "automatic steel defect", "performance for automatic", "defects detection", "automatic steel", "recognition of swap-body", "swap-bodies using camera", "camera mounted", "knowledge scientist", "unlocking the data-driven", "data-driven organization", "scientist", "unlocking", "system level approach", "discrete-time nonlinear system", "level approach", "system level", "approach to discrete-time", "instance learning framework", "two-stage multiple instance", "cancer in mammogram", "multiple instance", "efficient exploration", "exploration and exploitation", "synergy between reinforcement", "learning and motion", "pbc", "massive mimo system", "downlink spectral efficiency", "multi-antenna user", "spectral efficiency", "outbreak in south", "south africa", "data to inform", "africa", "text annotation tool", "collaborative text annotation", "teamtat", "annotation tool", "collaborative text", "temporal excitation", "excitation and aggregation", "aggregation for action", "tea", "pedestrian zone", "approach for trajectory", "prediction in pedestrian", "zone", "social behavior graph", "linear least-square problem", "training of deep", "networks for linear", "eigendecomposition-free training", "least-square problem", "translating workflow net", "process tree", "algorithmic approach", "workflow net", "nets to proces", "span representation", "learning of span", "study through named", "weak supervision approach", "training for language", "naturalness of language", "human tacit assumption", "probing neural language", "tacit assumption", "models for human", "bridging anaphora resolution", "anaphora resolution", "resolution as question", "bridging anaphora", "anaphora", "implicit gender bia", "discovery of implicit", "implicit gender", "unsupervised discovery", "injection into dialogue", "generation via language", "knowledge injection", "injection", "sparsity-constrained group testing", "improved bound", "sparsity-constrained group", "error streaming quantile", "relative error streaming", "streaming quantile", "error streaming", "relative error", "sampling for deep", "dynamic sampling", "dictionary-based attention block", "unknown period", "solutions with unknown", "calculation of time-periodic", "time-periodic solution", "calculation", "opinion summarization", "multi-document opinion summarization", "controlled multi-document opinion", "self-supervised and controlled", "signal recognition", "learning for signal", "signal", "zero-shot", "generalized zero-shot learning", "neuromorphic hardware", "noc-based neuromorphic platform", "mapping large-scale spiking", "large-scale spiking neural", "neuromorphic platform", "compact self-normalizing neural", "self-normalizing neural network", "highly compact self-normalizing", "depthnet nano", "approaches to recommender", "conversational recommender system", "conversational recommender", "human parsing", "rectification strategy", "strategy for human", "self-learning with rectification", "challenge multiparty dialogues-based", "multiparty dialogues-based machine", "dialogues-based machine reading", "reading comprehension dataset", "network for hyperspectral", "litedensenet", "hyperspectral image clustering", "fast algorithm", "cnn for hyperspectral", "fast and accurate", "powers of operator", "sentence embedding transfer", "few-sample sentence embedding", "embedding transfer", "few-sample sentence", "continuous stochastic policy", "stochastic policy", "learning of continuou", "counterfactual learning", "residual policy learning", "spatiotemporal data analysi", "spatiotemporal datum", "chronological network", "analysis with chronological", "url data analysi", "wireless sensor", "industrial wireless sensor", "delayed packet-coupled oscillator", "synchronisation of delayed", "latent regularization", "tumor classification", "regularization for feature", "selection using kernel", "kernel method", "cellular automatum", "inferring temporal composition", "probabilistic automatum", "temporal composition", "compositions of action", "predicting skill shortage", "labor market", "skill shortage", "shortages in labor", "pavement condition index", "portrait", "rasterize and backprop", "dense shape", "reconstruct", "interpretable model evaluation", "model evaluation", "interpretable model", "rapid", "reproducible", "algebraic multigrid", "multigrid using gaussian", "coarsening in algebraic", "statistical discrimination", "ratings-guided market", "discrimination in ratings-guided", "one-sided matching market", "neural network grammar", "samples in evolutionary", "averaging", "bius transform", "operator valued datum", "model reduction approach", "valued datum", "reduction approach", "amtnet for action", "two-stream amtnet", "two-stream", "amtnet", "mobile manipulation", "stability-guaranteed reinforcement learning", "contact-rich manipulation", "learning for contact-rich", "stability-guaranteed reinforcement", "cloud environment based", "selection and intrusion", "detection in cloud", "markov linear system", "jump markov linear", "jump markov", "consistent linear system", "solving consistent linear"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "deep", "depth": [0, 1]}, {"source": "learning", "target": "machine", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning based", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "learning approach", "depth": [0, 1]}, {"source": "network", "target": "graph", "depth": [0, 0]}, {"source": "network", "target": "capsule network", "depth": [0, 2]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "generative adversarial network", "depth": [0, 1]}, {"source": "network", "target": "adversarial network", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 1]}, {"source": "machine learning", "target": "learning approach", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning based", "depth": [0, 2]}, {"source": "machine learning", "target": "machine learning model", "depth": [0, 2]}, {"source": "deep neural network", "target": "chest x-ray image", "depth": [0, 1]}, {"source": "deep neural network", "target": "x-ray image", "depth": [0, 1]}, {"source": "deep neural network", "target": "neural network laundering", "depth": [0, 3]}, {"source": "deep neural network", "target": "removing black-box backdoor", "depth": [0, 3]}, {"source": "deep neural network", "target": "black-box backdoor watermark", "depth": [0, 3]}, {"source": "model", "target": "language model", "depth": [0, 1]}, {"source": "model", "target": "residual energy-based model", "depth": [0, 3]}, {"source": "model", "target": "models for text", "depth": [0, 3]}, {"source": "model", "target": "energy-based model", "depth": [0, 2]}, {"source": "model", "target": "stochastic block model", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "image segmentation", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "medical image segmentation", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "x-ray image", "depth": [0, 1]}, {"source": "system", "target": "dynamical system", "depth": [0, 1]}, {"source": "system", "target": "recommender system", "depth": [0, 1]}, {"source": "system", "target": "polynomial-delay enumeration algorithm", "depth": [0, 3]}, {"source": "system", "target": "enumeration algorithm", "depth": [0, 3]}, {"source": "system", "target": "polynomial-delay enumeration", "depth": [0, 3]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "representation", "depth": [0, 1]}, {"source": "graph", "target": "planar graph", "depth": [0, 3]}, {"source": "graph", "target": "graph representation", "depth": [0, 2]}, {"source": "graph", "target": "mat\u00e9rn field", "depth": [0, 3]}, {"source": "detection", "target": "object detection", "depth": [0, 1]}, {"source": "detection", "target": "anomaly detection", "depth": [0, 1]}, {"source": "detection", "target": "detection and prevention", "depth": [0, 2]}, {"source": "detection", "target": "action detection", "depth": [0, 2]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "image", "target": "single image", "depth": [0, 1]}, {"source": "image", "target": "image captioning", "depth": [0, 2]}, {"source": "image", "target": "captioning", "depth": [0, 2]}, {"source": "image", "target": "deep", "depth": [0, 1]}, {"source": "image", "target": "microscopy image", "depth": [0, 2]}, {"source": "machine translation", "target": "neural machine translation", "depth": [0, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [0, 1]}, {"source": "machine translation", "target": "translation", "depth": [0, 1]}, {"source": "machine translation", "target": "machine", "depth": [0, 1]}, {"source": "machine translation", "target": "non-autoregressive machine translation", "depth": [0, 2]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "salient object detection", "depth": [1, 2]}, {"source": "object detection", "target": "vehicle", "depth": [1, 1]}, {"source": "object detection", "target": "point cloud", "depth": [1, 1]}, {"source": "object detection", "target": "object detection method", "depth": [1, 3]}, {"source": "dataset", "target": "dialogue dataset", "depth": [1, 3]}, {"source": "dataset", "target": "scene understanding", "depth": [1, 3]}, {"source": "dataset", "target": "datasets for scene", "depth": [1, 3]}, {"source": "dataset", "target": "understanding", "depth": [1, 1]}, {"source": "dataset", "target": "scene", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "learning bound", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement learning", "target": "interactive recommendation", "depth": [1, 3]}, {"source": "deep reinforcement learning", "target": "self-paced deep reinforcement", "depth": [1, 3]}, {"source": "deep", "target": "deep network", "depth": [1, 1]}, {"source": "deep", "target": "deep global registration", "depth": [1, 3]}, {"source": "deep", "target": "global registration", "depth": [1, 3]}, {"source": "deep", "target": "deep global", "depth": [1, 3]}, {"source": "deep", "target": "registration", "depth": [1, 2]}, {"source": "question answering", "target": "answering", "depth": [1, 1]}, {"source": "question answering", "target": "robust question answering", "depth": [1, 3]}, {"source": "question answering", "target": "robust question", "depth": [1, 3]}, {"source": "question answering", "target": "multi-hop question answering", "depth": [1, 3]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "unsupervised neural machine", "depth": [1, 2]}, {"source": "neural machine translation", "target": "multilingual neural machine", "depth": [1, 3]}, {"source": "neural machine translation", "target": "machine translation model", "depth": [1, 3]}, {"source": "recognition", "target": "speaker recognition", "depth": [1, 2]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "video recognition", "depth": [1, 3]}, {"source": "recognition", "target": "nonlinear feature", "depth": [1, 3]}, {"source": "datum", "target": "data augmentation", "depth": [1, 1]}, {"source": "datum", "target": "generative data augmentation", "depth": [1, 3]}, {"source": "datum", "target": "commonsense reasoning", "depth": [1, 2]}, {"source": "datum", "target": "augmentation for commonsense", "depth": [1, 3]}, {"source": "datum", "target": "generative datum", "depth": [1, 3]}, {"source": "analysi", "target": "extended analysi", "depth": [1, 3]}, {"source": "analysi", "target": "overlapping co-clustering", "depth": [1, 3]}, {"source": "analysi", "target": "non-exhaustive", "depth": [1, 3]}, {"source": "analysi", "target": "overlapping", "depth": [1, 3]}, {"source": "analysi", "target": "extended", "depth": [1, 2]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "conditional generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "generative", "depth": [1, 2]}, {"source": "generative adversarial network", "target": "domain", "depth": [1, 1]}, {"source": "language model", "target": "neural language model", "depth": [1, 1]}, {"source": "language model", "target": "neural language", "depth": [1, 2]}, {"source": "language model", "target": "pretrained language model", "depth": [1, 2]}, {"source": "language model", "target": "pretrained language", "depth": [1, 2]}, {"source": "language model", "target": "pre-trained language model", "depth": [1, 2]}, {"source": "classification", "target": "image classification", "depth": [1, 1]}, {"source": "classification", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "classification", "target": "hyperspectral image", "depth": [1, 1]}, {"source": "classification", "target": "cnn", "depth": [1, 1]}, {"source": "classification", "target": "text classification", "depth": [1, 1]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "deep reinforcement", "depth": [1, 1]}, {"source": "learning approach", "target": "graph learning approach", "depth": [1, 3]}, {"source": "segmentation", "target": "image segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "instance segmentation", "depth": [1, 2]}, {"source": "segmentation", "target": "soft color segmentation", "depth": [1, 3]}, {"source": "segmentation", "target": "fast soft color", "depth": [1, 3]}, {"source": "transfer learning", "target": "deep transfer learning", "depth": [1, 1]}, {"source": "transfer learning", "target": "deep transfer", "depth": [1, 2]}, {"source": "transfer learning", "target": "adversarial transfer learning", "depth": [1, 3]}, {"source": "transfer learning", "target": "adversarial transfer", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "interactive recommendation", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "self-paced deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "dynamic contents caching", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "approach for dynamic", "depth": [1, 3]}, {"source": "generation", "target": "text generation", "depth": [1, 1]}, {"source": "generation", "target": "playlist generation", "depth": [1, 3]}, {"source": "generation", "target": "comparison of method", "depth": [1, 3]}, {"source": "generation", "target": "methods for treatment", "depth": [1, 3]}, {"source": "generation", "target": "treatment assignment", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 1]}, {"source": "social medium", "target": "social media datum", "depth": [1, 3]}, {"source": "social medium", "target": "media datum", "depth": [1, 3]}, {"source": "social medium", "target": "events in social", "depth": [1, 3]}, {"source": "social medium", "target": "override critical topic", "depth": [1, 3]}, {"source": "algorithm", "target": "precedence constrained scheduling", "depth": [1, 3]}, {"source": "algorithm", "target": "combinatorial algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "ptas for precedence", "depth": [1, 3]}, {"source": "algorithm", "target": "precedence constrained", "depth": [1, 3]}, {"source": "algorithm", "target": "constrained scheduling", "depth": [1, 3]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 1]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 2]}, {"source": "natural language", "target": "language inference", "depth": [1, 2]}, {"source": "natural language", "target": "language processing", "depth": [1, 1]}, {"source": "natural language", "target": "natural language generation", "depth": [1, 2]}, {"source": "neural machine", "target": "translation", "depth": [1, 1]}, {"source": "neural machine", "target": "multilingual neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "segmentations of thai", "depth": [1, 3]}, {"source": "neural machine", "target": "thai sentence", "depth": [1, 3]}, {"source": "neural machine", "target": "sentences for neural", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "point cloud", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "scan-based semantic segmentation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "lidar point cloud", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "experimental study", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation of lidar", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "estimation", "depth": [1, 1]}, {"source": "pose estimation", "target": "shape and pose", "depth": [1, 2]}, {"source": "object", "target": "object detector", "depth": [1, 2]}, {"source": "object", "target": "object reconstruction", "depth": [1, 3]}, {"source": "object", "target": "point cloud", "depth": [1, 1]}, {"source": "object", "target": "iou guided", "depth": [1, 3]}, {"source": "object", "target": "detector for point", "depth": [1, 3]}, {"source": "generative adversarial", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "generative", "depth": [1, 2]}, {"source": "generative adversarial", "target": "domain", "depth": [1, 1]}, {"source": "generative adversarial", "target": "adaptation", "depth": [1, 1]}, {"source": "generative adversarial", "target": "clustering small dataset", "depth": [1, 3]}, {"source": "anomaly detection", "target": "video", "depth": [1, 1]}, {"source": "anomaly detection", "target": "time series", "depth": [1, 1]}, {"source": "anomaly detection", "target": "surveillance video", "depth": [1, 3]}, {"source": "anomaly detection", "target": "detection in surveillance", "depth": [1, 3]}, {"source": "anomaly detection", "target": "anomaly", "depth": [1, 2]}, {"source": "optimization", "target": "distributed optimization", "depth": [1, 2]}, {"source": "optimization", "target": "preserving statistical privacy", "depth": [1, 3]}, {"source": "optimization", "target": "statistical privacy", "depth": [1, 3]}, {"source": "optimization", "target": "privacy in distributed", "depth": [1, 3]}, {"source": "optimization", "target": "architecture generator optimization", "depth": [1, 3]}, {"source": "translation", "target": "machine", "depth": [1, 1]}, {"source": "translation", "target": "speech translation", "depth": [1, 3]}, {"source": "translation", "target": "speech", "depth": [1, 1]}, {"source": "translation", "target": "in-depth walkthrough", "depth": [1, 3]}, {"source": "translation", "target": "walkthrough on evolution", "depth": [1, 3]}, {"source": "transformer", "target": "understanding", "depth": [1, 1]}, {"source": "transformer", "target": "chinese ner", "depth": [1, 3]}, {"source": "transformer", "target": "flat-lattice transformer", "depth": [1, 3]}, {"source": "transformer", "target": "ner using flat-lattice", "depth": [1, 3]}, {"source": "transformer", "target": "ner", "depth": [1, 3]}, {"source": "federated learning", "target": "federated", "depth": [1, 2]}, {"source": "federated learning", "target": "non-iid datum", "depth": [1, 3]}, {"source": "federated learning", "target": "learning with hierarchical", "depth": [1, 3]}, {"source": "federated learning", "target": "hierarchical clustering", "depth": [1, 2]}, {"source": "federated learning", "target": "clustering of local", "depth": [1, 3]}, {"source": "data augmentation", "target": "generative data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "commonsense reasoning", "depth": [1, 2]}, {"source": "data augmentation", "target": "augmentation for commonsense", "depth": [1, 3]}, {"source": "data augmentation", "target": "generative datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "reasoning", "depth": [1, 1]}, {"source": "method", "target": "acoustical classification", "depth": [1, 3]}, {"source": "method", "target": "nonlinear method", "depth": [1, 3]}, {"source": "method", "target": "speech act", "depth": [1, 3]}, {"source": "method", "target": "acts using nonlinear", "depth": [1, 3]}, {"source": "method", "target": "generating typology", "depth": [1, 3]}, {"source": "approach", "target": "cross-domain slot filling", "depth": [1, 3]}, {"source": "approach", "target": "approach for cross-domain", "depth": [1, 3]}, {"source": "approach", "target": "slot filling", "depth": [1, 2]}, {"source": "approach", "target": "cross-domain slot", "depth": [1, 3]}, {"source": "approach", "target": "coach", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "image segmentation", "target": "biomedical image segmentation", "depth": [1, 3]}, {"source": "image segmentation", "target": "biomedical image", "depth": [1, 2]}, {"source": "image segmentation", "target": "crossing aggregation network", "depth": [1, 3]}, {"source": "problem", "target": "laplacian eigenvalue problem", "depth": [1, 3]}, {"source": "problem", "target": "laplacian eigenvalue", "depth": [1, 3]}, {"source": "problem", "target": "eigenvalue problem", "depth": [1, 2]}, {"source": "problem", "target": "numerical scheme", "depth": [1, 3]}, {"source": "problem", "target": "reformulation", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 2]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 2]}, {"source": "knowledge graph", "target": "event-centric question answering", "depth": [1, 3]}, {"source": "knowledge graph", "target": "answering over knowledge", "depth": [1, 3]}, {"source": "knowledge graph", "target": "event-qa", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "texts into arabic", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "arabic script", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "script using recurrent", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "judeo-arabic text", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "medication information extraction", "depth": [1, 3]}, {"source": "survey", "target": "edge performance benchmarking", "depth": [1, 3]}, {"source": "survey", "target": "performance benchmarking", "depth": [1, 3]}, {"source": "survey", "target": "survey on edge", "depth": [1, 3]}, {"source": "survey", "target": "edge performance", "depth": [1, 3]}, {"source": "survey", "target": "benchmarking", "depth": [1, 2]}, {"source": "adversarial network", "target": "generative", "depth": [1, 2]}, {"source": "adversarial network", "target": "domain", "depth": [1, 1]}, {"source": "adversarial network", "target": "adaptation", "depth": [1, 1]}, {"source": "adversarial network", "target": "cosmological mass map", "depth": [1, 3]}, {"source": "adversarial network", "target": "conditional generative adversarial", "depth": [1, 3]}, {"source": "representation", "target": "representation learning", "depth": [1, 1]}, {"source": "representation", "target": "label", "depth": [1, 1]}, {"source": "representation", "target": "graph representation", "depth": [1, 2]}, {"source": "representation", "target": "mat\u00e9rn field", "depth": [1, 3]}, {"source": "representation", "target": "spde approach", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "deep convolutional", "depth": [1, 2]}, {"source": "deep convolutional neural", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "deep convolutional neural", "target": "screening chest radiograph", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "neural network architecture", "depth": [1, 2]}, {"source": "deep convolutional neural", "target": "chest radiograph", "depth": [1, 3]}, {"source": "point cloud", "target": "lidar point cloud", "depth": [1, 2]}, {"source": "point cloud", "target": "image and point", "depth": [1, 3]}, {"source": "point cloud", "target": "object detection method", "depth": [1, 3]}, {"source": "point cloud", "target": "detection method", "depth": [1, 2]}, {"source": "point cloud", "target": "method on image", "depth": [1, 3]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "word", "depth": [1, 2]}, {"source": "embedding", "target": "tree embedding", "depth": [1, 3]}, {"source": "embedding", "target": "deadlines or delay", "depth": [1, 3]}, {"source": "embedding", "target": "deterministic framework", "depth": [1, 3]}, {"source": "application", "target": "streaming network", "depth": [1, 3]}, {"source": "application", "target": "streaming", "depth": [1, 1]}, {"source": "application", "target": "smart fish farming", "depth": [1, 3]}, {"source": "application", "target": "opportunities and challenge", "depth": [1, 3]}, {"source": "application", "target": "fish farming", "depth": [1, 3]}, {"source": "learning model", "target": "deep learning model", "depth": [1, 1]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "time series", "depth": [1, 1]}, {"source": "learning model", "target": "indian patient", "depth": [1, 3]}, {"source": "learning model", "target": "model and mobile", "depth": [1, 3]}, {"source": "language", "target": "state complexity bound", "depth": [1, 3]}, {"source": "language", "target": "group language", "depth": [1, 3]}, {"source": "language", "target": "complexity bound", "depth": [1, 3]}, {"source": "language", "target": "commutative closure", "depth": [1, 3]}, {"source": "language", "target": "closure of group", "depth": [1, 3]}, {"source": "estimation", "target": "pose", "depth": [1, 1]}, {"source": "estimation", "target": "object pose estimation", "depth": [1, 3]}, {"source": "estimation", "target": "object pose", "depth": [1, 3]}, {"source": "estimation", "target": "density estimation", "depth": [1, 3]}, {"source": "estimation", "target": "density", "depth": [1, 3]}, {"source": "word embedding", "target": "geometry-aware domain adaptation", "depth": [1, 3]}, {"source": "word embedding", "target": "adaptation for unsupervised", "depth": [1, 3]}, {"source": "word embedding", "target": "unsupervised alignment", "depth": [1, 3]}, {"source": "word embedding", "target": "alignment of word", "depth": [1, 3]}, {"source": "word embedding", "target": "geometry-aware domain", "depth": [1, 3]}, {"source": "review", "target": "dilemma", "depth": [1, 3]}, {"source": "review", "target": "demosaicking", "depth": [1, 3]}, {"source": "review", "target": "denoising", "depth": [1, 3]}, {"source": "review", "target": "graph learning approach", "depth": [1, 3]}, {"source": "review", "target": "recommender system", "depth": [1, 1]}, {"source": "neural architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "architecture search", "depth": [1, 1]}, {"source": "neural architecture", "target": "architecture", "depth": [1, 1]}, {"source": "neural architecture", "target": "efficient neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "synthesi", "depth": [1, 1]}, {"source": "time series", "target": "deep learning model", "depth": [1, 1]}, {"source": "time series", "target": "series", "depth": [1, 3]}, {"source": "time series", "target": "unsupervised anomaly detection", "depth": [1, 3]}, {"source": "time series", "target": "anomaly detection method", "depth": [1, 3]}, {"source": "time series", "target": "find a unicorn", "depth": [1, 3]}, {"source": "feature", "target": "combination of feature", "depth": [1, 3]}, {"source": "feature", "target": "based on combination", "depth": [1, 3]}, {"source": "feature", "target": "features for automatic", "depth": [1, 3]}, {"source": "feature", "target": "automatic news retrieval", "depth": [1, 3]}, {"source": "feature", "target": "approach based", "depth": [1, 3]}, {"source": "case study", "target": "data science approach", "depth": [1, 3]}, {"source": "case study", "target": "quora case study", "depth": [1, 3]}, {"source": "case study", "target": "semantically duplicate question", "depth": [1, 3]}, {"source": "case study", "target": "identifying semantically duplicate", "depth": [1, 3]}, {"source": "case study", "target": "science approach", "depth": [1, 3]}, {"source": "text generation", "target": "residual energy-based model", "depth": [1, 3]}, {"source": "text generation", "target": "models for text", "depth": [1, 3]}, {"source": "text generation", "target": "energy-based model", "depth": [1, 2]}, {"source": "text generation", "target": "controlled text generation", "depth": [1, 3]}, {"source": "text generation", "target": "formats controlled text", "depth": [1, 3]}, {"source": "representation learning", "target": "self-supervised representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "self-supervised representation", "depth": [1, 3]}, {"source": "representation learning", "target": "disentangled representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "graph representation learning", "depth": [1, 3]}, {"source": "representation learning", "target": "graph representation", "depth": [1, 2]}, {"source": "quantum", "target": "quantum walk", "depth": [1, 2]}, {"source": "quantum", "target": "topological quantum compiling", "depth": [1, 3]}, {"source": "quantum", "target": "quantum compiling", "depth": [1, 3]}, {"source": "quantum", "target": "compiling with reinforcement", "depth": [1, 3]}, {"source": "quantum", "target": "topological quantum", "depth": [1, 3]}, {"source": "clustering", "target": "multilingual news streaming", "depth": [1, 3]}, {"source": "clustering", "target": "clustering for multilingual", "depth": [1, 3]}, {"source": "clustering", "target": "batch clustering", "depth": [1, 3]}, {"source": "clustering", "target": "streaming", "depth": [1, 1]}, {"source": "clustering", "target": "batch", "depth": [1, 2]}, {"source": "graph neural network", "target": "chest radiograph screening", "depth": [1, 3]}, {"source": "graph neural network", "target": "comorbidity aware chest", "depth": [1, 3]}, {"source": "graph neural network", "target": "aware chest radiograph", "depth": [1, 3]}, {"source": "graph neural network", "target": "learning decision ensemble", "depth": [1, 3]}, {"source": "graph neural network", "target": "radiograph screening", "depth": [1, 3]}, {"source": "information", "target": "modeling", "depth": [1, 1]}, {"source": "information", "target": "ground terrain recognition", "depth": [1, 3]}, {"source": "information", "target": "information for ground", "depth": [1, 3]}, {"source": "information", "target": "terrain recognition", "depth": [1, 3]}, {"source": "information", "target": "ground terrain", "depth": [1, 3]}, {"source": "machine", "target": "analysis for machine", "depth": [1, 3]}, {"source": "machine", "target": "levels of analysi", "depth": [1, 3]}, {"source": "machine", "target": "level", "depth": [1, 2]}, {"source": "machine", "target": "diagnose cough", "depth": [1, 3]}, {"source": "machine", "target": "recognize and diagnose", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "aspect-based sentiment analysi", "depth": [1, 2]}, {"source": "sentiment analysi", "target": "visual sentiment analysi", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "visual sentiment", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "survey on visual", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "sentiment", "depth": [1, 3]}, {"source": "x-ray image", "target": "chest x-ray image", "depth": [1, 1]}, {"source": "x-ray image", "target": "chest x-ray", "depth": [1, 1]}, {"source": "x-ray image", "target": "posteroanterior chest x-ray", "depth": [1, 3]}, {"source": "x-ray image", "target": "limited posteroanterior chest", "depth": [1, 3]}, {"source": "x-ray image", "target": "fine-tuned deep neural", "depth": [1, 3]}, {"source": "resource allocation", "target": "large cellular network", "depth": [1, 3]}, {"source": "resource allocation", "target": "coordinated transmission scheme", "depth": [1, 3]}, {"source": "resource allocation", "target": "cellular network", "depth": [1, 2]}, {"source": "resource allocation", "target": "allocation and coordinated", "depth": [1, 3]}, {"source": "resource allocation", "target": "coordinated transmission", "depth": [1, 3]}, {"source": "code", "target": "impact of datum", "depth": [1, 3]}, {"source": "code", "target": "data partitioning", "depth": [1, 3]}, {"source": "code", "target": "partitioning for approximate", "depth": [1, 3]}, {"source": "code", "target": "approximate memory", "depth": [1, 3]}, {"source": "code", "target": "assessing impact", "depth": [1, 3]}, {"source": "understanding", "target": "spatial transformer network", "depth": [1, 3]}, {"source": "understanding", "target": "understanding when spatial", "depth": [1, 3]}, {"source": "understanding", "target": "support invariance", "depth": [1, 3]}, {"source": "understanding", "target": "spatial transformer", "depth": [1, 3]}, {"source": "understanding", "target": "transformer network", "depth": [1, 2]}, {"source": "communication", "target": "periodic broadcast", "depth": [1, 3]}, {"source": "communication", "target": "combining of directional", "depth": [1, 3]}, {"source": "communication", "target": "directional antenna", "depth": [1, 3]}, {"source": "communication", "target": "antennas for periodic", "depth": [1, 3]}, {"source": "communication", "target": "hybrid combining", "depth": [1, 3]}, {"source": "design", "target": "user-space emulation framework", "depth": [1, 3]}, {"source": "design", "target": "domain-specific soc design", "depth": [1, 3]}, {"source": "design", "target": "emulation framework", "depth": [1, 3]}, {"source": "design", "target": "user-space emulation", "depth": [1, 3]}, {"source": "design", "target": "soc design", "depth": [1, 3]}, {"source": "task", "target": "offensive language detection", "depth": [1, 3]}, {"source": "task", "target": "language detection", "depth": [1, 3]}, {"source": "task", "target": "offensive language", "depth": [1, 2]}, {"source": "task", "target": "pre-trained transformer network", "depth": [1, 3]}, {"source": "task", "target": "transformer network", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image", "depth": [1, 1]}, {"source": "image classification", "target": "few-shot image classification", "depth": [1, 3]}, {"source": "image classification", "target": "divergent search", "depth": [1, 3]}, {"source": "image classification", "target": "search for few-shot", "depth": [1, 3]}, {"source": "attack", "target": "adversarial attack", "depth": [1, 1]}, {"source": "attack", "target": "attacks and defense", "depth": [1, 2]}, {"source": "attack", "target": "interpretation perspective", "depth": [1, 3]}, {"source": "attack", "target": "defense", "depth": [1, 2]}, {"source": "attack", "target": "perspective", "depth": [1, 1]}, {"source": "video", "target": "surveillance video", "depth": [1, 3]}, {"source": "video", "target": "learning for anomaly", "depth": [1, 3]}, {"source": "video", "target": "detection in surveillance", "depth": [1, 3]}, {"source": "video", "target": "continual learning", "depth": [1, 1]}, {"source": "video", "target": "video frame", "depth": [1, 3]}, {"source": "text", "target": "text classification", "depth": [1, 1]}, {"source": "text", "target": "cnn for text", "depth": [1, 3]}, {"source": "text", "target": "light-weighted cnn", "depth": [1, 3]}, {"source": "text", "target": "cnn", "depth": [1, 1]}, {"source": "text", "target": "bilingual text extraction", "depth": [1, 3]}, {"source": "prediction", "target": "stock market prediction", "depth": [1, 3]}, {"source": "prediction", "target": "market prediction", "depth": [1, 3]}, {"source": "prediction", "target": "stock market", "depth": [1, 3]}, {"source": "prediction", "target": "learning for stock", "depth": [1, 3]}, {"source": "prediction", "target": "stock", "depth": [1, 3]}, {"source": "challenge", "target": "industry practice", "depth": [1, 3]}, {"source": "challenge", "target": "model interpretability", "depth": [1, 3]}, {"source": "challenge", "target": "factors in model", "depth": [1, 3]}, {"source": "challenge", "target": "human factor", "depth": [1, 3]}, {"source": "challenge", "target": "interpretability", "depth": [1, 2]}, {"source": "autonomous vehicle", "target": "vehicle", "depth": [1, 1]}, {"source": "autonomous vehicle", "target": "reinforced cooperative autonomou", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "cooperative autonomous vehicle", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "autonomous vehicle collision", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "vehicle collision avoidance", "depth": [1, 3]}, {"source": "architecture", "target": "efficient neural architecture", "depth": [1, 3]}, {"source": "architecture", "target": "synthesi", "depth": [1, 1]}, {"source": "architecture", "target": "multilingual wikipedium", "depth": [1, 3]}, {"source": "architecture", "target": "wikipedium", "depth": [1, 3]}, {"source": "architecture", "target": "architecture generator optimization", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 1]}, {"source": "deep learning based", "target": "learning based framework", "depth": [1, 2]}, {"source": "deep learning based", "target": "learning based packet", "depth": [1, 3]}, {"source": "deep learning based", "target": "based packet detection", "depth": [1, 3]}, {"source": "deep learning based", "target": "carrier frequency offset", "depth": [1, 3]}, {"source": "efficient", "target": "efficient neural architecture", "depth": [1, 3]}, {"source": "efficient", "target": "synthesi", "depth": [1, 1]}, {"source": "efficient", "target": "efficient video action", "depth": [1, 3]}, {"source": "efficient", "target": "video action modeling", "depth": [1, 3]}, {"source": "efficient", "target": "efficient video", "depth": [1, 3]}, {"source": "chest x-ray", "target": "chest x-ray image", "depth": [1, 1]}, {"source": "chest x-ray", "target": "detection in chest", "depth": [1, 3]}, {"source": "chest x-ray", "target": "posteroanterior chest x-ray", "depth": [1, 3]}, {"source": "chest x-ray", "target": "limited posteroanterior chest", "depth": [1, 3]}, {"source": "chest x-ray", "target": "fine-tuned deep neural", "depth": [1, 3]}, {"source": "relation extraction", "target": "neural relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "neural relation", "depth": [1, 3]}, {"source": "relation extraction", "target": "extraction", "depth": [1, 2]}, {"source": "relation extraction", "target": "dialogue-based relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "dialogue-based relation", "depth": [1, 3]}, {"source": "training", "target": "dnn", "depth": [1, 2]}, {"source": "training", "target": "fat separation", "depth": [1, 3]}, {"source": "training", "target": "supervised training", "depth": [1, 3]}, {"source": "training", "target": "training transformer", "depth": [1, 3]}, {"source": "training", "target": "difficulty of training", "depth": [1, 3]}, {"source": "blockchain", "target": "blockchain metatransaction", "depth": [1, 3]}, {"source": "blockchain", "target": "metatransaction", "depth": [1, 3]}, {"source": "blockchain", "target": "transactions over ethereum", "depth": [1, 3]}, {"source": "blockchain", "target": "ethereum blockchain", "depth": [1, 3]}, {"source": "blockchain", "target": "network analysi", "depth": [1, 2]}, {"source": "control", "target": "adaptive control", "depth": [1, 3]}, {"source": "control", "target": "bayesian learning", "depth": [1, 3]}, {"source": "control", "target": "control with bayesian", "depth": [1, 3]}, {"source": "control", "target": "mathcal", "depth": [1, 3]}, {"source": "control", "target": "multi-attribute text generation", "depth": [1, 3]}, {"source": "game", "target": "cops and robber", "depth": [1, 3]}, {"source": "game", "target": "robbers game", "depth": [1, 3]}, {"source": "game", "target": "general cop", "depth": [1, 3]}, {"source": "game", "target": "games with randomnes", "depth": [1, 3]}, {"source": "game", "target": "cop", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "generative model", "target": "linking generative model", "depth": [1, 3]}, {"source": "generative model", "target": "nearest neighbor retrieval", "depth": [1, 3]}, {"source": "generative model", "target": "nearest neighbor", "depth": [1, 2]}, {"source": "text classification", "target": "cnn for text", "depth": [1, 3]}, {"source": "text classification", "target": "light-weighted cnn", "depth": [1, 3]}, {"source": "text classification", "target": "cnn", "depth": [1, 1]}, {"source": "text classification", "target": "learning based", "depth": [1, 1]}, {"source": "text classification", "target": "multi-label text classification", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "gun audio sample", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "meets artificial intelligence", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "audio samples meet", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "samples meets artificial", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "digital forensic", "depth": [1, 3]}, {"source": "deep learning model", "target": "stock price prediction", "depth": [1, 3]}, {"source": "deep learning model", "target": "time series analysis-based", "depth": [1, 3]}, {"source": "deep learning model", "target": "series analysis-based stock", "depth": [1, 3]}, {"source": "deep learning model", "target": "analysis-based stock price", "depth": [1, 3]}, {"source": "deep learning model", "target": "understanding deep learning", "depth": [1, 3]}, {"source": "robust", "target": "robust testing", "depth": [1, 3]}, {"source": "robust", "target": "low-dimensional function", "depth": [1, 3]}, {"source": "robust", "target": "testing of low-dimensional", "depth": [1, 3]}, {"source": "robust", "target": "function", "depth": [1, 1]}, {"source": "robust", "target": "testing", "depth": [1, 1]}, {"source": "synthesi", "target": "efficient neural architecture", "depth": [1, 3]}, {"source": "synthesi", "target": "algebra-based loop synthesi", "depth": [1, 3]}, {"source": "synthesi", "target": "loop synthesi", "depth": [1, 3]}, {"source": "synthesi", "target": "algebra-based loop", "depth": [1, 3]}, {"source": "synthesi", "target": "loop", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "multi-agent reinforcement", "depth": [1, 2]}, {"source": "multi-agent reinforcement learning", "target": "model extraction library", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "reinforcement learning model", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "learning model extraction", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "networked system control", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "medical image", "target": "crossing aggregation network", "depth": [1, 3]}, {"source": "medical image", "target": "crossing aggregation", "depth": [1, 3]}, {"source": "medical image", "target": "aggregation network", "depth": [1, 3]}, {"source": "medical image", "target": "network for medical", "depth": [1, 3]}, {"source": "social network", "target": "multi-lingual social network", "depth": [1, 3]}, {"source": "social network", "target": "characterising user content", "depth": [1, 3]}, {"source": "social network", "target": "user content", "depth": [1, 3]}, {"source": "social network", "target": "characterising user", "depth": [1, 3]}, {"source": "social network", "target": "modern social network", "depth": [1, 3]}, {"source": "modeling", "target": "stochastic confounder", "depth": [1, 3]}, {"source": "modeling", "target": "modeling with stochastic", "depth": [1, 3]}, {"source": "modeling", "target": "causal modeling", "depth": [1, 3]}, {"source": "modeling", "target": "confounder", "depth": [1, 3]}, {"source": "modeling", "target": "causal", "depth": [1, 2]}, {"source": "testing", "target": "group testing", "depth": [1, 1]}, {"source": "testing", "target": "group", "depth": [1, 2]}, {"source": "testing", "target": "robust testing", "depth": [1, 3]}, {"source": "testing", "target": "low-dimensional function", "depth": [1, 3]}, {"source": "testing", "target": "testing of low-dimensional", "depth": [1, 3]}, {"source": "perspective", "target": "attacks and defense", "depth": [1, 2]}, {"source": "perspective", "target": "interpretation perspective", "depth": [1, 3]}, {"source": "perspective", "target": "adversarial attack", "depth": [1, 1]}, {"source": "perspective", "target": "defense", "depth": [1, 2]}, {"source": "perspective", "target": "interpretation", "depth": [1, 3]}, {"source": "edge computing", "target": "mobile edge computing", "depth": [1, 2]}, {"source": "edge computing", "target": "mobile edge", "depth": [1, 2]}, {"source": "edge computing", "target": "heterogeneous mobile edge", "depth": [1, 3]}, {"source": "edge computing", "target": "energy harvesting", "depth": [1, 2]}, {"source": "edge computing", "target": "offloading in heterogeneou", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 2]}, {"source": "convolutional network", "target": "recurrent convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "long-term recurrent convolutional", "depth": [1, 3]}, {"source": "convolutional network", "target": "detecting driver distraction", "depth": [1, 3]}, {"source": "domain", "target": "adaptation", "depth": [1, 1]}, {"source": "domain", "target": "domain generalization", "depth": [1, 2]}, {"source": "domain", "target": "generalization", "depth": [1, 1]}, {"source": "domain", "target": "continuous domain", "depth": [1, 3]}, {"source": "domain", "target": "sampling in continuou", "depth": [1, 3]}, {"source": "matching", "target": "approximate pattern matching", "depth": [1, 3]}, {"source": "matching", "target": "faster approximate pattern", "depth": [1, 3]}, {"source": "matching", "target": "pattern matching", "depth": [1, 3]}, {"source": "matching", "target": "unified approach", "depth": [1, 2]}, {"source": "matching", "target": "approximate pattern", "depth": [1, 3]}, {"source": "neural architecture search", "target": "architecture search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "state machine design", "depth": [1, 3]}, {"source": "neural architecture search", "target": "liquid state machine", "depth": [1, 3]}, {"source": "neural architecture search", "target": "search based framework", "depth": [1, 3]}, {"source": "neural architecture search", "target": "architecture search based", "depth": [1, 3]}, {"source": "autoencoder", "target": "variational autoencoder", "depth": [1, 1]}, {"source": "autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "autoencoder", "target": "representation of molecule", "depth": [1, 3]}, {"source": "autoencoder", "target": "molecules using graph", "depth": [1, 3]}, {"source": "autoencoder", "target": "graph variational", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "representation of molecule", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "molecules using graph", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "graph variational", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "continuous representation", "depth": [1, 3]}, {"source": "lower bound", "target": "tight lower bound", "depth": [1, 3]}, {"source": "lower bound", "target": "related contraction problem", "depth": [1, 3]}, {"source": "lower bound", "target": "contraction problem", "depth": [1, 3]}, {"source": "lower bound", "target": "tight lower", "depth": [1, 3]}, {"source": "lower bound", "target": "hadwiger number", "depth": [1, 3]}, {"source": "natural language processing", "target": "language processing", "depth": [1, 1]}, {"source": "natural language processing", "target": "hip replacement dislocation", "depth": [1, 3]}, {"source": "natural language processing", "target": "adverse event detection", "depth": [1, 3]}, {"source": "natural language processing", "target": "detecting total hip", "depth": [1, 3]}, {"source": "natural language processing", "target": "total hip replacement", "depth": [1, 3]}, {"source": "deep transfer learning", "target": "deep transfer", "depth": [1, 2]}, {"source": "deep transfer learning", "target": "arbitrary sensor geometry", "depth": [1, 3]}, {"source": "deep transfer learning", "target": "sparse array selection", "depth": [1, 3]}, {"source": "deep transfer learning", "target": "array selection", "depth": [1, 3]}, {"source": "deep transfer learning", "target": "selection across arbitrary", "depth": [1, 3]}, {"source": "search", "target": "few-shot image classification", "depth": [1, 3]}, {"source": "search", "target": "divergent search", "depth": [1, 3]}, {"source": "search", "target": "search for few-shot", "depth": [1, 3]}, {"source": "search", "target": "few-shot image", "depth": [1, 3]}, {"source": "search", "target": "search via parallel", "depth": [1, 3]}, {"source": "continual learning", "target": "implicit gating mechanism", "depth": [1, 3]}, {"source": "continual learning", "target": "implicit gating", "depth": [1, 3]}, {"source": "continual learning", "target": "gating mechanism", "depth": [1, 3]}, {"source": "continual learning", "target": "mechanism for continual", "depth": [1, 3]}, {"source": "continual learning", "target": "implicit", "depth": [1, 3]}, {"source": "theory", "target": "algebraic datatype", "depth": [1, 3]}, {"source": "theory", "target": "theory of algebraic", "depth": [1, 3]}, {"source": "theory", "target": "datatype", "depth": [1, 3]}, {"source": "theory", "target": "algebraic", "depth": [1, 2]}, {"source": "theory", "target": "politenes", "depth": [1, 3]}, {"source": "big datum", "target": "enabling big datum", "depth": [1, 3]}, {"source": "big datum", "target": "farplas automotive", "depth": [1, 3]}, {"source": "big datum", "target": "analytics at manufacturing", "depth": [1, 3]}, {"source": "big datum", "target": "manufacturing field", "depth": [1, 3]}, {"source": "big datum", "target": "analytics architecture design", "depth": [1, 3]}, {"source": "pandemic", "target": "forecast and forecasting", "depth": [1, 3]}, {"source": "pandemic", "target": "forecasting to learn", "depth": [1, 3]}, {"source": "pandemic", "target": "learning to forecast", "depth": [1, 3]}, {"source": "pandemic", "target": "forecast", "depth": [1, 3]}, {"source": "pandemic", "target": "forecasting", "depth": [1, 2]}, {"source": "set", "target": "labelled point set", "depth": [1, 3]}, {"source": "set", "target": "point set", "depth": [1, 2]}, {"source": "set", "target": "paths on labelled", "depth": [1, 3]}, {"source": "set", "target": "labelled point", "depth": [1, 3]}, {"source": "set", "target": "compatible path", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attacks and defense", "depth": [1, 2]}, {"source": "adversarial attack", "target": "interpretation perspective", "depth": [1, 3]}, {"source": "adversarial attack", "target": "defense", "depth": [1, 2]}, {"source": "adversarial attack", "target": "interpretation", "depth": [1, 3]}, {"source": "adversarial attack", "target": "universal audio adversarial", "depth": [1, 3]}, {"source": "adaptation", "target": "imbalanced satellite datum", "depth": [1, 3]}, {"source": "adaptation", "target": "reliably predicting", "depth": [1, 3]}, {"source": "adaptation", "target": "satellite datum", "depth": [1, 3]}, {"source": "adaptation", "target": "climate adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "predicting from imbalanced", "depth": [1, 3]}, {"source": "platform", "target": "molecular inverse-design platform", "depth": [1, 3]}, {"source": "platform", "target": "material industry", "depth": [1, 3]}, {"source": "platform", "target": "platform for material", "depth": [1, 3]}, {"source": "platform", "target": "inverse-design platform", "depth": [1, 3]}, {"source": "platform", "target": "molecular inverse-design", "depth": [1, 3]}, {"source": "interaction", "target": "human-object interaction", "depth": [1, 2]}, {"source": "interaction", "target": "business transaction", "depth": [1, 3]}, {"source": "interaction", "target": "interactions or busines", "depth": [1, 3]}, {"source": "interaction", "target": "social interaction", "depth": [1, 3]}, {"source": "interaction", "target": "transaction", "depth": [1, 2]}, {"source": "learning based", "target": "machine learning based", "depth": [1, 2]}, {"source": "learning based", "target": "learning based packet", "depth": [1, 3]}, {"source": "learning based", "target": "based packet detection", "depth": [1, 3]}, {"source": "learning based", "target": "carrier frequency offset", "depth": [1, 3]}, {"source": "learning based", "target": "frequency offset estimation", "depth": [1, 3]}, {"source": "contact tracing", "target": "tracing", "depth": [1, 2]}, {"source": "contact tracing", "target": "blind contact tracing", "depth": [1, 3]}, {"source": "contact tracing", "target": "note on blind", "depth": [1, 3]}, {"source": "contact tracing", "target": "blind contact", "depth": [1, 3]}, {"source": "contact tracing", "target": "tracing at scale", "depth": [1, 3]}, {"source": "environment", "target": "skid-steering kinematic model", "depth": [1, 3]}, {"source": "environment", "target": "subarctic environment", "depth": [1, 3]}, {"source": "environment", "target": "kinematic model", "depth": [1, 3]}, {"source": "environment", "target": "models for subarctic", "depth": [1, 3]}, {"source": "environment", "target": "evaluation of skid-steering", "depth": [1, 3]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 1]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 2]}, {"source": "model predictive control", "target": "learning model predictive", "depth": [1, 3]}, {"source": "model predictive control", "target": "nonlinear model predictive", "depth": [1, 3]}, {"source": "model predictive control", "target": "nonlinear model", "depth": [1, 3]}, {"source": "inference", "target": "quantized communication", "depth": [1, 3]}, {"source": "inference", "target": "inference with sparse", "depth": [1, 3]}, {"source": "inference", "target": "sparse and quantized", "depth": [1, 3]}, {"source": "inference", "target": "distributed inference", "depth": [1, 3]}, {"source": "inference", "target": "sparse", "depth": [1, 2]}, {"source": "function", "target": "robust testing", "depth": [1, 3]}, {"source": "function", "target": "low-dimensional function", "depth": [1, 3]}, {"source": "function", "target": "testing of low-dimensional", "depth": [1, 3]}, {"source": "function", "target": "bayesian optimisation", "depth": [1, 3]}, {"source": "function", "target": "function in bayesian", "depth": [1, 3]}, {"source": "internet of thing", "target": "thing", "depth": [1, 3]}, {"source": "internet of thing", "target": "mobile agent framework", "depth": [1, 3]}, {"source": "internet of thing", "target": "localized mobile agent", "depth": [1, 3]}, {"source": "internet of thing", "target": "mobile agent", "depth": [1, 3]}, {"source": "internet of thing", "target": "agent framework", "depth": [1, 3]}, {"source": "control system", "target": "industrial control system", "depth": [1, 2]}, {"source": "control system", "target": "nonlinear control system", "depth": [1, 3]}, {"source": "control system", "target": "nonlinear control", "depth": [1, 2]}, {"source": "control system", "target": "testbed for teaching", "depth": [1, 3]}, {"source": "control system", "target": "teaching cybersecurity", "depth": [1, 3]}, {"source": "power system", "target": "transmission capacity allocation", "depth": [1, 3]}, {"source": "power system", "target": "wind-dominated power system", "depth": [1, 3]}, {"source": "power system", "target": "reserve and transmission", "depth": [1, 3]}, {"source": "power system", "target": "transmission capacity", "depth": [1, 3]}, {"source": "power system", "target": "capacity allocation", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 1]}, {"source": "human pose", "target": "explicit occlusion training", "depth": [1, 3]}, {"source": "human pose", "target": "occlusion training", "depth": [1, 3]}, {"source": "human pose", "target": "networks with explicit", "depth": [1, 3]}, {"source": "human pose", "target": "explicit occlusion", "depth": [1, 3]}, {"source": "person re-identification", "target": "hard sample mining", "depth": [1, 3]}, {"source": "person re-identification", "target": "active hard sample", "depth": [1, 3]}, {"source": "person re-identification", "target": "sample mining", "depth": [1, 3]}, {"source": "person re-identification", "target": "active hard", "depth": [1, 3]}, {"source": "person re-identification", "target": "hard sample", "depth": [1, 3]}, {"source": "twitter", "target": "dynamic topic modeling", "depth": [1, 3]}, {"source": "twitter", "target": "twitter narrative", "depth": [1, 3]}, {"source": "twitter", "target": "dynamic topic", "depth": [1, 3]}, {"source": "twitter", "target": "governors and cabinet", "depth": [1, 3]}, {"source": "twitter", "target": "cabinet executive", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading comprehension", "depth": [1, 1]}, {"source": "reading comprehension", "target": "machine reading", "depth": [1, 3]}, {"source": "reading comprehension", "target": "comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "requiring reasoning process", "depth": [1, 3]}, {"source": "reading comprehension", "target": "reading comprehension benchmark", "depth": [1, 3]}, {"source": "attention", "target": "long-short range attention", "depth": [1, 3]}, {"source": "attention", "target": "range attention", "depth": [1, 3]}, {"source": "attention", "target": "lite transformer", "depth": [1, 3]}, {"source": "attention", "target": "transformer with long-short", "depth": [1, 3]}, {"source": "attention", "target": "long-short range", "depth": [1, 3]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 2]}, {"source": "attention network", "target": "item knowledge graph", "depth": [1, 3]}, {"source": "attention network", "target": "contextualized graph attention", "depth": [1, 3]}, {"source": "attention network", "target": "network for recommendation", "depth": [1, 3]}, {"source": "attention network", "target": "recommendation with item", "depth": [1, 3]}, {"source": "dynamical system", "target": "linear dynamical system", "depth": [1, 3]}, {"source": "dynamical system", "target": "continuous linear dynamical", "depth": [1, 3]}, {"source": "dynamical system", "target": "continuous linear", "depth": [1, 3]}, {"source": "dynamical system", "target": "invariants for continuou", "depth": [1, 3]}, {"source": "dynamical system", "target": "learning nonlinear dynamical", "depth": [1, 3]}, {"source": "speech recognition", "target": "pay attention", "depth": [1, 3]}, {"source": "speech recognition", "target": "visual modality", "depth": [1, 3]}, {"source": "speech recognition", "target": "modality in speech", "depth": [1, 3]}, {"source": "speech recognition", "target": "teach dnn", "depth": [1, 3]}, {"source": "speech recognition", "target": "dnns to pay", "depth": [1, 3]}, {"source": "space", "target": "scientific text", "depth": [1, 3]}, {"source": "space", "target": "space of meaning", "depth": [1, 3]}, {"source": "space", "target": "meaning for scientific", "depth": [1, 3]}, {"source": "space", "target": "informational space", "depth": [1, 3]}, {"source": "space", "target": "meaning", "depth": [1, 3]}, {"source": "evolution", "target": "epidemic evolution", "depth": [1, 3]}, {"source": "evolution", "target": "models really predictive", "depth": [1, 3]}, {"source": "evolution", "target": "compartmental model", "depth": [1, 3]}, {"source": "evolution", "target": "simulation", "depth": [1, 2]}, {"source": "evolution", "target": "predictive", "depth": [1, 2]}, {"source": "generalization", "target": "domain generalization", "depth": [1, 2]}, {"source": "generalization", "target": "joint depth-pose learning", "depth": [1, 3]}, {"source": "generalization", "target": "learning without posenet", "depth": [1, 3]}, {"source": "generalization", "target": "joint depth-pose", "depth": [1, 3]}, {"source": "generalization", "target": "depth-pose learning", "depth": [1, 3]}, {"source": "privacy", "target": "differential privacy", "depth": [1, 2]}, {"source": "privacy", "target": "differential", "depth": [1, 3]}, {"source": "privacy", "target": "tailbiting convolutional code", "depth": [1, 3]}, {"source": "privacy", "target": "nested tailbiting convolutional", "depth": [1, 3]}, {"source": "privacy", "target": "codes for secrecy", "depth": [1, 3]}, {"source": "extended version", "target": "cqe in description", "depth": [1, 3]}, {"source": "extended version", "target": "instance indistinguishability", "depth": [1, 3]}, {"source": "extended version", "target": "description logic", "depth": [1, 3]}, {"source": "extended version", "target": "logics through instance", "depth": [1, 3]}, {"source": "extended version", "target": "cqe", "depth": [1, 3]}, {"source": "time", "target": "commitment toward time", "depth": [1, 3]}, {"source": "time", "target": "intention as commitment", "depth": [1, 3]}, {"source": "time", "target": "commitment", "depth": [1, 2]}, {"source": "time", "target": "intention", "depth": [1, 3]}, {"source": "time", "target": "multi-layered cake cutting", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "generic ensemble based", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "ensemble based deep", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "based deep convolutional", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "crossing aggregation network", "depth": [1, 3]}, {"source": "label", "target": "mining self-similarity", "depth": [1, 3]}, {"source": "label", "target": "label super-resolution", "depth": [1, 3]}, {"source": "label", "target": "epitomic representation", "depth": [1, 3]}, {"source": "label", "target": "super-resolution with epitomic", "depth": [1, 3]}, {"source": "label", "target": "mining", "depth": [1, 2]}, {"source": "technical report", "target": "extended technical report", "depth": [1, 3]}, {"source": "technical report", "target": "approximate quantile computation", "depth": [1, 3]}, {"source": "technical report", "target": "large-scale datum", "depth": [1, 3]}, {"source": "technical report", "target": "survey of approximate", "depth": [1, 3]}, {"source": "technical report", "target": "approximate quantile", "depth": [1, 3]}, {"source": "chest x-ray image", "target": "posteroanterior chest x-ray", "depth": [1, 3]}, {"source": "chest x-ray image", "target": "limited posteroanterior chest", "depth": [1, 3]}, {"source": "chest x-ray image", "target": "fine-tuned deep neural", "depth": [1, 3]}, {"source": "chest x-ray image", "target": "coronet", "depth": [1, 3]}, {"source": "chest x-ray image", "target": "network for detection", "depth": [1, 3]}, {"source": "deep learning approach", "target": "noisy ecg", "depth": [1, 3]}, {"source": "deep learning approach", "target": "rpnet", "depth": [1, 3]}, {"source": "deep learning approach", "target": "robust r peak", "depth": [1, 3]}, {"source": "deep learning approach", "target": "peak detection", "depth": [1, 3]}, {"source": "deep learning approach", "target": "oct datum", "depth": [1, 3]}, {"source": "benchmark", "target": "dataset and benchmark", "depth": [1, 3]}, {"source": "benchmark", "target": "underwater imagery", "depth": [1, 3]}, {"source": "benchmark", "target": "segmentation of underwater", "depth": [1, 3]}, {"source": "benchmark", "target": "imagery", "depth": [1, 2]}, {"source": "benchmark", "target": "evaluation benchmark", "depth": [1, 2]}, {"source": "bert", "target": "embeddings during fine-tuning", "depth": [1, 3]}, {"source": "bert", "target": "bert embedding", "depth": [1, 3]}, {"source": "bert", "target": "fine-tuning", "depth": [1, 2]}, {"source": "bert", "target": "universal dependency", "depth": [1, 3]}, {"source": "bert", "target": "dependency", "depth": [1, 3]}, {"source": "path", "target": "labelled point set", "depth": [1, 3]}, {"source": "path", "target": "point set", "depth": [1, 2]}, {"source": "path", "target": "paths on labelled", "depth": [1, 3]}, {"source": "path", "target": "labelled point", "depth": [1, 3]}, {"source": "path", "target": "compatible path", "depth": [1, 3]}, {"source": "feature extraction", "target": "discriminative feature extraction", "depth": [1, 3]}, {"source": "feature extraction", "target": "salient object detection", "depth": [1, 2]}, {"source": "feature extraction", "target": "discriminative feature", "depth": [1, 3]}, {"source": "feature extraction", "target": "dfnet", "depth": [1, 3]}, {"source": "feature extraction", "target": "discriminative", "depth": [1, 3]}, {"source": "speech", "target": "speech synthesi", "depth": [1, 3]}, {"source": "speech", "target": "speech translation", "depth": [1, 3]}, {"source": "speech", "target": "advancing speech synthesi", "depth": [1, 3]}, {"source": "speech", "target": "synthesis using eeg", "depth": [1, 3]}, {"source": "speech", "target": "advancing speech", "depth": [1, 3]}, {"source": "empirical study", "target": "market impact conditional", "depth": [1, 3]}, {"source": "empirical study", "target": "study of market", "depth": [1, 3]}, {"source": "empirical study", "target": "market impact", "depth": [1, 3]}, {"source": "empirical study", "target": "order-flow imbalance", "depth": [1, 3]}, {"source": "empirical study", "target": "conditional on order-flow", "depth": [1, 3]}, {"source": "reinforcement", "target": "driven representation", "depth": [1, 3]}, {"source": "reinforcement", "target": "driven", "depth": [1, 3]}, {"source": "reinforcement", "target": "augmented datum", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning with augmented", "depth": [1, 3]}, {"source": "reinforcement", "target": "augmented", "depth": [1, 3]}, {"source": "tensor", "target": "tensor ring completion", "depth": [1, 3]}, {"source": "tensor", "target": "hierarchical tensor ring", "depth": [1, 3]}, {"source": "tensor", "target": "ring completion", "depth": [1, 3]}, {"source": "tensor", "target": "tensor ring", "depth": [1, 3]}, {"source": "tensor", "target": "hierarchical tensor", "depth": [1, 3]}, {"source": "language processing", "target": "evolutionary-based approach", "depth": [1, 3]}, {"source": "language processing", "target": "approach for natural", "depth": [1, 3]}, {"source": "language processing", "target": "processing", "depth": [1, 3]}, {"source": "language processing", "target": "chinese natural language", "depth": [1, 3]}, {"source": "language processing", "target": "revisiting pre-trained model", "depth": [1, 3]}, {"source": "research", "target": "security and privacy", "depth": [1, 3]}, {"source": "research", "target": "white paper", "depth": [1, 2]}, {"source": "research", "target": "research challenge", "depth": [1, 2]}, {"source": "research", "target": "challenges for trust", "depth": [1, 3]}, {"source": "research", "target": "trust", "depth": [1, 3]}, {"source": "medium", "target": "categorization of crisi", "depth": [1, 3]}, {"source": "medium", "target": "crisis event", "depth": [1, 3]}, {"source": "medium", "target": "events in social", "depth": [1, 3]}, {"source": "medium", "target": "multimodal categorization", "depth": [1, 3]}, {"source": "medium", "target": "categorization", "depth": [1, 3]}, {"source": "structure", "target": "stable tournament solution", "depth": [1, 3]}, {"source": "structure", "target": "tournament solution", "depth": [1, 3]}, {"source": "structure", "target": "structure of stable", "depth": [1, 3]}, {"source": "structure", "target": "stable tournament", "depth": [1, 3]}, {"source": "structure", "target": "solution", "depth": [1, 1]}, {"source": "approximation", "target": "optimal streaming approximation", "depth": [1, 3]}, {"source": "approximation", "target": "streaming approximation", "depth": [1, 3]}, {"source": "approximation", "target": "optimal streaming", "depth": [1, 3]}, {"source": "approximation", "target": "boolean", "depth": [1, 2]}, {"source": "approximation", "target": "streaming", "depth": [1, 1]}, {"source": "cnn", "target": "cnn for text", "depth": [1, 3]}, {"source": "cnn", "target": "light-weighted cnn", "depth": [1, 3]}, {"source": "cnn", "target": "enhance spatiotemporal", "depth": [1, 3]}, {"source": "cnn", "target": "mega-scale dataset", "depth": [1, 3]}, {"source": "cnn", "target": "datasets further enhance", "depth": [1, 3]}, {"source": "online", "target": "sarcasm communication online", "depth": [1, 3]}, {"source": "online", "target": "communication online", "depth": [1, 3]}, {"source": "online", "target": "effect of sociocultural", "depth": [1, 3]}, {"source": "online", "target": "variables on sarcasm", "depth": [1, 3]}, {"source": "online", "target": "sarcasm communication", "depth": [1, 3]}, {"source": "complexity", "target": "rank and complexity", "depth": [1, 3]}, {"source": "complexity", "target": "tensor rank", "depth": [1, 3]}, {"source": "complexity", "target": "rank", "depth": [1, 2]}, {"source": "complexity", "target": "subgraph isomorphism", "depth": [1, 3]}, {"source": "complexity", "target": "formula complexity", "depth": [1, 3]}, {"source": "active learning", "target": "halfspaces almost optimally", "depth": [1, 3]}, {"source": "active learning", "target": "location and active", "depth": [1, 3]}, {"source": "active learning", "target": "point location", "depth": [1, 3]}, {"source": "active learning", "target": "learning halfspace", "depth": [1, 3]}, {"source": "active learning", "target": "adversarial active learning", "depth": [1, 3]}, {"source": "architecture search", "target": "knowledge-inherited neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "modulenet", "depth": [1, 3]}, {"source": "architecture search", "target": "multimodal neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "deep multimodal neural", "depth": [1, 3]}, {"source": "architecture search", "target": "deep multimodal", "depth": [1, 3]}, {"source": "block model", "target": "stochastic block model", "depth": [1, 2]}, {"source": "block model", "target": "stochastic block", "depth": [1, 2]}, {"source": "block model", "target": "assortative-constrained stochastic block", "depth": [1, 3]}, {"source": "block model", "target": "permuted striped block", "depth": [1, 3]}, {"source": "block model", "target": "striped block model", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "distillation", "depth": [1, 2]}, {"source": "knowledge distillation", "target": "loss for knowledge", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "triplet los", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "los", "depth": [1, 2]}, {"source": "knowledge distillation", "target": "knowledge", "depth": [1, 1]}, {"source": "language understanding", "target": "natural language understanding", "depth": [1, 3]}, {"source": "language understanding", "target": "dual learning", "depth": [1, 3]}, {"source": "language understanding", "target": "virtual adversarial training", "depth": [1, 3]}, {"source": "language understanding", "target": "token-aware virtual adversarial", "depth": [1, 3]}, {"source": "language understanding", "target": "virtual adversarial", "depth": [1, 3]}, {"source": "question", "target": "answering", "depth": [1, 1]}, {"source": "question", "target": "robust question answering", "depth": [1, 3]}, {"source": "question", "target": "sub-part alignment", "depth": [1, 3]}, {"source": "question", "target": "answering through sub-part", "depth": [1, 3]}, {"source": "question", "target": "robust question", "depth": [1, 3]}, {"source": "sign language", "target": "sign language recognition", "depth": [1, 2]}, {"source": "sign language", "target": "language recognition", "depth": [1, 2]}, {"source": "sign language", "target": "sign", "depth": [1, 2]}, {"source": "sign language", "target": "neural network array", "depth": [1, 3]}, {"source": "sign language", "target": "network array", "depth": [1, 3]}, {"source": "pose", "target": "multi-camera rgb-d dataset", "depth": [1, 3]}, {"source": "pose", "target": "dataset for object", "depth": [1, 3]}, {"source": "pose", "target": "object recognition", "depth": [1, 3]}, {"source": "pose", "target": "ycb-m", "depth": [1, 3]}, {"source": "pose", "target": "rgb-d dataset", "depth": [1, 3]}, {"source": "reasoning", "target": "commonsense reasoning", "depth": [1, 2]}, {"source": "reasoning", "target": "generative data augmentation", "depth": [1, 3]}, {"source": "reasoning", "target": "augmentation for commonsense", "depth": [1, 3]}, {"source": "reasoning", "target": "generative datum", "depth": [1, 3]}, {"source": "reasoning", "target": "application to commonsense", "depth": [1, 3]}, {"source": "predictive control", "target": "model predictive", "depth": [1, 2]}, {"source": "predictive control", "target": "learning model predictive", "depth": [1, 3]}, {"source": "predictive control", "target": "decentralized learning model", "depth": [1, 3]}, {"source": "predictive control", "target": "nonlinear multi-agent system", "depth": [1, 3]}, {"source": "predictive control", "target": "optimization for nonlinear", "depth": [1, 3]}, {"source": "performance", "target": "steel defects detection", "depth": [1, 3]}, {"source": "performance", "target": "automatic steel defect", "depth": [1, 3]}, {"source": "performance", "target": "performance for automatic", "depth": [1, 3]}, {"source": "performance", "target": "defects detection", "depth": [1, 3]}, {"source": "performance", "target": "automatic steel", "depth": [1, 3]}, {"source": "vehicle", "target": "detection and recognition", "depth": [1, 2]}, {"source": "vehicle", "target": "recognition of swap-body", "depth": [1, 3]}, {"source": "vehicle", "target": "swap-bodies using camera", "depth": [1, 3]}, {"source": "vehicle", "target": "camera mounted", "depth": [1, 3]}, {"source": "vehicle", "target": "vehicle re-identification", "depth": [1, 2]}, {"source": "knowledge", "target": "knowledge scientist", "depth": [1, 3]}, {"source": "knowledge", "target": "unlocking the data-driven", "depth": [1, 3]}, {"source": "knowledge", "target": "data-driven organization", "depth": [1, 3]}, {"source": "knowledge", "target": "scientist", "depth": [1, 3]}, {"source": "knowledge", "target": "unlocking", "depth": [1, 3]}, {"source": "nonlinear system", "target": "system level approach", "depth": [1, 3]}, {"source": "nonlinear system", "target": "discrete-time nonlinear system", "depth": [1, 3]}, {"source": "nonlinear system", "target": "level approach", "depth": [1, 3]}, {"source": "nonlinear system", "target": "system level", "depth": [1, 3]}, {"source": "nonlinear system", "target": "approach to discrete-time", "depth": [1, 3]}, {"source": "learning framework", "target": "multiple instance learning", "depth": [1, 2]}, {"source": "learning framework", "target": "instance learning framework", "depth": [1, 3]}, {"source": "learning framework", "target": "two-stage multiple instance", "depth": [1, 3]}, {"source": "learning framework", "target": "cancer in mammogram", "depth": [1, 3]}, {"source": "learning framework", "target": "multiple instance", "depth": [1, 3]}, {"source": "motion planning", "target": "efficient exploration", "depth": [1, 3]}, {"source": "motion planning", "target": "exploration and exploitation", "depth": [1, 3]}, {"source": "motion planning", "target": "synergy between reinforcement", "depth": [1, 3]}, {"source": "motion planning", "target": "learning and motion", "depth": [1, 3]}, {"source": "motion planning", "target": "pbc", "depth": [1, 3]}, {"source": "massive mimo", "target": "cell-free massive mimo", "depth": [1, 2]}, {"source": "massive mimo", "target": "massive mimo system", "depth": [1, 3]}, {"source": "massive mimo", "target": "downlink spectral efficiency", "depth": [1, 3]}, {"source": "massive mimo", "target": "multi-antenna user", "depth": [1, 3]}, {"source": "massive mimo", "target": "spectral efficiency", "depth": [1, 3]}, {"source": "study", "target": "outbreak in south", "depth": [1, 3]}, {"source": "study", "target": "south africa", "depth": [1, 3]}, {"source": "study", "target": "data to inform", "depth": [1, 3]}, {"source": "study", "target": "outbreak", "depth": [1, 2]}, {"source": "study", "target": "africa", "depth": [1, 3]}, {"source": "human pose estimation", "target": "explicit occlusion training", "depth": [1, 3]}, {"source": "human pose estimation", "target": "occlusion training", "depth": [1, 3]}, {"source": "human pose estimation", "target": "networks with explicit", "depth": [1, 3]}, {"source": "human pose estimation", "target": "explicit occlusion", "depth": [1, 3]}, {"source": "human pose estimation", "target": "human", "depth": [1, 2]}, {"source": "tool", "target": "text annotation tool", "depth": [1, 3]}, {"source": "tool", "target": "collaborative text annotation", "depth": [1, 3]}, {"source": "tool", "target": "teamtat", "depth": [1, 3]}, {"source": "tool", "target": "annotation tool", "depth": [1, 3]}, {"source": "tool", "target": "collaborative text", "depth": [1, 3]}, {"source": "action recognition", "target": "temporal excitation", "depth": [1, 3]}, {"source": "action recognition", "target": "excitation and aggregation", "depth": [1, 3]}, {"source": "action recognition", "target": "aggregation for action", "depth": [1, 3]}, {"source": "action recognition", "target": "tea", "depth": [1, 3]}, {"source": "action recognition", "target": "action", "depth": [1, 1]}, {"source": "trajectory prediction", "target": "pedestrian zone", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "approach for trajectory", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "prediction in pedestrian", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "zone", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "social behavior graph", "depth": [1, 3]}, {"source": "deep network", "target": "linear least-square problem", "depth": [1, 3]}, {"source": "deep network", "target": "training of deep", "depth": [1, 3]}, {"source": "deep network", "target": "networks for linear", "depth": [1, 3]}, {"source": "deep network", "target": "eigendecomposition-free training", "depth": [1, 3]}, {"source": "deep network", "target": "least-square problem", "depth": [1, 3]}, {"source": "tree", "target": "translating workflow net", "depth": [1, 3]}, {"source": "tree", "target": "process tree", "depth": [1, 3]}, {"source": "tree", "target": "algorithmic approach", "depth": [1, 3]}, {"source": "tree", "target": "workflow net", "depth": [1, 3]}, {"source": "tree", "target": "nets to proces", "depth": [1, 3]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 2]}, {"source": "named entity recognition", "target": "span representation", "depth": [1, 3]}, {"source": "named entity recognition", "target": "learning of span", "depth": [1, 3]}, {"source": "named entity recognition", "target": "study through named", "depth": [1, 3]}, {"source": "named entity recognition", "target": "weak supervision approach", "depth": [1, 3]}, {"source": "named entity", "target": "entity recognition", "depth": [1, 2]}, {"source": "named entity", "target": "fine-grained named entity", "depth": [1, 2]}, {"source": "named entity", "target": "span representation", "depth": [1, 3]}, {"source": "named entity", "target": "learning of span", "depth": [1, 3]}, {"source": "named entity", "target": "study through named", "depth": [1, 3]}, {"source": "adversarial training", "target": "virtual adversarial training", "depth": [1, 3]}, {"source": "adversarial training", "target": "token-aware virtual adversarial", "depth": [1, 3]}, {"source": "adversarial training", "target": "virtual adversarial", "depth": [1, 3]}, {"source": "adversarial training", "target": "training for language", "depth": [1, 3]}, {"source": "adversarial training", "target": "naturalness of language", "depth": [1, 3]}, {"source": "neural language model", "target": "neural language", "depth": [1, 2]}, {"source": "neural language model", "target": "human tacit assumption", "depth": [1, 3]}, {"source": "neural language model", "target": "probing neural language", "depth": [1, 3]}, {"source": "neural language model", "target": "tacit assumption", "depth": [1, 3]}, {"source": "neural language model", "target": "models for human", "depth": [1, 3]}, {"source": "answering", "target": "bridging anaphora resolution", "depth": [1, 3]}, {"source": "answering", "target": "anaphora resolution", "depth": [1, 3]}, {"source": "answering", "target": "resolution as question", "depth": [1, 3]}, {"source": "answering", "target": "bridging anaphora", "depth": [1, 3]}, {"source": "answering", "target": "anaphora", "depth": [1, 3]}, {"source": "bia", "target": "implicit gender bia", "depth": [1, 3]}, {"source": "bia", "target": "gender bia", "depth": [1, 2]}, {"source": "bia", "target": "discovery of implicit", "depth": [1, 3]}, {"source": "bia", "target": "implicit gender", "depth": [1, 3]}, {"source": "bia", "target": "unsupervised discovery", "depth": [1, 3]}, {"source": "dialogue generation", "target": "dialogue", "depth": [1, 2]}, {"source": "dialogue generation", "target": "injection into dialogue", "depth": [1, 3]}, {"source": "dialogue generation", "target": "generation via language", "depth": [1, 3]}, {"source": "dialogue generation", "target": "knowledge injection", "depth": [1, 3]}, {"source": "dialogue generation", "target": "injection", "depth": [1, 3]}, {"source": "group testing", "target": "group", "depth": [1, 2]}, {"source": "group testing", "target": "sparsity-constrained group testing", "depth": [1, 3]}, {"source": "group testing", "target": "improved bound", "depth": [1, 3]}, {"source": "group testing", "target": "bounds and algorithm", "depth": [1, 2]}, {"source": "group testing", "target": "sparsity-constrained group", "depth": [1, 3]}, {"source": "error", "target": "error streaming quantile", "depth": [1, 3]}, {"source": "error", "target": "relative error streaming", "depth": [1, 3]}, {"source": "error", "target": "streaming quantile", "depth": [1, 3]}, {"source": "error", "target": "error streaming", "depth": [1, 3]}, {"source": "error", "target": "relative error", "depth": [1, 3]}, {"source": "metric learning", "target": "deep metric learning", "depth": [1, 2]}, {"source": "metric learning", "target": "deep metric", "depth": [1, 2]}, {"source": "metric learning", "target": "sampling for deep", "depth": [1, 3]}, {"source": "metric learning", "target": "dynamic sampling", "depth": [1, 3]}, {"source": "metric learning", "target": "dictionary-based attention block", "depth": [1, 3]}, {"source": "solution", "target": "unknown period", "depth": [1, 3]}, {"source": "solution", "target": "solutions with unknown", "depth": [1, 3]}, {"source": "solution", "target": "calculation of time-periodic", "depth": [1, 3]}, {"source": "solution", "target": "time-periodic solution", "depth": [1, 3]}, {"source": "solution", "target": "calculation", "depth": [1, 3]}, {"source": "summarization", "target": "opinion summarization", "depth": [1, 3]}, {"source": "summarization", "target": "document", "depth": [1, 2]}, {"source": "summarization", "target": "multi-document opinion summarization", "depth": [1, 3]}, {"source": "summarization", "target": "controlled multi-document opinion", "depth": [1, 3]}, {"source": "summarization", "target": "self-supervised and controlled", "depth": [1, 3]}, {"source": "zero-shot learning", "target": "signal recognition", "depth": [1, 3]}, {"source": "zero-shot learning", "target": "learning for signal", "depth": [1, 3]}, {"source": "zero-shot learning", "target": "signal", "depth": [1, 3]}, {"source": "zero-shot learning", "target": "zero-shot", "depth": [1, 3]}, {"source": "zero-shot learning", "target": "generalized zero-shot learning", "depth": [1, 3]}, {"source": "spiking neural network", "target": "neuromorphic hardware", "depth": [1, 3]}, {"source": "spiking neural network", "target": "noc-based neuromorphic platform", "depth": [1, 3]}, {"source": "spiking neural network", "target": "mapping large-scale spiking", "depth": [1, 3]}, {"source": "spiking neural network", "target": "large-scale spiking neural", "depth": [1, 3]}, {"source": "spiking neural network", "target": "neuromorphic platform", "depth": [1, 3]}, {"source": "depth estimation", "target": "monocular depth estimation", "depth": [1, 2]}, {"source": "depth estimation", "target": "compact self-normalizing neural", "depth": [1, 3]}, {"source": "depth estimation", "target": "self-normalizing neural network", "depth": [1, 3]}, {"source": "depth estimation", "target": "highly compact self-normalizing", "depth": [1, 3]}, {"source": "depth estimation", "target": "depthnet nano", "depth": [1, 3]}, {"source": "recommender system", "target": "graph learning approach", "depth": [1, 3]}, {"source": "recommender system", "target": "approaches to recommender", "depth": [1, 3]}, {"source": "recommender system", "target": "graph learning", "depth": [1, 2]}, {"source": "recommender system", "target": "conversational recommender system", "depth": [1, 3]}, {"source": "recommender system", "target": "conversational recommender", "depth": [1, 3]}, {"source": "strategy", "target": "human parsing", "depth": [1, 3]}, {"source": "strategy", "target": "rectification strategy", "depth": [1, 3]}, {"source": "strategy", "target": "strategy for human", "depth": [1, 3]}, {"source": "strategy", "target": "self-learning with rectification", "depth": [1, 3]}, {"source": "strategy", "target": "parsing", "depth": [1, 2]}, {"source": "machine reading comprehension", "target": "machine reading", "depth": [1, 3]}, {"source": "machine reading comprehension", "target": "challenge multiparty dialogues-based", "depth": [1, 3]}, {"source": "machine reading comprehension", "target": "multiparty dialogues-based machine", "depth": [1, 3]}, {"source": "machine reading comprehension", "target": "dialogues-based machine reading", "depth": [1, 3]}, {"source": "machine reading comprehension", "target": "reading comprehension dataset", "depth": [1, 3]}, {"source": "hyperspectral image", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "hyperspectral image", "target": "lightweight network", "depth": [1, 2]}, {"source": "hyperspectral image", "target": "network for hyperspectral", "depth": [1, 3]}, {"source": "hyperspectral image", "target": "litedensenet", "depth": [1, 3]}, {"source": "hyperspectral image", "target": "hyperspectral image clustering", "depth": [1, 3]}, {"source": "fast", "target": "fast algorithm", "depth": [1, 3]}, {"source": "fast", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "fast", "target": "cnn for hyperspectral", "depth": [1, 3]}, {"source": "fast", "target": "fast and accurate", "depth": [1, 3]}, {"source": "fast", "target": "powers of operator", "depth": [1, 3]}, {"source": "transfer", "target": "sentence embedding transfer", "depth": [1, 3]}, {"source": "transfer", "target": "few-sample sentence embedding", "depth": [1, 3]}, {"source": "transfer", "target": "embedding transfer", "depth": [1, 3]}, {"source": "transfer", "target": "sentence embedding", "depth": [1, 2]}, {"source": "transfer", "target": "few-sample sentence", "depth": [1, 3]}, {"source": "policy", "target": "continuous stochastic policy", "depth": [1, 3]}, {"source": "policy", "target": "stochastic policy", "depth": [1, 3]}, {"source": "policy", "target": "learning of continuou", "depth": [1, 3]}, {"source": "policy", "target": "counterfactual learning", "depth": [1, 3]}, {"source": "policy", "target": "residual policy learning", "depth": [1, 3]}, {"source": "data analysi", "target": "spatiotemporal data analysi", "depth": [1, 3]}, {"source": "data analysi", "target": "spatiotemporal datum", "depth": [1, 3]}, {"source": "data analysi", "target": "chronological network", "depth": [1, 3]}, {"source": "data analysi", "target": "analysis with chronological", "depth": [1, 3]}, {"source": "data analysi", "target": "url data analysi", "depth": [1, 3]}, {"source": "sensor network", "target": "wireless sensor network", "depth": [1, 2]}, {"source": "sensor network", "target": "wireless sensor", "depth": [1, 3]}, {"source": "sensor network", "target": "industrial wireless sensor", "depth": [1, 3]}, {"source": "sensor network", "target": "delayed packet-coupled oscillator", "depth": [1, 3]}, {"source": "sensor network", "target": "synchronisation of delayed", "depth": [1, 3]}, {"source": "feature selection", "target": "latent regularization", "depth": [1, 3]}, {"source": "feature selection", "target": "tumor classification", "depth": [1, 3]}, {"source": "feature selection", "target": "regularization for feature", "depth": [1, 3]}, {"source": "feature selection", "target": "selection using kernel", "depth": [1, 3]}, {"source": "feature selection", "target": "kernel method", "depth": [1, 3]}, {"source": "automatum", "target": "cellular automatum", "depth": [1, 3]}, {"source": "automatum", "target": "inferring temporal composition", "depth": [1, 3]}, {"source": "automatum", "target": "probabilistic automatum", "depth": [1, 3]}, {"source": "automatum", "target": "temporal composition", "depth": [1, 3]}, {"source": "automatum", "target": "compositions of action", "depth": [1, 3]}, {"source": "machine learning approach", "target": "predicting skill shortage", "depth": [1, 3]}, {"source": "machine learning approach", "target": "labor market", "depth": [1, 3]}, {"source": "machine learning approach", "target": "skill shortage", "depth": [1, 3]}, {"source": "machine learning approach", "target": "shortages in labor", "depth": [1, 3]}, {"source": "machine learning approach", "target": "pavement condition index", "depth": [1, 3]}, {"source": "single image", "target": "portrait", "depth": [1, 3]}, {"source": "single image", "target": "rasterize and backprop", "depth": [1, 3]}, {"source": "single image", "target": "dense shape", "depth": [1, 3]}, {"source": "single image", "target": "shape and pose", "depth": [1, 2]}, {"source": "single image", "target": "reconstruct", "depth": [1, 3]}, {"source": "evaluation", "target": "interpretable model evaluation", "depth": [1, 3]}, {"source": "evaluation", "target": "model evaluation", "depth": [1, 3]}, {"source": "evaluation", "target": "interpretable model", "depth": [1, 3]}, {"source": "evaluation", "target": "rapid", "depth": [1, 3]}, {"source": "evaluation", "target": "reproducible", "depth": [1, 3]}, {"source": "gaussian process", "target": "algebraic multigrid", "depth": [1, 3]}, {"source": "gaussian process", "target": "multigrid using gaussian", "depth": [1, 3]}, {"source": "gaussian process", "target": "coarsening in algebraic", "depth": [1, 3]}, {"source": "gaussian process", "target": "process", "depth": [1, 2]}, {"source": "gaussian process", "target": "algebraic", "depth": [1, 2]}, {"source": "market", "target": "statistical discrimination", "depth": [1, 3]}, {"source": "market", "target": "ratings-guided market", "depth": [1, 3]}, {"source": "market", "target": "discrimination in ratings-guided", "depth": [1, 3]}, {"source": "market", "target": "discrimination", "depth": [1, 2]}, {"source": "market", "target": "one-sided matching market", "depth": [1, 3]}, {"source": "clinical text", "target": "clinical text mining", "depth": [1, 2]}, {"source": "clinical text", "target": "mining in russian", "depth": [1, 2]}, {"source": "clinical text", "target": "text mining", "depth": [1, 2]}, {"source": "clinical text", "target": "medication information extraction", "depth": [1, 3]}, {"source": "clinical text", "target": "neural network grammar", "depth": [1, 3]}, {"source": "sampling", "target": "deep metric learning", "depth": [1, 2]}, {"source": "sampling", "target": "sampling for deep", "depth": [1, 3]}, {"source": "sampling", "target": "deep metric", "depth": [1, 2]}, {"source": "sampling", "target": "dynamic sampling", "depth": [1, 3]}, {"source": "sampling", "target": "continuous domain", "depth": [1, 3]}, {"source": "computation", "target": "evolutionary computation", "depth": [1, 2]}, {"source": "computation", "target": "samples in evolutionary", "depth": [1, 3]}, {"source": "computation", "target": "averaging", "depth": [1, 3]}, {"source": "computation", "target": "sample", "depth": [1, 2]}, {"source": "computation", "target": "bius transform", "depth": [1, 3]}, {"source": "streaming", "target": "optimal streaming approximation", "depth": [1, 3]}, {"source": "streaming", "target": "streaming approximation", "depth": [1, 3]}, {"source": "streaming", "target": "optimal streaming", "depth": [1, 3]}, {"source": "streaming", "target": "boolean", "depth": [1, 2]}, {"source": "streaming", "target": "streaming network", "depth": [1, 3]}, {"source": "inverse problem", "target": "operator valued datum", "depth": [1, 3]}, {"source": "inverse problem", "target": "model reduction approach", "depth": [1, 3]}, {"source": "inverse problem", "target": "valued datum", "depth": [1, 3]}, {"source": "inverse problem", "target": "model reduction", "depth": [1, 2]}, {"source": "inverse problem", "target": "reduction approach", "depth": [1, 3]}, {"source": "action", "target": "action detection", "depth": [1, 2]}, {"source": "action", "target": "amtnet for action", "depth": [1, 3]}, {"source": "action", "target": "two-stream amtnet", "depth": [1, 3]}, {"source": "action", "target": "two-stream", "depth": [1, 3]}, {"source": "action", "target": "amtnet", "depth": [1, 3]}, {"source": "manipulation", "target": "mobile manipulation", "depth": [1, 3]}, {"source": "manipulation", "target": "stability-guaranteed reinforcement learning", "depth": [1, 3]}, {"source": "manipulation", "target": "contact-rich manipulation", "depth": [1, 3]}, {"source": "manipulation", "target": "learning for contact-rich", "depth": [1, 3]}, {"source": "manipulation", "target": "stability-guaranteed reinforcement", "depth": [1, 3]}, {"source": "learning algorithm", "target": "machine learning algorithm", "depth": [1, 2]}, {"source": "learning algorithm", "target": "cloud environment based", "depth": [1, 3]}, {"source": "learning algorithm", "target": "selection and intrusion", "depth": [1, 3]}, {"source": "learning algorithm", "target": "intrusion detection", "depth": [1, 2]}, {"source": "learning algorithm", "target": "detection in cloud", "depth": [1, 3]}, {"source": "linear system", "target": "markov linear system", "depth": [1, 3]}, {"source": "linear system", "target": "jump markov linear", "depth": [1, 3]}, {"source": "linear system", "target": "jump markov", "depth": [1, 3]}, {"source": "linear system", "target": "consistent linear system", "depth": [1, 3]}, {"source": "linear system", "target": "solving consistent linear", "depth": [1, 3]}]}