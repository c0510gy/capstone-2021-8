{"node": [["neural network", "deep neural network", "network", "graph neural network", "convolutional neural network", "learning", "reinforcement learning", "machine learning", "deep learning", "deep reinforcement learning", "model", "language model", "graph", "datum", "analysis", "representation learning", "machine translation", "system"], ["spiking neural network", "contrastive learning", "contrastive", "deep reinforcement", "multi-agent reinforcement learning", "deep", "deep learning model", "deep learning framework", "learning framework", "learning model", "social network", "deep network", "state", "machine", "adversarial attack", "pre-trained language model", "knowledge graph", "graph embedding", "deep convolutional neural", "graph convolutional", "data augmentation", "survey", "graph representation learning", "graph representation", "representation", "neural machine translation", "neural machine", "translation", "online", "recommendation", "question answering", "visual question answering", "visual question", "generation", "text generation", "knowledge graph embedding", "federated learning", "detection", "object detection", "anomaly detection", "anomaly", "object", "domain adaptation", "adaptation", "domain", "optimization", "bayesian optimization", "bayesian", "algorithm", "natural language", "natural language processing", "language processing", "natural language inference", "task", "tweet", "shared task", "identification", "deep generative", "segmentation", "case study", "social medium", "study", "transformer", "transfer learning", "transfer", "classification", "image classification", "image", "loss", "language", "embedding", "method", "image recognition", "efficient", "prediction", "recognition", "speech recognition", "pre-training", "video object", "speech", "code", "image segmentation", "medical image segmentation", "medical image", "generative adversarial network", "adversarial network", "generative adversarial", "nlp", "processing", "text", "summarization", "control", "optimal control", "problem", "word embedding", "evaluation", "language understanding", "spoken language understanding", "function", "feature selection", "tensor decomposition", "learning approach", "challenge", "training", "adversarial training", "robust", "attack", "architecture search", "neural architecture search", "neural architecture", "fast", "decision making", "point cloud", "cloud", "voice conversion", "variational autoencoder", "approach", "approximation", "recurrent neural network", "tree", "decision tree", "pose estimation", "convolutional network", "graph convolutional network", "differential equation", "text classification", "sentiment analysis", "bandit", "clustering", "feature", "dataset", "generalization", "semantic parsing", "structure", "application", "artificial intelligence", "relation extraction", "fairness", "optimal transport", "perspective", "combinatorial", "monte carlo", "architecture", "search", "space", "motion planning", "planning", "attention network", "graph attention network", "graph attention", "extended version", "extended", "blockchain", "game", "attention", "inference", "autoencoder", "classifier", "computing", "active learning", "logic", "hol", "matrix", "sampling", "style transfer", "differentially private", "framework", "knowledge distillation", "action recognition", "semantic segmentation", "differential privacy", "privacy", "named entity recognition", "entity recognition", "named entity", "multi-task learning", "speech enhancement", "environment", "knowledge transfer", "online learning", "action", "communication", "simulation", "constraint", "information", "time series", "trajectory prediction", "decomposition", "channel", "abstractive summarization", "language inference", "policy", "policy optimization", "object recognition", "learn", "empirical study", "deep learning based", "gaussian proces", "performance", "computation", "parsing", "understanding", "robot", "generative model", "human", "semi-supervised learning", "complexity", "signal", "emotion recognition", "exploration", "test", "quantum", "bert", "retrieval", "synthesis", "type", "ranking", "compressed sensing", "protocol", "feedback", "causal", "alignment", "assessment", "coding", "self-supervised learning", "recommender system", "twitter", "review", "sequence", "future direction", "pandemic", "query", "speaker recognition", "normalization", "matching", "gradient descent", "chest x-ray", "time", "reading comprehension", "reasoning", "regression", "gradient", "imitation learning", "few-shot learning", "face", "medical imaging", "function approximation", "technical report", "contact tracing", "metric learning", "tracking", "generative", "theory", "edge", "smart contract", "intelligent surface", "dynamic environment", "process", "market", "gan", "galerkin method", "flow", "hypergraph", "modeling", "research", "counterfactual explanation", "distribution", "polynomial time", "sentiment classification", "geometry", "bound", "distributed", "pattern", "fair", "robustness", "verification", "tensor", "autonomous vehicle", "kernel", "data analysis", "estimation", "benchmark", "question", "recovery", "extraction", "image denoising", "lightweight", "face recognition", "model predictive control", "sequence labeling", "regularization"], ["model-based reinforcement learning", "model-based reinforcement", "meta reinforcement learning", "beamforming", "smart grid", "machine learning method", "learning method", "machine learning approach", "pre-trained language", "masked language model", "dialogue generation", "factor graph grammar", "graph convolutional neural", "neural network model", "unlabeled datum", "augmentation", "reinforcement learning approach", "path planning", "stochastic analysis", "unsupervised representation learning", "learning for neural", "link prediction", "recommendation system", "answering", "story generation", "unsupervised domain adaptation", "unsupervised domain", "document-level neural machine", "deep learning method", "radiology report", "scene representation", "scene", "few-shot image", "motion prediction", "speech translation", "source code", "machine translation system", "translation system", "hard negative", "medium", "comparative study", "text summarization", "text datum", "security", "stream", "spoken language", "natural language understanding", "isabelle", "deep learning approach", "challenges and opportunity", "efficient neural architecture", "fast and slow", "voice conversion challenge", "conversion challenge", "sensor fusion", "approximation algorithm", "convolutional recurrent neural", "decision", "human pose estimation", "human pose", "ordinary differential equation", "neural ordinary differential", "stochastic differential equation", "partial differential equation", "weak supervision", "label", "online social network", "intelligence", "combinatorial perspective", "motion", "version", "adaptive feature", "fictitious play", "stochastic game", "social learning", "gaussian process", "hyperspectral image classification", "hyperspectral image", "text style transfer", "text style", "unsupervised text style", "dynamic graph", "local differential privacy", "backdoor attack", "voice activity detection", "human action recognition", "strongly convex", "vehicle routing", "online decision", "time series forecasting", "discrete space", "neural abstractive summarization", "general framework", "visual representation", "learning based", "gaussian process regression", "process regression", "deep generative model", "wireless network", "speech emotion recognition", "machine learning model", "video object segmentation", "object segmentation", "multilingual bert", "entity alignment", "transport", "technology", "deep learning application", "voxceleb speaker recognition", "speaker recognition challenge", "recognition challenge", "batch normalization", "batch", "library", "adaptive gradient", "imaging", "tracing", "object tracking", "reconfigurable intelligent surface", "discontinuous galerkin method", "discontinuous galerkin", "normalizing flow", "interpretability", "deep image prior", "deep image", "teaching", "information maximization", "entity", "adversarial robustness", "sparse coding", "speaker verification", "speaker", "cellular network", "language model pre-training", "edge computing", "denoising", "model predictive", "predictive control", "multi-agent reinforcement"], ["temporal knowledge graph", "knowledge graph completion", "speech recognition model", "training speech recognition", "cost framework", "adversarial deep reinforcement", "synthetic news generation", "extracting informative", "joint named entity", "generating radiology report", "memory-driven transformer", "transfer learning framework", "parkinson disease patient", "adversarial data augmentation", "adversarial datum", "unsupervised data augmentation", "high-performance graph representation", "loss function", "generation for anomaly", "unsupervised anomaly detection", "description of world", "language for description", "voice qualifier", "acoustic correlate", "qualifier", "wrench measurement", "method for constraint", "constraint inference", "inference using pose", "efficient constrained sampling", "efficient constrained", "mirror-langevin algorithm", "constrained sampling", "page", "paper length prediction", "length prediction", "video object detection", "augmentation for neural", "training for neural", "multilingual neural machine", "feedback insertion-deletion code", "insertion-deletion code", "feedback insertion-deletion", "varying human skin", "recognition model", "single machine", "mutual information maximization", "cross-domain sentiment classification", "roman urdu text", "analysis of lime", "simulation study", "study on turnpike", "stream of problem", "euclidean space", "f-measure to roc", "recall and f-measure", "markedness and correlation", "informedness", "isabelle function", "lucas-interpretation on isabelle", "lucas-interpretation", "human skin tone", "unsupervised approach", "approach towards varying", "information-theoretic feature selection", "decomposition and submodularity", "selection via tensor", "lightweight generative adversarial", "text-guided image manipulation", "image manipulation", "conditional generative adversarial", "opportunity", "image extreme inpainting", "challenge on image", "progressive bert training", "bert training", "black-box adversarial attack", "detecting adversarial attack", "neural networks serve", "slow decision making", "slow decision", "frameworkfor reproducible deep", "reproducible deep learning", "sensor fusion approach", "fusion approach", "viral-fusion", "kernelized bandit", "methods for kernelized", "approximation method", "long short term", "short term memory", "probability tree", "causal reasoning", "detection and pose", "deep convolutional network", "multiclass debiasing method", "thy algorithm shalt", "bear false witness", "cross-lingual text classification", "benchmarking cross-lingual text", "aspect-based sentiment analysis", "sentiment", "latvian tweet", "thresholded lasso bandit", "lasso bandit", "thresholded lasso", "learning multi-layer graph", "representation for clustering", "multi-layer graph", "common representation", "learn robust feature", "robust feature", "patterns count-based label", "labels for dataset", "count-based label", "domain generalization", "generalization in semantic", "concurrent process history", "process history", "structure of concurrent", "concurrent proces", "residual learning", "embedding with atrous", "atrous convolution", "ldbc social network", "social network graph", "nlp application", "cloud-assisted middleware-based iot", "enhancement of non-functional", "artificial intelligence symposium", "upper-rhine artificial intelligence", "research impact", "semi-supervised relation extraction", "distantly-supervised relation extraction", "consistent evaluation", "accurate and consistent", "fairness for edge", "edge prediction", "minimal code", "perspectives on minimal", "carlo tree search", "monte carlo tree", "tree search", "robust training", "features via orthogonal", "superposition spiking neural", "quantum superposition spiking", "superposition spiking", "quantum superposition", "supernet", "near-optimal high-performance graph", "high-performance graph", "embedding of hierarchical", "hierarchical structure", "structure in euclidean", "volumetric medical image", "semi-supervised medical image", "explainable multi-robot motion", "multi-robot motion planning", "cross-lingual natural language", "ris-assisted haps backhauling", "full-duplex ris-assisted hap", "equivalence for assisted", "assisted grading", "adaptive feature selection", "children speech", "state sharding model", "state sharding", "sharding model", "zero-sum stochastic game", "channel parallel sampling", "groups of channel", "sampling with attention", "dynamic graph convolutional", "bound membership inference", "differentially private learning", "membership inference", "private learning", "graph variational autoencoder", "network classifiers based", "classifiers based", "earnings call", "framework for measuring", "productive performance", "systolic computing", "computing on gpu", "pretext-based active learning", "pal", "pool-based active learning", "aldataset", "teaching logic", "meta-language for teaching", "matrices are underrated", "correspondence matrix", "correspondence", "thompson sampling", "marginalised gaussian process", "nested sampling", "joint neural architecture", "autotuned data-parallel training", "function for image", "performance guarantee", "based physics-informed neural", "artists style transfer", "regularized mahalanobis metric", "differentially private text", "private text perturbation", "turnpikes in stochastic", "scalable bayesian learning", "bayesian learning", "learning of causal", "high density anomaly", "density anomaly", "detection of high", "high density", "long financial report", "conditional variational autoencoder", "generating long financial", "lidar semantic segmentation", "adaptation in lidar", "application-agnostic data sharing", "study of joint", "improve captcha robustness", "bot attack", "improve captcha", "speech enhancement aided", "controller for escaping", "escaping trap", "tampc", "skeleton-based action recognition", "attention-augmented graph convolutional", "perspective on transfer", "projection-free online learning", "projection-free online", "lipschitz continuity", "combinatorial action", "learning with combinatorial", "online decision tree", "trees with fairness", "learning with adversarial", "learning of unsupervised", "strategic communication", "multiway relay communication", "fundamental issue", "power constraint", "identification over channel", "channels with power", "deterministic identification", "sell hard information", "hard information", "sell hard", "series", "series forecasting", "continuous and discrete", "spaces for text", "collaborative training", "edit-based unsupervised summarization", "unsupervised summarization", "overfitting or underfitting", "underfitting", "understand robustness drop", "robustness drop", "multimodal language sequence", "temporal graph attention", "fuzzy query attention", "multi-agent trajectory prediction", "query attention", "prediction with fuzzy", "sharding", "mixed supervision", "making", "matrix decomposition", "graph-regularization for matrix", "learnable graph-regularization", "identification of informative", "english tweet", "dirichlet graph variational", "graph variational", "neighbor-aware graph attention", "network for recommendation", "neighbor-aware graph", "online recommendation system", "guided neural abstractive", "framework for guided", "haps backhauling", "imbalanced domain adaptation", "fair knowledge transfer", "fair knowledge", "trainable natural logic", "logic theorem prover", "natural logic theorem", "learning as abduction", "optimization with multiple", "multiple optima", "quantizing neural", "online recommendation", "regret in online", "complex dynamics forecasting", "augmenting physical model", "dynamics forecasting", "learning visual representation", "human interaction", "muscle", "edge continuum", "discussion on context-awareness", "regularized inference privacy", "data-driven regularized inference", "inference privacy", "regularized inference", "study of transformer", "transformers for source", "multi-disease chest x-ray", "generalized deep learning", "based collocation method", "dimensional potential problem", "probabilistic states estimation", "physics-informed gaussian proces", "gpus for productive", "optima for reinforcement", "graph computation", "reducing communication", "communication and synchronization", "lake symbol", "island parsing", "symbols for island", "understanding opportunity", "opportunities and challenge", "challenges of geographic", "gender-inclusion in os", "person-specific following robot", "autonomous person-specific", "person-specific", "lyapunov-stable orientation estimator", "network anomaly detection", "estimation from rgb", "meta-learning for domain", "online semi-supervised learning", "bandit feedback", "learning with bandit", "quantum sample", "complexity of quantum", "learnability and complexity", "measuring the digital", "corrupted signal", "localization in wireless", "multiscale fractal analysis", "music-induced emotion recognition", "fractal analysis", "explainable online validation", "practical application", "string space", "optimization over string", "bos", "oil exploration", "learning for ga", "gas and oil", "ga", "models understand instruction", "language models understand", "turking test", "semi-supervised video object", "bert post-pretraining alignment", "multilingual bert post-pretraining", "fine-grained image retrieval", "image retrieval", "exploration of incremental", "fine-grained attribute analysis", "fine-grained attribute", "attribute analysis", "analysis for person", "session type", "imperative session type", "functional and imperative", "imperative session", "crowdsourced ranking", "algorithmic instability", "instabilities in crowdsourced", "coded compressed sensing", "undersampled fourier measurement", "photoacoustic tomography reduce", "barrington plays card", "plays card", "card-based protocol", "complexity of card-based", "ethics in nlp", "epistemic operator", "thinking about causation", "causal language", "critical assessment", "two-stage coding", "z-channel", "two-stage", "supervised sparse coding", "human mesh registration", "implicit surface correspondence", "surface correspondence", "pose and shape", "recommender system based", "telegram social network", "system based", "traits in telegram", "twitter dataset", "analysis of twitter", "twitter and youtube", "youtube during uselection", "review of technology", "distributed computing", "tackling", "hidden automatic sequence", "automatic sequence", "hidden", "architectural element", "survey of architectural", "query complexity", "complexity of adversarial", "tongji university", "filtered batch normalization", "filtered batch", "ultrasound image", "matching in ultrasound", "feature matching", "stochastic gradient descent", "single-objective optimization benefit", "multi-objective gradient descent", "local search", "social visual question", "characterizing dataset", "tinysocial dataset", "span-level processing", "iobe", "library for span-level", "chest x-ray image", "strategies for sentiment", "analysis of latvian", "divergences between time", "differentiable divergence", "machine reading comprehension", "machine reading", "multilingual synthetic question", "cross-lingual reading comprehension", "reasoning in probability", "efficient truncated regression", "statistically efficient truncated", "truncated regression", "adaptive gradient quantization", "gradient quantization", "tree-based transformer", "pre-training for table", "table understanding", "understanding with tree-based", "demonstration", "robot manipulation task", "language-conditioned imitation learning", "decoding brain signal", "brain signal", "learning for decoding", "eye tracking", "event camera", "real-time face", "tracking and blink", "chest x-ray dataset", "large-scale chest x-ray", "x-ray dataset", "linear function approximation", "linear function", "basis function approximation", "curl-free radial basis", "joint named", "transducers solved efficiently", "constraints with concatenation", "concatenation and transducer", "transducers solved", "digital contact tracing", "agent-based model", "model for evaluating", "tag-based music retrieval", "multimodal metric learning", "music retrieval", "learning for tag-based", "multi-object tracking", "multi object tracking", "single-shot multi object", "deep generative lda", "generative lda", "lda", "theory for semiautomatum", "krohn-rhodes theory", "semiautomatum", "krohn-rhode", "all-weather object recognition", "prediction with optimal", "enhancement aided", "tracking data collection", "data collection protocol", "remotely located subject", "eye tracking datum", "intelligent surface assisted", "weighted incremental evolution", "incremental evolution strategy", "instance weighted incremental", "random process", "observations of random", "financial market", "impact of publicly", "information transfer", "non-saturating gan training", "gan training", "divergence minimization", "training as divergence", "mixed-discontinuous galerkin method", "elastic-viscoelastic composite structure", "interpolation in normalizing", "principled interpolation", "energy-efficient autonomous ornithopter", "autonomous ornithopter", "kinodynamic planning", "higher arity vc-dimension", "hypergraph regularity", "arity vc-dimension", "regularity and higher", "generative modeling", "pathological visual question", "falsifiable interpretability research", "interpretability research", "falsifiable interpretability", "generate counterfactual explanation", "few-shot image recognition", "recognition with manifold", "unsupervised cross-lingual adaptation", "cross-lingual adaptation", "tabular gan", "uneven distribution", "gans for uneven", "framework for semi-supervised", "free bipartite graph", "finding efficient domination", "free bipartite", "active graph representation", "deep active graph", "active graph", "hyperbolic geometry", "endowing fasttext", "hypertext", "polar coded repetition", "coded repetition", "polar coded", "dynamic distributed mi", "improved bound", "distributed mi", "information-theoretic feature", "combinatorial multi-bandit problem", "energy management", "allocation of treatment", "fair allocation", "inherent trade-off", "treatment", "pandemic with natural", "robustness of supervised", "typological feature", "prediction of typological", "sigtyp", "shared", "cnn compression", "reordering for cnn", "tensor reordering", "compression", "connected autonomous vehicle", "networks and connected", "learning a kernel", "kernel from context", "attention-based clustering", "cross-modal language model", "knowledge guided deep", "guided deep neural", "geo-spatiotemporal data analysis", "graph trussness", "estimation of graph", "efficient estimation", "trussness", "benchmark for pool-based", "sparse linear classifier", "recovery of sparse", "mixture of response", "optimal subarchitecture extraction", "subarchitecture extraction", "optimal subarchitecture", "bound for image", "optimizing a self-supervised", "brain mri image", "neural networks model-based", "networks model-based brain", "model-based brain tumor", "lightweight inference compilation", "inference compilation", "lightweight inference", "resolution face recognition", "low resolution face", "multi scale identity-preserved", "multi scale", "distributed model predictive", "nonlinear continuous-time system", "neural sequence labeling", "neural sequence", "clinical concept extraction", "effective regularization", "loss-function metalearning", "regularization through loss-function", "metalearning"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "spiking neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "contrastive learning", "depth": [0, 1]}, {"source": "learning", "target": "contrastive", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "model-based reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "model-based reinforcement", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "meta reinforcement learning", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning framework", "depth": [0, 1]}, {"source": "deep learning", "target": "learning framework", "depth": [0, 1]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "deep network", "depth": [0, 1]}, {"source": "network", "target": "spiking neural network", "depth": [0, 1]}, {"source": "network", "target": "beamforming", "depth": [0, 2]}, {"source": "model", "target": "language model", "depth": [0, 0]}, {"source": "model", "target": "state", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "smart grid", "depth": [0, 2]}, {"source": "machine learning", "target": "machine learning method", "depth": [0, 2]}, {"source": "machine learning", "target": "learning method", "depth": [0, 2]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 2]}, {"source": "deep neural network", "target": "adversarial attack", "depth": [0, 1]}, {"source": "language model", "target": "pre-trained language model", "depth": [0, 1]}, {"source": "language model", "target": "pre-trained language", "depth": [0, 2]}, {"source": "language model", "target": "masked language model", "depth": [0, 2]}, {"source": "language model", "target": "dialogue generation", "depth": [0, 2]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "graph embedding", "depth": [0, 1]}, {"source": "graph", "target": "factor graph grammar", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "graph convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "graph convolutional", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "neural network model", "depth": [0, 2]}, {"source": "datum", "target": "data augmentation", "depth": [0, 1]}, {"source": "datum", "target": "unlabeled datum", "depth": [0, 2]}, {"source": "datum", "target": "augmentation", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "path planning", "depth": [0, 2]}, {"source": "analysis", "target": "stochastic analysis", "depth": [0, 2]}, {"source": "analysis", "target": "survey", "depth": [0, 1]}, {"source": "representation learning", "target": "graph representation learning", "depth": [0, 1]}, {"source": "representation learning", "target": "graph representation", "depth": [0, 1]}, {"source": "representation learning", "target": "representation", "depth": [0, 1]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [0, 2]}, {"source": "machine translation", "target": "neural machine translation", "depth": [0, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [0, 1]}, {"source": "machine translation", "target": "translation", "depth": [0, 1]}, {"source": "machine translation", "target": "machine", "depth": [0, 1]}, {"source": "machine translation", "target": "learning for neural", "depth": [0, 2]}, {"source": "graph neural network", "target": "link prediction", "depth": [0, 2]}, {"source": "system", "target": "recommendation system", "depth": [0, 2]}, {"source": "system", "target": "online", "depth": [0, 1]}, {"source": "system", "target": "recommendation", "depth": [0, 1]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 1]}, {"source": "question answering", "target": "visual question", "depth": [1, 1]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "generation", "target": "text generation", "depth": [1, 1]}, {"source": "generation", "target": "survey", "depth": [1, 1]}, {"source": "generation", "target": "story generation", "depth": [1, 2]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "temporal knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph completion", "depth": [1, 3]}, {"source": "federated learning", "target": "speech recognition model", "depth": [1, 3]}, {"source": "federated learning", "target": "training speech recognition", "depth": [1, 3]}, {"source": "federated learning", "target": "cost framework", "depth": [1, 3]}, {"source": "detection", "target": "object detection", "depth": [1, 1]}, {"source": "detection", "target": "anomaly detection", "depth": [1, 1]}, {"source": "detection", "target": "anomaly", "depth": [1, 1]}, {"source": "detection", "target": "object", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "adversarial deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "synthetic news generation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "optimization", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "optimization", "target": "bayesian", "depth": [1, 1]}, {"source": "optimization", "target": "algorithm", "depth": [1, 1]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 1]}, {"source": "natural language", "target": "language processing", "depth": [1, 1]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 1]}, {"source": "task", "target": "tweet", "depth": [1, 1]}, {"source": "task", "target": "shared task", "depth": [1, 1]}, {"source": "task", "target": "identification", "depth": [1, 1]}, {"source": "task", "target": "extracting informative", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "learning for neural", "depth": [1, 2]}, {"source": "neural machine translation", "target": "document-level neural machine", "depth": [1, 2]}, {"source": "deep", "target": "deep generative", "depth": [1, 1]}, {"source": "deep", "target": "segmentation", "depth": [1, 1]}, {"source": "deep", "target": "deep learning method", "depth": [1, 2]}, {"source": "case study", "target": "social medium", "depth": [1, 1]}, {"source": "case study", "target": "study", "depth": [1, 1]}, {"source": "case study", "target": "joint named entity", "depth": [1, 3]}, {"source": "transformer", "target": "generating radiology report", "depth": [1, 3]}, {"source": "transformer", "target": "memory-driven transformer", "depth": [1, 3]}, {"source": "transformer", "target": "radiology report", "depth": [1, 2]}, {"source": "transfer learning", "target": "transfer learning framework", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 1]}, {"source": "transfer learning", "target": "parkinson disease patient", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "adversarial data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "adversarial datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "unsupervised data augmentation", "depth": [1, 3]}, {"source": "representation", "target": "scene representation", "depth": [1, 2]}, {"source": "representation", "target": "object", "depth": [1, 1]}, {"source": "representation", "target": "scene", "depth": [1, 2]}, {"source": "representation", "target": "high-performance graph representation", "depth": [1, 3]}, {"source": "classification", "target": "image classification", "depth": [1, 1]}, {"source": "classification", "target": "image", "depth": [1, 1]}, {"source": "classification", "target": "loss", "depth": [1, 1]}, {"source": "classification", "target": "loss function", "depth": [1, 3]}, {"source": "anomaly detection", "target": "anomaly", "depth": [1, 1]}, {"source": "anomaly detection", "target": "generation for anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "unsupervised anomaly detection", "depth": [1, 3]}, {"source": "language", "target": "embedding", "depth": [1, 1]}, {"source": "language", "target": "description of world", "depth": [1, 3]}, {"source": "language", "target": "language for description", "depth": [1, 3]}, {"source": "survey", "target": "text generation", "depth": [1, 1]}, {"source": "survey", "target": "voice qualifier", "depth": [1, 3]}, {"source": "survey", "target": "acoustic correlate", "depth": [1, 3]}, {"source": "survey", "target": "qualifier", "depth": [1, 3]}, {"source": "method", "target": "wrench measurement", "depth": [1, 3]}, {"source": "method", "target": "method for constraint", "depth": [1, 3]}, {"source": "method", "target": "constraint inference", "depth": [1, 3]}, {"source": "method", "target": "inference using pose", "depth": [1, 3]}, {"source": "image", "target": "image classification", "depth": [1, 1]}, {"source": "image", "target": "image recognition", "depth": [1, 1]}, {"source": "image", "target": "few-shot image", "depth": [1, 2]}, {"source": "efficient", "target": "efficient constrained sampling", "depth": [1, 3]}, {"source": "efficient", "target": "efficient constrained", "depth": [1, 3]}, {"source": "efficient", "target": "mirror-langevin algorithm", "depth": [1, 3]}, {"source": "efficient", "target": "constrained sampling", "depth": [1, 3]}, {"source": "prediction", "target": "motion prediction", "depth": [1, 2]}, {"source": "prediction", "target": "page", "depth": [1, 3]}, {"source": "prediction", "target": "paper length prediction", "depth": [1, 3]}, {"source": "prediction", "target": "length prediction", "depth": [1, 3]}, {"source": "recognition", "target": "image recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "pre-training", "depth": [1, 1]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "video object detection", "depth": [1, 3]}, {"source": "object detection", "target": "video object", "depth": [1, 1]}, {"source": "translation", "target": "machine", "depth": [1, 1]}, {"source": "translation", "target": "speech translation", "depth": [1, 2]}, {"source": "translation", "target": "speech", "depth": [1, 1]}, {"source": "neural machine", "target": "augmentation for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "training for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "multilingual neural machine", "depth": [1, 3]}, {"source": "code", "target": "source code", "depth": [1, 2]}, {"source": "code", "target": "feedback insertion-deletion code", "depth": [1, 3]}, {"source": "code", "target": "insertion-deletion code", "depth": [1, 3]}, {"source": "code", "target": "feedback insertion-deletion", "depth": [1, 3]}, {"source": "segmentation", "target": "image segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "varying human skin", "depth": [1, 3]}, {"source": "algorithm", "target": "efficient constrained sampling", "depth": [1, 3]}, {"source": "algorithm", "target": "efficient constrained", "depth": [1, 3]}, {"source": "algorithm", "target": "mirror-langevin algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "constrained sampling", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech recognition model", "depth": [1, 3]}, {"source": "speech recognition", "target": "training speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "cost framework", "depth": [1, 3]}, {"source": "speech recognition", "target": "recognition model", "depth": [1, 3]}, {"source": "natural language processing", "target": "language processing", "depth": [1, 1]}, {"source": "natural language processing", "target": "nlp", "depth": [1, 1]}, {"source": "natural language processing", "target": "processing", "depth": [1, 1]}, {"source": "machine", "target": "machine translation system", "depth": [1, 2]}, {"source": "machine", "target": "translation system", "depth": [1, 2]}, {"source": "machine", "target": "single machine", "depth": [1, 3]}, {"source": "contrastive learning", "target": "contrastive", "depth": [1, 1]}, {"source": "contrastive learning", "target": "hard negative", "depth": [1, 2]}, {"source": "contrastive learning", "target": "mutual information maximization", "depth": [1, 3]}, {"source": "contrastive learning", "target": "cross-domain sentiment classification", "depth": [1, 3]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "roman urdu text", "depth": [1, 3]}, {"source": "social medium", "target": "comparative study", "depth": [1, 2]}, {"source": "text", "target": "text summarization", "depth": [1, 2]}, {"source": "text", "target": "summarization", "depth": [1, 1]}, {"source": "text", "target": "text datum", "depth": [1, 2]}, {"source": "text", "target": "analysis of lime", "depth": [1, 3]}, {"source": "control", "target": "optimal control", "depth": [1, 1]}, {"source": "control", "target": "state", "depth": [1, 1]}, {"source": "control", "target": "simulation study", "depth": [1, 3]}, {"source": "control", "target": "study on turnpike", "depth": [1, 3]}, {"source": "problem", "target": "stream of problem", "depth": [1, 3]}, {"source": "problem", "target": "security", "depth": [1, 2]}, {"source": "problem", "target": "stream", "depth": [1, 2]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "graph embedding", "depth": [1, 1]}, {"source": "embedding", "target": "euclidean space", "depth": [1, 3]}, {"source": "evaluation", "target": "f-measure to roc", "depth": [1, 3]}, {"source": "evaluation", "target": "recall and f-measure", "depth": [1, 3]}, {"source": "evaluation", "target": "markedness and correlation", "depth": [1, 3]}, {"source": "evaluation", "target": "informedness", "depth": [1, 3]}, {"source": "language understanding", "target": "spoken language understanding", "depth": [1, 1]}, {"source": "language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "language understanding", "target": "natural language understanding", "depth": [1, 2]}, {"source": "function", "target": "isabelle function", "depth": [1, 3]}, {"source": "function", "target": "lucas-interpretation on isabelle", "depth": [1, 3]}, {"source": "function", "target": "isabelle", "depth": [1, 2]}, {"source": "function", "target": "lucas-interpretation", "depth": [1, 3]}, {"source": "adversarial network", "target": "varying human skin", "depth": [1, 3]}, {"source": "adversarial network", "target": "human skin tone", "depth": [1, 3]}, {"source": "adversarial network", "target": "unsupervised approach", "depth": [1, 3]}, {"source": "adversarial network", "target": "approach towards varying", "depth": [1, 3]}, {"source": "feature selection", "target": "information-theoretic feature selection", "depth": [1, 3]}, {"source": "feature selection", "target": "decomposition and submodularity", "depth": [1, 3]}, {"source": "feature selection", "target": "selection via tensor", "depth": [1, 3]}, {"source": "feature selection", "target": "tensor decomposition", "depth": [1, 1]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "adversarial deep reinforcement", "depth": [1, 3]}, {"source": "generative adversarial", "target": "lightweight generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "text-guided image manipulation", "depth": [1, 3]}, {"source": "generative adversarial", "target": "image manipulation", "depth": [1, 3]}, {"source": "generative adversarial", "target": "conditional generative adversarial", "depth": [1, 3]}, {"source": "challenge", "target": "challenges and opportunity", "depth": [1, 2]}, {"source": "challenge", "target": "opportunity", "depth": [1, 3]}, {"source": "challenge", "target": "image extreme inpainting", "depth": [1, 3]}, {"source": "challenge", "target": "challenge on image", "depth": [1, 3]}, {"source": "training", "target": "adversarial training", "depth": [1, 1]}, {"source": "training", "target": "robust", "depth": [1, 1]}, {"source": "training", "target": "progressive bert training", "depth": [1, 3]}, {"source": "training", "target": "bert training", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "black-box adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "detecting adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "neural networks serve", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "fast", "target": "fast and slow", "depth": [1, 2]}, {"source": "fast", "target": "slow decision making", "depth": [1, 3]}, {"source": "fast", "target": "decision making", "depth": [1, 1]}, {"source": "fast", "target": "slow decision", "depth": [1, 3]}, {"source": "point cloud", "target": "cloud", "depth": [1, 1]}, {"source": "point cloud", "target": "frameworkfor reproducible deep", "depth": [1, 3]}, {"source": "point cloud", "target": "reproducible deep learning", "depth": [1, 3]}, {"source": "voice conversion", "target": "voice conversion challenge", "depth": [1, 2]}, {"source": "voice conversion", "target": "conversion challenge", "depth": [1, 2]}, {"source": "voice conversion", "target": "variational autoencoder", "depth": [1, 1]}, {"source": "approach", "target": "sensor fusion approach", "depth": [1, 3]}, {"source": "approach", "target": "sensor fusion", "depth": [1, 2]}, {"source": "approach", "target": "fusion approach", "depth": [1, 3]}, {"source": "approach", "target": "viral-fusion", "depth": [1, 3]}, {"source": "approximation", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "approximation", "target": "kernelized bandit", "depth": [1, 3]}, {"source": "approximation", "target": "methods for kernelized", "depth": [1, 3]}, {"source": "approximation", "target": "approximation method", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "convolutional recurrent neural", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "long short term", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "short term memory", "depth": [1, 3]}, {"source": "tree", "target": "decision tree", "depth": [1, 1]}, {"source": "tree", "target": "decision", "depth": [1, 2]}, {"source": "tree", "target": "probability tree", "depth": [1, 3]}, {"source": "tree", "target": "causal reasoning", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "detection and pose", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 3]}, {"source": "word embedding", "target": "multiclass debiasing method", "depth": [1, 3]}, {"source": "word embedding", "target": "thy algorithm shalt", "depth": [1, 3]}, {"source": "word embedding", "target": "bear false witness", "depth": [1, 3]}, {"source": "differential equation", "target": "ordinary differential equation", "depth": [1, 2]}, {"source": "differential equation", "target": "neural ordinary differential", "depth": [1, 2]}, {"source": "differential equation", "target": "stochastic differential equation", "depth": [1, 2]}, {"source": "differential equation", "target": "partial differential equation", "depth": [1, 2]}, {"source": "text classification", "target": "weak supervision", "depth": [1, 2]}, {"source": "text classification", "target": "cross-lingual text classification", "depth": [1, 3]}, {"source": "text classification", "target": "benchmarking cross-lingual text", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "tweet", "depth": [1, 1]}, {"source": "sentiment analysis", "target": "aspect-based sentiment analysis", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "sentiment", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "latvian tweet", "depth": [1, 3]}, {"source": "bandit", "target": "thresholded lasso bandit", "depth": [1, 3]}, {"source": "bandit", "target": "lasso bandit", "depth": [1, 3]}, {"source": "bandit", "target": "thresholded lasso", "depth": [1, 3]}, {"source": "clustering", "target": "learning multi-layer graph", "depth": [1, 3]}, {"source": "clustering", "target": "representation for clustering", "depth": [1, 3]}, {"source": "clustering", "target": "multi-layer graph", "depth": [1, 3]}, {"source": "clustering", "target": "common representation", "depth": [1, 3]}, {"source": "feature", "target": "speech", "depth": [1, 1]}, {"source": "feature", "target": "learn robust feature", "depth": [1, 3]}, {"source": "feature", "target": "robust feature", "depth": [1, 3]}, {"source": "dataset", "target": "patterns count-based label", "depth": [1, 3]}, {"source": "dataset", "target": "labels for dataset", "depth": [1, 3]}, {"source": "dataset", "target": "count-based label", "depth": [1, 3]}, {"source": "dataset", "target": "label", "depth": [1, 2]}, {"source": "generalization", "target": "semantic parsing", "depth": [1, 1]}, {"source": "generalization", "target": "domain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "structure", "target": "concurrent process history", "depth": [1, 3]}, {"source": "structure", "target": "process history", "depth": [1, 3]}, {"source": "structure", "target": "structure of concurrent", "depth": [1, 3]}, {"source": "structure", "target": "concurrent proces", "depth": [1, 3]}, {"source": "graph embedding", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "graph embedding", "target": "residual learning", "depth": [1, 3]}, {"source": "graph embedding", "target": "embedding with atrous", "depth": [1, 3]}, {"source": "graph embedding", "target": "atrous convolution", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 2]}, {"source": "social network", "target": "ldbc social network", "depth": [1, 3]}, {"source": "social network", "target": "social network graph", "depth": [1, 3]}, {"source": "application", "target": "nlp application", "depth": [1, 3]}, {"source": "application", "target": "cloud-assisted middleware-based iot", "depth": [1, 3]}, {"source": "application", "target": "enhancement of non-functional", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "artificial intelligence symposium", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "upper-rhine artificial intelligence", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "research impact", "depth": [1, 3]}, {"source": "relation extraction", "target": "semi-supervised relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "distantly-supervised relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "consistent evaluation", "depth": [1, 3]}, {"source": "relation extraction", "target": "accurate and consistent", "depth": [1, 3]}, {"source": "fairness", "target": "optimal transport", "depth": [1, 1]}, {"source": "fairness", "target": "fairness for edge", "depth": [1, 3]}, {"source": "fairness", "target": "edge prediction", "depth": [1, 3]}, {"source": "perspective", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "perspective", "target": "combinatorial", "depth": [1, 1]}, {"source": "perspective", "target": "minimal code", "depth": [1, 3]}, {"source": "perspective", "target": "perspectives on minimal", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo tree search", "depth": [1, 3]}, {"source": "monte carlo", "target": "monte carlo tree", "depth": [1, 3]}, {"source": "monte carlo", "target": "tree search", "depth": [1, 3]}, {"source": "robust", "target": "robust training", "depth": [1, 3]}, {"source": "robust", "target": "learn robust feature", "depth": [1, 3]}, {"source": "robust", "target": "robust feature", "depth": [1, 3]}, {"source": "robust", "target": "features via orthogonal", "depth": [1, 3]}, {"source": "spiking neural network", "target": "superposition spiking neural", "depth": [1, 3]}, {"source": "spiking neural network", "target": "quantum superposition spiking", "depth": [1, 3]}, {"source": "spiking neural network", "target": "superposition spiking", "depth": [1, 3]}, {"source": "spiking neural network", "target": "quantum superposition", "depth": [1, 3]}, {"source": "architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture", "target": "search", "depth": [1, 1]}, {"source": "architecture", "target": "supernet", "depth": [1, 3]}, {"source": "graph representation", "target": "graph representation learning", "depth": [1, 1]}, {"source": "graph representation", "target": "high-performance graph representation", "depth": [1, 3]}, {"source": "graph representation", "target": "near-optimal high-performance graph", "depth": [1, 3]}, {"source": "graph representation", "target": "high-performance graph", "depth": [1, 3]}, {"source": "space", "target": "euclidean space", "depth": [1, 3]}, {"source": "space", "target": "embedding of hierarchical", "depth": [1, 3]}, {"source": "space", "target": "hierarchical structure", "depth": [1, 3]}, {"source": "space", "target": "structure in euclidean", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "image segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "image segmentation", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "motion planning", "target": "motion", "depth": [1, 2]}, {"source": "motion planning", "target": "planning", "depth": [1, 1]}, {"source": "motion planning", "target": "explainable multi-robot motion", "depth": [1, 3]}, {"source": "motion planning", "target": "multi-robot motion planning", "depth": [1, 3]}, {"source": "language processing", "target": "nlp", "depth": [1, 1]}, {"source": "language processing", "target": "processing", "depth": [1, 1]}, {"source": "language processing", "target": "cross-lingual natural language", "depth": [1, 3]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 1]}, {"source": "attention network", "target": "graph attention", "depth": [1, 1]}, {"source": "attention network", "target": "ris-assisted haps backhauling", "depth": [1, 3]}, {"source": "attention network", "target": "full-duplex ris-assisted hap", "depth": [1, 3]}, {"source": "extended version", "target": "extended", "depth": [1, 1]}, {"source": "extended version", "target": "version", "depth": [1, 2]}, {"source": "extended version", "target": "equivalence for assisted", "depth": [1, 3]}, {"source": "extended version", "target": "assisted grading", "depth": [1, 3]}, {"source": "speech", "target": "speech translation", "depth": [1, 2]}, {"source": "speech", "target": "adaptive feature selection", "depth": [1, 3]}, {"source": "speech", "target": "adaptive feature", "depth": [1, 2]}, {"source": "speech", "target": "children speech", "depth": [1, 3]}, {"source": "blockchain", "target": "state sharding model", "depth": [1, 3]}, {"source": "blockchain", "target": "state sharding", "depth": [1, 3]}, {"source": "blockchain", "target": "sharding model", "depth": [1, 3]}, {"source": "blockchain", "target": "state", "depth": [1, 1]}, {"source": "game", "target": "zero-sum stochastic game", "depth": [1, 3]}, {"source": "game", "target": "fictitious play", "depth": [1, 2]}, {"source": "game", "target": "stochastic game", "depth": [1, 2]}, {"source": "attention", "target": "channel parallel sampling", "depth": [1, 3]}, {"source": "attention", "target": "groups of channel", "depth": [1, 3]}, {"source": "attention", "target": "sampling with attention", "depth": [1, 3]}, {"source": "graph convolutional", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "graph convolutional", "target": "graph convolutional neural", "depth": [1, 2]}, {"source": "graph convolutional", "target": "dynamic graph convolutional", "depth": [1, 3]}, {"source": "inference", "target": "bound membership inference", "depth": [1, 3]}, {"source": "inference", "target": "differentially private learning", "depth": [1, 3]}, {"source": "inference", "target": "membership inference", "depth": [1, 3]}, {"source": "inference", "target": "private learning", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 1]}, {"source": "variational autoencoder", "target": "voice conversion challenge", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "conversion challenge", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "classifier", "target": "network classifiers based", "depth": [1, 3]}, {"source": "classifier", "target": "social learning", "depth": [1, 2]}, {"source": "classifier", "target": "classifiers based", "depth": [1, 3]}, {"source": "learning framework", "target": "deep learning framework", "depth": [1, 1]}, {"source": "learning framework", "target": "earnings call", "depth": [1, 3]}, {"source": "learning framework", "target": "framework for measuring", "depth": [1, 3]}, {"source": "computing", "target": "productive performance", "depth": [1, 3]}, {"source": "computing", "target": "systolic computing", "depth": [1, 3]}, {"source": "computing", "target": "computing on gpu", "depth": [1, 3]}, {"source": "active learning", "target": "pretext-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "pal", "depth": [1, 3]}, {"source": "active learning", "target": "pool-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "aldataset", "depth": [1, 3]}, {"source": "logic", "target": "hol", "depth": [1, 1]}, {"source": "logic", "target": "teaching logic", "depth": [1, 3]}, {"source": "logic", "target": "isabelle", "depth": [1, 2]}, {"source": "logic", "target": "meta-language for teaching", "depth": [1, 3]}, {"source": "matrix", "target": "matrices are underrated", "depth": [1, 3]}, {"source": "matrix", "target": "correspondence matrix", "depth": [1, 3]}, {"source": "matrix", "target": "correspondence", "depth": [1, 3]}, {"source": "sampling", "target": "thompson sampling", "depth": [1, 3]}, {"source": "sampling", "target": "marginalised gaussian process", "depth": [1, 3]}, {"source": "sampling", "target": "nested sampling", "depth": [1, 3]}, {"source": "sampling", "target": "gaussian process", "depth": [1, 2]}, {"source": "neural architecture", "target": "search", "depth": [1, 1]}, {"source": "neural architecture", "target": "joint neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "autotuned data-parallel training", "depth": [1, 3]}, {"source": "image classification", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image", "depth": [1, 2]}, {"source": "image classification", "target": "loss function", "depth": [1, 3]}, {"source": "image classification", "target": "function for image", "depth": [1, 3]}, {"source": "loss", "target": "loss function", "depth": [1, 3]}, {"source": "loss", "target": "function for image", "depth": [1, 3]}, {"source": "loss", "target": "performance guarantee", "depth": [1, 3]}, {"source": "neural architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture search", "target": "search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "based physics-informed neural", "depth": [1, 3]}, {"source": "style transfer", "target": "text style transfer", "depth": [1, 2]}, {"source": "style transfer", "target": "text style", "depth": [1, 2]}, {"source": "style transfer", "target": "unsupervised text style", "depth": [1, 2]}, {"source": "style transfer", "target": "artists style transfer", "depth": [1, 3]}, {"source": "differentially private", "target": "regularized mahalanobis metric", "depth": [1, 3]}, {"source": "differentially private", "target": "differentially private text", "depth": [1, 3]}, {"source": "differentially private", "target": "private text perturbation", "depth": [1, 3]}, {"source": "optimal control", "target": "simulation study", "depth": [1, 3]}, {"source": "optimal control", "target": "study on turnpike", "depth": [1, 3]}, {"source": "optimal control", "target": "turnpikes in stochastic", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "bayesian", "target": "scalable bayesian learning", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian learning", "depth": [1, 3]}, {"source": "bayesian", "target": "learning of causal", "depth": [1, 3]}, {"source": "framework", "target": "high density anomaly", "depth": [1, 3]}, {"source": "framework", "target": "density anomaly", "depth": [1, 3]}, {"source": "framework", "target": "detection of high", "depth": [1, 3]}, {"source": "framework", "target": "high density", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "long financial report", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "conditional variational autoencoder", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "generating long financial", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "dynamic graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "dynamic graph", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "action recognition", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "lidar semantic segmentation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "adaptation in lidar", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "adaptation", "depth": [1, 1]}, {"source": "differential privacy", "target": "privacy", "depth": [1, 1]}, {"source": "differential privacy", "target": "local differential privacy", "depth": [1, 2]}, {"source": "differential privacy", "target": "application-agnostic data sharing", "depth": [1, 3]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "joint named entity", "depth": [1, 3]}, {"source": "named entity recognition", "target": "study of joint", "depth": [1, 3]}, {"source": "attack", "target": "backdoor attack", "depth": [1, 2]}, {"source": "attack", "target": "improve captcha robustness", "depth": [1, 3]}, {"source": "attack", "target": "bot attack", "depth": [1, 3]}, {"source": "attack", "target": "improve captcha", "depth": [1, 3]}, {"source": "multi-task learning", "target": "speech enhancement aided", "depth": [1, 3]}, {"source": "multi-task learning", "target": "voice activity detection", "depth": [1, 2]}, {"source": "multi-task learning", "target": "speech enhancement", "depth": [1, 1]}, {"source": "environment", "target": "controller for escaping", "depth": [1, 3]}, {"source": "environment", "target": "escaping trap", "depth": [1, 3]}, {"source": "environment", "target": "tampc", "depth": [1, 3]}, {"source": "action recognition", "target": "human action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "attention-augmented graph convolutional", "depth": [1, 3]}, {"source": "transfer", "target": "knowledge transfer", "depth": [1, 1]}, {"source": "transfer", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "transfer", "target": "perspective on transfer", "depth": [1, 3]}, {"source": "transfer", "target": "combinatorial", "depth": [1, 1]}, {"source": "online learning", "target": "projection-free online learning", "depth": [1, 3]}, {"source": "online learning", "target": "strongly convex", "depth": [1, 2]}, {"source": "online learning", "target": "projection-free online", "depth": [1, 3]}, {"source": "online learning", "target": "lipschitz continuity", "depth": [1, 3]}, {"source": "action", "target": "combinatorial action", "depth": [1, 3]}, {"source": "action", "target": "vehicle routing", "depth": [1, 2]}, {"source": "action", "target": "learning with combinatorial", "depth": [1, 3]}, {"source": "decision tree", "target": "decision", "depth": [1, 2]}, {"source": "decision tree", "target": "online decision tree", "depth": [1, 3]}, {"source": "decision tree", "target": "online decision", "depth": [1, 2]}, {"source": "decision tree", "target": "trees with fairness", "depth": [1, 3]}, {"source": "contrastive", "target": "learning with adversarial", "depth": [1, 3]}, {"source": "contrastive", "target": "learning of unsupervised", "depth": [1, 3]}, {"source": "contrastive", "target": "cloud", "depth": [1, 1]}, {"source": "communication", "target": "strategic communication", "depth": [1, 3]}, {"source": "communication", "target": "multiway relay communication", "depth": [1, 3]}, {"source": "communication", "target": "fundamental issue", "depth": [1, 3]}, {"source": "simulation", "target": "simulation study", "depth": [1, 3]}, {"source": "simulation", "target": "study on turnpike", "depth": [1, 3]}, {"source": "simulation", "target": "turnpikes in stochastic", "depth": [1, 3]}, {"source": "constraint", "target": "power constraint", "depth": [1, 3]}, {"source": "constraint", "target": "identification over channel", "depth": [1, 3]}, {"source": "constraint", "target": "channels with power", "depth": [1, 3]}, {"source": "constraint", "target": "deterministic identification", "depth": [1, 3]}, {"source": "information", "target": "sell hard information", "depth": [1, 3]}, {"source": "information", "target": "hard information", "depth": [1, 3]}, {"source": "information", "target": "sell hard", "depth": [1, 3]}, {"source": "time series", "target": "series", "depth": [1, 3]}, {"source": "time series", "target": "time series forecasting", "depth": [1, 2]}, {"source": "time series", "target": "series forecasting", "depth": [1, 3]}, {"source": "text generation", "target": "continuous and discrete", "depth": [1, 3]}, {"source": "text generation", "target": "discrete space", "depth": [1, 2]}, {"source": "text generation", "target": "spaces for text", "depth": [1, 3]}, {"source": "text generation", "target": "collaborative training", "depth": [1, 3]}, {"source": "summarization", "target": "text summarization", "depth": [1, 2]}, {"source": "summarization", "target": "edit-based unsupervised summarization", "depth": [1, 3]}, {"source": "summarization", "target": "unsupervised summarization", "depth": [1, 3]}, {"source": "adversarial training", "target": "overfitting or underfitting", "depth": [1, 3]}, {"source": "adversarial training", "target": "underfitting", "depth": [1, 3]}, {"source": "adversarial training", "target": "understand robustness drop", "depth": [1, 3]}, {"source": "adversarial training", "target": "robustness drop", "depth": [1, 3]}, {"source": "graph attention network", "target": "graph attention", "depth": [1, 1]}, {"source": "graph attention network", "target": "multimodal language sequence", "depth": [1, 3]}, {"source": "graph attention network", "target": "temporal graph attention", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "fuzzy query attention", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "multi-agent trajectory prediction", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "query attention", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "prediction with fuzzy", "depth": [1, 3]}, {"source": "state", "target": "state sharding model", "depth": [1, 3]}, {"source": "state", "target": "state sharding", "depth": [1, 3]}, {"source": "state", "target": "sharding model", "depth": [1, 3]}, {"source": "state", "target": "sharding", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "medical image", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "medical image", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "medical image", "target": "mixed supervision", "depth": [1, 3]}, {"source": "decision making", "target": "making", "depth": [1, 3]}, {"source": "decision making", "target": "slow decision making", "depth": [1, 3]}, {"source": "decision making", "target": "fast and slow", "depth": [1, 2]}, {"source": "decomposition", "target": "matrix decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "graph-regularization for matrix", "depth": [1, 3]}, {"source": "decomposition", "target": "learnable graph-regularization", "depth": [1, 3]}, {"source": "identification", "target": "deterministic identification", "depth": [1, 3]}, {"source": "identification", "target": "channel", "depth": [1, 1]}, {"source": "identification", "target": "identification of informative", "depth": [1, 3]}, {"source": "identification", "target": "english tweet", "depth": [1, 3]}, {"source": "autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "autoencoder", "target": "dirichlet graph variational", "depth": [1, 3]}, {"source": "autoencoder", "target": "graph variational", "depth": [1, 3]}, {"source": "recommendation", "target": "neighbor-aware graph attention", "depth": [1, 3]}, {"source": "recommendation", "target": "network for recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "neighbor-aware graph", "depth": [1, 3]}, {"source": "recommendation", "target": "online recommendation system", "depth": [1, 3]}, {"source": "abstractive summarization", "target": "neural abstractive summarization", "depth": [1, 2]}, {"source": "abstractive summarization", "target": "guided neural abstractive", "depth": [1, 3]}, {"source": "abstractive summarization", "target": "general framework", "depth": [1, 2]}, {"source": "abstractive summarization", "target": "framework for guided", "depth": [1, 3]}, {"source": "graph attention", "target": "ris-assisted haps backhauling", "depth": [1, 3]}, {"source": "graph attention", "target": "full-duplex ris-assisted hap", "depth": [1, 3]}, {"source": "graph attention", "target": "haps backhauling", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "imbalanced domain adaptation", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "fair knowledge transfer", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "fair knowledge", "depth": [1, 3]}, {"source": "natural language inference", "target": "trainable natural logic", "depth": [1, 3]}, {"source": "natural language inference", "target": "logic theorem prover", "depth": [1, 3]}, {"source": "natural language inference", "target": "natural logic theorem", "depth": [1, 3]}, {"source": "language inference", "target": "trainable natural logic", "depth": [1, 3]}, {"source": "language inference", "target": "logic theorem prover", "depth": [1, 3]}, {"source": "language inference", "target": "natural logic theorem", "depth": [1, 3]}, {"source": "language inference", "target": "learning as abduction", "depth": [1, 3]}, {"source": "policy", "target": "policy optimization", "depth": [1, 1]}, {"source": "policy", "target": "optimization with multiple", "depth": [1, 3]}, {"source": "policy", "target": "multiple optima", "depth": [1, 3]}, {"source": "object", "target": "scene representation", "depth": [1, 2]}, {"source": "object", "target": "object recognition", "depth": [1, 1]}, {"source": "object", "target": "quantizing neural", "depth": [1, 3]}, {"source": "online", "target": "online recommendation system", "depth": [1, 3]}, {"source": "online", "target": "recommendation system", "depth": [1, 2]}, {"source": "online", "target": "online recommendation", "depth": [1, 3]}, {"source": "online", "target": "regret in online", "depth": [1, 3]}, {"source": "deep network", "target": "complex dynamics forecasting", "depth": [1, 3]}, {"source": "deep network", "target": "augmenting physical model", "depth": [1, 3]}, {"source": "deep network", "target": "dynamics forecasting", "depth": [1, 3]}, {"source": "learn", "target": "learning visual representation", "depth": [1, 3]}, {"source": "learn", "target": "human interaction", "depth": [1, 3]}, {"source": "learn", "target": "muscle", "depth": [1, 3]}, {"source": "learn", "target": "visual representation", "depth": [1, 2]}, {"source": "cloud", "target": "learning of unsupervised", "depth": [1, 3]}, {"source": "cloud", "target": "edge continuum", "depth": [1, 3]}, {"source": "cloud", "target": "discussion on context-awareness", "depth": [1, 3]}, {"source": "search", "target": "supernet", "depth": [1, 3]}, {"source": "privacy", "target": "regularized inference privacy", "depth": [1, 3]}, {"source": "privacy", "target": "data-driven regularized inference", "depth": [1, 3]}, {"source": "privacy", "target": "inference privacy", "depth": [1, 3]}, {"source": "privacy", "target": "regularized inference", "depth": [1, 3]}, {"source": "empirical study", "target": "source code", "depth": [1, 2]}, {"source": "empirical study", "target": "study of transformer", "depth": [1, 3]}, {"source": "empirical study", "target": "transformers for source", "depth": [1, 3]}, {"source": "deep learning model", "target": "learning model", "depth": [1, 1]}, {"source": "deep learning model", "target": "multi-disease chest x-ray", "depth": [1, 3]}, {"source": "deep learning model", "target": "generalized deep learning", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 2]}, {"source": "deep learning based", "target": "based collocation method", "depth": [1, 3]}, {"source": "deep learning based", "target": "dimensional potential problem", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "probabilistic states estimation", "depth": [1, 3]}, {"source": "gaussian proces", "target": "physics-informed gaussian proces", "depth": [1, 3]}, {"source": "performance", "target": "productive performance", "depth": [1, 3]}, {"source": "performance", "target": "systolic computing", "depth": [1, 3]}, {"source": "performance", "target": "computing on gpu", "depth": [1, 3]}, {"source": "performance", "target": "gpus for productive", "depth": [1, 3]}, {"source": "policy optimization", "target": "optimization with multiple", "depth": [1, 3]}, {"source": "policy optimization", "target": "multiple optima", "depth": [1, 3]}, {"source": "policy optimization", "target": "optima for reinforcement", "depth": [1, 3]}, {"source": "computation", "target": "graph computation", "depth": [1, 3]}, {"source": "computation", "target": "reducing communication", "depth": [1, 3]}, {"source": "computation", "target": "communication and synchronization", "depth": [1, 3]}, {"source": "parsing", "target": "lake symbol", "depth": [1, 3]}, {"source": "parsing", "target": "island parsing", "depth": [1, 3]}, {"source": "parsing", "target": "symbols for island", "depth": [1, 3]}, {"source": "understanding", "target": "understanding opportunity", "depth": [1, 3]}, {"source": "understanding", "target": "opportunities and challenge", "depth": [1, 3]}, {"source": "understanding", "target": "challenges of geographic", "depth": [1, 3]}, {"source": "understanding", "target": "gender-inclusion in os", "depth": [1, 3]}, {"source": "robot", "target": "person-specific following robot", "depth": [1, 3]}, {"source": "robot", "target": "autonomous person-specific", "depth": [1, 3]}, {"source": "robot", "target": "person-specific", "depth": [1, 3]}, {"source": "robot", "target": "lyapunov-stable orientation estimator", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative", "depth": [1, 1]}, {"source": "generative model", "target": "network anomaly detection", "depth": [1, 3]}, {"source": "human", "target": "human pose estimation", "depth": [1, 2]}, {"source": "human", "target": "human pose", "depth": [1, 2]}, {"source": "human", "target": "estimation from rgb", "depth": [1, 3]}, {"source": "semantic parsing", "target": "domain generalization", "depth": [1, 3]}, {"source": "semantic parsing", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "semantic parsing", "target": "meta-learning for domain", "depth": [1, 3]}, {"source": "semantic parsing", "target": "domain", "depth": [1, 1]}, {"source": "semi-supervised learning", "target": "online semi-supervised learning", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "bandit feedback", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "learning with bandit", "depth": [1, 3]}, {"source": "complexity", "target": "quantum sample", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of quantum", "depth": [1, 3]}, {"source": "complexity", "target": "learnability and complexity", "depth": [1, 3]}, {"source": "deep learning framework", "target": "earnings call", "depth": [1, 3]}, {"source": "deep learning framework", "target": "framework for measuring", "depth": [1, 3]}, {"source": "deep learning framework", "target": "measuring the digital", "depth": [1, 3]}, {"source": "signal", "target": "corrupted signal", "depth": [1, 3]}, {"source": "signal", "target": "localization in wireless", "depth": [1, 3]}, {"source": "signal", "target": "wireless network", "depth": [1, 2]}, {"source": "emotion recognition", "target": "speech emotion recognition", "depth": [1, 2]}, {"source": "emotion recognition", "target": "multiscale fractal analysis", "depth": [1, 3]}, {"source": "emotion recognition", "target": "music-induced emotion recognition", "depth": [1, 3]}, {"source": "emotion recognition", "target": "fractal analysis", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "explainable online validation", "depth": [1, 3]}, {"source": "learning model", "target": "practical application", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "string space", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "optimization over string", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "bos", "depth": [1, 3]}, {"source": "exploration", "target": "oil exploration", "depth": [1, 3]}, {"source": "exploration", "target": "learning for ga", "depth": [1, 3]}, {"source": "exploration", "target": "gas and oil", "depth": [1, 3]}, {"source": "exploration", "target": "ga", "depth": [1, 3]}, {"source": "test", "target": "models understand instruction", "depth": [1, 3]}, {"source": "test", "target": "language models understand", "depth": [1, 3]}, {"source": "test", "target": "turking test", "depth": [1, 3]}, {"source": "video object", "target": "video object segmentation", "depth": [1, 2]}, {"source": "video object", "target": "object segmentation", "depth": [1, 2]}, {"source": "video object", "target": "video object detection", "depth": [1, 3]}, {"source": "video object", "target": "semi-supervised video object", "depth": [1, 3]}, {"source": "quantum", "target": "quantum sample", "depth": [1, 3]}, {"source": "quantum", "target": "complexity of quantum", "depth": [1, 3]}, {"source": "quantum", "target": "learnability and complexity", "depth": [1, 3]}, {"source": "bert", "target": "multilingual bert", "depth": [1, 2]}, {"source": "bert", "target": "bert post-pretraining alignment", "depth": [1, 3]}, {"source": "bert", "target": "multilingual bert post-pretraining", "depth": [1, 3]}, {"source": "retrieval", "target": "fine-grained image retrieval", "depth": [1, 3]}, {"source": "retrieval", "target": "image retrieval", "depth": [1, 3]}, {"source": "retrieval", "target": "exploration of incremental", "depth": [1, 3]}, {"source": "synthesis", "target": "fine-grained attribute analysis", "depth": [1, 3]}, {"source": "synthesis", "target": "fine-grained attribute", "depth": [1, 3]}, {"source": "synthesis", "target": "attribute analysis", "depth": [1, 3]}, {"source": "synthesis", "target": "analysis for person", "depth": [1, 3]}, {"source": "type", "target": "session type", "depth": [1, 3]}, {"source": "type", "target": "imperative session type", "depth": [1, 3]}, {"source": "type", "target": "functional and imperative", "depth": [1, 3]}, {"source": "type", "target": "imperative session", "depth": [1, 3]}, {"source": "ranking", "target": "crowdsourced ranking", "depth": [1, 3]}, {"source": "ranking", "target": "algorithmic instability", "depth": [1, 3]}, {"source": "ranking", "target": "instabilities in crowdsourced", "depth": [1, 3]}, {"source": "compressed sensing", "target": "coded compressed sensing", "depth": [1, 3]}, {"source": "compressed sensing", "target": "undersampled fourier measurement", "depth": [1, 3]}, {"source": "compressed sensing", "target": "photoacoustic tomography reduce", "depth": [1, 3]}, {"source": "protocol", "target": "barrington plays card", "depth": [1, 3]}, {"source": "protocol", "target": "plays card", "depth": [1, 3]}, {"source": "protocol", "target": "card-based protocol", "depth": [1, 3]}, {"source": "protocol", "target": "complexity of card-based", "depth": [1, 3]}, {"source": "study", "target": "source code", "depth": [1, 2]}, {"source": "study", "target": "study of transformer", "depth": [1, 3]}, {"source": "study", "target": "transformers for source", "depth": [1, 3]}, {"source": "study", "target": "ethics in nlp", "depth": [1, 3]}, {"source": "extended", "target": "version", "depth": [1, 2]}, {"source": "extended", "target": "equivalence for assisted", "depth": [1, 3]}, {"source": "extended", "target": "assisted grading", "depth": [1, 3]}, {"source": "feedback", "target": "feedback insertion-deletion code", "depth": [1, 3]}, {"source": "feedback", "target": "insertion-deletion code", "depth": [1, 3]}, {"source": "feedback", "target": "feedback insertion-deletion", "depth": [1, 3]}, {"source": "entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "entity recognition", "target": "joint named entity", "depth": [1, 3]}, {"source": "entity recognition", "target": "study of joint", "depth": [1, 3]}, {"source": "causal", "target": "epistemic operator", "depth": [1, 3]}, {"source": "causal", "target": "thinking about causation", "depth": [1, 3]}, {"source": "causal", "target": "causal language", "depth": [1, 3]}, {"source": "alignment", "target": "entity alignment", "depth": [1, 2]}, {"source": "alignment", "target": "critical assessment", "depth": [1, 3]}, {"source": "alignment", "target": "assessment", "depth": [1, 1]}, {"source": "optimal transport", "target": "transport", "depth": [1, 2]}, {"source": "optimal transport", "target": "fairness for edge", "depth": [1, 3]}, {"source": "optimal transport", "target": "edge prediction", "depth": [1, 3]}, {"source": "coding", "target": "two-stage coding", "depth": [1, 3]}, {"source": "coding", "target": "z-channel", "depth": [1, 3]}, {"source": "coding", "target": "two-stage", "depth": [1, 3]}, {"source": "coding", "target": "supervised sparse coding", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "human mesh registration", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "implicit surface correspondence", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "surface correspondence", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "pose and shape", "depth": [1, 3]}, {"source": "recommender system", "target": "recommender system based", "depth": [1, 3]}, {"source": "recommender system", "target": "telegram social network", "depth": [1, 3]}, {"source": "recommender system", "target": "system based", "depth": [1, 3]}, {"source": "recommender system", "target": "traits in telegram", "depth": [1, 3]}, {"source": "twitter", "target": "twitter dataset", "depth": [1, 3]}, {"source": "twitter", "target": "analysis of twitter", "depth": [1, 3]}, {"source": "twitter", "target": "twitter and youtube", "depth": [1, 3]}, {"source": "twitter", "target": "youtube during uselection", "depth": [1, 3]}, {"source": "review", "target": "review of technology", "depth": [1, 3]}, {"source": "review", "target": "distributed computing", "depth": [1, 3]}, {"source": "review", "target": "tackling", "depth": [1, 3]}, {"source": "review", "target": "technology", "depth": [1, 2]}, {"source": "sequence", "target": "hidden automatic sequence", "depth": [1, 3]}, {"source": "sequence", "target": "automatic sequence", "depth": [1, 3]}, {"source": "sequence", "target": "hidden", "depth": [1, 3]}, {"source": "future direction", "target": "deep learning application", "depth": [1, 2]}, {"source": "future direction", "target": "architectural element", "depth": [1, 3]}, {"source": "future direction", "target": "smart grid", "depth": [1, 2]}, {"source": "future direction", "target": "survey of architectural", "depth": [1, 3]}, {"source": "pandemic", "target": "review of technology", "depth": [1, 3]}, {"source": "pandemic", "target": "distributed computing", "depth": [1, 3]}, {"source": "pandemic", "target": "tackling", "depth": [1, 3]}, {"source": "pandemic", "target": "technology", "depth": [1, 2]}, {"source": "query", "target": "query complexity", "depth": [1, 3]}, {"source": "query", "target": "complexity of adversarial", "depth": [1, 3]}, {"source": "speaker recognition", "target": "voxceleb speaker recognition", "depth": [1, 2]}, {"source": "speaker recognition", "target": "speaker recognition challenge", "depth": [1, 2]}, {"source": "speaker recognition", "target": "recognition challenge", "depth": [1, 2]}, {"source": "speaker recognition", "target": "tongji university", "depth": [1, 3]}, {"source": "normalization", "target": "filtered batch normalization", "depth": [1, 3]}, {"source": "normalization", "target": "batch normalization", "depth": [1, 2]}, {"source": "normalization", "target": "filtered batch", "depth": [1, 3]}, {"source": "normalization", "target": "batch", "depth": [1, 2]}, {"source": "matching", "target": "ultrasound image", "depth": [1, 3]}, {"source": "matching", "target": "matching in ultrasound", "depth": [1, 3]}, {"source": "matching", "target": "feature matching", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "residual learning", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "embedding with atrous", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "atrous convolution", "depth": [1, 3]}, {"source": "gradient descent", "target": "stochastic gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "single-objective optimization benefit", "depth": [1, 3]}, {"source": "gradient descent", "target": "multi-objective gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "local search", "depth": [1, 3]}, {"source": "visual question answering", "target": "visual question", "depth": [1, 1]}, {"source": "visual question answering", "target": "social visual question", "depth": [1, 3]}, {"source": "visual question answering", "target": "characterizing dataset", "depth": [1, 3]}, {"source": "visual question answering", "target": "tinysocial dataset", "depth": [1, 3]}, {"source": "processing", "target": "span-level processing", "depth": [1, 3]}, {"source": "processing", "target": "iobe", "depth": [1, 3]}, {"source": "processing", "target": "library for span-level", "depth": [1, 3]}, {"source": "processing", "target": "library", "depth": [1, 2]}, {"source": "chest x-ray", "target": "chest x-ray image", "depth": [1, 3]}, {"source": "chest x-ray", "target": "multi-disease chest x-ray", "depth": [1, 3]}, {"source": "chest x-ray", "target": "generalized deep learning", "depth": [1, 3]}, {"source": "tweet", "target": "latvian tweet", "depth": [1, 3]}, {"source": "tweet", "target": "strategies for sentiment", "depth": [1, 3]}, {"source": "tweet", "target": "analysis of latvian", "depth": [1, 3]}, {"source": "time", "target": "divergences between time", "depth": [1, 3]}, {"source": "time", "target": "differentiable divergence", "depth": [1, 3]}, {"source": "time", "target": "series", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading", "depth": [1, 3]}, {"source": "reading comprehension", "target": "multilingual synthetic question", "depth": [1, 3]}, {"source": "reading comprehension", "target": "cross-lingual reading comprehension", "depth": [1, 3]}, {"source": "reasoning", "target": "probability tree", "depth": [1, 3]}, {"source": "reasoning", "target": "causal reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "reasoning in probability", "depth": [1, 3]}, {"source": "regression", "target": "efficient truncated regression", "depth": [1, 3]}, {"source": "regression", "target": "statistically efficient truncated", "depth": [1, 3]}, {"source": "regression", "target": "truncated regression", "depth": [1, 3]}, {"source": "gradient", "target": "adaptive gradient", "depth": [1, 2]}, {"source": "gradient", "target": "adaptive gradient quantization", "depth": [1, 3]}, {"source": "gradient", "target": "gradient quantization", "depth": [1, 3]}, {"source": "pre-training", "target": "tree-based transformer", "depth": [1, 3]}, {"source": "pre-training", "target": "pre-training for table", "depth": [1, 3]}, {"source": "pre-training", "target": "table understanding", "depth": [1, 3]}, {"source": "pre-training", "target": "understanding with tree-based", "depth": [1, 3]}, {"source": "imitation learning", "target": "demonstration", "depth": [1, 3]}, {"source": "imitation learning", "target": "robot manipulation task", "depth": [1, 3]}, {"source": "imitation learning", "target": "language-conditioned imitation learning", "depth": [1, 3]}, {"source": "few-shot learning", "target": "decoding brain signal", "depth": [1, 3]}, {"source": "few-shot learning", "target": "brain signal", "depth": [1, 3]}, {"source": "few-shot learning", "target": "learning for decoding", "depth": [1, 3]}, {"source": "face", "target": "eye tracking", "depth": [1, 3]}, {"source": "face", "target": "event camera", "depth": [1, 3]}, {"source": "face", "target": "real-time face", "depth": [1, 3]}, {"source": "face", "target": "tracking and blink", "depth": [1, 3]}, {"source": "medical imaging", "target": "imaging", "depth": [1, 2]}, {"source": "medical imaging", "target": "chest x-ray dataset", "depth": [1, 3]}, {"source": "medical imaging", "target": "large-scale chest x-ray", "depth": [1, 3]}, {"source": "medical imaging", "target": "x-ray dataset", "depth": [1, 3]}, {"source": "function approximation", "target": "linear function approximation", "depth": [1, 3]}, {"source": "function approximation", "target": "linear function", "depth": [1, 3]}, {"source": "function approximation", "target": "basis function approximation", "depth": [1, 3]}, {"source": "function approximation", "target": "curl-free radial basis", "depth": [1, 3]}, {"source": "named entity", "target": "joint named entity", "depth": [1, 3]}, {"source": "named entity", "target": "study of joint", "depth": [1, 3]}, {"source": "named entity", "target": "joint named", "depth": [1, 3]}, {"source": "technical report", "target": "transducers solved efficiently", "depth": [1, 3]}, {"source": "technical report", "target": "constraints with concatenation", "depth": [1, 3]}, {"source": "technical report", "target": "concatenation and transducer", "depth": [1, 3]}, {"source": "technical report", "target": "transducers solved", "depth": [1, 3]}, {"source": "contact tracing", "target": "tracing", "depth": [1, 2]}, {"source": "contact tracing", "target": "digital contact tracing", "depth": [1, 3]}, {"source": "contact tracing", "target": "agent-based model", "depth": [1, 3]}, {"source": "contact tracing", "target": "model for evaluating", "depth": [1, 3]}, {"source": "metric learning", "target": "tag-based music retrieval", "depth": [1, 3]}, {"source": "metric learning", "target": "multimodal metric learning", "depth": [1, 3]}, {"source": "metric learning", "target": "music retrieval", "depth": [1, 3]}, {"source": "metric learning", "target": "learning for tag-based", "depth": [1, 3]}, {"source": "tracking", "target": "object tracking", "depth": [1, 2]}, {"source": "tracking", "target": "multi-object tracking", "depth": [1, 3]}, {"source": "tracking", "target": "multi object tracking", "depth": [1, 3]}, {"source": "tracking", "target": "single-shot multi object", "depth": [1, 3]}, {"source": "generative", "target": "deep generative", "depth": [1, 1]}, {"source": "generative", "target": "deep generative lda", "depth": [1, 3]}, {"source": "generative", "target": "generative lda", "depth": [1, 3]}, {"source": "generative", "target": "lda", "depth": [1, 3]}, {"source": "theory", "target": "theory for semiautomatum", "depth": [1, 3]}, {"source": "theory", "target": "krohn-rhodes theory", "depth": [1, 3]}, {"source": "theory", "target": "semiautomatum", "depth": [1, 3]}, {"source": "theory", "target": "krohn-rhode", "depth": [1, 3]}, {"source": "object recognition", "target": "scene representation", "depth": [1, 2]}, {"source": "object recognition", "target": "quantizing neural", "depth": [1, 3]}, {"source": "object recognition", "target": "scene", "depth": [1, 2]}, {"source": "object recognition", "target": "all-weather object recognition", "depth": [1, 3]}, {"source": "edge", "target": "fairness for edge", "depth": [1, 3]}, {"source": "edge", "target": "edge prediction", "depth": [1, 3]}, {"source": "edge", "target": "prediction with optimal", "depth": [1, 3]}, {"source": "speech enhancement", "target": "speech enhancement aided", "depth": [1, 3]}, {"source": "speech enhancement", "target": "voice activity detection", "depth": [1, 2]}, {"source": "speech enhancement", "target": "enhancement aided", "depth": [1, 3]}, {"source": "smart contract", "target": "tracking data collection", "depth": [1, 3]}, {"source": "smart contract", "target": "data collection protocol", "depth": [1, 3]}, {"source": "smart contract", "target": "remotely located subject", "depth": [1, 3]}, {"source": "smart contract", "target": "eye tracking datum", "depth": [1, 3]}, {"source": "intelligent surface", "target": "reconfigurable intelligent surface", "depth": [1, 2]}, {"source": "intelligent surface", "target": "wireless network", "depth": [1, 2]}, {"source": "intelligent surface", "target": "intelligent surface assisted", "depth": [1, 3]}, {"source": "dynamic environment", "target": "weighted incremental evolution", "depth": [1, 3]}, {"source": "dynamic environment", "target": "incremental evolution strategy", "depth": [1, 3]}, {"source": "dynamic environment", "target": "instance weighted incremental", "depth": [1, 3]}, {"source": "process", "target": "gaussian process", "depth": [1, 2]}, {"source": "process", "target": "random process", "depth": [1, 3]}, {"source": "process", "target": "observations of random", "depth": [1, 3]}, {"source": "market", "target": "financial market", "depth": [1, 3]}, {"source": "market", "target": "impact of publicly", "depth": [1, 3]}, {"source": "market", "target": "information transfer", "depth": [1, 3]}, {"source": "gan", "target": "non-saturating gan training", "depth": [1, 3]}, {"source": "gan", "target": "gan training", "depth": [1, 3]}, {"source": "gan", "target": "divergence minimization", "depth": [1, 3]}, {"source": "gan", "target": "training as divergence", "depth": [1, 3]}, {"source": "domain", "target": "domain generalization", "depth": [1, 3]}, {"source": "domain", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "domain", "target": "meta-learning for domain", "depth": [1, 3]}, {"source": "galerkin method", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "galerkin method", "target": "discontinuous galerkin", "depth": [1, 2]}, {"source": "galerkin method", "target": "mixed-discontinuous galerkin method", "depth": [1, 3]}, {"source": "galerkin method", "target": "elastic-viscoelastic composite structure", "depth": [1, 3]}, {"source": "flow", "target": "normalizing flow", "depth": [1, 2]}, {"source": "flow", "target": "interpolation in normalizing", "depth": [1, 3]}, {"source": "flow", "target": "principled interpolation", "depth": [1, 3]}, {"source": "planning", "target": "motion", "depth": [1, 2]}, {"source": "planning", "target": "energy-efficient autonomous ornithopter", "depth": [1, 3]}, {"source": "planning", "target": "autonomous ornithopter", "depth": [1, 3]}, {"source": "planning", "target": "kinodynamic planning", "depth": [1, 3]}, {"source": "hypergraph", "target": "higher arity vc-dimension", "depth": [1, 3]}, {"source": "hypergraph", "target": "hypergraph regularity", "depth": [1, 3]}, {"source": "hypergraph", "target": "arity vc-dimension", "depth": [1, 3]}, {"source": "hypergraph", "target": "regularity and higher", "depth": [1, 3]}, {"source": "modeling", "target": "generative modeling", "depth": [1, 3]}, {"source": "visual question", "target": "social visual question", "depth": [1, 3]}, {"source": "visual question", "target": "characterizing dataset", "depth": [1, 3]}, {"source": "visual question", "target": "tinysocial dataset", "depth": [1, 3]}, {"source": "visual question", "target": "pathological visual question", "depth": [1, 3]}, {"source": "research", "target": "falsifiable interpretability research", "depth": [1, 3]}, {"source": "research", "target": "interpretability research", "depth": [1, 3]}, {"source": "research", "target": "falsifiable interpretability", "depth": [1, 3]}, {"source": "research", "target": "interpretability", "depth": [1, 2]}, {"source": "pre-trained language model", "target": "pre-trained language", "depth": [1, 2]}, {"source": "pre-trained language model", "target": "dialogue generation", "depth": [1, 2]}, {"source": "counterfactual explanation", "target": "generate counterfactual explanation", "depth": [1, 3]}, {"source": "counterfactual explanation", "target": "deep image prior", "depth": [1, 2]}, {"source": "counterfactual explanation", "target": "deep image", "depth": [1, 2]}, {"source": "image recognition", "target": "few-shot image recognition", "depth": [1, 3]}, {"source": "image recognition", "target": "recognition with manifold", "depth": [1, 3]}, {"source": "image recognition", "target": "few-shot image", "depth": [1, 2]}, {"source": "adaptation", "target": "lidar semantic segmentation", "depth": [1, 3]}, {"source": "adaptation", "target": "adaptation in lidar", "depth": [1, 3]}, {"source": "adaptation", "target": "unsupervised cross-lingual adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "cross-lingual adaptation", "depth": [1, 3]}, {"source": "distribution", "target": "tabular gan", "depth": [1, 3]}, {"source": "distribution", "target": "uneven distribution", "depth": [1, 3]}, {"source": "distribution", "target": "gans for uneven", "depth": [1, 3]}, {"source": "hol", "target": "isabelle", "depth": [1, 2]}, {"source": "hol", "target": "teaching logic", "depth": [1, 3]}, {"source": "hol", "target": "meta-language for teaching", "depth": [1, 3]}, {"source": "hol", "target": "teaching", "depth": [1, 2]}, {"source": "medical image segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "mixed supervision", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "framework for semi-supervised", "depth": [1, 3]}, {"source": "polynomial time", "target": "free bipartite graph", "depth": [1, 3]}, {"source": "polynomial time", "target": "finding efficient domination", "depth": [1, 3]}, {"source": "polynomial time", "target": "free bipartite", "depth": [1, 3]}, {"source": "sentiment classification", "target": "mutual information maximization", "depth": [1, 3]}, {"source": "sentiment classification", "target": "cross-domain sentiment classification", "depth": [1, 3]}, {"source": "sentiment classification", "target": "information maximization", "depth": [1, 2]}, {"source": "graph representation learning", "target": "active graph representation", "depth": [1, 3]}, {"source": "graph representation learning", "target": "deep active graph", "depth": [1, 3]}, {"source": "graph representation learning", "target": "active graph", "depth": [1, 3]}, {"source": "deep generative", "target": "deep generative lda", "depth": [1, 3]}, {"source": "deep generative", "target": "generative lda", "depth": [1, 3]}, {"source": "deep generative", "target": "lda", "depth": [1, 3]}, {"source": "deep generative", "target": "deep generative model", "depth": [1, 2]}, {"source": "geometry", "target": "hyperbolic geometry", "depth": [1, 3]}, {"source": "geometry", "target": "endowing fasttext", "depth": [1, 3]}, {"source": "geometry", "target": "hypertext", "depth": [1, 3]}, {"source": "channel", "target": "deterministic identification", "depth": [1, 3]}, {"source": "channel", "target": "polar coded repetition", "depth": [1, 3]}, {"source": "channel", "target": "coded repetition", "depth": [1, 3]}, {"source": "channel", "target": "polar coded", "depth": [1, 3]}, {"source": "bound", "target": "dynamic distributed mi", "depth": [1, 3]}, {"source": "bound", "target": "improved bound", "depth": [1, 3]}, {"source": "bound", "target": "distributed mi", "depth": [1, 3]}, {"source": "distributed", "target": "dynamic distributed mi", "depth": [1, 3]}, {"source": "distributed", "target": "improved bound", "depth": [1, 3]}, {"source": "distributed", "target": "distributed mi", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "information-theoretic feature selection", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "decomposition and submodularity", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "selection via tensor", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "information-theoretic feature", "depth": [1, 3]}, {"source": "combinatorial", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "combinatorial", "target": "combinatorial multi-bandit problem", "depth": [1, 3]}, {"source": "combinatorial", "target": "energy management", "depth": [1, 3]}, {"source": "assessment", "target": "entity alignment", "depth": [1, 2]}, {"source": "assessment", "target": "critical assessment", "depth": [1, 3]}, {"source": "assessment", "target": "entity", "depth": [1, 2]}, {"source": "pattern", "target": "patterns count-based label", "depth": [1, 3]}, {"source": "pattern", "target": "labels for dataset", "depth": [1, 3]}, {"source": "pattern", "target": "count-based label", "depth": [1, 3]}, {"source": "pattern", "target": "label", "depth": [1, 2]}, {"source": "fair", "target": "allocation of treatment", "depth": [1, 3]}, {"source": "fair", "target": "fair allocation", "depth": [1, 3]}, {"source": "fair", "target": "inherent trade-off", "depth": [1, 3]}, {"source": "fair", "target": "treatment", "depth": [1, 3]}, {"source": "nlp", "target": "pandemic with natural", "depth": [1, 3]}, {"source": "nlp", "target": "intelligence", "depth": [1, 2]}, {"source": "nlp", "target": "ethics in nlp", "depth": [1, 3]}, {"source": "robustness", "target": "adversarial robustness", "depth": [1, 2]}, {"source": "robustness", "target": "supervised sparse coding", "depth": [1, 3]}, {"source": "robustness", "target": "sparse coding", "depth": [1, 2]}, {"source": "robustness", "target": "robustness of supervised", "depth": [1, 3]}, {"source": "shared task", "target": "typological feature", "depth": [1, 3]}, {"source": "shared task", "target": "prediction of typological", "depth": [1, 3]}, {"source": "shared task", "target": "sigtyp", "depth": [1, 3]}, {"source": "shared task", "target": "shared", "depth": [1, 3]}, {"source": "verification", "target": "speaker verification", "depth": [1, 2]}, {"source": "verification", "target": "speaker", "depth": [1, 2]}, {"source": "tensor", "target": "cnn compression", "depth": [1, 3]}, {"source": "tensor", "target": "reordering for cnn", "depth": [1, 3]}, {"source": "tensor", "target": "tensor reordering", "depth": [1, 3]}, {"source": "tensor", "target": "compression", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "connected autonomous vehicle", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "cellular network", "depth": [1, 2]}, {"source": "autonomous vehicle", "target": "networks and connected", "depth": [1, 3]}, {"source": "kernel", "target": "learning a kernel", "depth": [1, 3]}, {"source": "kernel", "target": "kernel from context", "depth": [1, 3]}, {"source": "kernel", "target": "attention-based clustering", "depth": [1, 3]}, {"source": "spoken language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "spoken language understanding", "target": "cross-modal language model", "depth": [1, 3]}, {"source": "spoken language understanding", "target": "language model pre-training", "depth": [1, 2]}, {"source": "data analysis", "target": "knowledge guided deep", "depth": [1, 3]}, {"source": "data analysis", "target": "guided deep neural", "depth": [1, 3]}, {"source": "data analysis", "target": "geo-spatiotemporal data analysis", "depth": [1, 3]}, {"source": "estimation", "target": "graph trussness", "depth": [1, 3]}, {"source": "estimation", "target": "estimation of graph", "depth": [1, 3]}, {"source": "estimation", "target": "efficient estimation", "depth": [1, 3]}, {"source": "estimation", "target": "trussness", "depth": [1, 3]}, {"source": "benchmark", "target": "pool-based active learning", "depth": [1, 3]}, {"source": "benchmark", "target": "aldataset", "depth": [1, 3]}, {"source": "benchmark", "target": "benchmark for pool-based", "depth": [1, 3]}, {"source": "benchmark", "target": "edge computing", "depth": [1, 2]}, {"source": "recovery", "target": "sparse linear classifier", "depth": [1, 3]}, {"source": "recovery", "target": "recovery of sparse", "depth": [1, 3]}, {"source": "recovery", "target": "mixture of response", "depth": [1, 3]}, {"source": "extraction", "target": "optimal subarchitecture extraction", "depth": [1, 3]}, {"source": "extraction", "target": "subarchitecture extraction", "depth": [1, 3]}, {"source": "extraction", "target": "optimal subarchitecture", "depth": [1, 3]}, {"source": "extraction", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "image denoising", "target": "denoising", "depth": [1, 2]}, {"source": "image denoising", "target": "bound for image", "depth": [1, 3]}, {"source": "image denoising", "target": "optimizing a self-supervised", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "brain mri image", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "neural networks model-based", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "networks model-based brain", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "model-based brain tumor", "depth": [1, 3]}, {"source": "lightweight", "target": "lightweight inference compilation", "depth": [1, 3]}, {"source": "lightweight", "target": "inference compilation", "depth": [1, 3]}, {"source": "lightweight", "target": "lightweight inference", "depth": [1, 3]}, {"source": "face recognition", "target": "resolution face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "low resolution face", "depth": [1, 3]}, {"source": "face recognition", "target": "multi scale identity-preserved", "depth": [1, 3]}, {"source": "face recognition", "target": "multi scale", "depth": [1, 3]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 2]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 2]}, {"source": "model predictive control", "target": "distributed model predictive", "depth": [1, 3]}, {"source": "model predictive control", "target": "nonlinear continuous-time system", "depth": [1, 3]}, {"source": "sequence labeling", "target": "neural sequence labeling", "depth": [1, 3]}, {"source": "sequence labeling", "target": "neural sequence", "depth": [1, 3]}, {"source": "sequence labeling", "target": "clinical concept extraction", "depth": [1, 3]}, {"source": "regularization", "target": "effective regularization", "depth": [1, 3]}, {"source": "regularization", "target": "loss-function metalearning", "depth": [1, 3]}, {"source": "regularization", "target": "regularization through loss-function", "depth": [1, 3]}, {"source": "regularization", "target": "metalearning", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "multi-agent reinforcement", "depth": [1, 2]}, {"source": "anomaly", "target": "high density anomaly", "depth": [1, 3]}, {"source": "anomaly", "target": "density anomaly", "depth": [1, 3]}, {"source": "anomaly", "target": "detection of high", "depth": [1, 3]}]}