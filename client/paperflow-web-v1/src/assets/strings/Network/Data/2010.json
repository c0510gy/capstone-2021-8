{"node": [["neural network", "deep neural network", "network", "graph neural network", "convolutional neural network", "learning", "reinforcement learning", "machine learning", "deep learning", "deep reinforcement learning", "model", "language model", "graph", "datum", "representation learning", "analysi", "machine translation", "system"], ["spiking neural network", "contrastive learning", "contrastive", "deep reinforcement", "multi-agent reinforcement learning", "deep", "deep learning model", "deep learning framework", "learning framework", "learning model", "social network", "deep network", "machine", "adversarial attack", "pre-trained language model", "knowledge graph", "graph embedding", "deep convolutional neural", "graph convolutional", "data augmentation", "graph representation learning", "graph representation", "representation", "survey", "neural machine translation", "neural machine", "translation", "online", "question answering", "visual question answering", "visual question", "generation", "text generation", "knowledge graph embedding", "federated learning", "speech recognition", "detection", "object detection", "anomaly detection", "anomaly", "object", "learning approach", "domain adaptation", "adaptation", "domain", "optimization", "bayesian optimization", "bayesian", "algorithm", "natural language", "natural language processing", "language processing", "natural language inference", "language inference", "nlp", "task", "tweet", "shared task", "identification", "deep generative", "segmentation", "case study", "social medium", "study", "named entity recognition", "transformer", "transfer learning", "transfer", "classification", "image classification", "image", "los", "language", "embedding", "method", "image recognition", "recognition", "efficient", "prediction", "pre-training", "action recognition", "video object", "speech", "code", "feedback", "image segmentation", "medical image segmentation", "medical image", "semantic segmentation", "generative adversarial network", "adversarial network", "generative adversarial", "processing", "text", "summarization", "control", "optimal control", "state", "problem", "word embedding", "evaluation", "language understanding", "spoken language understanding", "function", "feature selection", "tensor decomposition", "challenge", "training", "adversarial training", "robust", "attack", "architecture search", "neural architecture search", "neural architecture", "search", "fast", "decision making", "point cloud", "cloud", "voice conversion", "variational autoencoder", "approach", "approximation", "bandit", "recurrent neural network", "tree", "decision tree", "pose estimation", "convolutional network", "graph convolutional network", "differential equation", "text classification", "sentiment analysi", "clustering", "feature", "dataset", "pattern", "generalization", "semantic parsing", "parsing", "structure", "application", "artificial intelligence", "relation extraction", "fairnes", "optimal transport", "perspective", "combinatorial", "monte carlo", "architecture", "space", "motion planning", "planning", "attention network", "graph attention network", "graph attention", "extended version", "extended", "blockchain", "game", "attention", "inference", "autoencoder", "classifier", "computing", "performance", "active learning", "logic", "hol", "matrix", "sampling", "style transfer", "differentially private", "simulation", "framework", "knowledge distillation", "differential privacy", "privacy", "entity recognition", "named entity", "multi-task learning", "speech enhancement", "environment", "knowledge transfer", "online learning", "action", "communication", "constraint", "information", "time series", "trajectory prediction", "decomposition", "channel", "recommendation", "abstractive summarization", "policy", "policy optimization", "object recognition", "learn", "empirical study", "chest x-ray", "deep learning based", "gaussian proces", "computation", "understanding", "robot", "generative model", "human", "semi-supervised learning", "complexity", "quantum", "signal", "emotion recognition", "exploration", "test", "bert", "retrieval", "synthesi", "type", "ranking", "compressed sensing", "protocol", "causal", "alignment", "assessment", "edge", "coding", "self-supervised learning", "recommender system", "twitter", "review", "sequence", "future direction", "continuou", "pandemic", "query", "speaker recognition", "normalization", "matching", "gradient descent", "time", "reading comprehension", "reasoning", "regression", "gradient", "imitation learning", "few-shot learning", "face", "medical imaging", "function approximation", "technical report", "contact tracing", "metric learning", "tracking", "generative", "theory", "smart contract", "intelligent surface", "dynamic environment", "process", "market", "gan", "galerkin method", "flow", "hypergraph", "modeling", "research", "counterfactual explanation", "distribution", "polynomial time", "sentiment classification", "geometry", "bound", "distributed", "fair", "robustnes", "verification", "tensor", "autonomous vehicle", "kernel", "data analysi", "estimation", "benchmark", "question", "recovery", "extraction", "image denoising", "lightweight", "face recognition", "model predictive control", "sequence labeling", "regularization"], ["model-based reinforcement learning", "model-based reinforcement", "beamforming", "smart grid", "machine learning method", "learning method", "machine learning approach", "pre-trained language", "masked language model", "dialogue generation", "graph convolutional neural", "neural network model", "unlabeled datum", "augmentation", "reinforcement learning approach", "path planning", "unsupervised representation learning", "unsupervised representation", "stochastic analysi", "learning for neural", "link prediction", "recommendation system", "answering", "story generation", "understanding and generation", "unsupervised domain adaptation", "unsupervised domain", "document-level neural machine", "deep learning method", "radiology report", "scene representation", "scene", "world", "few-shot image", "image super-resolution", "motion prediction", "speech translation", "machine translation system", "source code", "constrained", "translation system", "security", "hard negative", "information maximization", "medium", "comparative study", "text summarization", "text datum", "stream", "practical guide", "spoken language", "natural language understanding", "isabelle", "deep learning approach", "challenges and opportunity", "efficient neural architecture", "fast and slow", "voice conversion challenge", "conversion challenge", "sensor fusion", "approximation algorithm", "convolutional recurrent neural", "decision", "human pose estimation", "human pose", "weakly supervised", "dynamic graph", "ordinary differential equation", "neural ordinary differential", "stochastic differential equation", "partial differential equation", "weak supervision", "label", "online social network", "intelligence", "transport", "combinatorial perspective", "motion", "version", "adaptive feature", "fictitious play", "stochastic game", "social learning", "teaching", "gaussian process", "tabular datum", "hyperspectral image classification", "hyperspectral image", "text style transfer", "text style", "unsupervised text style", "human action recognition", "local differential privacy", "backdoor attack", "voice activity detection", "activity detection", "controller", "strongly convex", "vehicle routing", "online decision", "time series forecasting", "discrete space", "neural abstractive summarization", "general framework", "visual representation", "regularized", "learning based", "gaussian process regression", "process regression", "power grid", "autonomou", "deep generative model", "sample", "wireless network", "speech emotion recognition", "machine learning model", "video object segmentation", "object segmentation", "multilingual bert", "incremental learning", "entity alignment", "entity", "sparse coding", "technology", "deep learning application", "voxceleb speaker recognition", "speaker recognition challenge", "recognition challenge", "batch normalization", "batch", "library", "divergence", "adaptive gradient", "manipulation task", "imaging", "tracing", "object tracking", "reconfigurable intelligent surface", "mimo system", "impact", "discontinuous galerkin method", "discontinuous galerkin", "normalizing flow", "interpolation", "interpretability", "deep image prior", "deep image", "image prior", "manifold", "trade-off", "nlp model", "adversarial robustnes", "speaker verification", "speaker", "cellular network", "vehicle", "context", "graph kernel", "language model pre-training", "model pre-training", "edge computing", "linear classifier", "denoising", "model predictive", "predictive control", "multi-agent reinforcement"], ["block model", "state sharding model", "state sharding", "sharding model", "detecting adversarial attack", "neural networks serve", "state of relevant", "relevant neuron", "generative language model", "open knowledge graph", "models are open", "open knowledge", "classifying malware image", "unsupervised data augmentation", "naive augmentation", "reinforcement learning task", "versus human attention", "decomposing human-object interaction", "hoi analysi", "integrating and decomposing", "networks for link", "potential energy approximation", "metal organic framework", "organic framework potential", "online recommendation system", "online recommendation", "regret in online", "answering over knowledge", "domain question answering", "improving language understanding", "temporal knowledge graph", "knowledge graph completion", "graph completion", "speech recognition model", "training speech recognition", "cost framework", "recognition model", "weakly-supervised object detection", "adversarial deep reinforcement", "synthetic news generation", "adversarial deep", "generating diverse question", "virtual cell optimization", "cell optimization", "extracting informative", "handcrafted feature", "augmentation for neural", "foreground removal", "joint named entity", "study of joint", "generating radiology report", "memory-driven transformer", "reports via memory-driven", "generating radiology", "transfer learning framework", "parkinson disease patient", "transfer learning improve", "bci models classification", "adversarial data augmentation", "adversarial datum", "high-performance graph representation", "near-optimal high-performance graph", "loss function", "function for image", "generation for anomaly", "unsupervised anomaly detection", "graph regularized autoencoder", "regularized autoencoder", "description of world", "language for description", "description", "voice qualifier", "acoustic correlate", "qualifier", "correlate", "wrench measurement", "method for constraint", "constraint inference", "inference using pose", "pose and wrench", "efficient constrained sampling", "efficient constrained", "mirror-langevin algorithm", "constrained sampling", "page", "paper length prediction", "length prediction", "paper length", "few-shot image recognition", "video object detection", "comprehensive attention self-distillation", "didi machine translation", "training for neural", "multilingual neural machine", "token-level adaptive training", "adaptive training", "feedback insertion-deletion code", "insertion-deletion code", "feedback insertion-deletion", "volumetric medical image", "varying human skin", "human skin tone", "unsupervised approach", "models with federated", "honey encryption scheme", "generate contextually similar", "single machine", "stream of problem", "mutual information maximization", "cross-domain sentiment classification", "roman urdu text", "analysis for roman", "roman urdu", "analysis of lime", "lime for text", "simulation study", "study on turnpike", "turnpikes in stochastic", "bandit problem", "euclidean space", "embedding of hierarchical", "hierarchical structure", "f-measure to roc", "recall and f-measure", "markedness and correlation", "informednes", "roc", "improving language", "isabelle function", "lucas-interpretation on isabelle", "lucas-interpretation", "approach towards varying", "varying human", "information-theoretic feature selection", "decomposition and submodularity", "selection via tensor", "information-theoretic feature", "lightweight generative adversarial", "text-guided image manipulation", "image manipulation", "conditional generative adversarial", "generative adversarial framework", "opportunity", "image extreme inpainting", "challenge on image", "extreme inpainting", "progressive bert training", "bert training", "transformer growth", "black-box adversarial attack", "cooperative multi-component architecture", "slow decision making", "slow decision", "interleaving fast", "frameworkfor reproducible deep", "reproducible deep learning", "modular multi-task frameworkfor", "multi-task frameworkfor reproducible", "discrete speech representation", "self-supervised discrete speech", "sensor fusion approach", "fusion approach", "viral-fusion", "sensor", "kernelized bandit", "methods for kernelized", "approximation method", "long short term", "short term memory", "term memory recurrent", "memory recurrent neural", "probability tree", "causal reasoning", "reasoning in probability", "detection and pose", "bounds of projection", "deep convolutional network", "dynamic graph convolutional", "multiclass debiasing method", "thy algorithm shalt", "bear false witnes", "evaluation of multiclas", "multiclass debiasing", "positivity preserving logarithmic", "cross-lingual text classification", "benchmarking cross-lingual text", "kinnews and kirnews", "kinyarwanda and kirundi", "aspect-based sentiment analysi", "sentiment", "latvian tweet", "strategies for sentiment", "thresholded lasso bandit", "lasso bandit", "thresholded lasso", "lasso", "thresholded", "learning multi-layer graph", "representation for clustering", "multi-layer graph", "common representation", "learning multi-layer", "learn robust feature", "robust feature", "features via orthogonal", "learn robust", "patterns count-based label", "labels for dataset", "count-based label", "domain generalization", "generalization in semantic", "meta-learning for domain", "concurrent process history", "process history", "structure of concurrent", "concurrent proces", "history", "residual learning", "embedding with atrou", "atrous convolution", "convolution and residual", "ldbc social network", "social network graph", "programming contest", "complex query", "nlp application", "cloud-assisted middleware-based iot", "enhancement of non-functional", "requirements for cloud-assisted", "middleware-based iot", "artificial intelligence symposium", "upper-rhine artificial intelligence", "research impact", "key industry", "semi-supervised relation extraction", "distantly-supervised relation extraction", "consistent evaluation", "accurate and consistent", "dataset for distantly-supervised", "fairness for edge", "edge prediction", "prediction with optimal", "minimal code", "perspectives on minimal", "minimal", "carlo tree search", "monte carlo tree", "tree search", "goal directed molecule", "carlo tree", "robust training", "superposition spiking neural", "quantum superposition spiking", "superposition spiking", "quantum superposition", "deep spiking neural", "supernet", "europe and usa", "high-performance graph", "near-optimal high-performance", "structure in euclidean", "unsupervised embedding", "semi-supervised medical image", "mixed supervision", "explainable multi-robot motion", "multi-robot motion planning", "planning via segmentation", "cross-lingual natural language", "language processing framework", "infodemic management", "ris-assisted haps backhauling", "full-duplex ris-assisted hap", "haps backhauling", "equivalence for assisted", "assisted grading", "grading of functional", "adaptive feature selection", "children speech", "disfluency in child", "sharding", "zero-sum stochastic game", "play in zero-sum", "fictitiou", "channel parallel sampling", "groups of channel", "sampling with attention", "channel parallel", "parallel sampling", "predicting biomedical interaction", "bound membership inference", "differentially private learning", "membership inference", "private learning", "bound membership", "graph variational autoencoder", "dirichlet graph variational", "network classifiers based", "classifiers based", "based on social", "network classifier", "earnings call", "framework for measuring", "measuring the digital", "digital strategy", "productive performance", "systolic computing", "computing on gpu", "gpus for productive", "pretext-based active learning", "pal", "pool-based active learning", "aldataset", "benchmark for pool-based", "teaching logic", "meta-language for teaching", "matrices are underrated", "correspondence matrix", "correspondence", "left exact category", "exact category", "thompson sampling", "marginalised gaussian process", "nested sampling", "processes with nested", "joint neural architecture", "autotuned data-parallel training", "joint neural", "based physics-informed neural", "heterogeneous porous material", "modified neural architecture", "artists style transfer", "multiple artists style", "regularized mahalanobis metric", "differentially private text", "private text perturbation", "text perturbation method", "mahalanobis metric", "stochastic lq optimal", "scalable bayesian learning", "bayesian learning", "learning of causal", "causal dag", "high density anomaly", "density anomaly", "detection of high", "high density", "algorithmic framework", "long financial report", "conditional variational autoencoder", "generating long financial", "financial report", "report using conditional", "attention-augmented graph convolutional", "lidar semantic segmentation", "adaptation in lidar", "discrete wasserstein training", "importance-aware semantic segmentation", "application-agnostic data sharing", "learning to noise", "data sharing", "joint named", "improve captcha robustnes", "bot attack", "improve captcha", "captcha robustnes", "speech enhancement aided", "enhancement aided", "controller for escaping", "escaping trap", "tampc", "escaping", "skeleton-based action recognition", "efficient skeleton-based human", "skeleton-based human action", "perspective on transfer", "adversarial knowledge transfer", "projection-free online learning", "projection-free online", "lipschitz continuity", "bounds without lipschitz", "combinatorial action", "learning with combinatorial", "application to vehicle", "routing", "online decision tree", "trees with fairnes", "streaming decision tree", "learning with adversarial", "learning of unsupervised", "predictive plasticity", "gradients with clapp", "strategic communication", "multiway relay communication", "fundamental issue", "recent advance", "relay communication", "simulation of flexible", "power constraint", "identification over channel", "channels with power", "deterministic identification", "sell hard information", "hard information", "sell hard", "sell", "enriching word embedding", "series", "series forecasting", "weekly time series", "strong baseline", "continuous and discrete", "spaces for text", "collaborative training", "training of gan", "edit-based unsupervised summarization", "unsupervised summarization", "model for edit-based", "q-learning with language", "overfitting or underfitting", "underfitting", "understand robustness drop", "robustness drop", "drop in adversarial", "multimodal language sequence", "temporal graph attention", "unaligned human multimodal", "multimodal temporal graph", "fuzzy query attention", "multi-agent trajectory prediction", "query attention", "prediction with fuzzy", "fuzzy query", "state space model", "framework for semi-supervised", "making", "matrix decomposition", "graph-regularization for matrix", "learnable graph-regularization", "graph-regularization", "reward attribution decomposition", "identification of informative", "english tweet", "graph variational", "dirichlet graph", "implicit rank-minimizing autoencoder", "neighbor-aware graph attention", "network for recommendation", "neighbor-aware graph", "guided neural abstractive", "framework for guided", "multimodal abstractive summarization", "backhauling with graph", "imbalanced domain adaptation", "fair knowledge transfer", "fair knowledge", "transfer for imbalanced", "imbalanced domain", "trainable natural logic", "logic theorem prover", "natural logic theorem", "learning as abduction", "multimodal contrastive learning", "optimization with multiple", "multiple optima", "optima for reinforcement", "pomo", "quantizing neural", "orthogonal object", "online non-convex optimization", "complex dynamics forecasting", "augmenting physical model", "dynamics forecasting", "physical model", "models with deep", "learning visual representation", "human interaction", "muscle", "representation from human", "edge continuum", "discussion on context-awarenes", "iot cloud", "context-awareness to bettersupport", "channel pruning search", "differentiable channel pruning", "pruning search", "channel pruning", "regularized inference privacy", "data-driven regularized inference", "inference privacy", "regularized inference", "study of transformer", "transformers for source", "protecting visual recommender", "multi-disease chest x-ray", "generalized deep learning", "multi-disease chest", "based collocation method", "dimensional potential problem", "learning based collocation", "collocation method", "probabilistic states estimation", "physics-informed gaussian proces", "performance cost", "mitigation policy optimization", "graph computation", "reducing communication", "communication and synchronization", "synchronization in graph", "pull", "lake symbol", "island parsing", "symbols for island", "lake", "symbol", "understanding opportunity", "opportunities and challenge", "challenges of geographic", "gender-inclusion in os", "geographic gender-inclusion", "person-specific following robot", "autonomous person-specific", "person-specific", "lyapunov-stable orientation estimator", "network anomaly detection", "usage of generative", "models for network", "estimation from rgb", "rgb and lidar", "hperl", "semi-autoregressive bottom-up semantic", "online semi-supervised learning", "bandit feedback", "learning with bandit", "neural graph consensu", "quantum sample", "complexity of quantum", "learnability and complexity", "strategy of company", "corrupted signal", "localization in wireles", "networks from corrupted", "robust localization", "multiscale fractal analysi", "music-induced emotion recognition", "fractal analysi", "analysis on eeg", "explainable online validation", "practical application", "online validation", "validation of machine", "string space", "optimization over string", "bos", "high-dimensional bayesian optimization", "constrained bayesian optimization", "oil exploration", "learning for ga", "gas and oil", "ga", "model exploration", "models understand instruction", "language models understand", "turking test", "understand instruction", "models understand", "semi-supervised video object", "cyclic mechanism", "learnability", "bert post-pretraining alignment", "multilingual bert post-pretraining", "post-pretraining alignment", "bert post-pretraining", "fine-grained image retrieval", "image retrieval", "exploration of incremental", "learning for fine-grained", "fine-grained attribute analysi", "fine-grained attribute", "attribute analysi", "analysis for person", "taking a closer", "session type", "imperative session type", "functional and imperative", "imperative session", "relating functional", "crowdsourced ranking", "algorithmic instability", "instabilities in crowdsourced", "origins of algorithmic", "instability", "coded compressed sensing", "undersampled fourier measurement", "photoacoustic tomography reduce", "sensing photoacoustic tomography", "compressed sensing photoacoustic", "barrington plays card", "plays card", "card-based protocol", "complexity of card-based", "barrington play", "ethics in nlp", "program equivalence", "insertion-deletion", "pre-training for named", "epistemic operator", "thinking about causation", "causal language", "language with epistemic", "causation", "critical assessment", "two-stage coding", "z-channel", "two-stage", "supervised sparse coding", "human mesh registration", "implicit surface correspondence", "surface correspondence", "pose and shape", "human mesh", "recommender system based", "telegram social network", "system based", "traits in telegram", "telegram social", "twitter dataset", "analysis of twitter", "twitter and youtube", "youtube during uselection", "uselection", "review of technology", "distributed computing", "tackling", "capacity-achieving code", "hidden automatic sequence", "automatic sequence", "hidden", "dna sequence", "codes for recovery", "architectural element", "survey of architectural", "applications and future", "continuous gaze redirection", "controllable continuous gaze", "gaze redirection", "continuous gaze", "controllable continuou", "analyzing societal impact", "query complexity", "complexity of adversarial", "hub label", "eccentricity query", "tongji university", "idlab voxceleb speaker", "filtered batch normalization", "filtered batch", "filtered", "ultrasound image", "matching in ultrasound", "feature matching", "ultrasound", "high-order relation construction", "geometric algebra", "stochastic gradient descent", "single-objective optimization benefit", "multi-objective gradient descent", "local search", "optimization benefit", "social visual question", "characterizing dataset", "tinysocial dataset", "pathological visual question", "span-level processing", "iobe", "library for span-level", "span-level", "chest x-ray image", "posteroanterior chest x-ray", "analysis of latvian", "fine-tuning strategy", "pretraining and fine-tuning", "divergences between time", "differentiable divergence", "machine reading comprehension", "machine reading", "multilingual synthetic question", "cross-lingual reading comprehension", "synthetic question", "algorithms for causal", "human-level concept learning", "efficient truncated regression", "statistically efficient truncated", "truncated regression", "statistically efficient", "efficient truncated", "adaptive gradient quantization", "gradient quantization", "data-parallel sgd", "quantization for data-parallel", "tree-based transformer", "pre-training for table", "table understanding", "understanding with tree-based", "structure-aware pre-training", "demonstration", "robot manipulation task", "language-conditioned imitation learning", "learning for robot", "decoding brain signal", "brain signal", "learning for decoding", "decoding brain", "spatial regression", "eye tracking", "event camera", "real-time face", "tracking and blink", "blink detection", "chest x-ray dataset", "large-scale chest x-ray", "x-ray dataset", "valuation for medical", "linear function approximation", "linear function", "basis function approximation", "curl-free radial basi", "radial basis function", "named", "transducers solved efficiently", "constraints with concatenation", "concatenation and transducer", "transducers solved", "string constraint", "digital contact tracing", "agent-based model", "model for evaluating", "evaluating method", "tag-based music retrieval", "multimodal metric learning", "music retrieval", "learning for tag-based", "multimodal metric", "multi-object tracking", "multi object tracking", "single-shot multi object", "multi object", "deep generative lda", "generative lda", "lda", "generative neurosymbolic machine", "theory for semiautomatum", "krohn-rhodes theory", "semiautomatum", "krohn-rhode", "cyber-physical systems theory", "all-weather object recognition", "infrared sensing", "learning for voice", "tracking data collection", "data collection protocol", "remotely located subject", "eye tracking datum", "tracking datum", "intelligent surface assisted", "two-tile reconfigurable intelligent", "weighted incremental evolution", "incremental evolution strategy", "instance weighted incremental", "weighted incremental", "incremental evolution", "random process", "observations of random", "polynomial representation", "representations of high-dimensional", "financial market", "impact of publicly", "information transfer", "transfer to financial", "non-saturating gan training", "gan training", "divergence minimization", "training as divergence", "non-saturating", "structural causal model", "causal model", "mixed-discontinuous galerkin method", "elastic-viscoelastic composite structure", "linear dynamical elastic-viscoelastic", "interpolation in normalizing", "principled interpolation", "normalizing", "energy-efficient autonomous ornithopter", "autonomous ornithopter", "kinodynamic planning", "energy-efficient autonomou", "higher arity vc-dimension", "hypergraph regularity", "arity vc-dimension", "regularity and higher", "higher arity", "autoregressive generative modeling", "generative modeling", "laws for autoregressive", "scaling law", "law", "falsifiable interpretability research", "interpretability research", "falsifiable interpretability", "theoretical opportunity", "dialogue generation based", "generation with pre-trained", "open-domain dialogue generation", "generate counterfactual explanation", "priors to generate", "recognition with manifold", "ann structure", "unsupervised cross-lingual adaptation", "cross-lingual adaptation", "adaptation for sequence", "tabular gan", "uneven distribution", "gans for uneven", "tabular", "probability distribution", "meta-language", "automatic data augmentation", "free bipartite graph", "finding efficient domination", "free bipartite", "efficient domination", "bipartite graph", "classification with contrastive", "learning and mutual", "active graph representation", "deep active graph", "active graph", "deep active", "handling missing datum", "deep generative factorization", "hyperbolic geometry", "endowing fasttext", "hypertext", "fasttext with hyperbolic", "endowing", "polar coded repetition", "coded repetition", "polar coded", "low-capacity channel", "dynamic distributed mi", "improved bound", "distributed mi", "mis with improved", "dynamic distributed", "submodularity", "combinatorial multi-bandit problem", "energy management", "application to energy", "combinatorial multi-bandit", "intrinsic quality assessment", "assessment of argument", "verification of pattern", "performance guarantee", "loss and performance", "minimax classification", "allocation of treatment", "fair allocation", "inherent trade-off", "treatment", "pandemic with natural", "interpretation of nlp", "robustness of supervised", "supervised sparse", "typological feature", "prediction of typological", "sigtyp", "shared", "translation beyond english", "playing a part", "part", "cnn compression", "reordering for cnn", "tensor reordering", "compression", "reordering", "connected autonomous vehicle", "connected autonomou", "networks and connected", "learning a kernel", "kernel from context", "attention-based clustering", "cross-modal language model", "cross-modal language", "knowledge guided deep", "guided deep neural", "geo-spatiotemporal data analysi", "knowledge guided", "guided deep", "graph trussnes", "estimation of graph", "efficient estimation", "trussnes", "faster uncertainty estimation", "workflow-based benchmark", "generating adequate distractor", "adequate distractor", "generating adequate", "multiple-choice question", "distractors for multiple-choice", "sparse linear classifier", "recovery of sparse", "mixture of response", "sparse linear", "optimal subarchitecture extraction", "subarchitecture extraction", "optimal subarchitecture", "algorithm for optimal", "bound for image", "optimizing a self-supervised", "self-supervised bound", "optimizing", "brain mri image", "neural networks model-based", "networks model-based brain", "model-based brain tumor", "brain tumor detection", "lightweight inference compilation", "inference compilation", "lightweight inference", "metropolis-hastings with lightweight", "accelerating metropolis-hasting", "resolution face recognition", "low resolution face", "multi scale identity-preserved", "multi scale", "scale identity-preserved u-net", "distributed model predictive", "nonlinear continuous-time system", "modular framework", "neural sequence labeling", "neural sequence", "clinical concept extraction", "nlnde at cantemist", "concept extraction", "effective regularization", "loss-function metalearning", "regularization through loss-function", "metalearning", "loss-function", "competitive multi-agent reinforcement", "convergence and optimality", "information asymmetry", "asymmetry in competitive"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 0]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "spiking neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "contrastive learning", "depth": [0, 1]}, {"source": "learning", "target": "contrastive", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "model-based reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "multi-agent reinforcement learning", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "model-based reinforcement", "depth": [0, 2]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning framework", "depth": [0, 1]}, {"source": "deep learning", "target": "learning framework", "depth": [0, 1]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "network", "target": "social network", "depth": [0, 1]}, {"source": "network", "target": "deep network", "depth": [0, 1]}, {"source": "network", "target": "spiking neural network", "depth": [0, 1]}, {"source": "network", "target": "beamforming", "depth": [0, 2]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "model", "target": "language model", "depth": [0, 0]}, {"source": "model", "target": "block model", "depth": [0, 3]}, {"source": "model", "target": "state sharding model", "depth": [0, 3]}, {"source": "model", "target": "state sharding", "depth": [0, 3]}, {"source": "model", "target": "sharding model", "depth": [0, 3]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "smart grid", "depth": [0, 2]}, {"source": "machine learning", "target": "machine learning method", "depth": [0, 2]}, {"source": "machine learning", "target": "learning method", "depth": [0, 2]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 2]}, {"source": "deep neural network", "target": "detecting adversarial attack", "depth": [0, 3]}, {"source": "deep neural network", "target": "neural networks serve", "depth": [0, 3]}, {"source": "deep neural network", "target": "adversarial attack", "depth": [0, 1]}, {"source": "deep neural network", "target": "state of relevant", "depth": [0, 3]}, {"source": "deep neural network", "target": "relevant neuron", "depth": [0, 3]}, {"source": "language model", "target": "pre-trained language model", "depth": [0, 1]}, {"source": "language model", "target": "pre-trained language", "depth": [0, 2]}, {"source": "language model", "target": "masked language model", "depth": [0, 2]}, {"source": "language model", "target": "dialogue generation", "depth": [0, 2]}, {"source": "language model", "target": "generative language model", "depth": [0, 3]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "graph embedding", "depth": [0, 1]}, {"source": "graph", "target": "open knowledge graph", "depth": [0, 3]}, {"source": "graph", "target": "models are open", "depth": [0, 3]}, {"source": "graph", "target": "open knowledge", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "graph convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "graph convolutional", "depth": [0, 1]}, {"source": "convolutional neural network", "target": "neural network model", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "classifying malware image", "depth": [0, 3]}, {"source": "datum", "target": "data augmentation", "depth": [0, 1]}, {"source": "datum", "target": "unlabeled datum", "depth": [0, 2]}, {"source": "datum", "target": "augmentation", "depth": [0, 2]}, {"source": "datum", "target": "unsupervised data augmentation", "depth": [0, 3]}, {"source": "datum", "target": "naive augmentation", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "path planning", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "reinforcement learning task", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "versus human attention", "depth": [0, 3]}, {"source": "representation learning", "target": "graph representation learning", "depth": [0, 1]}, {"source": "representation learning", "target": "graph representation", "depth": [0, 1]}, {"source": "representation learning", "target": "representation", "depth": [0, 1]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [0, 2]}, {"source": "representation learning", "target": "unsupervised representation", "depth": [0, 2]}, {"source": "analysi", "target": "stochastic analysi", "depth": [0, 2]}, {"source": "analysi", "target": "survey", "depth": [0, 1]}, {"source": "analysi", "target": "decomposing human-object interaction", "depth": [0, 3]}, {"source": "analysi", "target": "hoi analysi", "depth": [0, 3]}, {"source": "analysi", "target": "integrating and decomposing", "depth": [0, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [0, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [0, 1]}, {"source": "machine translation", "target": "translation", "depth": [0, 1]}, {"source": "machine translation", "target": "machine", "depth": [0, 1]}, {"source": "machine translation", "target": "learning for neural", "depth": [0, 2]}, {"source": "graph neural network", "target": "link prediction", "depth": [0, 2]}, {"source": "graph neural network", "target": "networks for link", "depth": [0, 3]}, {"source": "graph neural network", "target": "potential energy approximation", "depth": [0, 3]}, {"source": "graph neural network", "target": "metal organic framework", "depth": [0, 3]}, {"source": "graph neural network", "target": "organic framework potential", "depth": [0, 3]}, {"source": "system", "target": "online recommendation system", "depth": [0, 3]}, {"source": "system", "target": "recommendation system", "depth": [0, 2]}, {"source": "system", "target": "online recommendation", "depth": [0, 3]}, {"source": "system", "target": "regret in online", "depth": [0, 3]}, {"source": "system", "target": "online", "depth": [0, 1]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 1]}, {"source": "question answering", "target": "visual question", "depth": [1, 1]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "answering over knowledge", "depth": [1, 3]}, {"source": "question answering", "target": "domain question answering", "depth": [1, 3]}, {"source": "generation", "target": "text generation", "depth": [1, 1]}, {"source": "generation", "target": "survey", "depth": [1, 1]}, {"source": "generation", "target": "story generation", "depth": [1, 2]}, {"source": "generation", "target": "improving language understanding", "depth": [1, 3]}, {"source": "generation", "target": "understanding and generation", "depth": [1, 2]}, {"source": "knowledge graph", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "graph embedding", "depth": [1, 1]}, {"source": "knowledge graph", "target": "temporal knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "knowledge graph completion", "depth": [1, 3]}, {"source": "knowledge graph", "target": "graph completion", "depth": [1, 3]}, {"source": "federated learning", "target": "speech recognition model", "depth": [1, 3]}, {"source": "federated learning", "target": "training speech recognition", "depth": [1, 3]}, {"source": "federated learning", "target": "cost framework", "depth": [1, 3]}, {"source": "federated learning", "target": "speech recognition", "depth": [1, 1]}, {"source": "federated learning", "target": "recognition model", "depth": [1, 3]}, {"source": "detection", "target": "object detection", "depth": [1, 1]}, {"source": "detection", "target": "anomaly detection", "depth": [1, 1]}, {"source": "detection", "target": "anomaly", "depth": [1, 1]}, {"source": "detection", "target": "object", "depth": [1, 1]}, {"source": "detection", "target": "weakly-supervised object detection", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "adversarial deep reinforcement", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "synthetic news generation", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "adversarial deep", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "unsupervised domain", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "generating diverse question", "depth": [1, 3]}, {"source": "optimization", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "optimization", "target": "bayesian", "depth": [1, 1]}, {"source": "optimization", "target": "algorithm", "depth": [1, 1]}, {"source": "optimization", "target": "virtual cell optimization", "depth": [1, 3]}, {"source": "optimization", "target": "cell optimization", "depth": [1, 3]}, {"source": "natural language", "target": "natural language processing", "depth": [1, 1]}, {"source": "natural language", "target": "language processing", "depth": [1, 1]}, {"source": "natural language", "target": "natural language inference", "depth": [1, 1]}, {"source": "natural language", "target": "language inference", "depth": [1, 1]}, {"source": "natural language", "target": "nlp", "depth": [1, 1]}, {"source": "task", "target": "tweet", "depth": [1, 1]}, {"source": "task", "target": "shared task", "depth": [1, 1]}, {"source": "task", "target": "identification", "depth": [1, 1]}, {"source": "task", "target": "extracting informative", "depth": [1, 3]}, {"source": "task", "target": "handcrafted feature", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "translation", "depth": [1, 1]}, {"source": "neural machine translation", "target": "learning for neural", "depth": [1, 2]}, {"source": "neural machine translation", "target": "document-level neural machine", "depth": [1, 2]}, {"source": "neural machine translation", "target": "augmentation for neural", "depth": [1, 3]}, {"source": "deep", "target": "deep generative", "depth": [1, 1]}, {"source": "deep", "target": "segmentation", "depth": [1, 1]}, {"source": "deep", "target": "deep learning method", "depth": [1, 2]}, {"source": "deep", "target": "foreground removal", "depth": [1, 3]}, {"source": "deep", "target": "learning method", "depth": [1, 2]}, {"source": "case study", "target": "social medium", "depth": [1, 1]}, {"source": "case study", "target": "study", "depth": [1, 1]}, {"source": "case study", "target": "joint named entity", "depth": [1, 3]}, {"source": "case study", "target": "named entity recognition", "depth": [1, 1]}, {"source": "case study", "target": "study of joint", "depth": [1, 3]}, {"source": "transformer", "target": "generating radiology report", "depth": [1, 3]}, {"source": "transformer", "target": "memory-driven transformer", "depth": [1, 3]}, {"source": "transformer", "target": "radiology report", "depth": [1, 2]}, {"source": "transformer", "target": "reports via memory-driven", "depth": [1, 3]}, {"source": "transformer", "target": "generating radiology", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer learning framework", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer", "depth": [1, 1]}, {"source": "transfer learning", "target": "parkinson disease patient", "depth": [1, 3]}, {"source": "transfer learning", "target": "transfer learning improve", "depth": [1, 3]}, {"source": "transfer learning", "target": "bci models classification", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "adversarial data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "adversarial datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "unsupervised data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "naive augmentation", "depth": [1, 3]}, {"source": "representation", "target": "scene representation", "depth": [1, 2]}, {"source": "representation", "target": "object", "depth": [1, 1]}, {"source": "representation", "target": "scene", "depth": [1, 2]}, {"source": "representation", "target": "high-performance graph representation", "depth": [1, 3]}, {"source": "representation", "target": "near-optimal high-performance graph", "depth": [1, 3]}, {"source": "classification", "target": "image classification", "depth": [1, 1]}, {"source": "classification", "target": "image", "depth": [1, 1]}, {"source": "classification", "target": "los", "depth": [1, 1]}, {"source": "classification", "target": "loss function", "depth": [1, 3]}, {"source": "classification", "target": "function for image", "depth": [1, 3]}, {"source": "anomaly detection", "target": "anomaly", "depth": [1, 1]}, {"source": "anomaly detection", "target": "generation for anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "unsupervised anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "graph regularized autoencoder", "depth": [1, 3]}, {"source": "anomaly detection", "target": "regularized autoencoder", "depth": [1, 3]}, {"source": "language", "target": "embedding", "depth": [1, 1]}, {"source": "language", "target": "description of world", "depth": [1, 3]}, {"source": "language", "target": "language for description", "depth": [1, 3]}, {"source": "language", "target": "world", "depth": [1, 2]}, {"source": "language", "target": "description", "depth": [1, 3]}, {"source": "survey", "target": "text generation", "depth": [1, 1]}, {"source": "survey", "target": "voice qualifier", "depth": [1, 3]}, {"source": "survey", "target": "acoustic correlate", "depth": [1, 3]}, {"source": "survey", "target": "qualifier", "depth": [1, 3]}, {"source": "survey", "target": "correlate", "depth": [1, 3]}, {"source": "method", "target": "wrench measurement", "depth": [1, 3]}, {"source": "method", "target": "method for constraint", "depth": [1, 3]}, {"source": "method", "target": "constraint inference", "depth": [1, 3]}, {"source": "method", "target": "inference using pose", "depth": [1, 3]}, {"source": "method", "target": "pose and wrench", "depth": [1, 3]}, {"source": "image", "target": "image classification", "depth": [1, 1]}, {"source": "image", "target": "image recognition", "depth": [1, 1]}, {"source": "image", "target": "few-shot image", "depth": [1, 2]}, {"source": "image", "target": "recognition", "depth": [1, 1]}, {"source": "image", "target": "image super-resolution", "depth": [1, 2]}, {"source": "efficient", "target": "efficient constrained sampling", "depth": [1, 3]}, {"source": "efficient", "target": "efficient constrained", "depth": [1, 3]}, {"source": "efficient", "target": "mirror-langevin algorithm", "depth": [1, 3]}, {"source": "efficient", "target": "constrained sampling", "depth": [1, 3]}, {"source": "efficient", "target": "algorithm", "depth": [1, 1]}, {"source": "prediction", "target": "motion prediction", "depth": [1, 2]}, {"source": "prediction", "target": "page", "depth": [1, 3]}, {"source": "prediction", "target": "paper length prediction", "depth": [1, 3]}, {"source": "prediction", "target": "length prediction", "depth": [1, 3]}, {"source": "prediction", "target": "paper length", "depth": [1, 3]}, {"source": "recognition", "target": "image recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "pre-training", "depth": [1, 1]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "few-shot image recognition", "depth": [1, 3]}, {"source": "object detection", "target": "object", "depth": [1, 1]}, {"source": "object detection", "target": "video object detection", "depth": [1, 3]}, {"source": "object detection", "target": "video object", "depth": [1, 1]}, {"source": "object detection", "target": "weakly-supervised object detection", "depth": [1, 3]}, {"source": "object detection", "target": "comprehensive attention self-distillation", "depth": [1, 3]}, {"source": "translation", "target": "machine", "depth": [1, 1]}, {"source": "translation", "target": "speech translation", "depth": [1, 2]}, {"source": "translation", "target": "speech", "depth": [1, 1]}, {"source": "translation", "target": "machine translation system", "depth": [1, 2]}, {"source": "translation", "target": "didi machine translation", "depth": [1, 3]}, {"source": "neural machine", "target": "augmentation for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "training for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "multilingual neural machine", "depth": [1, 3]}, {"source": "neural machine", "target": "token-level adaptive training", "depth": [1, 3]}, {"source": "neural machine", "target": "adaptive training", "depth": [1, 3]}, {"source": "code", "target": "source code", "depth": [1, 2]}, {"source": "code", "target": "feedback insertion-deletion code", "depth": [1, 3]}, {"source": "code", "target": "insertion-deletion code", "depth": [1, 3]}, {"source": "code", "target": "feedback insertion-deletion", "depth": [1, 3]}, {"source": "code", "target": "feedback", "depth": [1, 1]}, {"source": "segmentation", "target": "image segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "segmentation", "target": "semantic segmentation", "depth": [1, 1]}, {"source": "segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "generative adversarial", "depth": [1, 1]}, {"source": "generative adversarial network", "target": "varying human skin", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "human skin tone", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "unsupervised approach", "depth": [1, 3]}, {"source": "algorithm", "target": "efficient constrained sampling", "depth": [1, 3]}, {"source": "algorithm", "target": "efficient constrained", "depth": [1, 3]}, {"source": "algorithm", "target": "mirror-langevin algorithm", "depth": [1, 3]}, {"source": "algorithm", "target": "constrained sampling", "depth": [1, 3]}, {"source": "algorithm", "target": "constrained", "depth": [1, 2]}, {"source": "speech recognition", "target": "speech recognition model", "depth": [1, 3]}, {"source": "speech recognition", "target": "training speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "cost framework", "depth": [1, 3]}, {"source": "speech recognition", "target": "recognition model", "depth": [1, 3]}, {"source": "speech recognition", "target": "models with federated", "depth": [1, 3]}, {"source": "natural language processing", "target": "language processing", "depth": [1, 1]}, {"source": "natural language processing", "target": "nlp", "depth": [1, 1]}, {"source": "natural language processing", "target": "processing", "depth": [1, 1]}, {"source": "natural language processing", "target": "honey encryption scheme", "depth": [1, 3]}, {"source": "natural language processing", "target": "generate contextually similar", "depth": [1, 3]}, {"source": "machine", "target": "machine translation system", "depth": [1, 2]}, {"source": "machine", "target": "translation system", "depth": [1, 2]}, {"source": "machine", "target": "single machine", "depth": [1, 3]}, {"source": "machine", "target": "stream of problem", "depth": [1, 3]}, {"source": "machine", "target": "security", "depth": [1, 2]}, {"source": "contrastive learning", "target": "contrastive", "depth": [1, 1]}, {"source": "contrastive learning", "target": "hard negative", "depth": [1, 2]}, {"source": "contrastive learning", "target": "mutual information maximization", "depth": [1, 3]}, {"source": "contrastive learning", "target": "cross-domain sentiment classification", "depth": [1, 3]}, {"source": "contrastive learning", "target": "information maximization", "depth": [1, 2]}, {"source": "social medium", "target": "medium", "depth": [1, 2]}, {"source": "social medium", "target": "roman urdu text", "depth": [1, 3]}, {"source": "social medium", "target": "comparative study", "depth": [1, 2]}, {"source": "social medium", "target": "analysis for roman", "depth": [1, 3]}, {"source": "social medium", "target": "roman urdu", "depth": [1, 3]}, {"source": "text", "target": "text summarization", "depth": [1, 2]}, {"source": "text", "target": "summarization", "depth": [1, 1]}, {"source": "text", "target": "text datum", "depth": [1, 2]}, {"source": "text", "target": "analysis of lime", "depth": [1, 3]}, {"source": "text", "target": "lime for text", "depth": [1, 3]}, {"source": "control", "target": "optimal control", "depth": [1, 1]}, {"source": "control", "target": "state", "depth": [1, 1]}, {"source": "control", "target": "simulation study", "depth": [1, 3]}, {"source": "control", "target": "study on turnpike", "depth": [1, 3]}, {"source": "control", "target": "turnpikes in stochastic", "depth": [1, 3]}, {"source": "problem", "target": "stream of problem", "depth": [1, 3]}, {"source": "problem", "target": "security", "depth": [1, 2]}, {"source": "problem", "target": "stream", "depth": [1, 2]}, {"source": "problem", "target": "bandit problem", "depth": [1, 3]}, {"source": "problem", "target": "practical guide", "depth": [1, 2]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "graph embedding", "depth": [1, 1]}, {"source": "embedding", "target": "euclidean space", "depth": [1, 3]}, {"source": "embedding", "target": "embedding of hierarchical", "depth": [1, 3]}, {"source": "embedding", "target": "hierarchical structure", "depth": [1, 3]}, {"source": "evaluation", "target": "f-measure to roc", "depth": [1, 3]}, {"source": "evaluation", "target": "recall and f-measure", "depth": [1, 3]}, {"source": "evaluation", "target": "markedness and correlation", "depth": [1, 3]}, {"source": "evaluation", "target": "informednes", "depth": [1, 3]}, {"source": "evaluation", "target": "roc", "depth": [1, 3]}, {"source": "language understanding", "target": "spoken language understanding", "depth": [1, 1]}, {"source": "language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "language understanding", "target": "natural language understanding", "depth": [1, 2]}, {"source": "language understanding", "target": "improving language understanding", "depth": [1, 3]}, {"source": "language understanding", "target": "improving language", "depth": [1, 3]}, {"source": "function", "target": "isabelle function", "depth": [1, 3]}, {"source": "function", "target": "lucas-interpretation on isabelle", "depth": [1, 3]}, {"source": "function", "target": "isabelle", "depth": [1, 2]}, {"source": "function", "target": "lucas-interpretation", "depth": [1, 3]}, {"source": "function", "target": "image classification", "depth": [1, 1]}, {"source": "adversarial network", "target": "varying human skin", "depth": [1, 3]}, {"source": "adversarial network", "target": "human skin tone", "depth": [1, 3]}, {"source": "adversarial network", "target": "unsupervised approach", "depth": [1, 3]}, {"source": "adversarial network", "target": "approach towards varying", "depth": [1, 3]}, {"source": "adversarial network", "target": "varying human", "depth": [1, 3]}, {"source": "feature selection", "target": "information-theoretic feature selection", "depth": [1, 3]}, {"source": "feature selection", "target": "decomposition and submodularity", "depth": [1, 3]}, {"source": "feature selection", "target": "selection via tensor", "depth": [1, 3]}, {"source": "feature selection", "target": "tensor decomposition", "depth": [1, 1]}, {"source": "feature selection", "target": "information-theoretic feature", "depth": [1, 3]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "adversarial deep reinforcement", "depth": [1, 3]}, {"source": "learning approach", "target": "synthetic news generation", "depth": [1, 3]}, {"source": "learning approach", "target": "adversarial deep", "depth": [1, 3]}, {"source": "generative adversarial", "target": "lightweight generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "text-guided image manipulation", "depth": [1, 3]}, {"source": "generative adversarial", "target": "image manipulation", "depth": [1, 3]}, {"source": "generative adversarial", "target": "conditional generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative adversarial framework", "depth": [1, 3]}, {"source": "challenge", "target": "challenges and opportunity", "depth": [1, 2]}, {"source": "challenge", "target": "opportunity", "depth": [1, 3]}, {"source": "challenge", "target": "image extreme inpainting", "depth": [1, 3]}, {"source": "challenge", "target": "challenge on image", "depth": [1, 3]}, {"source": "challenge", "target": "extreme inpainting", "depth": [1, 3]}, {"source": "training", "target": "adversarial training", "depth": [1, 1]}, {"source": "training", "target": "robust", "depth": [1, 1]}, {"source": "training", "target": "progressive bert training", "depth": [1, 3]}, {"source": "training", "target": "bert training", "depth": [1, 3]}, {"source": "training", "target": "transformer growth", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack", "depth": [1, 1]}, {"source": "adversarial attack", "target": "black-box adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "detecting adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "neural networks serve", "depth": [1, 3]}, {"source": "adversarial attack", "target": "state of relevant", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "architecture search", "target": "search", "depth": [1, 1]}, {"source": "architecture search", "target": "cooperative multi-component architecture", "depth": [1, 3]}, {"source": "fast", "target": "fast and slow", "depth": [1, 2]}, {"source": "fast", "target": "slow decision making", "depth": [1, 3]}, {"source": "fast", "target": "decision making", "depth": [1, 1]}, {"source": "fast", "target": "slow decision", "depth": [1, 3]}, {"source": "fast", "target": "interleaving fast", "depth": [1, 3]}, {"source": "point cloud", "target": "cloud", "depth": [1, 1]}, {"source": "point cloud", "target": "frameworkfor reproducible deep", "depth": [1, 3]}, {"source": "point cloud", "target": "reproducible deep learning", "depth": [1, 3]}, {"source": "point cloud", "target": "modular multi-task frameworkfor", "depth": [1, 3]}, {"source": "point cloud", "target": "multi-task frameworkfor reproducible", "depth": [1, 3]}, {"source": "voice conversion", "target": "voice conversion challenge", "depth": [1, 2]}, {"source": "voice conversion", "target": "conversion challenge", "depth": [1, 2]}, {"source": "voice conversion", "target": "variational autoencoder", "depth": [1, 1]}, {"source": "voice conversion", "target": "discrete speech representation", "depth": [1, 3]}, {"source": "voice conversion", "target": "self-supervised discrete speech", "depth": [1, 3]}, {"source": "approach", "target": "sensor fusion approach", "depth": [1, 3]}, {"source": "approach", "target": "sensor fusion", "depth": [1, 2]}, {"source": "approach", "target": "fusion approach", "depth": [1, 3]}, {"source": "approach", "target": "viral-fusion", "depth": [1, 3]}, {"source": "approach", "target": "sensor", "depth": [1, 3]}, {"source": "approximation", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "approximation", "target": "kernelized bandit", "depth": [1, 3]}, {"source": "approximation", "target": "methods for kernelized", "depth": [1, 3]}, {"source": "approximation", "target": "approximation method", "depth": [1, 3]}, {"source": "approximation", "target": "bandit", "depth": [1, 1]}, {"source": "recurrent neural network", "target": "convolutional recurrent neural", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "long short term", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "short term memory", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "term memory recurrent", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "memory recurrent neural", "depth": [1, 3]}, {"source": "tree", "target": "decision tree", "depth": [1, 1]}, {"source": "tree", "target": "decision", "depth": [1, 2]}, {"source": "tree", "target": "probability tree", "depth": [1, 3]}, {"source": "tree", "target": "causal reasoning", "depth": [1, 3]}, {"source": "tree", "target": "reasoning in probability", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 2]}, {"source": "pose estimation", "target": "detection and pose", "depth": [1, 3]}, {"source": "pose estimation", "target": "weakly supervised", "depth": [1, 2]}, {"source": "pose estimation", "target": "bounds of projection", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "deep convolutional network", "depth": [1, 3]}, {"source": "convolutional network", "target": "dynamic graph convolutional", "depth": [1, 3]}, {"source": "convolutional network", "target": "dynamic graph", "depth": [1, 2]}, {"source": "word embedding", "target": "multiclass debiasing method", "depth": [1, 3]}, {"source": "word embedding", "target": "thy algorithm shalt", "depth": [1, 3]}, {"source": "word embedding", "target": "bear false witnes", "depth": [1, 3]}, {"source": "word embedding", "target": "evaluation of multiclas", "depth": [1, 3]}, {"source": "word embedding", "target": "multiclass debiasing", "depth": [1, 3]}, {"source": "differential equation", "target": "ordinary differential equation", "depth": [1, 2]}, {"source": "differential equation", "target": "neural ordinary differential", "depth": [1, 2]}, {"source": "differential equation", "target": "stochastic differential equation", "depth": [1, 2]}, {"source": "differential equation", "target": "partial differential equation", "depth": [1, 2]}, {"source": "differential equation", "target": "positivity preserving logarithmic", "depth": [1, 3]}, {"source": "text classification", "target": "weak supervision", "depth": [1, 2]}, {"source": "text classification", "target": "cross-lingual text classification", "depth": [1, 3]}, {"source": "text classification", "target": "benchmarking cross-lingual text", "depth": [1, 3]}, {"source": "text classification", "target": "kinnews and kirnews", "depth": [1, 3]}, {"source": "text classification", "target": "kinyarwanda and kirundi", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "tweet", "depth": [1, 1]}, {"source": "sentiment analysi", "target": "aspect-based sentiment analysi", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "sentiment", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "latvian tweet", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "strategies for sentiment", "depth": [1, 3]}, {"source": "bandit", "target": "thresholded lasso bandit", "depth": [1, 3]}, {"source": "bandit", "target": "lasso bandit", "depth": [1, 3]}, {"source": "bandit", "target": "thresholded lasso", "depth": [1, 3]}, {"source": "bandit", "target": "lasso", "depth": [1, 3]}, {"source": "bandit", "target": "thresholded", "depth": [1, 3]}, {"source": "clustering", "target": "learning multi-layer graph", "depth": [1, 3]}, {"source": "clustering", "target": "representation for clustering", "depth": [1, 3]}, {"source": "clustering", "target": "multi-layer graph", "depth": [1, 3]}, {"source": "clustering", "target": "common representation", "depth": [1, 3]}, {"source": "clustering", "target": "learning multi-layer", "depth": [1, 3]}, {"source": "feature", "target": "speech", "depth": [1, 1]}, {"source": "feature", "target": "learn robust feature", "depth": [1, 3]}, {"source": "feature", "target": "robust feature", "depth": [1, 3]}, {"source": "feature", "target": "features via orthogonal", "depth": [1, 3]}, {"source": "feature", "target": "learn robust", "depth": [1, 3]}, {"source": "dataset", "target": "patterns count-based label", "depth": [1, 3]}, {"source": "dataset", "target": "labels for dataset", "depth": [1, 3]}, {"source": "dataset", "target": "count-based label", "depth": [1, 3]}, {"source": "dataset", "target": "label", "depth": [1, 2]}, {"source": "dataset", "target": "pattern", "depth": [1, 1]}, {"source": "generalization", "target": "semantic parsing", "depth": [1, 1]}, {"source": "generalization", "target": "domain generalization", "depth": [1, 3]}, {"source": "generalization", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "generalization", "target": "meta-learning for domain", "depth": [1, 3]}, {"source": "generalization", "target": "parsing", "depth": [1, 1]}, {"source": "structure", "target": "concurrent process history", "depth": [1, 3]}, {"source": "structure", "target": "process history", "depth": [1, 3]}, {"source": "structure", "target": "structure of concurrent", "depth": [1, 3]}, {"source": "structure", "target": "concurrent proces", "depth": [1, 3]}, {"source": "structure", "target": "history", "depth": [1, 3]}, {"source": "graph embedding", "target": "knowledge graph embedding", "depth": [1, 1]}, {"source": "graph embedding", "target": "residual learning", "depth": [1, 3]}, {"source": "graph embedding", "target": "embedding with atrou", "depth": [1, 3]}, {"source": "graph embedding", "target": "atrous convolution", "depth": [1, 3]}, {"source": "graph embedding", "target": "convolution and residual", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 2]}, {"source": "social network", "target": "ldbc social network", "depth": [1, 3]}, {"source": "social network", "target": "social network graph", "depth": [1, 3]}, {"source": "social network", "target": "programming contest", "depth": [1, 3]}, {"source": "social network", "target": "complex query", "depth": [1, 3]}, {"source": "application", "target": "nlp application", "depth": [1, 3]}, {"source": "application", "target": "cloud-assisted middleware-based iot", "depth": [1, 3]}, {"source": "application", "target": "enhancement of non-functional", "depth": [1, 3]}, {"source": "application", "target": "requirements for cloud-assisted", "depth": [1, 3]}, {"source": "application", "target": "middleware-based iot", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "artificial intelligence symposium", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "upper-rhine artificial intelligence", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "research impact", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "key industry", "depth": [1, 3]}, {"source": "relation extraction", "target": "semi-supervised relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "distantly-supervised relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "consistent evaluation", "depth": [1, 3]}, {"source": "relation extraction", "target": "accurate and consistent", "depth": [1, 3]}, {"source": "relation extraction", "target": "dataset for distantly-supervised", "depth": [1, 3]}, {"source": "fairnes", "target": "optimal transport", "depth": [1, 1]}, {"source": "fairnes", "target": "fairness for edge", "depth": [1, 3]}, {"source": "fairnes", "target": "edge prediction", "depth": [1, 3]}, {"source": "fairnes", "target": "prediction with optimal", "depth": [1, 3]}, {"source": "fairnes", "target": "transport", "depth": [1, 2]}, {"source": "perspective", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "perspective", "target": "combinatorial", "depth": [1, 1]}, {"source": "perspective", "target": "minimal code", "depth": [1, 3]}, {"source": "perspective", "target": "perspectives on minimal", "depth": [1, 3]}, {"source": "perspective", "target": "minimal", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo tree search", "depth": [1, 3]}, {"source": "monte carlo", "target": "monte carlo tree", "depth": [1, 3]}, {"source": "monte carlo", "target": "tree search", "depth": [1, 3]}, {"source": "monte carlo", "target": "goal directed molecule", "depth": [1, 3]}, {"source": "monte carlo", "target": "carlo tree", "depth": [1, 3]}, {"source": "robust", "target": "robust training", "depth": [1, 3]}, {"source": "robust", "target": "learn robust feature", "depth": [1, 3]}, {"source": "robust", "target": "robust feature", "depth": [1, 3]}, {"source": "robust", "target": "features via orthogonal", "depth": [1, 3]}, {"source": "robust", "target": "learn robust", "depth": [1, 3]}, {"source": "spiking neural network", "target": "superposition spiking neural", "depth": [1, 3]}, {"source": "spiking neural network", "target": "quantum superposition spiking", "depth": [1, 3]}, {"source": "spiking neural network", "target": "superposition spiking", "depth": [1, 3]}, {"source": "spiking neural network", "target": "quantum superposition", "depth": [1, 3]}, {"source": "spiking neural network", "target": "deep spiking neural", "depth": [1, 3]}, {"source": "architecture", "target": "neural architecture search", "depth": [1, 1]}, {"source": "architecture", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture", "target": "search", "depth": [1, 1]}, {"source": "architecture", "target": "supernet", "depth": [1, 3]}, {"source": "architecture", "target": "europe and usa", "depth": [1, 3]}, {"source": "graph representation", "target": "graph representation learning", "depth": [1, 1]}, {"source": "graph representation", "target": "high-performance graph representation", "depth": [1, 3]}, {"source": "graph representation", "target": "near-optimal high-performance graph", "depth": [1, 3]}, {"source": "graph representation", "target": "high-performance graph", "depth": [1, 3]}, {"source": "graph representation", "target": "near-optimal high-performance", "depth": [1, 3]}, {"source": "space", "target": "euclidean space", "depth": [1, 3]}, {"source": "space", "target": "embedding of hierarchical", "depth": [1, 3]}, {"source": "space", "target": "hierarchical structure", "depth": [1, 3]}, {"source": "space", "target": "structure in euclidean", "depth": [1, 3]}, {"source": "space", "target": "unsupervised embedding", "depth": [1, 3]}, {"source": "image segmentation", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "image segmentation", "target": "medical image", "depth": [1, 1]}, {"source": "image segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "image segmentation", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "image segmentation", "target": "mixed supervision", "depth": [1, 3]}, {"source": "motion planning", "target": "motion", "depth": [1, 2]}, {"source": "motion planning", "target": "planning", "depth": [1, 1]}, {"source": "motion planning", "target": "explainable multi-robot motion", "depth": [1, 3]}, {"source": "motion planning", "target": "multi-robot motion planning", "depth": [1, 3]}, {"source": "motion planning", "target": "planning via segmentation", "depth": [1, 3]}, {"source": "language processing", "target": "nlp", "depth": [1, 1]}, {"source": "language processing", "target": "processing", "depth": [1, 1]}, {"source": "language processing", "target": "cross-lingual natural language", "depth": [1, 3]}, {"source": "language processing", "target": "language processing framework", "depth": [1, 3]}, {"source": "language processing", "target": "infodemic management", "depth": [1, 3]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 1]}, {"source": "attention network", "target": "graph attention", "depth": [1, 1]}, {"source": "attention network", "target": "ris-assisted haps backhauling", "depth": [1, 3]}, {"source": "attention network", "target": "full-duplex ris-assisted hap", "depth": [1, 3]}, {"source": "attention network", "target": "haps backhauling", "depth": [1, 3]}, {"source": "extended version", "target": "extended", "depth": [1, 1]}, {"source": "extended version", "target": "version", "depth": [1, 2]}, {"source": "extended version", "target": "equivalence for assisted", "depth": [1, 3]}, {"source": "extended version", "target": "assisted grading", "depth": [1, 3]}, {"source": "extended version", "target": "grading of functional", "depth": [1, 3]}, {"source": "speech", "target": "speech translation", "depth": [1, 2]}, {"source": "speech", "target": "adaptive feature selection", "depth": [1, 3]}, {"source": "speech", "target": "adaptive feature", "depth": [1, 2]}, {"source": "speech", "target": "children speech", "depth": [1, 3]}, {"source": "speech", "target": "disfluency in child", "depth": [1, 3]}, {"source": "blockchain", "target": "state sharding model", "depth": [1, 3]}, {"source": "blockchain", "target": "state sharding", "depth": [1, 3]}, {"source": "blockchain", "target": "sharding model", "depth": [1, 3]}, {"source": "blockchain", "target": "state", "depth": [1, 1]}, {"source": "blockchain", "target": "sharding", "depth": [1, 3]}, {"source": "game", "target": "zero-sum stochastic game", "depth": [1, 3]}, {"source": "game", "target": "fictitious play", "depth": [1, 2]}, {"source": "game", "target": "stochastic game", "depth": [1, 2]}, {"source": "game", "target": "play in zero-sum", "depth": [1, 3]}, {"source": "game", "target": "fictitiou", "depth": [1, 3]}, {"source": "attention", "target": "channel parallel sampling", "depth": [1, 3]}, {"source": "attention", "target": "groups of channel", "depth": [1, 3]}, {"source": "attention", "target": "sampling with attention", "depth": [1, 3]}, {"source": "attention", "target": "channel parallel", "depth": [1, 3]}, {"source": "attention", "target": "parallel sampling", "depth": [1, 3]}, {"source": "graph convolutional", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "graph convolutional", "target": "graph convolutional neural", "depth": [1, 2]}, {"source": "graph convolutional", "target": "dynamic graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional", "target": "dynamic graph", "depth": [1, 2]}, {"source": "graph convolutional", "target": "predicting biomedical interaction", "depth": [1, 3]}, {"source": "inference", "target": "bound membership inference", "depth": [1, 3]}, {"source": "inference", "target": "differentially private learning", "depth": [1, 3]}, {"source": "inference", "target": "membership inference", "depth": [1, 3]}, {"source": "inference", "target": "private learning", "depth": [1, 3]}, {"source": "inference", "target": "bound membership", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoder", "depth": [1, 1]}, {"source": "variational autoencoder", "target": "voice conversion challenge", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "conversion challenge", "depth": [1, 2]}, {"source": "variational autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "dirichlet graph variational", "depth": [1, 3]}, {"source": "classifier", "target": "network classifiers based", "depth": [1, 3]}, {"source": "classifier", "target": "social learning", "depth": [1, 2]}, {"source": "classifier", "target": "classifiers based", "depth": [1, 3]}, {"source": "classifier", "target": "based on social", "depth": [1, 3]}, {"source": "classifier", "target": "network classifier", "depth": [1, 3]}, {"source": "learning framework", "target": "deep learning framework", "depth": [1, 1]}, {"source": "learning framework", "target": "earnings call", "depth": [1, 3]}, {"source": "learning framework", "target": "framework for measuring", "depth": [1, 3]}, {"source": "learning framework", "target": "measuring the digital", "depth": [1, 3]}, {"source": "learning framework", "target": "digital strategy", "depth": [1, 3]}, {"source": "computing", "target": "productive performance", "depth": [1, 3]}, {"source": "computing", "target": "systolic computing", "depth": [1, 3]}, {"source": "computing", "target": "computing on gpu", "depth": [1, 3]}, {"source": "computing", "target": "gpus for productive", "depth": [1, 3]}, {"source": "computing", "target": "performance", "depth": [1, 1]}, {"source": "active learning", "target": "pretext-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "pal", "depth": [1, 3]}, {"source": "active learning", "target": "pool-based active learning", "depth": [1, 3]}, {"source": "active learning", "target": "aldataset", "depth": [1, 3]}, {"source": "active learning", "target": "benchmark for pool-based", "depth": [1, 3]}, {"source": "logic", "target": "hol", "depth": [1, 1]}, {"source": "logic", "target": "teaching logic", "depth": [1, 3]}, {"source": "logic", "target": "isabelle", "depth": [1, 2]}, {"source": "logic", "target": "meta-language for teaching", "depth": [1, 3]}, {"source": "logic", "target": "teaching", "depth": [1, 2]}, {"source": "matrix", "target": "matrices are underrated", "depth": [1, 3]}, {"source": "matrix", "target": "correspondence matrix", "depth": [1, 3]}, {"source": "matrix", "target": "correspondence", "depth": [1, 3]}, {"source": "matrix", "target": "left exact category", "depth": [1, 3]}, {"source": "matrix", "target": "exact category", "depth": [1, 3]}, {"source": "sampling", "target": "thompson sampling", "depth": [1, 3]}, {"source": "sampling", "target": "marginalised gaussian process", "depth": [1, 3]}, {"source": "sampling", "target": "nested sampling", "depth": [1, 3]}, {"source": "sampling", "target": "gaussian process", "depth": [1, 2]}, {"source": "sampling", "target": "processes with nested", "depth": [1, 3]}, {"source": "neural architecture", "target": "search", "depth": [1, 1]}, {"source": "neural architecture", "target": "joint neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "autotuned data-parallel training", "depth": [1, 3]}, {"source": "neural architecture", "target": "joint neural", "depth": [1, 3]}, {"source": "neural architecture", "target": "tabular datum", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image classification", "depth": [1, 2]}, {"source": "image classification", "target": "hyperspectral image", "depth": [1, 2]}, {"source": "image classification", "target": "loss function", "depth": [1, 3]}, {"source": "image classification", "target": "function for image", "depth": [1, 3]}, {"source": "image classification", "target": "los", "depth": [1, 1]}, {"source": "neural architecture search", "target": "efficient neural architecture", "depth": [1, 2]}, {"source": "neural architecture search", "target": "search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "based physics-informed neural", "depth": [1, 3]}, {"source": "neural architecture search", "target": "heterogeneous porous material", "depth": [1, 3]}, {"source": "neural architecture search", "target": "modified neural architecture", "depth": [1, 3]}, {"source": "style transfer", "target": "text style transfer", "depth": [1, 2]}, {"source": "style transfer", "target": "text style", "depth": [1, 2]}, {"source": "style transfer", "target": "unsupervised text style", "depth": [1, 2]}, {"source": "style transfer", "target": "artists style transfer", "depth": [1, 3]}, {"source": "style transfer", "target": "multiple artists style", "depth": [1, 3]}, {"source": "differentially private", "target": "regularized mahalanobis metric", "depth": [1, 3]}, {"source": "differentially private", "target": "differentially private text", "depth": [1, 3]}, {"source": "differentially private", "target": "private text perturbation", "depth": [1, 3]}, {"source": "differentially private", "target": "text perturbation method", "depth": [1, 3]}, {"source": "differentially private", "target": "mahalanobis metric", "depth": [1, 3]}, {"source": "optimal control", "target": "simulation study", "depth": [1, 3]}, {"source": "optimal control", "target": "study on turnpike", "depth": [1, 3]}, {"source": "optimal control", "target": "turnpikes in stochastic", "depth": [1, 3]}, {"source": "optimal control", "target": "stochastic lq optimal", "depth": [1, 3]}, {"source": "optimal control", "target": "simulation", "depth": [1, 1]}, {"source": "bayesian", "target": "bayesian optimization", "depth": [1, 1]}, {"source": "bayesian", "target": "scalable bayesian learning", "depth": [1, 3]}, {"source": "bayesian", "target": "bayesian learning", "depth": [1, 3]}, {"source": "bayesian", "target": "learning of causal", "depth": [1, 3]}, {"source": "bayesian", "target": "causal dag", "depth": [1, 3]}, {"source": "framework", "target": "high density anomaly", "depth": [1, 3]}, {"source": "framework", "target": "density anomaly", "depth": [1, 3]}, {"source": "framework", "target": "detection of high", "depth": [1, 3]}, {"source": "framework", "target": "high density", "depth": [1, 3]}, {"source": "framework", "target": "algorithmic framework", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "long financial report", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "conditional variational autoencoder", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "generating long financial", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "financial report", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "report using conditional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "dynamic graph convolutional", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "dynamic graph", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "action recognition", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "human action recognition", "depth": [1, 2]}, {"source": "graph convolutional network", "target": "attention-augmented graph convolutional", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "lidar semantic segmentation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "adaptation in lidar", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "adaptation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "discrete wasserstein training", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "importance-aware semantic segmentation", "depth": [1, 3]}, {"source": "differential privacy", "target": "privacy", "depth": [1, 1]}, {"source": "differential privacy", "target": "local differential privacy", "depth": [1, 2]}, {"source": "differential privacy", "target": "application-agnostic data sharing", "depth": [1, 3]}, {"source": "differential privacy", "target": "learning to noise", "depth": [1, 3]}, {"source": "differential privacy", "target": "data sharing", "depth": [1, 3]}, {"source": "named entity recognition", "target": "entity recognition", "depth": [1, 1]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "joint named entity", "depth": [1, 3]}, {"source": "named entity recognition", "target": "study of joint", "depth": [1, 3]}, {"source": "named entity recognition", "target": "joint named", "depth": [1, 3]}, {"source": "attack", "target": "backdoor attack", "depth": [1, 2]}, {"source": "attack", "target": "improve captcha robustnes", "depth": [1, 3]}, {"source": "attack", "target": "bot attack", "depth": [1, 3]}, {"source": "attack", "target": "improve captcha", "depth": [1, 3]}, {"source": "attack", "target": "captcha robustnes", "depth": [1, 3]}, {"source": "multi-task learning", "target": "speech enhancement aided", "depth": [1, 3]}, {"source": "multi-task learning", "target": "voice activity detection", "depth": [1, 2]}, {"source": "multi-task learning", "target": "speech enhancement", "depth": [1, 1]}, {"source": "multi-task learning", "target": "enhancement aided", "depth": [1, 3]}, {"source": "multi-task learning", "target": "activity detection", "depth": [1, 2]}, {"source": "environment", "target": "controller for escaping", "depth": [1, 3]}, {"source": "environment", "target": "escaping trap", "depth": [1, 3]}, {"source": "environment", "target": "tampc", "depth": [1, 3]}, {"source": "environment", "target": "controller", "depth": [1, 2]}, {"source": "environment", "target": "escaping", "depth": [1, 3]}, {"source": "action recognition", "target": "human action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 3]}, {"source": "action recognition", "target": "attention-augmented graph convolutional", "depth": [1, 3]}, {"source": "action recognition", "target": "efficient skeleton-based human", "depth": [1, 3]}, {"source": "action recognition", "target": "skeleton-based human action", "depth": [1, 3]}, {"source": "transfer", "target": "knowledge transfer", "depth": [1, 1]}, {"source": "transfer", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "transfer", "target": "perspective on transfer", "depth": [1, 3]}, {"source": "transfer", "target": "combinatorial", "depth": [1, 1]}, {"source": "transfer", "target": "adversarial knowledge transfer", "depth": [1, 3]}, {"source": "online learning", "target": "projection-free online learning", "depth": [1, 3]}, {"source": "online learning", "target": "strongly convex", "depth": [1, 2]}, {"source": "online learning", "target": "projection-free online", "depth": [1, 3]}, {"source": "online learning", "target": "lipschitz continuity", "depth": [1, 3]}, {"source": "online learning", "target": "bounds without lipschitz", "depth": [1, 3]}, {"source": "action", "target": "combinatorial action", "depth": [1, 3]}, {"source": "action", "target": "vehicle routing", "depth": [1, 2]}, {"source": "action", "target": "learning with combinatorial", "depth": [1, 3]}, {"source": "action", "target": "application to vehicle", "depth": [1, 3]}, {"source": "action", "target": "routing", "depth": [1, 3]}, {"source": "decision tree", "target": "decision", "depth": [1, 2]}, {"source": "decision tree", "target": "online decision tree", "depth": [1, 3]}, {"source": "decision tree", "target": "online decision", "depth": [1, 2]}, {"source": "decision tree", "target": "trees with fairnes", "depth": [1, 3]}, {"source": "decision tree", "target": "streaming decision tree", "depth": [1, 3]}, {"source": "contrastive", "target": "learning with adversarial", "depth": [1, 3]}, {"source": "contrastive", "target": "learning of unsupervised", "depth": [1, 3]}, {"source": "contrastive", "target": "cloud", "depth": [1, 1]}, {"source": "contrastive", "target": "predictive plasticity", "depth": [1, 3]}, {"source": "contrastive", "target": "gradients with clapp", "depth": [1, 3]}, {"source": "communication", "target": "strategic communication", "depth": [1, 3]}, {"source": "communication", "target": "multiway relay communication", "depth": [1, 3]}, {"source": "communication", "target": "fundamental issue", "depth": [1, 3]}, {"source": "communication", "target": "recent advance", "depth": [1, 3]}, {"source": "communication", "target": "relay communication", "depth": [1, 3]}, {"source": "simulation", "target": "simulation study", "depth": [1, 3]}, {"source": "simulation", "target": "study on turnpike", "depth": [1, 3]}, {"source": "simulation", "target": "turnpikes in stochastic", "depth": [1, 3]}, {"source": "simulation", "target": "stochastic lq optimal", "depth": [1, 3]}, {"source": "simulation", "target": "simulation of flexible", "depth": [1, 3]}, {"source": "constraint", "target": "power constraint", "depth": [1, 3]}, {"source": "constraint", "target": "identification over channel", "depth": [1, 3]}, {"source": "constraint", "target": "channels with power", "depth": [1, 3]}, {"source": "constraint", "target": "deterministic identification", "depth": [1, 3]}, {"source": "constraint", "target": "identification", "depth": [1, 1]}, {"source": "information", "target": "sell hard information", "depth": [1, 3]}, {"source": "information", "target": "hard information", "depth": [1, 3]}, {"source": "information", "target": "sell hard", "depth": [1, 3]}, {"source": "information", "target": "sell", "depth": [1, 3]}, {"source": "information", "target": "enriching word embedding", "depth": [1, 3]}, {"source": "time series", "target": "series", "depth": [1, 3]}, {"source": "time series", "target": "time series forecasting", "depth": [1, 2]}, {"source": "time series", "target": "series forecasting", "depth": [1, 3]}, {"source": "time series", "target": "weekly time series", "depth": [1, 3]}, {"source": "time series", "target": "strong baseline", "depth": [1, 3]}, {"source": "text generation", "target": "continuous and discrete", "depth": [1, 3]}, {"source": "text generation", "target": "discrete space", "depth": [1, 2]}, {"source": "text generation", "target": "spaces for text", "depth": [1, 3]}, {"source": "text generation", "target": "collaborative training", "depth": [1, 3]}, {"source": "text generation", "target": "training of gan", "depth": [1, 3]}, {"source": "summarization", "target": "text summarization", "depth": [1, 2]}, {"source": "summarization", "target": "edit-based unsupervised summarization", "depth": [1, 3]}, {"source": "summarization", "target": "unsupervised summarization", "depth": [1, 3]}, {"source": "summarization", "target": "model for edit-based", "depth": [1, 3]}, {"source": "summarization", "target": "q-learning with language", "depth": [1, 3]}, {"source": "adversarial training", "target": "overfitting or underfitting", "depth": [1, 3]}, {"source": "adversarial training", "target": "underfitting", "depth": [1, 3]}, {"source": "adversarial training", "target": "understand robustness drop", "depth": [1, 3]}, {"source": "adversarial training", "target": "robustness drop", "depth": [1, 3]}, {"source": "adversarial training", "target": "drop in adversarial", "depth": [1, 3]}, {"source": "graph attention network", "target": "graph attention", "depth": [1, 1]}, {"source": "graph attention network", "target": "multimodal language sequence", "depth": [1, 3]}, {"source": "graph attention network", "target": "temporal graph attention", "depth": [1, 3]}, {"source": "graph attention network", "target": "unaligned human multimodal", "depth": [1, 3]}, {"source": "graph attention network", "target": "multimodal temporal graph", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "fuzzy query attention", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "multi-agent trajectory prediction", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "query attention", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "prediction with fuzzy", "depth": [1, 3]}, {"source": "trajectory prediction", "target": "fuzzy query", "depth": [1, 3]}, {"source": "state", "target": "state sharding model", "depth": [1, 3]}, {"source": "state", "target": "state sharding", "depth": [1, 3]}, {"source": "state", "target": "sharding model", "depth": [1, 3]}, {"source": "state", "target": "sharding", "depth": [1, 3]}, {"source": "state", "target": "state space model", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 1]}, {"source": "medical image", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "medical image", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "medical image", "target": "mixed supervision", "depth": [1, 3]}, {"source": "medical image", "target": "framework for semi-supervised", "depth": [1, 3]}, {"source": "decision making", "target": "making", "depth": [1, 3]}, {"source": "decision making", "target": "slow decision making", "depth": [1, 3]}, {"source": "decision making", "target": "fast and slow", "depth": [1, 2]}, {"source": "decision making", "target": "slow decision", "depth": [1, 3]}, {"source": "decision making", "target": "interleaving fast", "depth": [1, 3]}, {"source": "decomposition", "target": "matrix decomposition", "depth": [1, 3]}, {"source": "decomposition", "target": "graph-regularization for matrix", "depth": [1, 3]}, {"source": "decomposition", "target": "learnable graph-regularization", "depth": [1, 3]}, {"source": "decomposition", "target": "graph-regularization", "depth": [1, 3]}, {"source": "decomposition", "target": "reward attribution decomposition", "depth": [1, 3]}, {"source": "identification", "target": "deterministic identification", "depth": [1, 3]}, {"source": "identification", "target": "channel", "depth": [1, 1]}, {"source": "identification", "target": "identification of informative", "depth": [1, 3]}, {"source": "identification", "target": "english tweet", "depth": [1, 3]}, {"source": "identification", "target": "tweet", "depth": [1, 1]}, {"source": "autoencoder", "target": "graph variational autoencoder", "depth": [1, 3]}, {"source": "autoencoder", "target": "dirichlet graph variational", "depth": [1, 3]}, {"source": "autoencoder", "target": "graph variational", "depth": [1, 3]}, {"source": "autoencoder", "target": "dirichlet graph", "depth": [1, 3]}, {"source": "autoencoder", "target": "implicit rank-minimizing autoencoder", "depth": [1, 3]}, {"source": "recommendation", "target": "neighbor-aware graph attention", "depth": [1, 3]}, {"source": "recommendation", "target": "network for recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "neighbor-aware graph", "depth": [1, 3]}, {"source": "recommendation", "target": "online recommendation system", "depth": [1, 3]}, {"source": "recommendation", "target": "recommendation system", "depth": [1, 2]}, {"source": "abstractive summarization", "target": "neural abstractive summarization", "depth": [1, 2]}, {"source": "abstractive summarization", "target": "guided neural abstractive", "depth": [1, 3]}, {"source": "abstractive summarization", "target": "general framework", "depth": [1, 2]}, {"source": "abstractive summarization", "target": "framework for guided", "depth": [1, 3]}, {"source": "abstractive summarization", "target": "multimodal abstractive summarization", "depth": [1, 3]}, {"source": "graph attention", "target": "ris-assisted haps backhauling", "depth": [1, 3]}, {"source": "graph attention", "target": "full-duplex ris-assisted hap", "depth": [1, 3]}, {"source": "graph attention", "target": "haps backhauling", "depth": [1, 3]}, {"source": "graph attention", "target": "backhauling with graph", "depth": [1, 3]}, {"source": "graph attention", "target": "neighbor-aware graph attention", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "imbalanced domain adaptation", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "fair knowledge transfer", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "fair knowledge", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "transfer for imbalanced", "depth": [1, 3]}, {"source": "knowledge transfer", "target": "imbalanced domain", "depth": [1, 3]}, {"source": "natural language inference", "target": "trainable natural logic", "depth": [1, 3]}, {"source": "natural language inference", "target": "logic theorem prover", "depth": [1, 3]}, {"source": "natural language inference", "target": "natural logic theorem", "depth": [1, 3]}, {"source": "natural language inference", "target": "learning as abduction", "depth": [1, 3]}, {"source": "natural language inference", "target": "multimodal contrastive learning", "depth": [1, 3]}, {"source": "language inference", "target": "trainable natural logic", "depth": [1, 3]}, {"source": "language inference", "target": "logic theorem prover", "depth": [1, 3]}, {"source": "language inference", "target": "natural logic theorem", "depth": [1, 3]}, {"source": "language inference", "target": "learning as abduction", "depth": [1, 3]}, {"source": "language inference", "target": "multimodal contrastive learning", "depth": [1, 3]}, {"source": "policy", "target": "policy optimization", "depth": [1, 1]}, {"source": "policy", "target": "optimization with multiple", "depth": [1, 3]}, {"source": "policy", "target": "multiple optima", "depth": [1, 3]}, {"source": "policy", "target": "optima for reinforcement", "depth": [1, 3]}, {"source": "policy", "target": "pomo", "depth": [1, 3]}, {"source": "object", "target": "scene representation", "depth": [1, 2]}, {"source": "object", "target": "object recognition", "depth": [1, 1]}, {"source": "object", "target": "quantizing neural", "depth": [1, 3]}, {"source": "object", "target": "scene", "depth": [1, 2]}, {"source": "object", "target": "orthogonal object", "depth": [1, 3]}, {"source": "online", "target": "online recommendation system", "depth": [1, 3]}, {"source": "online", "target": "recommendation system", "depth": [1, 2]}, {"source": "online", "target": "online recommendation", "depth": [1, 3]}, {"source": "online", "target": "regret in online", "depth": [1, 3]}, {"source": "online", "target": "online non-convex optimization", "depth": [1, 3]}, {"source": "deep network", "target": "complex dynamics forecasting", "depth": [1, 3]}, {"source": "deep network", "target": "augmenting physical model", "depth": [1, 3]}, {"source": "deep network", "target": "dynamics forecasting", "depth": [1, 3]}, {"source": "deep network", "target": "physical model", "depth": [1, 3]}, {"source": "deep network", "target": "models with deep", "depth": [1, 3]}, {"source": "learn", "target": "learning visual representation", "depth": [1, 3]}, {"source": "learn", "target": "human interaction", "depth": [1, 3]}, {"source": "learn", "target": "muscle", "depth": [1, 3]}, {"source": "learn", "target": "visual representation", "depth": [1, 2]}, {"source": "learn", "target": "representation from human", "depth": [1, 3]}, {"source": "cloud", "target": "learning of unsupervised", "depth": [1, 3]}, {"source": "cloud", "target": "edge continuum", "depth": [1, 3]}, {"source": "cloud", "target": "discussion on context-awarenes", "depth": [1, 3]}, {"source": "cloud", "target": "iot cloud", "depth": [1, 3]}, {"source": "cloud", "target": "context-awareness to bettersupport", "depth": [1, 3]}, {"source": "search", "target": "supernet", "depth": [1, 3]}, {"source": "search", "target": "channel pruning search", "depth": [1, 3]}, {"source": "search", "target": "differentiable channel pruning", "depth": [1, 3]}, {"source": "search", "target": "pruning search", "depth": [1, 3]}, {"source": "search", "target": "channel pruning", "depth": [1, 3]}, {"source": "privacy", "target": "regularized inference privacy", "depth": [1, 3]}, {"source": "privacy", "target": "data-driven regularized inference", "depth": [1, 3]}, {"source": "privacy", "target": "inference privacy", "depth": [1, 3]}, {"source": "privacy", "target": "regularized inference", "depth": [1, 3]}, {"source": "privacy", "target": "regularized", "depth": [1, 2]}, {"source": "empirical study", "target": "source code", "depth": [1, 2]}, {"source": "empirical study", "target": "study of transformer", "depth": [1, 3]}, {"source": "empirical study", "target": "transformers for source", "depth": [1, 3]}, {"source": "empirical study", "target": "study", "depth": [1, 1]}, {"source": "empirical study", "target": "protecting visual recommender", "depth": [1, 3]}, {"source": "deep learning model", "target": "learning model", "depth": [1, 1]}, {"source": "deep learning model", "target": "multi-disease chest x-ray", "depth": [1, 3]}, {"source": "deep learning model", "target": "generalized deep learning", "depth": [1, 3]}, {"source": "deep learning model", "target": "multi-disease chest", "depth": [1, 3]}, {"source": "deep learning model", "target": "chest x-ray", "depth": [1, 1]}, {"source": "deep learning based", "target": "learning based", "depth": [1, 2]}, {"source": "deep learning based", "target": "based collocation method", "depth": [1, 3]}, {"source": "deep learning based", "target": "dimensional potential problem", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based collocation", "depth": [1, 3]}, {"source": "deep learning based", "target": "collocation method", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "process regression", "depth": [1, 2]}, {"source": "gaussian proces", "target": "probabilistic states estimation", "depth": [1, 3]}, {"source": "gaussian proces", "target": "physics-informed gaussian proces", "depth": [1, 3]}, {"source": "gaussian proces", "target": "power grid", "depth": [1, 2]}, {"source": "performance", "target": "productive performance", "depth": [1, 3]}, {"source": "performance", "target": "systolic computing", "depth": [1, 3]}, {"source": "performance", "target": "computing on gpu", "depth": [1, 3]}, {"source": "performance", "target": "gpus for productive", "depth": [1, 3]}, {"source": "performance", "target": "performance cost", "depth": [1, 3]}, {"source": "policy optimization", "target": "optimization with multiple", "depth": [1, 3]}, {"source": "policy optimization", "target": "multiple optima", "depth": [1, 3]}, {"source": "policy optimization", "target": "optima for reinforcement", "depth": [1, 3]}, {"source": "policy optimization", "target": "pomo", "depth": [1, 3]}, {"source": "policy optimization", "target": "mitigation policy optimization", "depth": [1, 3]}, {"source": "computation", "target": "graph computation", "depth": [1, 3]}, {"source": "computation", "target": "reducing communication", "depth": [1, 3]}, {"source": "computation", "target": "communication and synchronization", "depth": [1, 3]}, {"source": "computation", "target": "synchronization in graph", "depth": [1, 3]}, {"source": "computation", "target": "pull", "depth": [1, 3]}, {"source": "parsing", "target": "lake symbol", "depth": [1, 3]}, {"source": "parsing", "target": "island parsing", "depth": [1, 3]}, {"source": "parsing", "target": "symbols for island", "depth": [1, 3]}, {"source": "parsing", "target": "lake", "depth": [1, 3]}, {"source": "parsing", "target": "symbol", "depth": [1, 3]}, {"source": "understanding", "target": "understanding opportunity", "depth": [1, 3]}, {"source": "understanding", "target": "opportunities and challenge", "depth": [1, 3]}, {"source": "understanding", "target": "challenges of geographic", "depth": [1, 3]}, {"source": "understanding", "target": "gender-inclusion in os", "depth": [1, 3]}, {"source": "understanding", "target": "geographic gender-inclusion", "depth": [1, 3]}, {"source": "robot", "target": "person-specific following robot", "depth": [1, 3]}, {"source": "robot", "target": "autonomous person-specific", "depth": [1, 3]}, {"source": "robot", "target": "autonomou", "depth": [1, 2]}, {"source": "robot", "target": "person-specific", "depth": [1, 3]}, {"source": "robot", "target": "lyapunov-stable orientation estimator", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 2]}, {"source": "generative model", "target": "deep generative", "depth": [1, 1]}, {"source": "generative model", "target": "network anomaly detection", "depth": [1, 3]}, {"source": "generative model", "target": "usage of generative", "depth": [1, 3]}, {"source": "generative model", "target": "models for network", "depth": [1, 3]}, {"source": "human", "target": "human pose estimation", "depth": [1, 2]}, {"source": "human", "target": "human pose", "depth": [1, 2]}, {"source": "human", "target": "estimation from rgb", "depth": [1, 3]}, {"source": "human", "target": "rgb and lidar", "depth": [1, 3]}, {"source": "human", "target": "hperl", "depth": [1, 3]}, {"source": "semantic parsing", "target": "domain generalization", "depth": [1, 3]}, {"source": "semantic parsing", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "semantic parsing", "target": "meta-learning for domain", "depth": [1, 3]}, {"source": "semantic parsing", "target": "domain", "depth": [1, 1]}, {"source": "semantic parsing", "target": "semi-autoregressive bottom-up semantic", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "online semi-supervised learning", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "bandit feedback", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "learning with bandit", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "feedback", "depth": [1, 1]}, {"source": "semi-supervised learning", "target": "neural graph consensu", "depth": [1, 3]}, {"source": "complexity", "target": "quantum sample", "depth": [1, 3]}, {"source": "complexity", "target": "complexity of quantum", "depth": [1, 3]}, {"source": "complexity", "target": "learnability and complexity", "depth": [1, 3]}, {"source": "complexity", "target": "sample", "depth": [1, 2]}, {"source": "complexity", "target": "quantum", "depth": [1, 1]}, {"source": "deep learning framework", "target": "earnings call", "depth": [1, 3]}, {"source": "deep learning framework", "target": "framework for measuring", "depth": [1, 3]}, {"source": "deep learning framework", "target": "measuring the digital", "depth": [1, 3]}, {"source": "deep learning framework", "target": "digital strategy", "depth": [1, 3]}, {"source": "deep learning framework", "target": "strategy of company", "depth": [1, 3]}, {"source": "signal", "target": "corrupted signal", "depth": [1, 3]}, {"source": "signal", "target": "localization in wireles", "depth": [1, 3]}, {"source": "signal", "target": "wireless network", "depth": [1, 2]}, {"source": "signal", "target": "networks from corrupted", "depth": [1, 3]}, {"source": "signal", "target": "robust localization", "depth": [1, 3]}, {"source": "emotion recognition", "target": "speech emotion recognition", "depth": [1, 2]}, {"source": "emotion recognition", "target": "multiscale fractal analysi", "depth": [1, 3]}, {"source": "emotion recognition", "target": "music-induced emotion recognition", "depth": [1, 3]}, {"source": "emotion recognition", "target": "fractal analysi", "depth": [1, 3]}, {"source": "emotion recognition", "target": "analysis on eeg", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "explainable online validation", "depth": [1, 3]}, {"source": "learning model", "target": "practical application", "depth": [1, 3]}, {"source": "learning model", "target": "online validation", "depth": [1, 3]}, {"source": "learning model", "target": "validation of machine", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "string space", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "optimization over string", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "bos", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "high-dimensional bayesian optimization", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "constrained bayesian optimization", "depth": [1, 3]}, {"source": "exploration", "target": "oil exploration", "depth": [1, 3]}, {"source": "exploration", "target": "learning for ga", "depth": [1, 3]}, {"source": "exploration", "target": "gas and oil", "depth": [1, 3]}, {"source": "exploration", "target": "ga", "depth": [1, 3]}, {"source": "exploration", "target": "model exploration", "depth": [1, 3]}, {"source": "test", "target": "models understand instruction", "depth": [1, 3]}, {"source": "test", "target": "language models understand", "depth": [1, 3]}, {"source": "test", "target": "turking test", "depth": [1, 3]}, {"source": "test", "target": "understand instruction", "depth": [1, 3]}, {"source": "test", "target": "models understand", "depth": [1, 3]}, {"source": "video object", "target": "video object segmentation", "depth": [1, 2]}, {"source": "video object", "target": "object segmentation", "depth": [1, 2]}, {"source": "video object", "target": "video object detection", "depth": [1, 3]}, {"source": "video object", "target": "semi-supervised video object", "depth": [1, 3]}, {"source": "video object", "target": "cyclic mechanism", "depth": [1, 3]}, {"source": "quantum", "target": "quantum sample", "depth": [1, 3]}, {"source": "quantum", "target": "complexity of quantum", "depth": [1, 3]}, {"source": "quantum", "target": "learnability and complexity", "depth": [1, 3]}, {"source": "quantum", "target": "sample", "depth": [1, 2]}, {"source": "quantum", "target": "learnability", "depth": [1, 3]}, {"source": "bert", "target": "multilingual bert", "depth": [1, 2]}, {"source": "bert", "target": "bert post-pretraining alignment", "depth": [1, 3]}, {"source": "bert", "target": "multilingual bert post-pretraining", "depth": [1, 3]}, {"source": "bert", "target": "post-pretraining alignment", "depth": [1, 3]}, {"source": "bert", "target": "bert post-pretraining", "depth": [1, 3]}, {"source": "retrieval", "target": "fine-grained image retrieval", "depth": [1, 3]}, {"source": "retrieval", "target": "image retrieval", "depth": [1, 3]}, {"source": "retrieval", "target": "exploration of incremental", "depth": [1, 3]}, {"source": "retrieval", "target": "incremental learning", "depth": [1, 2]}, {"source": "retrieval", "target": "learning for fine-grained", "depth": [1, 3]}, {"source": "synthesi", "target": "fine-grained attribute analysi", "depth": [1, 3]}, {"source": "synthesi", "target": "fine-grained attribute", "depth": [1, 3]}, {"source": "synthesi", "target": "attribute analysi", "depth": [1, 3]}, {"source": "synthesi", "target": "analysis for person", "depth": [1, 3]}, {"source": "synthesi", "target": "taking a closer", "depth": [1, 3]}, {"source": "type", "target": "session type", "depth": [1, 3]}, {"source": "type", "target": "imperative session type", "depth": [1, 3]}, {"source": "type", "target": "functional and imperative", "depth": [1, 3]}, {"source": "type", "target": "imperative session", "depth": [1, 3]}, {"source": "type", "target": "relating functional", "depth": [1, 3]}, {"source": "ranking", "target": "crowdsourced ranking", "depth": [1, 3]}, {"source": "ranking", "target": "algorithmic instability", "depth": [1, 3]}, {"source": "ranking", "target": "instabilities in crowdsourced", "depth": [1, 3]}, {"source": "ranking", "target": "origins of algorithmic", "depth": [1, 3]}, {"source": "ranking", "target": "instability", "depth": [1, 3]}, {"source": "compressed sensing", "target": "coded compressed sensing", "depth": [1, 3]}, {"source": "compressed sensing", "target": "undersampled fourier measurement", "depth": [1, 3]}, {"source": "compressed sensing", "target": "photoacoustic tomography reduce", "depth": [1, 3]}, {"source": "compressed sensing", "target": "sensing photoacoustic tomography", "depth": [1, 3]}, {"source": "compressed sensing", "target": "compressed sensing photoacoustic", "depth": [1, 3]}, {"source": "protocol", "target": "barrington plays card", "depth": [1, 3]}, {"source": "protocol", "target": "plays card", "depth": [1, 3]}, {"source": "protocol", "target": "card-based protocol", "depth": [1, 3]}, {"source": "protocol", "target": "complexity of card-based", "depth": [1, 3]}, {"source": "protocol", "target": "barrington play", "depth": [1, 3]}, {"source": "study", "target": "source code", "depth": [1, 2]}, {"source": "study", "target": "study of transformer", "depth": [1, 3]}, {"source": "study", "target": "transformers for source", "depth": [1, 3]}, {"source": "study", "target": "ethics in nlp", "depth": [1, 3]}, {"source": "study", "target": "nlp", "depth": [1, 1]}, {"source": "extended", "target": "version", "depth": [1, 2]}, {"source": "extended", "target": "equivalence for assisted", "depth": [1, 3]}, {"source": "extended", "target": "assisted grading", "depth": [1, 3]}, {"source": "extended", "target": "grading of functional", "depth": [1, 3]}, {"source": "extended", "target": "program equivalence", "depth": [1, 3]}, {"source": "feedback", "target": "feedback insertion-deletion code", "depth": [1, 3]}, {"source": "feedback", "target": "insertion-deletion code", "depth": [1, 3]}, {"source": "feedback", "target": "feedback insertion-deletion", "depth": [1, 3]}, {"source": "feedback", "target": "insertion-deletion", "depth": [1, 3]}, {"source": "feedback", "target": "online semi-supervised learning", "depth": [1, 3]}, {"source": "entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "entity recognition", "target": "joint named entity", "depth": [1, 3]}, {"source": "entity recognition", "target": "study of joint", "depth": [1, 3]}, {"source": "entity recognition", "target": "joint named", "depth": [1, 3]}, {"source": "entity recognition", "target": "pre-training for named", "depth": [1, 3]}, {"source": "causal", "target": "epistemic operator", "depth": [1, 3]}, {"source": "causal", "target": "thinking about causation", "depth": [1, 3]}, {"source": "causal", "target": "causal language", "depth": [1, 3]}, {"source": "causal", "target": "language with epistemic", "depth": [1, 3]}, {"source": "causal", "target": "causation", "depth": [1, 3]}, {"source": "alignment", "target": "entity alignment", "depth": [1, 2]}, {"source": "alignment", "target": "critical assessment", "depth": [1, 3]}, {"source": "alignment", "target": "assessment", "depth": [1, 1]}, {"source": "alignment", "target": "entity", "depth": [1, 2]}, {"source": "alignment", "target": "bert post-pretraining alignment", "depth": [1, 3]}, {"source": "optimal transport", "target": "transport", "depth": [1, 2]}, {"source": "optimal transport", "target": "fairness for edge", "depth": [1, 3]}, {"source": "optimal transport", "target": "edge prediction", "depth": [1, 3]}, {"source": "optimal transport", "target": "prediction with optimal", "depth": [1, 3]}, {"source": "optimal transport", "target": "edge", "depth": [1, 1]}, {"source": "coding", "target": "two-stage coding", "depth": [1, 3]}, {"source": "coding", "target": "z-channel", "depth": [1, 3]}, {"source": "coding", "target": "two-stage", "depth": [1, 3]}, {"source": "coding", "target": "supervised sparse coding", "depth": [1, 3]}, {"source": "coding", "target": "sparse coding", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "human mesh registration", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "implicit surface correspondence", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "surface correspondence", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "pose and shape", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "human mesh", "depth": [1, 3]}, {"source": "recommender system", "target": "recommender system based", "depth": [1, 3]}, {"source": "recommender system", "target": "telegram social network", "depth": [1, 3]}, {"source": "recommender system", "target": "system based", "depth": [1, 3]}, {"source": "recommender system", "target": "traits in telegram", "depth": [1, 3]}, {"source": "recommender system", "target": "telegram social", "depth": [1, 3]}, {"source": "twitter", "target": "twitter dataset", "depth": [1, 3]}, {"source": "twitter", "target": "analysis of twitter", "depth": [1, 3]}, {"source": "twitter", "target": "twitter and youtube", "depth": [1, 3]}, {"source": "twitter", "target": "youtube during uselection", "depth": [1, 3]}, {"source": "twitter", "target": "uselection", "depth": [1, 3]}, {"source": "review", "target": "review of technology", "depth": [1, 3]}, {"source": "review", "target": "distributed computing", "depth": [1, 3]}, {"source": "review", "target": "tackling", "depth": [1, 3]}, {"source": "review", "target": "technology", "depth": [1, 2]}, {"source": "review", "target": "capacity-achieving code", "depth": [1, 3]}, {"source": "sequence", "target": "hidden automatic sequence", "depth": [1, 3]}, {"source": "sequence", "target": "automatic sequence", "depth": [1, 3]}, {"source": "sequence", "target": "hidden", "depth": [1, 3]}, {"source": "sequence", "target": "dna sequence", "depth": [1, 3]}, {"source": "sequence", "target": "codes for recovery", "depth": [1, 3]}, {"source": "future direction", "target": "deep learning application", "depth": [1, 2]}, {"source": "future direction", "target": "architectural element", "depth": [1, 3]}, {"source": "future direction", "target": "smart grid", "depth": [1, 2]}, {"source": "future direction", "target": "survey of architectural", "depth": [1, 3]}, {"source": "future direction", "target": "applications and future", "depth": [1, 3]}, {"source": "continuou", "target": "continuous gaze redirection", "depth": [1, 3]}, {"source": "continuou", "target": "controllable continuous gaze", "depth": [1, 3]}, {"source": "continuou", "target": "gaze redirection", "depth": [1, 3]}, {"source": "continuou", "target": "continuous gaze", "depth": [1, 3]}, {"source": "continuou", "target": "controllable continuou", "depth": [1, 3]}, {"source": "pandemic", "target": "review of technology", "depth": [1, 3]}, {"source": "pandemic", "target": "distributed computing", "depth": [1, 3]}, {"source": "pandemic", "target": "tackling", "depth": [1, 3]}, {"source": "pandemic", "target": "technology", "depth": [1, 2]}, {"source": "pandemic", "target": "analyzing societal impact", "depth": [1, 3]}, {"source": "query", "target": "query complexity", "depth": [1, 3]}, {"source": "query", "target": "complexity of adversarial", "depth": [1, 3]}, {"source": "query", "target": "hub label", "depth": [1, 3]}, {"source": "query", "target": "eccentricity query", "depth": [1, 3]}, {"source": "query", "target": "label", "depth": [1, 2]}, {"source": "speaker recognition", "target": "voxceleb speaker recognition", "depth": [1, 2]}, {"source": "speaker recognition", "target": "speaker recognition challenge", "depth": [1, 2]}, {"source": "speaker recognition", "target": "recognition challenge", "depth": [1, 2]}, {"source": "speaker recognition", "target": "tongji university", "depth": [1, 3]}, {"source": "speaker recognition", "target": "idlab voxceleb speaker", "depth": [1, 3]}, {"source": "normalization", "target": "filtered batch normalization", "depth": [1, 3]}, {"source": "normalization", "target": "batch normalization", "depth": [1, 2]}, {"source": "normalization", "target": "filtered batch", "depth": [1, 3]}, {"source": "normalization", "target": "batch", "depth": [1, 2]}, {"source": "normalization", "target": "filtered", "depth": [1, 3]}, {"source": "matching", "target": "ultrasound image", "depth": [1, 3]}, {"source": "matching", "target": "matching in ultrasound", "depth": [1, 3]}, {"source": "matching", "target": "feature matching", "depth": [1, 3]}, {"source": "matching", "target": "ultrasound", "depth": [1, 3]}, {"source": "matching", "target": "high-order relation construction", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "residual learning", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "embedding with atrou", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "atrous convolution", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "convolution and residual", "depth": [1, 3]}, {"source": "knowledge graph embedding", "target": "geometric algebra", "depth": [1, 3]}, {"source": "gradient descent", "target": "stochastic gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "single-objective optimization benefit", "depth": [1, 3]}, {"source": "gradient descent", "target": "multi-objective gradient descent", "depth": [1, 3]}, {"source": "gradient descent", "target": "local search", "depth": [1, 3]}, {"source": "gradient descent", "target": "optimization benefit", "depth": [1, 3]}, {"source": "visual question answering", "target": "visual question", "depth": [1, 1]}, {"source": "visual question answering", "target": "social visual question", "depth": [1, 3]}, {"source": "visual question answering", "target": "characterizing dataset", "depth": [1, 3]}, {"source": "visual question answering", "target": "tinysocial dataset", "depth": [1, 3]}, {"source": "visual question answering", "target": "pathological visual question", "depth": [1, 3]}, {"source": "processing", "target": "span-level processing", "depth": [1, 3]}, {"source": "processing", "target": "iobe", "depth": [1, 3]}, {"source": "processing", "target": "library for span-level", "depth": [1, 3]}, {"source": "processing", "target": "library", "depth": [1, 2]}, {"source": "processing", "target": "span-level", "depth": [1, 3]}, {"source": "chest x-ray", "target": "chest x-ray image", "depth": [1, 3]}, {"source": "chest x-ray", "target": "multi-disease chest x-ray", "depth": [1, 3]}, {"source": "chest x-ray", "target": "generalized deep learning", "depth": [1, 3]}, {"source": "chest x-ray", "target": "multi-disease chest", "depth": [1, 3]}, {"source": "chest x-ray", "target": "posteroanterior chest x-ray", "depth": [1, 3]}, {"source": "tweet", "target": "latvian tweet", "depth": [1, 3]}, {"source": "tweet", "target": "strategies for sentiment", "depth": [1, 3]}, {"source": "tweet", "target": "analysis of latvian", "depth": [1, 3]}, {"source": "tweet", "target": "fine-tuning strategy", "depth": [1, 3]}, {"source": "tweet", "target": "pretraining and fine-tuning", "depth": [1, 3]}, {"source": "time", "target": "divergences between time", "depth": [1, 3]}, {"source": "time", "target": "differentiable divergence", "depth": [1, 3]}, {"source": "time", "target": "series", "depth": [1, 3]}, {"source": "time", "target": "divergence", "depth": [1, 2]}, {"source": "time", "target": "discrete space", "depth": [1, 2]}, {"source": "reading comprehension", "target": "machine reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "machine reading", "depth": [1, 3]}, {"source": "reading comprehension", "target": "multilingual synthetic question", "depth": [1, 3]}, {"source": "reading comprehension", "target": "cross-lingual reading comprehension", "depth": [1, 3]}, {"source": "reading comprehension", "target": "synthetic question", "depth": [1, 3]}, {"source": "reasoning", "target": "probability tree", "depth": [1, 3]}, {"source": "reasoning", "target": "causal reasoning", "depth": [1, 3]}, {"source": "reasoning", "target": "reasoning in probability", "depth": [1, 3]}, {"source": "reasoning", "target": "algorithms for causal", "depth": [1, 3]}, {"source": "reasoning", "target": "human-level concept learning", "depth": [1, 3]}, {"source": "regression", "target": "efficient truncated regression", "depth": [1, 3]}, {"source": "regression", "target": "statistically efficient truncated", "depth": [1, 3]}, {"source": "regression", "target": "truncated regression", "depth": [1, 3]}, {"source": "regression", "target": "statistically efficient", "depth": [1, 3]}, {"source": "regression", "target": "efficient truncated", "depth": [1, 3]}, {"source": "gradient", "target": "adaptive gradient", "depth": [1, 2]}, {"source": "gradient", "target": "adaptive gradient quantization", "depth": [1, 3]}, {"source": "gradient", "target": "gradient quantization", "depth": [1, 3]}, {"source": "gradient", "target": "data-parallel sgd", "depth": [1, 3]}, {"source": "gradient", "target": "quantization for data-parallel", "depth": [1, 3]}, {"source": "pre-training", "target": "tree-based transformer", "depth": [1, 3]}, {"source": "pre-training", "target": "pre-training for table", "depth": [1, 3]}, {"source": "pre-training", "target": "table understanding", "depth": [1, 3]}, {"source": "pre-training", "target": "understanding with tree-based", "depth": [1, 3]}, {"source": "pre-training", "target": "structure-aware pre-training", "depth": [1, 3]}, {"source": "imitation learning", "target": "demonstration", "depth": [1, 3]}, {"source": "imitation learning", "target": "robot manipulation task", "depth": [1, 3]}, {"source": "imitation learning", "target": "language-conditioned imitation learning", "depth": [1, 3]}, {"source": "imitation learning", "target": "manipulation task", "depth": [1, 2]}, {"source": "imitation learning", "target": "learning for robot", "depth": [1, 3]}, {"source": "few-shot learning", "target": "decoding brain signal", "depth": [1, 3]}, {"source": "few-shot learning", "target": "brain signal", "depth": [1, 3]}, {"source": "few-shot learning", "target": "learning for decoding", "depth": [1, 3]}, {"source": "few-shot learning", "target": "decoding brain", "depth": [1, 3]}, {"source": "few-shot learning", "target": "spatial regression", "depth": [1, 3]}, {"source": "face", "target": "eye tracking", "depth": [1, 3]}, {"source": "face", "target": "event camera", "depth": [1, 3]}, {"source": "face", "target": "real-time face", "depth": [1, 3]}, {"source": "face", "target": "tracking and blink", "depth": [1, 3]}, {"source": "face", "target": "blink detection", "depth": [1, 3]}, {"source": "medical imaging", "target": "imaging", "depth": [1, 2]}, {"source": "medical imaging", "target": "chest x-ray dataset", "depth": [1, 3]}, {"source": "medical imaging", "target": "large-scale chest x-ray", "depth": [1, 3]}, {"source": "medical imaging", "target": "x-ray dataset", "depth": [1, 3]}, {"source": "medical imaging", "target": "valuation for medical", "depth": [1, 3]}, {"source": "function approximation", "target": "linear function approximation", "depth": [1, 3]}, {"source": "function approximation", "target": "linear function", "depth": [1, 3]}, {"source": "function approximation", "target": "basis function approximation", "depth": [1, 3]}, {"source": "function approximation", "target": "curl-free radial basi", "depth": [1, 3]}, {"source": "function approximation", "target": "radial basis function", "depth": [1, 3]}, {"source": "named entity", "target": "joint named entity", "depth": [1, 3]}, {"source": "named entity", "target": "study of joint", "depth": [1, 3]}, {"source": "named entity", "target": "joint named", "depth": [1, 3]}, {"source": "named entity", "target": "pre-training for named", "depth": [1, 3]}, {"source": "named entity", "target": "named", "depth": [1, 3]}, {"source": "technical report", "target": "transducers solved efficiently", "depth": [1, 3]}, {"source": "technical report", "target": "constraints with concatenation", "depth": [1, 3]}, {"source": "technical report", "target": "concatenation and transducer", "depth": [1, 3]}, {"source": "technical report", "target": "transducers solved", "depth": [1, 3]}, {"source": "technical report", "target": "string constraint", "depth": [1, 3]}, {"source": "contact tracing", "target": "tracing", "depth": [1, 2]}, {"source": "contact tracing", "target": "digital contact tracing", "depth": [1, 3]}, {"source": "contact tracing", "target": "agent-based model", "depth": [1, 3]}, {"source": "contact tracing", "target": "model for evaluating", "depth": [1, 3]}, {"source": "contact tracing", "target": "evaluating method", "depth": [1, 3]}, {"source": "metric learning", "target": "tag-based music retrieval", "depth": [1, 3]}, {"source": "metric learning", "target": "multimodal metric learning", "depth": [1, 3]}, {"source": "metric learning", "target": "music retrieval", "depth": [1, 3]}, {"source": "metric learning", "target": "learning for tag-based", "depth": [1, 3]}, {"source": "metric learning", "target": "multimodal metric", "depth": [1, 3]}, {"source": "tracking", "target": "object tracking", "depth": [1, 2]}, {"source": "tracking", "target": "multi-object tracking", "depth": [1, 3]}, {"source": "tracking", "target": "multi object tracking", "depth": [1, 3]}, {"source": "tracking", "target": "single-shot multi object", "depth": [1, 3]}, {"source": "tracking", "target": "multi object", "depth": [1, 3]}, {"source": "generative", "target": "deep generative", "depth": [1, 1]}, {"source": "generative", "target": "deep generative lda", "depth": [1, 3]}, {"source": "generative", "target": "generative lda", "depth": [1, 3]}, {"source": "generative", "target": "lda", "depth": [1, 3]}, {"source": "generative", "target": "generative neurosymbolic machine", "depth": [1, 3]}, {"source": "theory", "target": "theory for semiautomatum", "depth": [1, 3]}, {"source": "theory", "target": "krohn-rhodes theory", "depth": [1, 3]}, {"source": "theory", "target": "semiautomatum", "depth": [1, 3]}, {"source": "theory", "target": "krohn-rhode", "depth": [1, 3]}, {"source": "theory", "target": "cyber-physical systems theory", "depth": [1, 3]}, {"source": "object recognition", "target": "scene representation", "depth": [1, 2]}, {"source": "object recognition", "target": "quantizing neural", "depth": [1, 3]}, {"source": "object recognition", "target": "scene", "depth": [1, 2]}, {"source": "object recognition", "target": "all-weather object recognition", "depth": [1, 3]}, {"source": "object recognition", "target": "infrared sensing", "depth": [1, 3]}, {"source": "edge", "target": "fairness for edge", "depth": [1, 3]}, {"source": "edge", "target": "edge prediction", "depth": [1, 3]}, {"source": "edge", "target": "prediction with optimal", "depth": [1, 3]}, {"source": "edge", "target": "transport", "depth": [1, 2]}, {"source": "edge", "target": "edge continuum", "depth": [1, 3]}, {"source": "speech enhancement", "target": "speech enhancement aided", "depth": [1, 3]}, {"source": "speech enhancement", "target": "voice activity detection", "depth": [1, 2]}, {"source": "speech enhancement", "target": "enhancement aided", "depth": [1, 3]}, {"source": "speech enhancement", "target": "activity detection", "depth": [1, 2]}, {"source": "speech enhancement", "target": "learning for voice", "depth": [1, 3]}, {"source": "smart contract", "target": "tracking data collection", "depth": [1, 3]}, {"source": "smart contract", "target": "data collection protocol", "depth": [1, 3]}, {"source": "smart contract", "target": "remotely located subject", "depth": [1, 3]}, {"source": "smart contract", "target": "eye tracking datum", "depth": [1, 3]}, {"source": "smart contract", "target": "tracking datum", "depth": [1, 3]}, {"source": "intelligent surface", "target": "reconfigurable intelligent surface", "depth": [1, 2]}, {"source": "intelligent surface", "target": "wireless network", "depth": [1, 2]}, {"source": "intelligent surface", "target": "intelligent surface assisted", "depth": [1, 3]}, {"source": "intelligent surface", "target": "two-tile reconfigurable intelligent", "depth": [1, 3]}, {"source": "intelligent surface", "target": "mimo system", "depth": [1, 2]}, {"source": "dynamic environment", "target": "weighted incremental evolution", "depth": [1, 3]}, {"source": "dynamic environment", "target": "incremental evolution strategy", "depth": [1, 3]}, {"source": "dynamic environment", "target": "instance weighted incremental", "depth": [1, 3]}, {"source": "dynamic environment", "target": "weighted incremental", "depth": [1, 3]}, {"source": "dynamic environment", "target": "incremental evolution", "depth": [1, 3]}, {"source": "process", "target": "gaussian process", "depth": [1, 2]}, {"source": "process", "target": "random process", "depth": [1, 3]}, {"source": "process", "target": "observations of random", "depth": [1, 3]}, {"source": "process", "target": "polynomial representation", "depth": [1, 3]}, {"source": "process", "target": "representations of high-dimensional", "depth": [1, 3]}, {"source": "market", "target": "financial market", "depth": [1, 3]}, {"source": "market", "target": "impact of publicly", "depth": [1, 3]}, {"source": "market", "target": "information transfer", "depth": [1, 3]}, {"source": "market", "target": "transfer to financial", "depth": [1, 3]}, {"source": "market", "target": "impact", "depth": [1, 2]}, {"source": "gan", "target": "non-saturating gan training", "depth": [1, 3]}, {"source": "gan", "target": "gan training", "depth": [1, 3]}, {"source": "gan", "target": "divergence minimization", "depth": [1, 3]}, {"source": "gan", "target": "training as divergence", "depth": [1, 3]}, {"source": "gan", "target": "non-saturating", "depth": [1, 3]}, {"source": "domain", "target": "domain generalization", "depth": [1, 3]}, {"source": "domain", "target": "generalization in semantic", "depth": [1, 3]}, {"source": "domain", "target": "meta-learning for domain", "depth": [1, 3]}, {"source": "domain", "target": "structural causal model", "depth": [1, 3]}, {"source": "domain", "target": "causal model", "depth": [1, 3]}, {"source": "galerkin method", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "galerkin method", "target": "discontinuous galerkin", "depth": [1, 2]}, {"source": "galerkin method", "target": "mixed-discontinuous galerkin method", "depth": [1, 3]}, {"source": "galerkin method", "target": "elastic-viscoelastic composite structure", "depth": [1, 3]}, {"source": "galerkin method", "target": "linear dynamical elastic-viscoelastic", "depth": [1, 3]}, {"source": "flow", "target": "normalizing flow", "depth": [1, 2]}, {"source": "flow", "target": "interpolation in normalizing", "depth": [1, 3]}, {"source": "flow", "target": "principled interpolation", "depth": [1, 3]}, {"source": "flow", "target": "interpolation", "depth": [1, 2]}, {"source": "flow", "target": "normalizing", "depth": [1, 3]}, {"source": "planning", "target": "motion", "depth": [1, 2]}, {"source": "planning", "target": "energy-efficient autonomous ornithopter", "depth": [1, 3]}, {"source": "planning", "target": "autonomous ornithopter", "depth": [1, 3]}, {"source": "planning", "target": "kinodynamic planning", "depth": [1, 3]}, {"source": "planning", "target": "energy-efficient autonomou", "depth": [1, 3]}, {"source": "hypergraph", "target": "higher arity vc-dimension", "depth": [1, 3]}, {"source": "hypergraph", "target": "hypergraph regularity", "depth": [1, 3]}, {"source": "hypergraph", "target": "arity vc-dimension", "depth": [1, 3]}, {"source": "hypergraph", "target": "regularity and higher", "depth": [1, 3]}, {"source": "hypergraph", "target": "higher arity", "depth": [1, 3]}, {"source": "modeling", "target": "autoregressive generative modeling", "depth": [1, 3]}, {"source": "modeling", "target": "generative modeling", "depth": [1, 3]}, {"source": "modeling", "target": "laws for autoregressive", "depth": [1, 3]}, {"source": "modeling", "target": "scaling law", "depth": [1, 3]}, {"source": "modeling", "target": "law", "depth": [1, 3]}, {"source": "visual question", "target": "social visual question", "depth": [1, 3]}, {"source": "visual question", "target": "characterizing dataset", "depth": [1, 3]}, {"source": "visual question", "target": "tinysocial dataset", "depth": [1, 3]}, {"source": "visual question", "target": "pathological visual question", "depth": [1, 3]}, {"source": "visual question", "target": "answering", "depth": [1, 2]}, {"source": "research", "target": "falsifiable interpretability research", "depth": [1, 3]}, {"source": "research", "target": "interpretability research", "depth": [1, 3]}, {"source": "research", "target": "falsifiable interpretability", "depth": [1, 3]}, {"source": "research", "target": "interpretability", "depth": [1, 2]}, {"source": "research", "target": "theoretical opportunity", "depth": [1, 3]}, {"source": "pre-trained language model", "target": "pre-trained language", "depth": [1, 2]}, {"source": "pre-trained language model", "target": "dialogue generation", "depth": [1, 2]}, {"source": "pre-trained language model", "target": "dialogue generation based", "depth": [1, 3]}, {"source": "pre-trained language model", "target": "generation with pre-trained", "depth": [1, 3]}, {"source": "pre-trained language model", "target": "open-domain dialogue generation", "depth": [1, 3]}, {"source": "counterfactual explanation", "target": "generate counterfactual explanation", "depth": [1, 3]}, {"source": "counterfactual explanation", "target": "deep image prior", "depth": [1, 2]}, {"source": "counterfactual explanation", "target": "deep image", "depth": [1, 2]}, {"source": "counterfactual explanation", "target": "image prior", "depth": [1, 2]}, {"source": "counterfactual explanation", "target": "priors to generate", "depth": [1, 3]}, {"source": "image recognition", "target": "few-shot image recognition", "depth": [1, 3]}, {"source": "image recognition", "target": "recognition with manifold", "depth": [1, 3]}, {"source": "image recognition", "target": "few-shot image", "depth": [1, 2]}, {"source": "image recognition", "target": "manifold", "depth": [1, 2]}, {"source": "image recognition", "target": "ann structure", "depth": [1, 3]}, {"source": "adaptation", "target": "lidar semantic segmentation", "depth": [1, 3]}, {"source": "adaptation", "target": "adaptation in lidar", "depth": [1, 3]}, {"source": "adaptation", "target": "unsupervised cross-lingual adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "cross-lingual adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "adaptation for sequence", "depth": [1, 3]}, {"source": "distribution", "target": "tabular gan", "depth": [1, 3]}, {"source": "distribution", "target": "uneven distribution", "depth": [1, 3]}, {"source": "distribution", "target": "gans for uneven", "depth": [1, 3]}, {"source": "distribution", "target": "tabular", "depth": [1, 3]}, {"source": "distribution", "target": "probability distribution", "depth": [1, 3]}, {"source": "hol", "target": "isabelle", "depth": [1, 2]}, {"source": "hol", "target": "teaching logic", "depth": [1, 3]}, {"source": "hol", "target": "meta-language for teaching", "depth": [1, 3]}, {"source": "hol", "target": "teaching", "depth": [1, 2]}, {"source": "hol", "target": "meta-language", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "volumetric medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "semi-supervised medical image", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "mixed supervision", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "framework for semi-supervised", "depth": [1, 3]}, {"source": "medical image segmentation", "target": "automatic data augmentation", "depth": [1, 3]}, {"source": "polynomial time", "target": "free bipartite graph", "depth": [1, 3]}, {"source": "polynomial time", "target": "finding efficient domination", "depth": [1, 3]}, {"source": "polynomial time", "target": "free bipartite", "depth": [1, 3]}, {"source": "polynomial time", "target": "efficient domination", "depth": [1, 3]}, {"source": "polynomial time", "target": "bipartite graph", "depth": [1, 3]}, {"source": "sentiment classification", "target": "mutual information maximization", "depth": [1, 3]}, {"source": "sentiment classification", "target": "cross-domain sentiment classification", "depth": [1, 3]}, {"source": "sentiment classification", "target": "information maximization", "depth": [1, 2]}, {"source": "sentiment classification", "target": "classification with contrastive", "depth": [1, 3]}, {"source": "sentiment classification", "target": "learning and mutual", "depth": [1, 3]}, {"source": "graph representation learning", "target": "active graph representation", "depth": [1, 3]}, {"source": "graph representation learning", "target": "deep active graph", "depth": [1, 3]}, {"source": "graph representation learning", "target": "active graph", "depth": [1, 3]}, {"source": "graph representation learning", "target": "deep active", "depth": [1, 3]}, {"source": "graph representation learning", "target": "handling missing datum", "depth": [1, 3]}, {"source": "deep generative", "target": "deep generative lda", "depth": [1, 3]}, {"source": "deep generative", "target": "generative lda", "depth": [1, 3]}, {"source": "deep generative", "target": "lda", "depth": [1, 3]}, {"source": "deep generative", "target": "deep generative model", "depth": [1, 2]}, {"source": "deep generative", "target": "deep generative factorization", "depth": [1, 3]}, {"source": "geometry", "target": "hyperbolic geometry", "depth": [1, 3]}, {"source": "geometry", "target": "endowing fasttext", "depth": [1, 3]}, {"source": "geometry", "target": "hypertext", "depth": [1, 3]}, {"source": "geometry", "target": "fasttext with hyperbolic", "depth": [1, 3]}, {"source": "geometry", "target": "endowing", "depth": [1, 3]}, {"source": "channel", "target": "deterministic identification", "depth": [1, 3]}, {"source": "channel", "target": "polar coded repetition", "depth": [1, 3]}, {"source": "channel", "target": "coded repetition", "depth": [1, 3]}, {"source": "channel", "target": "polar coded", "depth": [1, 3]}, {"source": "channel", "target": "low-capacity channel", "depth": [1, 3]}, {"source": "bound", "target": "dynamic distributed mi", "depth": [1, 3]}, {"source": "bound", "target": "improved bound", "depth": [1, 3]}, {"source": "bound", "target": "distributed mi", "depth": [1, 3]}, {"source": "bound", "target": "mis with improved", "depth": [1, 3]}, {"source": "bound", "target": "dynamic distributed", "depth": [1, 3]}, {"source": "distributed", "target": "dynamic distributed mi", "depth": [1, 3]}, {"source": "distributed", "target": "improved bound", "depth": [1, 3]}, {"source": "distributed", "target": "distributed mi", "depth": [1, 3]}, {"source": "distributed", "target": "mis with improved", "depth": [1, 3]}, {"source": "distributed", "target": "dynamic distributed", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "information-theoretic feature selection", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "decomposition and submodularity", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "selection via tensor", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "information-theoretic feature", "depth": [1, 3]}, {"source": "tensor decomposition", "target": "submodularity", "depth": [1, 3]}, {"source": "combinatorial", "target": "combinatorial perspective", "depth": [1, 2]}, {"source": "combinatorial", "target": "combinatorial multi-bandit problem", "depth": [1, 3]}, {"source": "combinatorial", "target": "energy management", "depth": [1, 3]}, {"source": "combinatorial", "target": "application to energy", "depth": [1, 3]}, {"source": "combinatorial", "target": "combinatorial multi-bandit", "depth": [1, 3]}, {"source": "assessment", "target": "entity alignment", "depth": [1, 2]}, {"source": "assessment", "target": "critical assessment", "depth": [1, 3]}, {"source": "assessment", "target": "entity", "depth": [1, 2]}, {"source": "assessment", "target": "intrinsic quality assessment", "depth": [1, 3]}, {"source": "assessment", "target": "assessment of argument", "depth": [1, 3]}, {"source": "pattern", "target": "patterns count-based label", "depth": [1, 3]}, {"source": "pattern", "target": "labels for dataset", "depth": [1, 3]}, {"source": "pattern", "target": "count-based label", "depth": [1, 3]}, {"source": "pattern", "target": "label", "depth": [1, 2]}, {"source": "pattern", "target": "verification of pattern", "depth": [1, 3]}, {"source": "los", "target": "loss function", "depth": [1, 3]}, {"source": "los", "target": "function for image", "depth": [1, 3]}, {"source": "los", "target": "performance guarantee", "depth": [1, 3]}, {"source": "los", "target": "loss and performance", "depth": [1, 3]}, {"source": "los", "target": "minimax classification", "depth": [1, 3]}, {"source": "fair", "target": "allocation of treatment", "depth": [1, 3]}, {"source": "fair", "target": "fair allocation", "depth": [1, 3]}, {"source": "fair", "target": "inherent trade-off", "depth": [1, 3]}, {"source": "fair", "target": "treatment", "depth": [1, 3]}, {"source": "fair", "target": "trade-off", "depth": [1, 2]}, {"source": "nlp", "target": "pandemic with natural", "depth": [1, 3]}, {"source": "nlp", "target": "intelligence", "depth": [1, 2]}, {"source": "nlp", "target": "ethics in nlp", "depth": [1, 3]}, {"source": "nlp", "target": "interpretation of nlp", "depth": [1, 3]}, {"source": "nlp", "target": "nlp model", "depth": [1, 2]}, {"source": "robustnes", "target": "adversarial robustnes", "depth": [1, 2]}, {"source": "robustnes", "target": "supervised sparse coding", "depth": [1, 3]}, {"source": "robustnes", "target": "sparse coding", "depth": [1, 2]}, {"source": "robustnes", "target": "robustness of supervised", "depth": [1, 3]}, {"source": "robustnes", "target": "supervised sparse", "depth": [1, 3]}, {"source": "shared task", "target": "typological feature", "depth": [1, 3]}, {"source": "shared task", "target": "prediction of typological", "depth": [1, 3]}, {"source": "shared task", "target": "sigtyp", "depth": [1, 3]}, {"source": "shared task", "target": "shared", "depth": [1, 3]}, {"source": "shared task", "target": "translation beyond english", "depth": [1, 3]}, {"source": "verification", "target": "speaker verification", "depth": [1, 2]}, {"source": "verification", "target": "speaker", "depth": [1, 2]}, {"source": "verification", "target": "verification of pattern", "depth": [1, 3]}, {"source": "verification", "target": "playing a part", "depth": [1, 3]}, {"source": "verification", "target": "part", "depth": [1, 3]}, {"source": "tensor", "target": "cnn compression", "depth": [1, 3]}, {"source": "tensor", "target": "reordering for cnn", "depth": [1, 3]}, {"source": "tensor", "target": "tensor reordering", "depth": [1, 3]}, {"source": "tensor", "target": "compression", "depth": [1, 3]}, {"source": "tensor", "target": "reordering", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "connected autonomous vehicle", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "connected autonomou", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "cellular network", "depth": [1, 2]}, {"source": "autonomous vehicle", "target": "networks and connected", "depth": [1, 3]}, {"source": "autonomous vehicle", "target": "vehicle", "depth": [1, 2]}, {"source": "kernel", "target": "learning a kernel", "depth": [1, 3]}, {"source": "kernel", "target": "kernel from context", "depth": [1, 3]}, {"source": "kernel", "target": "attention-based clustering", "depth": [1, 3]}, {"source": "kernel", "target": "context", "depth": [1, 2]}, {"source": "kernel", "target": "graph kernel", "depth": [1, 2]}, {"source": "spoken language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "spoken language understanding", "target": "cross-modal language model", "depth": [1, 3]}, {"source": "spoken language understanding", "target": "language model pre-training", "depth": [1, 2]}, {"source": "spoken language understanding", "target": "cross-modal language", "depth": [1, 3]}, {"source": "spoken language understanding", "target": "model pre-training", "depth": [1, 2]}, {"source": "data analysi", "target": "knowledge guided deep", "depth": [1, 3]}, {"source": "data analysi", "target": "guided deep neural", "depth": [1, 3]}, {"source": "data analysi", "target": "geo-spatiotemporal data analysi", "depth": [1, 3]}, {"source": "data analysi", "target": "knowledge guided", "depth": [1, 3]}, {"source": "data analysi", "target": "guided deep", "depth": [1, 3]}, {"source": "estimation", "target": "graph trussnes", "depth": [1, 3]}, {"source": "estimation", "target": "estimation of graph", "depth": [1, 3]}, {"source": "estimation", "target": "efficient estimation", "depth": [1, 3]}, {"source": "estimation", "target": "trussnes", "depth": [1, 3]}, {"source": "estimation", "target": "faster uncertainty estimation", "depth": [1, 3]}, {"source": "benchmark", "target": "pool-based active learning", "depth": [1, 3]}, {"source": "benchmark", "target": "aldataset", "depth": [1, 3]}, {"source": "benchmark", "target": "benchmark for pool-based", "depth": [1, 3]}, {"source": "benchmark", "target": "edge computing", "depth": [1, 2]}, {"source": "benchmark", "target": "workflow-based benchmark", "depth": [1, 3]}, {"source": "question", "target": "generating adequate distractor", "depth": [1, 3]}, {"source": "question", "target": "adequate distractor", "depth": [1, 3]}, {"source": "question", "target": "generating adequate", "depth": [1, 3]}, {"source": "question", "target": "multiple-choice question", "depth": [1, 3]}, {"source": "question", "target": "distractors for multiple-choice", "depth": [1, 3]}, {"source": "recovery", "target": "sparse linear classifier", "depth": [1, 3]}, {"source": "recovery", "target": "recovery of sparse", "depth": [1, 3]}, {"source": "recovery", "target": "mixture of response", "depth": [1, 3]}, {"source": "recovery", "target": "sparse linear", "depth": [1, 3]}, {"source": "recovery", "target": "linear classifier", "depth": [1, 2]}, {"source": "extraction", "target": "optimal subarchitecture extraction", "depth": [1, 3]}, {"source": "extraction", "target": "subarchitecture extraction", "depth": [1, 3]}, {"source": "extraction", "target": "optimal subarchitecture", "depth": [1, 3]}, {"source": "extraction", "target": "approximation algorithm", "depth": [1, 2]}, {"source": "extraction", "target": "algorithm for optimal", "depth": [1, 3]}, {"source": "image denoising", "target": "denoising", "depth": [1, 2]}, {"source": "image denoising", "target": "bound for image", "depth": [1, 3]}, {"source": "image denoising", "target": "optimizing a self-supervised", "depth": [1, 3]}, {"source": "image denoising", "target": "self-supervised bound", "depth": [1, 3]}, {"source": "image denoising", "target": "optimizing", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "brain mri image", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "neural networks model-based", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "networks model-based brain", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "model-based brain tumor", "depth": [1, 3]}, {"source": "deep convolutional neural", "target": "brain tumor detection", "depth": [1, 3]}, {"source": "lightweight", "target": "lightweight inference compilation", "depth": [1, 3]}, {"source": "lightweight", "target": "inference compilation", "depth": [1, 3]}, {"source": "lightweight", "target": "lightweight inference", "depth": [1, 3]}, {"source": "lightweight", "target": "metropolis-hastings with lightweight", "depth": [1, 3]}, {"source": "lightweight", "target": "accelerating metropolis-hasting", "depth": [1, 3]}, {"source": "face recognition", "target": "resolution face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "low resolution face", "depth": [1, 3]}, {"source": "face recognition", "target": "multi scale identity-preserved", "depth": [1, 3]}, {"source": "face recognition", "target": "multi scale", "depth": [1, 3]}, {"source": "face recognition", "target": "scale identity-preserved u-net", "depth": [1, 3]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 2]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 2]}, {"source": "model predictive control", "target": "distributed model predictive", "depth": [1, 3]}, {"source": "model predictive control", "target": "nonlinear continuous-time system", "depth": [1, 3]}, {"source": "model predictive control", "target": "modular framework", "depth": [1, 3]}, {"source": "sequence labeling", "target": "neural sequence labeling", "depth": [1, 3]}, {"source": "sequence labeling", "target": "neural sequence", "depth": [1, 3]}, {"source": "sequence labeling", "target": "clinical concept extraction", "depth": [1, 3]}, {"source": "sequence labeling", "target": "nlnde at cantemist", "depth": [1, 3]}, {"source": "sequence labeling", "target": "concept extraction", "depth": [1, 3]}, {"source": "regularization", "target": "effective regularization", "depth": [1, 3]}, {"source": "regularization", "target": "loss-function metalearning", "depth": [1, 3]}, {"source": "regularization", "target": "regularization through loss-function", "depth": [1, 3]}, {"source": "regularization", "target": "metalearning", "depth": [1, 3]}, {"source": "regularization", "target": "loss-function", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "multi-agent reinforcement", "depth": [1, 2]}, {"source": "multi-agent reinforcement learning", "target": "competitive multi-agent reinforcement", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "convergence and optimality", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "information asymmetry", "depth": [1, 3]}, {"source": "multi-agent reinforcement learning", "target": "asymmetry in competitive", "depth": [1, 3]}, {"source": "anomaly", "target": "high density anomaly", "depth": [1, 3]}, {"source": "anomaly", "target": "density anomaly", "depth": [1, 3]}, {"source": "anomaly", "target": "detection of high", "depth": [1, 3]}, {"source": "anomaly", "target": "high density", "depth": [1, 3]}, {"source": "anomaly", "target": "algorithmic framework", "depth": [1, 3]}]}