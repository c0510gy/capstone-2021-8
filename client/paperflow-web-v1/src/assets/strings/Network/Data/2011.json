{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "reinforcement learning", "deep learning", "machine learning", "deep reinforcement learning", "system", "model", "detection", "object detection", "graph", "representation learning"], ["graph neural network", "recurrent neural network", "transfer learning", "federated learning", "deep learning model", "learning model", "deep", "deep learning approach", "learning approach", "deep reinforcement", "reinforcement", "reinforcement learning approach", "training", "machine learning method", "learning method", "machine", "transfer", "anomaly detection", "object", "knowledge graph", "autonomous driving", "contrastive representation learning", "federated", "reconfigurable intelligent surface", "algorithm", "point cloud", "estimation", "problem", "classification", "survey", "datum", "approach", "recognition", "speech recognition", "action recognition", "speech", "image", "analysi", "semantic segmentation", "segmentation", "distillation", "language model", "generation", "face", "image classification", "control", "optimal control", "question answering", "visual question answering", "visual question", "optimization", "dataset", "domain adaptation", "model predictive control", "model predictive", "predictive control", "adaptation", "domain", "graph convolutional network", "graph convolutional", "communication", "prediction", "pose estimation", "human pose", "method", "embedding", "word embedding", "generative adversarial", "generative adversarial network", "adversarial network", "case study", "convolutional network", "information", "self-supervised learning", "code", "machine translation", "neural machine translation", "neural machine", "translation", "time", "flow", "learning framework", "task", "robot", "application", "theory", "blockchain", "differential equation", "stochastic differential equation", "semi-supervised learning", "artificial intelligence", "intelligence", "meta-learning", "approximation", "reconstruction", "efficient", "computing", "face recognition", "variational autoencoder", "matching", "video", "instance segmentation", "framework", "finite element method", "finite element", "game", "active learning", "sequence labeling", "attack", "adversarial attack", "medical image", "neural architecture search", "neural architecture", "search", "architecture search", "robust", "knowledge distillation", "knowledge", "linear system", "natural language", "lower bound", "dynamical system", "challenge", "social medium", "representation", "sentiment analysi", "study", "gan", "synthesi", "language", "human", "performance", "environment", "bound", "text", "uncertainty", "robustnes", "role", "state estimation", "time series", "motion planning", "attention network", "path planning", "depth estimation", "intelligent surface", "shape", "inference", "kernel", "conversion", "pandemic", "data augmentation", "gaussian proces", "social network", "generative model", "deep generative model", "recommendation", "text classification", "logic", "entity recognition", "named entity recognition", "named entity", "linear", "image generation", "service", "metric learning", "adversarial training", "library", "power system", "gaussian process", "interaction", "performance analysi", "fairnes", "research", "security", "fast", "edge computing", "recent advance", "modeling", "testing", "fading channel", "principle", "exploring", "learning technique", "transformer", "scene graph", "feature", "property", "perspective", "mobile robot", "deep learning based", "language understanding", "graph attention", "uncertainty estimation", "relation extraction", "galerkin method", "multi-view clustering", "strategy", "learning algorithm", "boltzmann machine", "denoising", "regularization", "augmented reality", "inference attack", "person re-identification", "review", "diffusion", "mobile device", "data analysi", "bayesian optimization", "construction", "distributed", "big datum", "trajectory planning", "experimental study", "continual learning", "resource allocation", "design", "weakly supervised", "action", "multi-task learning", "attention", "learning to segment"], ["multi-objective reinforcement learning", "relu network", "machine learning approach", "network acceleration", "recommender system", "mimo", "detection performance", "deep convolutional neural", "deep convolutional", "random graph", "random", "video object detection", "few-shot object detection", "unsupervised representation learning", "point", "registration", "drop estimation", "frenet space", "galaxy", "radio", "synthetic datum", "sequence datum", "ontology", "computational approach", "computational", "streaming", "decomposition", "machine learning model", "explaining deep learning", "relevance propagation", "convergence analysi", "convergence", "face generation", "image classification based", "networks for image", "hawkes process", "answering", "driving", "supervision", "unsupervised domain adaptation", "human action recognition", "human action", "skeleton-based action recognition", "dynamic graph", "motion prediction", "human pose estimation", "clustering", "temporal convolutional network", "sign language", "style transfer", "style", "contrastive self-supervised learning", "temporal information", "binary code", "binary", "linear time", "normalizing flow", "deep learning framework", "supervised graph", "autonomous learning", "autonomou", "multiple", "transaction", "diversity", "decoding", "deep learning method", "natural gradient", "result", "frame", "efficient and scalable", "neural vocoder", "instance", "integrated approach", "integrated", "element method", "weak galerkin finite", "galerkin finite element", "weak galerkin", "deep active learning", "backdoor attack", "medical image segmentation", "image segmentation", "speech separation", "natural language generation", "language generation", "bounds for approximate", "performance bound", "event", "nonlinear control", "bayesian network", "distributed optimization", "relational reasoning", "control barrier function", "barrier function", "graph attention network", "multi-view depth estimation", "multi-view depth", "reconfigurable intelligent", "shape estimation", "pose and shape", "variational inference", "unsupervised learning", "augmentation", "generalization in reinforcement", "deep generative", "theorem", "disentanglement", "few-shot image", "deep metric learning", "latent space", "process", "experiment", "systematic review", "large intelligent surface", "advance", "frequency domain", "machine learning technique", "uncertainty in deep", "movement", "audio", "template", "edge", "robot navigation", "motion control", "spoken language understanding", "spoken language", "improving rnn transducer", "rnn transducer", "discontinuous galerkin method", "incomplete multi-view clustering", "incomplete multi-view", "restricted boltzmann machine", "restricted boltzmann", "image denoising", "graph embedding", "state", "membership inference attack", "membership inference", "based privacy-preserving technique", "adversarial example based", "unsupervised person", "bert", "processing pipeline", "visual analytics approach", "analytics approach", "convex polytope", "mechanism", "manipulation", "safety guarantee", "artificial neuron", "neuron", "action detection", "camera"], ["latency-sensitive service delivery", "approximate blocked computation", "neural network acceleration", "precision-reconfigurable deep neural", "approximate blocked", "stable deep reinforcement", "balancing priority", "deterministic model", "design and update", "real-time system", "self-supervised models transfer", "models transfer", "self-supervised model", "methodology for co-constructing", "controllable environment", "selected improvement", "current application", "maximum convolutional neural", "response dynamic", "dynamics on random", "object detection processing", "sample pair generation", "ultrasound video contrastive", "video contrastive representation", "enabled federated learning", "intelligent surface enabled", "surface enabled federated", "novo drug design", "approximating retrosynthesi", "drug design", "retrosynthesis by graph", "generic traffic scenario", "graph constraint logic", "constraint logic", "algorithms for graph", "graph constraint", "fixed-parameter algorithm", "low overlap", "clouds with low", "predator", "estimation with machine", "fast ir drop", "drop", "monocular estimation", "long-term short-term planning", "efficient information diffusion", "video quality problem", "quality problem", "video quality", "patch-vq", "patching", "radio galaxy", "classification of radio", "data-efficient classification", "communication via diffusion", "survey on modulation", "modulation technique", "techniques in molecular", "molecular communication", "causal graph", "index direction", "main input", "direction with transfer", "graph as main", "on-shelf utility mining", "utility mining", "mining of sequence", "historical ontology", "approach to historical", "multi-talker speech recognition", "intrinsic image decomposition", "decomposition using paradigm", "image decomposition", "intrinsic image", "pathology-sensitive deep learning", "weakly labeled datum", "pathology-sensitive deep", "video capsule endoscopy", "capsule endoscopy based", "layer-wise relevance propagation", "models for structured", "analysis of homotopy-sgd", "non-convex optimization", "homotopy-sgd for non-convex", "distillation for semantic", "channel-wise distillation", "channel-wise", "language model performance", "model performance measure", "vocabulary size", "model performance", "performance measure", "lifting", "stylegan", "binary code generation", "cancer image classification", "cancer image", "deep image classification", "hawkes processes modeling", "inference and control", "processes modeling", "consistent visual question", "lexical perturbation", "stream-based monitoring language", "monitoring language", "optimizations for stream-based", "stream-based monitoring", "automatic optimization", "autonomous driving framework", "short-term trajectory planning", "driving framework", "scan dataset", "supervision for classification", "targeted self supervision", "small", "multi-talker speech", "deep orthogonal linear", "orthogonal linear network", "deep orthogonal", "networks are shallow", "orthogonal linear", "polyflow approximation", "immersion-based model predictive", "constrained nonlinear system", "uncertainty driven self-training", "adaptation for speech", "accurate anomaly detection", "accurate anomaly", "detection in dynamic", "fast and accurate", "manifolds support multiplexed", "support multiplexed integration", "low-dimensional manifolds support", "manifolds support", "support multiplexed", "communication delay", "optimisation with communication", "distributed optimisation", "delay", "optimisation", "scene-compliant motion prediction", "ellipse los", "loss for scene-compliant", "scene-compliant motion", "handling object symmetry", "cnn-based pose estimation", "object symmetry", "liquid simulation method", "simulation method", "evaluation of liquid", "liquid simulation", "perceptual evaluation", "dense graph", "embedding in dense", "matching through embedding", "dense", "narrative knowledge graph", "clustering in narrative", "narrative knowledge", "relation clustering", "controlled generative adversarial", "complexity controlled generative", "controlled generative", "self-supervised object detection", "detection without imagenet", "self-emd", "retrieval in clutter", "search for object", "urban twitter network", "networks and community", "microblogging in athen", "twitter network", "study of microblogging", "sign language segmentation", "saliency-based segmentation", "color information", "code generation", "systematic polarization-adjusted convolutional", "predictive control update", "control update interval", "control update", "data-enabled predictive control", "diversity in machine", "decoding and diversity", "researcher stating broader", "stating broader impact", "researcher stating", "stating broader", "modeling and analysi", "analysis of brain", "brain aging", "aging with normalizing", "supervised graph learning", "graph learning framework", "semantic uv mapping", "context-dependent task", "learning of multiple", "complexity controlled", "saliency-based video summarization", "enabling the sense", "dual-arm robot", "sense", "enabling", "dual-arm", "automatic specialization", "gaming application", "azp", "specialization", "gaming", "parallelism in blockchain", "theory of transaction", "transaction parallelism", "approximations of stochastic", "equations with unbounded", "convergence of smooth", "unbounded coefficient", "performance of self-supervised", "model for prediction", "prediction of power", "power output", "tight hardness result", "results for training", "hardness result", "tight hardnes", "urinary tract infection", "connected health", "people with dementium", "representation for connected", "learning for analysing", "interactive machine learning", "meta-learning in natural", "natural and artificial", "fourth industrial revolution", "natural gradient based", "eigenvalue-corrected natural gradient", "gradient based", "randomized quaternion singular", "properties in optimal", "turnpike property", "continuous-time result", "overview of discrete-time", "curvelet frame", "reconstruction using sparsity", "sparsity in curvelet", "photoacoustic reconstruction", "scalable neural vocoder", "vocoders for streaming", "fbwave", "aerial delivery network", "generation aerial delivery", "delivery network", "generation aerial", "aerial delivery", "set-based face recognition", "joint clustering", "clustering and classification", "clusterface", "classification for set-based", "direct evolutionary optimization", "binary latent", "evolutionary optimization", "optimization of variational", "autoencoders with binary", "maximum matching", "syntactic constituency path", "encoding syntactic constituency", "syntactic constituency", "constituency path", "segmentation of overlapping", "overlapping object", "star-convex polygon", "multistar", "hci methodological framework", "methodological framework", "dependency-based anomaly detection", "locally-aware constrained game", "games on network", "constrained game", "constrained", "memory-two zero-determinant strategy", "sequence labeling based", "uncertainty in gradient", "learning for sequence", "dnn", "attacks and defense", "generalized adversarial", "defense", "universal trigger adversarial", "trigger adversarial attack", "detecting universal trigger", "attack with honeypot", "universal trigger", "medical image translation", "manipulating medical image", "manifold disentanglement", "multi-talker", "multi-objective neural architecture", "transition in neural", "inter-layer transition", "robust instance segmentation", "robust instance", "dynamic convolution", "clouds through dynamic", "learning of halfspace", "data-free knowledge distillation", "pruning and quantization", "kd-lib", "pseudoinverse-free randomized block", "inconsistent linear system", "randomized block iterative", "block iterative method", "randomized block", "neighbor-augmented policy update", "sample-efficient natural language", "policy update", "approximate knowledge compilation", "knowledge compilation", "approximate knowledge", "compilation", "multiple faults estimation", "tractable design", "faults estimation", "estimation in dynamical", "framework and challenge", "federated crowdsensing", "crowdsensing", "starcraft multi-agent challenge", "social media network", "media network datum", "analysing social medium", "screening of user", "comments and communication", "information geometric interpretation", "frame less visual", "geometric interpretation", "visual space", "neural manifold", "deep language-independent network", "deep language-independent", "language-independent network", "world via sentiment", "network to analyze", "learnability in gan", "study of trait", "traits that affect", "affect learnability", "conditionally-independent pixel synthesi", "pixel synthesi", "image generator", "generators with conditionally-independent", "conditionally-independent pixel", "transition", "complex event", "recognition in complex", "twitter-based exploit detector", "centralized learning", "federated and centralized", "hybrid federated", "centralized", "hybrid", "adaptive nonlinear control", "bounds for adaptive", "adaptive nonlinear", "causal bayesian network", "learning causal bayesian", "networks from text", "causal bayesian", "role of uncertainty", "anticipatory", "improves robustnes", "distributed optimization scheme", "norm-bounded uncertainty", "optimization scheme", "scheme for state", "time series representation", "series representation learning", "self-supervised time series", "inter-intra relational reasoning", "robust motion planning", "robust motion", "planning for dynamic", "document understanding", "survey of deep", "approaches for ocr", "ocr and document", "predicting cardiovascular risk", "message-aware graph attention", "multi-robot path planning", "large-scale multi-robot path", "structured latent manifold", "conditional gan", "geometrically structured latent", "latent manifold", "train your conditional", "epipolar spatio-temporal network", "estimation using epipolar", "spatio-temporal network", "learning model predictive", "periodically correlated building", "aided multi-user network", "interplay between noma", "aided multi-user", "multi-view transformation network", "shape recognition", "transformation network", "multi-view transformation", "mvtn", "learnable volumetric aggregation", "multi-view human pose", "kernel using switchable", "continuous conversion", "switchable cyclegan", "cyclegan with adain", "economic risk evaluation", "learning for economic", "economic risk", "risk evaluation", "soft data augmentation", "learning by soft", "soft datum", "hybrid gaussian proces", "gaussian process model", "entity embedding vector", "hybrid gaussian", "lines using hybrid", "online social network", "social networks based", "marketing resource", "message distribution", "method for community", "provable multi-objective reinforcement", "learning with generative", "exploring global information", "session-based recommendation", "global information", "information for session-based", "exploring global", "supervised text classification", "text search", "supervised text", "classification using text", "modal intuitionistic logic", "intuitionistic logic", "theorems for modal", "goldblatt-thomason theorem", "interpretable multi-dataset evaluation", "multi-dataset evaluation", "evaluation for named", "graph convolutional adversarial", "convolutional adversarial network", "generate realistic dance", "realistic dance motion", "motions from audio", "linear symmetry-based disentanglement", "metric for linear", "symmetry-based disentanglement", "linear logic", "soft lexical constraint", "lexical constraint", "transformer with repositioning", "repositioning for neural", "few-shot image generation", "unsupervised few-shot image", "autoencoders for unsupervised", "augmentation-interpolative autoencoder", "service delivery", "latency-sensitive service", "delivery with uav-assisted", "delivery", "knowledge retention", "retention through metric", "retention", "virtual adversarial training", "latent space virtual", "space virtual adversarial", "virtual adversarial", "partially ordered hierarchical", "ordered hierarchical planner", "partially ordered", "hierarchical planner", "totally and partially", "perturbations for consistent", "industrial revolution", "power system testbed", "resilient power system", "cyber-physical resilient power", "system testbed", "resilient power", "deep gaussian process", "steerable conditional neural", "conditional neural process", "stochastic field", "kinetic simulation", "plasma-material interaction", "parallel", "pife-pic", "simulations of plasma-material", "conventional deep learning", "empirical performance analysi", "analysis of conventional", "conventional deep", "secure performance analysi", "minimax group fairnes", "algorithms and experiment", "group fairnes", "minimax group", "wearable computing research", "computing research", "trends in wearable", "wearable computing", "inflating cardinality estimate", "inflating cardinality", "cardinality estimate", "hll", "hyperloglog", "fast auxiliary space", "auxiliary space preconditioner", "preconditioners on surface", "auxiliary space", "space preconditioner", "edge computing applied", "internet of vehicle", "survey on blockchain", "blockchain and edge", "computing applied", "interpretable multi-dataset", "selective image encryption", "advances in selective", "selective image", "image encryption", "species diffusion", "competitive environment", "limitations of learning", "output of wave", "wave farm", "charles can pen-test", "vulnerability testing", "evolutionary approach", "approach to vulnerability", "pen-test", "incorporating pointing", "fast fading channel", "frequency domain equalization", "low-complexity frequency domain", "domain equalization", "speed-up ramp-counter adc", "locality principle", "adc using locality", "ramp-counter adc", "speed-up ramp-counter", "data science tool", "exploring the political", "science tool", "political pulse", "country using datum", "low-cost nir spectrometer", "egg storage time", "low-cost nir", "nir spectrometer", "multi-label image classification", "general multi-label image", "classification with transformer", "multi-label image", "general multi-label", "connecting context-specific adaptation", "humans to meta-learning", "context-specific adaptation", "bakhvalov-type mesh", "spectral finite element", "finite element approximation", "softfem", "rethinking uncertainty", "optimization under uncertainty", "robustness concept", "road scene graph", "scene representation dataset", "semantic graph-based scene", "graph-based scene representation", "intelligent vehicle", "heuristic domain adaptation", "heuristic domain", "robust dpg method", "robust dpg", "audio feature", "movement generation", "generation with audio", "parametric graph template", "properties and algorithm", "graph template", "parametric graph", "deep learning perspective", "perspectives from teacher", "teachers and student", "rubrics for capstone", "mobile robot navigation", "control for mobile", "navigation using machine", "low-resolution face recognition", "low-resolution face", "knowledge transfer", "transfer in deep", "computer-aided diagnosis system", "diagnosis system", "learning based computer-aided", "based computer-aided diagnosi", "understanding resource package", "language understanding resource", "resource package", "neural uncertainty estimation", "target speaker extraction", "transducer with target", "long-tail relation extraction", "learning relation prototype", "prototype from unlabeled", "texts for long-tail", "relation prototype", "matrix-free isogeometric galerkin", "isogeometric galerkin method", "interpolation based quadrature", "tensor product spline", "volumetrized deep generative", "progressively volumetrized deep", "data-efficient contextual learning", "image recovery", "unbalanced incomplete multi-view", "view evolution", "weak view", "deviation and adaptive", "adaptive strategy", "continuous blackjack", "equilibrium", "blackjack", "model learning algorithm", "accurate action model", "action model learning", "accurate action", "action model", "multinary restricted boltzmann", "tractable loss function", "color image generation", "text segmentation", "rethinking text segmentation", "regularization by denoising", "reconstruction and calibration", "calibration using regularization", "joint reconstruction", "nonlinear ill-posed equation", "regularization of system", "ill-posed equation", "systems of nonlinear", "transition state", "learning of transition", "offline reinforcement learning", "reinforcement learning hand-on", "deconstructing word embedding", "word embedding algorithm", "deconstructing word", "embedding algorithm", "deconstructing", "manufacturing execution system", "integrating augmented reality", "level for industry", "execution system", "cognition level", "visual emotion adaptation", "emotion adaptation", "visual emotion", "pure character-based neural", "technique against membership", "unsupervised person re-identification", "networks via asymmetric", "enhancing diversity", "diversity in teacher-student", "vietnamese review", "bert for sentiment", "analysis of vietnamese", "fine-tuning bert", "infodemic", "connectivity estimation", "role of spectral", "score-based generative modeling", "effective sample pair", "sample pair", "detection processing pipeline", "analysis and implication", "detection processing", "functional data analysi", "progressive functional datum", "monitor time-series datum", "random mapping function", "combinatorial bayesian optimization", "optimization with random", "random mapping", "exploring grid topology", "grid topology reconfiguration", "simple deep reinforcement", "lsat behavioral specification", "net length estimation", "blockchain mechanism", "characteristics of crypto", "mechanism and distributional", "crypto", "heap manipulation", "symbiotic construction", "construction for heap", "heap", "projective clustering approximation", "faster projective clustering", "projective clustering", "clustering approximation", "approximation of big", "multiple autonomous underwater", "autonomous underwater vehicle", "planning for multiple", "multiple autonomou", "labeling based", "isolated centrifugal fan", "tonal noise source", "numerical and experimental", "centrifugal fan", "study of tonal", "sequential targeting", "deep artificial neuron", "learning with deep", "deep artificial", "offloading and resource", "allocation in mobile", "energy-efficient resource allocation", "energy-efficient resource", "sequential task dependency", "compesation design", "narx model", "models for compesation", "identification of narx", "narx", "supervised object detection", "weakly supervised object", "cascade attentive dropout", "attentive dropout", "dropout for weakly", "battery", "learning a semantic", "robot cinematography", "incremental deep language", "deep language model", "re-framing incremental deep", "incremental deep", "deep language", "features for named", "scene graph classification", "prior knowledge", "graph classification", "classification by attention", "classification with prior", "partially labeled dataset", "multiple partially labeled", "dodnet", "labeled dataset", "segment multi-organ"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "transfer learning", "depth": [0, 1]}, {"source": "learning", "target": "federated learning", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 1]}, {"source": "deep learning", "target": "learning approach", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-objective reinforcement learning", "depth": [0, 2]}, {"source": "reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 1]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "graph neural network", "depth": [0, 1]}, {"source": "network", "target": "relu network", "depth": [0, 2]}, {"source": "network", "target": "training", "depth": [0, 1]}, {"source": "network", "target": "latency-sensitive service delivery", "depth": [0, 3]}, {"source": "machine learning", "target": "machine learning method", "depth": [0, 1]}, {"source": "machine learning", "target": "learning method", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 2]}, {"source": "machine learning", "target": "learning approach", "depth": [0, 1]}, {"source": "deep neural network", "target": "approximate blocked computation", "depth": [0, 3]}, {"source": "deep neural network", "target": "neural network acceleration", "depth": [0, 3]}, {"source": "deep neural network", "target": "precision-reconfigurable deep neural", "depth": [0, 3]}, {"source": "deep neural network", "target": "approximate blocked", "depth": [0, 3]}, {"source": "deep neural network", "target": "network acceleration", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "stable deep reinforcement", "depth": [0, 3]}, {"source": "deep reinforcement learning", "target": "balancing priority", "depth": [0, 3]}, {"source": "system", "target": "recommender system", "depth": [0, 2]}, {"source": "system", "target": "deterministic model", "depth": [0, 3]}, {"source": "system", "target": "design and update", "depth": [0, 3]}, {"source": "system", "target": "real-time system", "depth": [0, 3]}, {"source": "system", "target": "mimo", "depth": [0, 2]}, {"source": "model", "target": "self-supervised models transfer", "depth": [0, 3]}, {"source": "model", "target": "models transfer", "depth": [0, 3]}, {"source": "model", "target": "self-supervised model", "depth": [0, 3]}, {"source": "model", "target": "transfer", "depth": [0, 1]}, {"source": "model", "target": "methodology for co-constructing", "depth": [0, 3]}, {"source": "detection", "target": "object detection", "depth": [0, 0]}, {"source": "detection", "target": "anomaly detection", "depth": [0, 1]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "detection performance", "depth": [0, 2]}, {"source": "detection", "target": "controllable environment", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "selected improvement", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "current application", "depth": [0, 3]}, {"source": "convolutional neural network", "target": "maximum convolutional neural", "depth": [0, 3]}, {"source": "graph", "target": "random graph", "depth": [0, 2]}, {"source": "graph", "target": "random", "depth": [0, 2]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "graph", "target": "response dynamic", "depth": [0, 3]}, {"source": "graph", "target": "dynamics on random", "depth": [0, 3]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "video object detection", "depth": [0, 2]}, {"source": "object detection", "target": "few-shot object detection", "depth": [0, 2]}, {"source": "object detection", "target": "autonomous driving", "depth": [0, 1]}, {"source": "object detection", "target": "object detection processing", "depth": [0, 3]}, {"source": "representation learning", "target": "contrastive representation learning", "depth": [0, 1]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [0, 2]}, {"source": "representation learning", "target": "sample pair generation", "depth": [0, 3]}, {"source": "representation learning", "target": "ultrasound video contrastive", "depth": [0, 3]}, {"source": "representation learning", "target": "video contrastive representation", "depth": [0, 3]}, {"source": "federated learning", "target": "federated", "depth": [1, 1]}, {"source": "federated learning", "target": "enabled federated learning", "depth": [1, 3]}, {"source": "federated learning", "target": "intelligent surface enabled", "depth": [1, 3]}, {"source": "federated learning", "target": "surface enabled federated", "depth": [1, 3]}, {"source": "federated learning", "target": "reconfigurable intelligent surface", "depth": [1, 1]}, {"source": "graph neural network", "target": "novo drug design", "depth": [1, 3]}, {"source": "graph neural network", "target": "approximating retrosynthesi", "depth": [1, 3]}, {"source": "graph neural network", "target": "drug design", "depth": [1, 3]}, {"source": "graph neural network", "target": "retrosynthesis by graph", "depth": [1, 3]}, {"source": "graph neural network", "target": "generic traffic scenario", "depth": [1, 3]}, {"source": "algorithm", "target": "graph constraint logic", "depth": [1, 3]}, {"source": "algorithm", "target": "constraint logic", "depth": [1, 3]}, {"source": "algorithm", "target": "algorithms for graph", "depth": [1, 3]}, {"source": "algorithm", "target": "graph constraint", "depth": [1, 3]}, {"source": "algorithm", "target": "fixed-parameter algorithm", "depth": [1, 3]}, {"source": "point cloud", "target": "point", "depth": [1, 2]}, {"source": "point cloud", "target": "low overlap", "depth": [1, 3]}, {"source": "point cloud", "target": "clouds with low", "depth": [1, 3]}, {"source": "point cloud", "target": "predator", "depth": [1, 3]}, {"source": "point cloud", "target": "registration", "depth": [1, 2]}, {"source": "estimation", "target": "drop estimation", "depth": [1, 2]}, {"source": "estimation", "target": "estimation with machine", "depth": [1, 3]}, {"source": "estimation", "target": "fast ir drop", "depth": [1, 3]}, {"source": "estimation", "target": "drop", "depth": [1, 3]}, {"source": "estimation", "target": "monocular estimation", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "frenet space", "depth": [1, 2]}, {"source": "deep reinforcement", "target": "learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "efficient information diffusion", "depth": [1, 3]}, {"source": "problem", "target": "video quality problem", "depth": [1, 3]}, {"source": "problem", "target": "quality problem", "depth": [1, 3]}, {"source": "problem", "target": "video quality", "depth": [1, 3]}, {"source": "problem", "target": "patch-vq", "depth": [1, 3]}, {"source": "problem", "target": "patching", "depth": [1, 3]}, {"source": "classification", "target": "radio galaxy", "depth": [1, 3]}, {"source": "classification", "target": "classification of radio", "depth": [1, 3]}, {"source": "classification", "target": "data-efficient classification", "depth": [1, 3]}, {"source": "classification", "target": "galaxy", "depth": [1, 2]}, {"source": "classification", "target": "radio", "depth": [1, 2]}, {"source": "survey", "target": "communication via diffusion", "depth": [1, 3]}, {"source": "survey", "target": "survey on modulation", "depth": [1, 3]}, {"source": "survey", "target": "modulation technique", "depth": [1, 3]}, {"source": "survey", "target": "techniques in molecular", "depth": [1, 3]}, {"source": "survey", "target": "molecular communication", "depth": [1, 3]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "learning approach", "target": "frenet space", "depth": [1, 2]}, {"source": "transfer learning", "target": "causal graph", "depth": [1, 3]}, {"source": "transfer learning", "target": "index direction", "depth": [1, 3]}, {"source": "transfer learning", "target": "main input", "depth": [1, 3]}, {"source": "transfer learning", "target": "direction with transfer", "depth": [1, 3]}, {"source": "transfer learning", "target": "graph as main", "depth": [1, 3]}, {"source": "datum", "target": "synthetic datum", "depth": [1, 2]}, {"source": "datum", "target": "on-shelf utility mining", "depth": [1, 3]}, {"source": "datum", "target": "sequence datum", "depth": [1, 2]}, {"source": "datum", "target": "utility mining", "depth": [1, 3]}, {"source": "datum", "target": "mining of sequence", "depth": [1, 3]}, {"source": "approach", "target": "ontology", "depth": [1, 2]}, {"source": "approach", "target": "historical ontology", "depth": [1, 3]}, {"source": "approach", "target": "computational approach", "depth": [1, 2]}, {"source": "approach", "target": "approach to historical", "depth": [1, 3]}, {"source": "approach", "target": "computational", "depth": [1, 2]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "recognition", "target": "streaming", "depth": [1, 2]}, {"source": "image", "target": "decomposition", "depth": [1, 2]}, {"source": "image", "target": "intrinsic image decomposition", "depth": [1, 3]}, {"source": "image", "target": "decomposition using paradigm", "depth": [1, 3]}, {"source": "image", "target": "image decomposition", "depth": [1, 3]}, {"source": "image", "target": "intrinsic image", "depth": [1, 3]}, {"source": "deep learning model", "target": "pathology-sensitive deep learning", "depth": [1, 3]}, {"source": "deep learning model", "target": "weakly labeled datum", "depth": [1, 3]}, {"source": "deep learning model", "target": "pathology-sensitive deep", "depth": [1, 3]}, {"source": "deep learning model", "target": "video capsule endoscopy", "depth": [1, 3]}, {"source": "deep learning model", "target": "capsule endoscopy based", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "explaining deep learning", "depth": [1, 2]}, {"source": "learning model", "target": "layer-wise relevance propagation", "depth": [1, 3]}, {"source": "learning model", "target": "relevance propagation", "depth": [1, 2]}, {"source": "learning model", "target": "models for structured", "depth": [1, 3]}, {"source": "analysi", "target": "convergence analysi", "depth": [1, 2]}, {"source": "analysi", "target": "analysis of homotopy-sgd", "depth": [1, 3]}, {"source": "analysi", "target": "non-convex optimization", "depth": [1, 3]}, {"source": "analysi", "target": "homotopy-sgd for non-convex", "depth": [1, 3]}, {"source": "analysi", "target": "convergence", "depth": [1, 2]}, {"source": "semantic segmentation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "distillation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "channel-wise", "depth": [1, 3]}, {"source": "language model", "target": "language model performance", "depth": [1, 3]}, {"source": "language model", "target": "model performance measure", "depth": [1, 3]}, {"source": "language model", "target": "vocabulary size", "depth": [1, 3]}, {"source": "language model", "target": "model performance", "depth": [1, 3]}, {"source": "language model", "target": "performance measure", "depth": [1, 3]}, {"source": "generation", "target": "face generation", "depth": [1, 2]}, {"source": "generation", "target": "lifting", "depth": [1, 3]}, {"source": "generation", "target": "face", "depth": [1, 1]}, {"source": "generation", "target": "stylegan", "depth": [1, 3]}, {"source": "generation", "target": "binary code generation", "depth": [1, 3]}, {"source": "image classification", "target": "image classification based", "depth": [1, 2]}, {"source": "image classification", "target": "cancer image classification", "depth": [1, 3]}, {"source": "image classification", "target": "cancer image", "depth": [1, 3]}, {"source": "image classification", "target": "networks for image", "depth": [1, 2]}, {"source": "image classification", "target": "deep image classification", "depth": [1, 3]}, {"source": "control", "target": "optimal control", "depth": [1, 1]}, {"source": "control", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "control", "target": "inference and control", "depth": [1, 3]}, {"source": "control", "target": "processes modeling", "depth": [1, 3]}, {"source": "control", "target": "hawkes process", "depth": [1, 2]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 1]}, {"source": "question answering", "target": "visual question", "depth": [1, 1]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "consistent visual question", "depth": [1, 3]}, {"source": "question answering", "target": "lexical perturbation", "depth": [1, 3]}, {"source": "optimization", "target": "stream-based monitoring language", "depth": [1, 3]}, {"source": "optimization", "target": "monitoring language", "depth": [1, 3]}, {"source": "optimization", "target": "optimizations for stream-based", "depth": [1, 3]}, {"source": "optimization", "target": "stream-based monitoring", "depth": [1, 3]}, {"source": "optimization", "target": "automatic optimization", "depth": [1, 3]}, {"source": "autonomous driving", "target": "driving", "depth": [1, 2]}, {"source": "autonomous driving", "target": "autonomous driving framework", "depth": [1, 3]}, {"source": "autonomous driving", "target": "short-term trajectory planning", "depth": [1, 3]}, {"source": "autonomous driving", "target": "frenet space", "depth": [1, 2]}, {"source": "autonomous driving", "target": "driving framework", "depth": [1, 3]}, {"source": "dataset", "target": "scan dataset", "depth": [1, 3]}, {"source": "dataset", "target": "supervision for classification", "depth": [1, 3]}, {"source": "dataset", "target": "targeted self supervision", "depth": [1, 3]}, {"source": "dataset", "target": "small", "depth": [1, 3]}, {"source": "dataset", "target": "supervision", "depth": [1, 2]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "domain adaptation", "depth": [1, 1]}, {"source": "speech recognition", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "speech recognition", "target": "streaming", "depth": [1, 2]}, {"source": "speech recognition", "target": "multi-talker speech", "depth": [1, 3]}, {"source": "deep", "target": "deep orthogonal linear", "depth": [1, 3]}, {"source": "deep", "target": "orthogonal linear network", "depth": [1, 3]}, {"source": "deep", "target": "deep orthogonal", "depth": [1, 3]}, {"source": "deep", "target": "networks are shallow", "depth": [1, 3]}, {"source": "deep", "target": "orthogonal linear", "depth": [1, 3]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 1]}, {"source": "model predictive control", "target": "polyflow approximation", "depth": [1, 3]}, {"source": "model predictive control", "target": "immersion-based model predictive", "depth": [1, 3]}, {"source": "model predictive control", "target": "constrained nonlinear system", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "domain adaptation", "target": "uncertainty driven self-training", "depth": [1, 3]}, {"source": "domain adaptation", "target": "adaptation for speech", "depth": [1, 3]}, {"source": "action recognition", "target": "human action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "human action", "depth": [1, 2]}, {"source": "action recognition", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "graph convolutional", "depth": [1, 1]}, {"source": "anomaly detection", "target": "accurate anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "accurate anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "detection in dynamic", "depth": [1, 3]}, {"source": "anomaly detection", "target": "dynamic graph", "depth": [1, 2]}, {"source": "anomaly detection", "target": "fast and accurate", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "manifolds support multiplexed", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "support multiplexed integration", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "low-dimensional manifolds support", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "manifolds support", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "support multiplexed", "depth": [1, 3]}, {"source": "communication", "target": "communication delay", "depth": [1, 3]}, {"source": "communication", "target": "optimisation with communication", "depth": [1, 3]}, {"source": "communication", "target": "distributed optimisation", "depth": [1, 3]}, {"source": "communication", "target": "delay", "depth": [1, 3]}, {"source": "communication", "target": "optimisation", "depth": [1, 3]}, {"source": "prediction", "target": "motion prediction", "depth": [1, 2]}, {"source": "prediction", "target": "scene-compliant motion prediction", "depth": [1, 3]}, {"source": "prediction", "target": "ellipse los", "depth": [1, 3]}, {"source": "prediction", "target": "loss for scene-compliant", "depth": [1, 3]}, {"source": "prediction", "target": "scene-compliant motion", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "handling object symmetry", "depth": [1, 3]}, {"source": "pose estimation", "target": "cnn-based pose estimation", "depth": [1, 3]}, {"source": "pose estimation", "target": "object symmetry", "depth": [1, 3]}, {"source": "method", "target": "liquid simulation method", "depth": [1, 3]}, {"source": "method", "target": "simulation method", "depth": [1, 3]}, {"source": "method", "target": "evaluation of liquid", "depth": [1, 3]}, {"source": "method", "target": "liquid simulation", "depth": [1, 3]}, {"source": "method", "target": "perceptual evaluation", "depth": [1, 3]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "dense graph", "depth": [1, 3]}, {"source": "embedding", "target": "embedding in dense", "depth": [1, 3]}, {"source": "embedding", "target": "matching through embedding", "depth": [1, 3]}, {"source": "embedding", "target": "dense", "depth": [1, 3]}, {"source": "knowledge graph", "target": "narrative knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "clustering in narrative", "depth": [1, 3]}, {"source": "knowledge graph", "target": "narrative knowledge", "depth": [1, 3]}, {"source": "knowledge graph", "target": "relation clustering", "depth": [1, 3]}, {"source": "knowledge graph", "target": "clustering", "depth": [1, 2]}, {"source": "generative adversarial", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "generative adversarial", "target": "controlled generative", "depth": [1, 3]}, {"source": "object", "target": "self-supervised object detection", "depth": [1, 3]}, {"source": "object", "target": "detection without imagenet", "depth": [1, 3]}, {"source": "object", "target": "self-emd", "depth": [1, 3]}, {"source": "object", "target": "retrieval in clutter", "depth": [1, 3]}, {"source": "object", "target": "search for object", "depth": [1, 3]}, {"source": "case study", "target": "urban twitter network", "depth": [1, 3]}, {"source": "case study", "target": "networks and community", "depth": [1, 3]}, {"source": "case study", "target": "microblogging in athen", "depth": [1, 3]}, {"source": "case study", "target": "twitter network", "depth": [1, 3]}, {"source": "case study", "target": "study of microblogging", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "temporal convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "convolutional network", "target": "sign language segmentation", "depth": [1, 3]}, {"source": "convolutional network", "target": "sign language", "depth": [1, 2]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "transfer", "target": "style", "depth": [1, 2]}, {"source": "transfer", "target": "self-supervised models transfer", "depth": [1, 3]}, {"source": "transfer", "target": "models transfer", "depth": [1, 3]}, {"source": "transfer", "target": "self-supervised model", "depth": [1, 3]}, {"source": "information", "target": "contrastive self-supervised learning", "depth": [1, 2]}, {"source": "information", "target": "temporal information", "depth": [1, 2]}, {"source": "information", "target": "self-supervised learning", "depth": [1, 1]}, {"source": "information", "target": "saliency-based segmentation", "depth": [1, 3]}, {"source": "information", "target": "color information", "depth": [1, 3]}, {"source": "code", "target": "binary code generation", "depth": [1, 3]}, {"source": "code", "target": "binary code", "depth": [1, 2]}, {"source": "code", "target": "code generation", "depth": [1, 3]}, {"source": "code", "target": "binary", "depth": [1, 2]}, {"source": "code", "target": "systematic polarization-adjusted convolutional", "depth": [1, 3]}, {"source": "predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "predictive control", "target": "predictive control update", "depth": [1, 3]}, {"source": "predictive control", "target": "control update interval", "depth": [1, 3]}, {"source": "predictive control", "target": "control update", "depth": [1, 3]}, {"source": "predictive control", "target": "data-enabled predictive control", "depth": [1, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "diversity in machine", "depth": [1, 3]}, {"source": "machine translation", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "machine translation", "target": "translation", "depth": [1, 1]}, {"source": "time", "target": "linear time", "depth": [1, 2]}, {"source": "time", "target": "researcher stating broader", "depth": [1, 3]}, {"source": "time", "target": "stating broader impact", "depth": [1, 3]}, {"source": "time", "target": "researcher stating", "depth": [1, 3]}, {"source": "time", "target": "stating broader", "depth": [1, 3]}, {"source": "flow", "target": "normalizing flow", "depth": [1, 2]}, {"source": "flow", "target": "modeling and analysi", "depth": [1, 3]}, {"source": "flow", "target": "analysis of brain", "depth": [1, 3]}, {"source": "flow", "target": "brain aging", "depth": [1, 3]}, {"source": "flow", "target": "aging with normalizing", "depth": [1, 3]}, {"source": "learning framework", "target": "deep learning framework", "depth": [1, 2]}, {"source": "learning framework", "target": "supervised graph learning", "depth": [1, 3]}, {"source": "learning framework", "target": "graph learning framework", "depth": [1, 3]}, {"source": "learning framework", "target": "supervised graph", "depth": [1, 2]}, {"source": "learning framework", "target": "semantic uv mapping", "depth": [1, 3]}, {"source": "task", "target": "context-dependent task", "depth": [1, 3]}, {"source": "task", "target": "autonomous learning", "depth": [1, 2]}, {"source": "task", "target": "learning of multiple", "depth": [1, 3]}, {"source": "task", "target": "autonomou", "depth": [1, 2]}, {"source": "task", "target": "multiple", "depth": [1, 2]}, {"source": "generative adversarial network", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "controlled generative", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "complexity controlled", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "saliency-based video summarization", "depth": [1, 3]}, {"source": "adversarial network", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "controlled generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "complexity controlled", "depth": [1, 3]}, {"source": "adversarial network", "target": "saliency-based video summarization", "depth": [1, 3]}, {"source": "robot", "target": "enabling the sense", "depth": [1, 3]}, {"source": "robot", "target": "dual-arm robot", "depth": [1, 3]}, {"source": "robot", "target": "sense", "depth": [1, 3]}, {"source": "robot", "target": "enabling", "depth": [1, 3]}, {"source": "robot", "target": "dual-arm", "depth": [1, 3]}, {"source": "application", "target": "automatic specialization", "depth": [1, 3]}, {"source": "application", "target": "gaming application", "depth": [1, 3]}, {"source": "application", "target": "azp", "depth": [1, 3]}, {"source": "application", "target": "specialization", "depth": [1, 3]}, {"source": "application", "target": "gaming", "depth": [1, 3]}, {"source": "theory", "target": "parallelism in blockchain", "depth": [1, 3]}, {"source": "theory", "target": "theory of transaction", "depth": [1, 3]}, {"source": "theory", "target": "transaction parallelism", "depth": [1, 3]}, {"source": "theory", "target": "blockchain", "depth": [1, 1]}, {"source": "theory", "target": "transaction", "depth": [1, 2]}, {"source": "translation", "target": "diversity in machine", "depth": [1, 3]}, {"source": "translation", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "translation", "target": "diversity", "depth": [1, 2]}, {"source": "translation", "target": "machine", "depth": [1, 1]}, {"source": "translation", "target": "decoding", "depth": [1, 2]}, {"source": "differential equation", "target": "stochastic differential equation", "depth": [1, 1]}, {"source": "differential equation", "target": "approximations of stochastic", "depth": [1, 3]}, {"source": "differential equation", "target": "equations with unbounded", "depth": [1, 3]}, {"source": "differential equation", "target": "convergence of smooth", "depth": [1, 3]}, {"source": "differential equation", "target": "unbounded coefficient", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "contrastive self-supervised learning", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "temporal information", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "detection performance", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "controllable environment", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "performance of self-supervised", "depth": [1, 3]}, {"source": "learning method", "target": "machine learning method", "depth": [1, 1]}, {"source": "learning method", "target": "deep learning method", "depth": [1, 2]}, {"source": "learning method", "target": "model for prediction", "depth": [1, 3]}, {"source": "learning method", "target": "prediction of power", "depth": [1, 3]}, {"source": "learning method", "target": "power output", "depth": [1, 3]}, {"source": "training", "target": "tight hardness result", "depth": [1, 3]}, {"source": "training", "target": "results for training", "depth": [1, 3]}, {"source": "training", "target": "relu network", "depth": [1, 2]}, {"source": "training", "target": "hardness result", "depth": [1, 3]}, {"source": "training", "target": "tight hardnes", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "urinary tract infection", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "connected health", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "people with dementium", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "representation for connected", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "learning for analysing", "depth": [1, 3]}, {"source": "machine", "target": "diversity in machine", "depth": [1, 3]}, {"source": "machine", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "machine", "target": "diversity", "depth": [1, 2]}, {"source": "machine", "target": "decoding", "depth": [1, 2]}, {"source": "machine", "target": "interactive machine learning", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 1]}, {"source": "artificial intelligence", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "natural and artificial", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "meta-learning", "depth": [1, 1]}, {"source": "artificial intelligence", "target": "fourth industrial revolution", "depth": [1, 3]}, {"source": "approximation", "target": "natural gradient based", "depth": [1, 3]}, {"source": "approximation", "target": "eigenvalue-corrected natural gradient", "depth": [1, 3]}, {"source": "approximation", "target": "natural gradient", "depth": [1, 2]}, {"source": "approximation", "target": "gradient based", "depth": [1, 3]}, {"source": "approximation", "target": "randomized quaternion singular", "depth": [1, 3]}, {"source": "optimal control", "target": "properties in optimal", "depth": [1, 3]}, {"source": "optimal control", "target": "turnpike property", "depth": [1, 3]}, {"source": "optimal control", "target": "continuous-time result", "depth": [1, 3]}, {"source": "optimal control", "target": "overview of discrete-time", "depth": [1, 3]}, {"source": "optimal control", "target": "result", "depth": [1, 2]}, {"source": "reconstruction", "target": "curvelet frame", "depth": [1, 3]}, {"source": "reconstruction", "target": "reconstruction using sparsity", "depth": [1, 3]}, {"source": "reconstruction", "target": "sparsity in curvelet", "depth": [1, 3]}, {"source": "reconstruction", "target": "photoacoustic reconstruction", "depth": [1, 3]}, {"source": "reconstruction", "target": "frame", "depth": [1, 2]}, {"source": "efficient", "target": "scalable neural vocoder", "depth": [1, 3]}, {"source": "efficient", "target": "efficient and scalable", "depth": [1, 2]}, {"source": "efficient", "target": "vocoders for streaming", "depth": [1, 3]}, {"source": "efficient", "target": "neural vocoder", "depth": [1, 2]}, {"source": "efficient", "target": "fbwave", "depth": [1, 3]}, {"source": "computing", "target": "aerial delivery network", "depth": [1, 3]}, {"source": "computing", "target": "generation aerial delivery", "depth": [1, 3]}, {"source": "computing", "target": "delivery network", "depth": [1, 3]}, {"source": "computing", "target": "generation aerial", "depth": [1, 3]}, {"source": "computing", "target": "aerial delivery", "depth": [1, 3]}, {"source": "face recognition", "target": "set-based face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "joint clustering", "depth": [1, 3]}, {"source": "face recognition", "target": "clustering and classification", "depth": [1, 3]}, {"source": "face recognition", "target": "clusterface", "depth": [1, 3]}, {"source": "face recognition", "target": "classification for set-based", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "direct evolutionary optimization", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "binary latent", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "evolutionary optimization", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "optimization of variational", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "autoencoders with binary", "depth": [1, 3]}, {"source": "matching", "target": "maximum matching", "depth": [1, 3]}, {"source": "matching", "target": "dense graph", "depth": [1, 3]}, {"source": "matching", "target": "embedding in dense", "depth": [1, 3]}, {"source": "matching", "target": "matching through embedding", "depth": [1, 3]}, {"source": "matching", "target": "dense", "depth": [1, 3]}, {"source": "video", "target": "video quality problem", "depth": [1, 3]}, {"source": "video", "target": "quality problem", "depth": [1, 3]}, {"source": "video", "target": "video quality", "depth": [1, 3]}, {"source": "video", "target": "patch-vq", "depth": [1, 3]}, {"source": "video", "target": "patching", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "syntactic constituency path", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "encoding syntactic constituency", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "syntactic constituency", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "constituency path", "depth": [1, 3]}, {"source": "instance segmentation", "target": "instance", "depth": [1, 2]}, {"source": "instance segmentation", "target": "segmentation of overlapping", "depth": [1, 3]}, {"source": "instance segmentation", "target": "overlapping object", "depth": [1, 3]}, {"source": "instance segmentation", "target": "star-convex polygon", "depth": [1, 3]}, {"source": "instance segmentation", "target": "multistar", "depth": [1, 3]}, {"source": "framework", "target": "hci methodological framework", "depth": [1, 3]}, {"source": "framework", "target": "methodological framework", "depth": [1, 3]}, {"source": "framework", "target": "integrated approach", "depth": [1, 2]}, {"source": "framework", "target": "integrated", "depth": [1, 2]}, {"source": "framework", "target": "dependency-based anomaly detection", "depth": [1, 3]}, {"source": "finite element method", "target": "element method", "depth": [1, 2]}, {"source": "finite element method", "target": "weak galerkin finite", "depth": [1, 2]}, {"source": "finite element method", "target": "galerkin finite element", "depth": [1, 2]}, {"source": "finite element method", "target": "finite element", "depth": [1, 1]}, {"source": "finite element method", "target": "weak galerkin", "depth": [1, 2]}, {"source": "game", "target": "locally-aware constrained game", "depth": [1, 3]}, {"source": "game", "target": "games on network", "depth": [1, 3]}, {"source": "game", "target": "constrained game", "depth": [1, 3]}, {"source": "game", "target": "constrained", "depth": [1, 3]}, {"source": "game", "target": "memory-two zero-determinant strategy", "depth": [1, 3]}, {"source": "active learning", "target": "deep active learning", "depth": [1, 2]}, {"source": "active learning", "target": "sequence labeling based", "depth": [1, 3]}, {"source": "active learning", "target": "uncertainty in gradient", "depth": [1, 3]}, {"source": "active learning", "target": "learning for sequence", "depth": [1, 3]}, {"source": "active learning", "target": "sequence labeling", "depth": [1, 1]}, {"source": "attack", "target": "dnn", "depth": [1, 3]}, {"source": "attack", "target": "backdoor attack", "depth": [1, 2]}, {"source": "attack", "target": "attacks and defense", "depth": [1, 3]}, {"source": "attack", "target": "generalized adversarial", "depth": [1, 3]}, {"source": "attack", "target": "defense", "depth": [1, 3]}, {"source": "adversarial attack", "target": "universal trigger adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "trigger adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "detecting universal trigger", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack with honeypot", "depth": [1, 3]}, {"source": "adversarial attack", "target": "universal trigger", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "medical image", "target": "image segmentation", "depth": [1, 2]}, {"source": "medical image", "target": "medical image translation", "depth": [1, 3]}, {"source": "medical image", "target": "manipulating medical image", "depth": [1, 3]}, {"source": "medical image", "target": "manifold disentanglement", "depth": [1, 3]}, {"source": "speech", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "speech", "target": "streaming", "depth": [1, 2]}, {"source": "speech", "target": "multi-talker speech", "depth": [1, 3]}, {"source": "speech", "target": "multi-talker", "depth": [1, 3]}, {"source": "speech", "target": "speech separation", "depth": [1, 2]}, {"source": "neural architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "neural architecture search", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "neural architecture search", "target": "search", "depth": [1, 1]}, {"source": "neural architecture search", "target": "transition in neural", "depth": [1, 3]}, {"source": "neural architecture search", "target": "inter-layer transition", "depth": [1, 3]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "search", "depth": [1, 1]}, {"source": "architecture search", "target": "transition in neural", "depth": [1, 3]}, {"source": "architecture search", "target": "inter-layer transition", "depth": [1, 3]}, {"source": "robust", "target": "robust instance segmentation", "depth": [1, 3]}, {"source": "robust", "target": "robust instance", "depth": [1, 3]}, {"source": "robust", "target": "dynamic convolution", "depth": [1, 3]}, {"source": "robust", "target": "clouds through dynamic", "depth": [1, 3]}, {"source": "robust", "target": "learning of halfspace", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "distillation", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "knowledge", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "data-free knowledge distillation", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "pruning and quantization", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "kd-lib", "depth": [1, 3]}, {"source": "linear system", "target": "pseudoinverse-free randomized block", "depth": [1, 3]}, {"source": "linear system", "target": "inconsistent linear system", "depth": [1, 3]}, {"source": "linear system", "target": "randomized block iterative", "depth": [1, 3]}, {"source": "linear system", "target": "block iterative method", "depth": [1, 3]}, {"source": "linear system", "target": "randomized block", "depth": [1, 3]}, {"source": "natural language", "target": "natural language generation", "depth": [1, 2]}, {"source": "natural language", "target": "language generation", "depth": [1, 2]}, {"source": "natural language", "target": "neighbor-augmented policy update", "depth": [1, 3]}, {"source": "natural language", "target": "sample-efficient natural language", "depth": [1, 3]}, {"source": "natural language", "target": "policy update", "depth": [1, 3]}, {"source": "lower bound", "target": "approximate knowledge compilation", "depth": [1, 3]}, {"source": "lower bound", "target": "knowledge compilation", "depth": [1, 3]}, {"source": "lower bound", "target": "bounds for approximate", "depth": [1, 2]}, {"source": "lower bound", "target": "approximate knowledge", "depth": [1, 3]}, {"source": "lower bound", "target": "compilation", "depth": [1, 3]}, {"source": "dynamical system", "target": "multiple faults estimation", "depth": [1, 3]}, {"source": "dynamical system", "target": "tractable design", "depth": [1, 3]}, {"source": "dynamical system", "target": "performance bound", "depth": [1, 2]}, {"source": "dynamical system", "target": "faults estimation", "depth": [1, 3]}, {"source": "dynamical system", "target": "estimation in dynamical", "depth": [1, 3]}, {"source": "challenge", "target": "framework and challenge", "depth": [1, 3]}, {"source": "challenge", "target": "federated crowdsensing", "depth": [1, 3]}, {"source": "challenge", "target": "crowdsensing", "depth": [1, 3]}, {"source": "challenge", "target": "federated", "depth": [1, 1]}, {"source": "challenge", "target": "starcraft multi-agent challenge", "depth": [1, 3]}, {"source": "social medium", "target": "social media network", "depth": [1, 3]}, {"source": "social medium", "target": "media network datum", "depth": [1, 3]}, {"source": "social medium", "target": "analysing social medium", "depth": [1, 3]}, {"source": "social medium", "target": "screening of user", "depth": [1, 3]}, {"source": "social medium", "target": "comments and communication", "depth": [1, 3]}, {"source": "representation", "target": "information geometric interpretation", "depth": [1, 3]}, {"source": "representation", "target": "frame less visual", "depth": [1, 3]}, {"source": "representation", "target": "geometric interpretation", "depth": [1, 3]}, {"source": "representation", "target": "visual space", "depth": [1, 3]}, {"source": "representation", "target": "neural manifold", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "deep language-independent network", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "deep language-independent", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "language-independent network", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "world via sentiment", "depth": [1, 3]}, {"source": "sentiment analysi", "target": "network to analyze", "depth": [1, 3]}, {"source": "study", "target": "learnability in gan", "depth": [1, 3]}, {"source": "study", "target": "study of trait", "depth": [1, 3]}, {"source": "study", "target": "traits that affect", "depth": [1, 3]}, {"source": "study", "target": "affect learnability", "depth": [1, 3]}, {"source": "study", "target": "gan", "depth": [1, 1]}, {"source": "synthesi", "target": "conditionally-independent pixel synthesi", "depth": [1, 3]}, {"source": "synthesi", "target": "pixel synthesi", "depth": [1, 3]}, {"source": "synthesi", "target": "image generator", "depth": [1, 3]}, {"source": "synthesi", "target": "generators with conditionally-independent", "depth": [1, 3]}, {"source": "synthesi", "target": "conditionally-independent pixel", "depth": [1, 3]}, {"source": "language", "target": "stream-based monitoring language", "depth": [1, 3]}, {"source": "language", "target": "monitoring language", "depth": [1, 3]}, {"source": "language", "target": "optimizations for stream-based", "depth": [1, 3]}, {"source": "language", "target": "stream-based monitoring", "depth": [1, 3]}, {"source": "language", "target": "automatic optimization", "depth": [1, 3]}, {"source": "neural architecture", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "search", "depth": [1, 1]}, {"source": "neural architecture", "target": "transition in neural", "depth": [1, 3]}, {"source": "neural architecture", "target": "inter-layer transition", "depth": [1, 3]}, {"source": "neural architecture", "target": "transition", "depth": [1, 3]}, {"source": "human", "target": "human action recognition", "depth": [1, 2]}, {"source": "human", "target": "human action", "depth": [1, 2]}, {"source": "human", "target": "complex event", "depth": [1, 3]}, {"source": "human", "target": "recognition in complex", "depth": [1, 3]}, {"source": "human", "target": "event", "depth": [1, 2]}, {"source": "performance", "target": "detection performance", "depth": [1, 2]}, {"source": "performance", "target": "controllable environment", "depth": [1, 3]}, {"source": "performance", "target": "performance of self-supervised", "depth": [1, 3]}, {"source": "performance", "target": "environment", "depth": [1, 1]}, {"source": "performance", "target": "twitter-based exploit detector", "depth": [1, 3]}, {"source": "federated", "target": "centralized learning", "depth": [1, 3]}, {"source": "federated", "target": "federated and centralized", "depth": [1, 3]}, {"source": "federated", "target": "hybrid federated", "depth": [1, 3]}, {"source": "federated", "target": "centralized", "depth": [1, 3]}, {"source": "federated", "target": "hybrid", "depth": [1, 3]}, {"source": "bound", "target": "bounds for approximate", "depth": [1, 2]}, {"source": "bound", "target": "adaptive nonlinear control", "depth": [1, 3]}, {"source": "bound", "target": "nonlinear control", "depth": [1, 2]}, {"source": "bound", "target": "bounds for adaptive", "depth": [1, 3]}, {"source": "bound", "target": "adaptive nonlinear", "depth": [1, 3]}, {"source": "text", "target": "causal bayesian network", "depth": [1, 3]}, {"source": "text", "target": "learning causal bayesian", "depth": [1, 3]}, {"source": "text", "target": "networks from text", "depth": [1, 3]}, {"source": "text", "target": "causal bayesian", "depth": [1, 3]}, {"source": "text", "target": "bayesian network", "depth": [1, 2]}, {"source": "uncertainty", "target": "robustnes", "depth": [1, 1]}, {"source": "uncertainty", "target": "role of uncertainty", "depth": [1, 3]}, {"source": "uncertainty", "target": "role", "depth": [1, 1]}, {"source": "uncertainty", "target": "anticipatory", "depth": [1, 3]}, {"source": "uncertainty", "target": "improves robustnes", "depth": [1, 3]}, {"source": "state estimation", "target": "distributed optimization scheme", "depth": [1, 3]}, {"source": "state estimation", "target": "norm-bounded uncertainty", "depth": [1, 3]}, {"source": "state estimation", "target": "distributed optimization", "depth": [1, 2]}, {"source": "state estimation", "target": "optimization scheme", "depth": [1, 3]}, {"source": "state estimation", "target": "scheme for state", "depth": [1, 3]}, {"source": "time series", "target": "time series representation", "depth": [1, 3]}, {"source": "time series", "target": "series representation learning", "depth": [1, 3]}, {"source": "time series", "target": "self-supervised time series", "depth": [1, 3]}, {"source": "time series", "target": "inter-intra relational reasoning", "depth": [1, 3]}, {"source": "time series", "target": "relational reasoning", "depth": [1, 2]}, {"source": "motion planning", "target": "control barrier function", "depth": [1, 2]}, {"source": "motion planning", "target": "robust motion planning", "depth": [1, 3]}, {"source": "motion planning", "target": "barrier function", "depth": [1, 2]}, {"source": "motion planning", "target": "robust motion", "depth": [1, 3]}, {"source": "motion planning", "target": "planning for dynamic", "depth": [1, 3]}, {"source": "deep learning approach", "target": "document understanding", "depth": [1, 3]}, {"source": "deep learning approach", "target": "survey of deep", "depth": [1, 3]}, {"source": "deep learning approach", "target": "approaches for ocr", "depth": [1, 3]}, {"source": "deep learning approach", "target": "ocr and document", "depth": [1, 3]}, {"source": "deep learning approach", "target": "predicting cardiovascular risk", "depth": [1, 3]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 2]}, {"source": "attention network", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "attention network", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "attention network", "target": "path planning", "depth": [1, 1]}, {"source": "attention network", "target": "large-scale multi-robot path", "depth": [1, 3]}, {"source": "gan", "target": "structured latent manifold", "depth": [1, 3]}, {"source": "gan", "target": "conditional gan", "depth": [1, 3]}, {"source": "gan", "target": "geometrically structured latent", "depth": [1, 3]}, {"source": "gan", "target": "latent manifold", "depth": [1, 3]}, {"source": "gan", "target": "train your conditional", "depth": [1, 3]}, {"source": "depth estimation", "target": "multi-view depth estimation", "depth": [1, 2]}, {"source": "depth estimation", "target": "multi-view depth", "depth": [1, 2]}, {"source": "depth estimation", "target": "epipolar spatio-temporal network", "depth": [1, 3]}, {"source": "depth estimation", "target": "estimation using epipolar", "depth": [1, 3]}, {"source": "depth estimation", "target": "spatio-temporal network", "depth": [1, 3]}, {"source": "model predictive", "target": "predictive control update", "depth": [1, 3]}, {"source": "model predictive", "target": "control update interval", "depth": [1, 3]}, {"source": "model predictive", "target": "control update", "depth": [1, 3]}, {"source": "model predictive", "target": "learning model predictive", "depth": [1, 3]}, {"source": "model predictive", "target": "periodically correlated building", "depth": [1, 3]}, {"source": "reconfigurable intelligent surface", "target": "intelligent surface", "depth": [1, 1]}, {"source": "reconfigurable intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 2]}, {"source": "reconfigurable intelligent surface", "target": "aided multi-user network", "depth": [1, 3]}, {"source": "reconfigurable intelligent surface", "target": "interplay between noma", "depth": [1, 3]}, {"source": "reconfigurable intelligent surface", "target": "aided multi-user", "depth": [1, 3]}, {"source": "shape", "target": "multi-view transformation network", "depth": [1, 3]}, {"source": "shape", "target": "shape recognition", "depth": [1, 3]}, {"source": "shape", "target": "transformation network", "depth": [1, 3]}, {"source": "shape", "target": "multi-view transformation", "depth": [1, 3]}, {"source": "shape", "target": "mvtn", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 2]}, {"source": "human pose", "target": "shape estimation", "depth": [1, 2]}, {"source": "human pose", "target": "pose and shape", "depth": [1, 2]}, {"source": "human pose", "target": "learnable volumetric aggregation", "depth": [1, 3]}, {"source": "human pose", "target": "multi-view human pose", "depth": [1, 3]}, {"source": "inference", "target": "variational inference", "depth": [1, 2]}, {"source": "inference", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "inference", "target": "inference and control", "depth": [1, 3]}, {"source": "inference", "target": "processes modeling", "depth": [1, 3]}, {"source": "inference", "target": "hawkes process", "depth": [1, 2]}, {"source": "kernel", "target": "kernel using switchable", "depth": [1, 3]}, {"source": "kernel", "target": "continuous conversion", "depth": [1, 3]}, {"source": "kernel", "target": "switchable cyclegan", "depth": [1, 3]}, {"source": "kernel", "target": "cyclegan with adain", "depth": [1, 3]}, {"source": "kernel", "target": "conversion", "depth": [1, 1]}, {"source": "pandemic", "target": "economic risk evaluation", "depth": [1, 3]}, {"source": "pandemic", "target": "unsupervised learning", "depth": [1, 2]}, {"source": "pandemic", "target": "learning for economic", "depth": [1, 3]}, {"source": "pandemic", "target": "economic risk", "depth": [1, 3]}, {"source": "pandemic", "target": "risk evaluation", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "soft data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "learning by soft", "depth": [1, 3]}, {"source": "data augmentation", "target": "soft datum", "depth": [1, 3]}, {"source": "data augmentation", "target": "generalization in reinforcement", "depth": [1, 2]}, {"source": "gaussian proces", "target": "hybrid gaussian proces", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process model", "depth": [1, 3]}, {"source": "gaussian proces", "target": "entity embedding vector", "depth": [1, 3]}, {"source": "gaussian proces", "target": "hybrid gaussian", "depth": [1, 3]}, {"source": "gaussian proces", "target": "lines using hybrid", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "social network", "target": "social networks based", "depth": [1, 3]}, {"source": "social network", "target": "marketing resource", "depth": [1, 3]}, {"source": "social network", "target": "message distribution", "depth": [1, 3]}, {"source": "social network", "target": "method for community", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 1]}, {"source": "generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "generative model", "target": "multi-objective reinforcement learning", "depth": [1, 2]}, {"source": "generative model", "target": "provable multi-objective reinforcement", "depth": [1, 3]}, {"source": "generative model", "target": "learning with generative", "depth": [1, 3]}, {"source": "recommendation", "target": "exploring global information", "depth": [1, 3]}, {"source": "recommendation", "target": "session-based recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "global information", "depth": [1, 3]}, {"source": "recommendation", "target": "information for session-based", "depth": [1, 3]}, {"source": "recommendation", "target": "exploring global", "depth": [1, 3]}, {"source": "search", "target": "supervised text classification", "depth": [1, 3]}, {"source": "search", "target": "text search", "depth": [1, 3]}, {"source": "search", "target": "text classification", "depth": [1, 1]}, {"source": "search", "target": "supervised text", "depth": [1, 3]}, {"source": "search", "target": "classification using text", "depth": [1, 3]}, {"source": "logic", "target": "modal intuitionistic logic", "depth": [1, 3]}, {"source": "logic", "target": "intuitionistic logic", "depth": [1, 3]}, {"source": "logic", "target": "theorems for modal", "depth": [1, 3]}, {"source": "logic", "target": "goldblatt-thomason theorem", "depth": [1, 3]}, {"source": "logic", "target": "theorem", "depth": [1, 2]}, {"source": "entity recognition", "target": "named entity recognition", "depth": [1, 1]}, {"source": "entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "entity recognition", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "entity recognition", "target": "multi-dataset evaluation", "depth": [1, 3]}, {"source": "entity recognition", "target": "evaluation for named", "depth": [1, 3]}, {"source": "graph convolutional", "target": "graph convolutional adversarial", "depth": [1, 3]}, {"source": "graph convolutional", "target": "convolutional adversarial network", "depth": [1, 3]}, {"source": "graph convolutional", "target": "generate realistic dance", "depth": [1, 3]}, {"source": "graph convolutional", "target": "realistic dance motion", "depth": [1, 3]}, {"source": "graph convolutional", "target": "motions from audio", "depth": [1, 3]}, {"source": "linear", "target": "linear symmetry-based disentanglement", "depth": [1, 3]}, {"source": "linear", "target": "metric for linear", "depth": [1, 3]}, {"source": "linear", "target": "symmetry-based disentanglement", "depth": [1, 3]}, {"source": "linear", "target": "disentanglement", "depth": [1, 2]}, {"source": "linear", "target": "linear logic", "depth": [1, 3]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "soft lexical constraint", "depth": [1, 3]}, {"source": "neural machine translation", "target": "lexical constraint", "depth": [1, 3]}, {"source": "neural machine translation", "target": "transformer with repositioning", "depth": [1, 3]}, {"source": "neural machine translation", "target": "repositioning for neural", "depth": [1, 3]}, {"source": "image generation", "target": "few-shot image generation", "depth": [1, 3]}, {"source": "image generation", "target": "unsupervised few-shot image", "depth": [1, 3]}, {"source": "image generation", "target": "autoencoders for unsupervised", "depth": [1, 3]}, {"source": "image generation", "target": "few-shot image", "depth": [1, 2]}, {"source": "image generation", "target": "augmentation-interpolative autoencoder", "depth": [1, 3]}, {"source": "service", "target": "latency-sensitive service delivery", "depth": [1, 3]}, {"source": "service", "target": "service delivery", "depth": [1, 3]}, {"source": "service", "target": "latency-sensitive service", "depth": [1, 3]}, {"source": "service", "target": "delivery with uav-assisted", "depth": [1, 3]}, {"source": "service", "target": "delivery", "depth": [1, 3]}, {"source": "metric learning", "target": "deep metric learning", "depth": [1, 2]}, {"source": "metric learning", "target": "knowledge retention", "depth": [1, 3]}, {"source": "metric learning", "target": "retention through metric", "depth": [1, 3]}, {"source": "metric learning", "target": "knowledge", "depth": [1, 1]}, {"source": "metric learning", "target": "retention", "depth": [1, 3]}, {"source": "adversarial training", "target": "virtual adversarial training", "depth": [1, 3]}, {"source": "adversarial training", "target": "latent space virtual", "depth": [1, 3]}, {"source": "adversarial training", "target": "space virtual adversarial", "depth": [1, 3]}, {"source": "adversarial training", "target": "latent space", "depth": [1, 2]}, {"source": "adversarial training", "target": "virtual adversarial", "depth": [1, 3]}, {"source": "library", "target": "partially ordered hierarchical", "depth": [1, 3]}, {"source": "library", "target": "ordered hierarchical planner", "depth": [1, 3]}, {"source": "library", "target": "partially ordered", "depth": [1, 3]}, {"source": "library", "target": "hierarchical planner", "depth": [1, 3]}, {"source": "library", "target": "totally and partially", "depth": [1, 3]}, {"source": "visual question answering", "target": "visual question", "depth": [1, 1]}, {"source": "visual question answering", "target": "answering", "depth": [1, 2]}, {"source": "visual question answering", "target": "consistent visual question", "depth": [1, 3]}, {"source": "visual question answering", "target": "lexical perturbation", "depth": [1, 3]}, {"source": "visual question answering", "target": "perturbations for consistent", "depth": [1, 3]}, {"source": "intelligence", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "intelligence", "target": "natural and artificial", "depth": [1, 3]}, {"source": "intelligence", "target": "meta-learning", "depth": [1, 1]}, {"source": "intelligence", "target": "fourth industrial revolution", "depth": [1, 3]}, {"source": "intelligence", "target": "industrial revolution", "depth": [1, 3]}, {"source": "power system", "target": "power system testbed", "depth": [1, 3]}, {"source": "power system", "target": "resilient power system", "depth": [1, 3]}, {"source": "power system", "target": "cyber-physical resilient power", "depth": [1, 3]}, {"source": "power system", "target": "system testbed", "depth": [1, 3]}, {"source": "power system", "target": "resilient power", "depth": [1, 3]}, {"source": "gaussian process", "target": "process", "depth": [1, 2]}, {"source": "gaussian process", "target": "deep gaussian process", "depth": [1, 3]}, {"source": "gaussian process", "target": "steerable conditional neural", "depth": [1, 3]}, {"source": "gaussian process", "target": "conditional neural process", "depth": [1, 3]}, {"source": "gaussian process", "target": "stochastic field", "depth": [1, 3]}, {"source": "interaction", "target": "kinetic simulation", "depth": [1, 3]}, {"source": "interaction", "target": "plasma-material interaction", "depth": [1, 3]}, {"source": "interaction", "target": "parallel", "depth": [1, 3]}, {"source": "interaction", "target": "pife-pic", "depth": [1, 3]}, {"source": "interaction", "target": "simulations of plasma-material", "depth": [1, 3]}, {"source": "performance analysi", "target": "conventional deep learning", "depth": [1, 3]}, {"source": "performance analysi", "target": "empirical performance analysi", "depth": [1, 3]}, {"source": "performance analysi", "target": "analysis of conventional", "depth": [1, 3]}, {"source": "performance analysi", "target": "conventional deep", "depth": [1, 3]}, {"source": "performance analysi", "target": "secure performance analysi", "depth": [1, 3]}, {"source": "fairnes", "target": "minimax group fairnes", "depth": [1, 3]}, {"source": "fairnes", "target": "algorithms and experiment", "depth": [1, 3]}, {"source": "fairnes", "target": "group fairnes", "depth": [1, 3]}, {"source": "fairnes", "target": "minimax group", "depth": [1, 3]}, {"source": "fairnes", "target": "experiment", "depth": [1, 2]}, {"source": "research", "target": "wearable computing research", "depth": [1, 3]}, {"source": "research", "target": "computing research", "depth": [1, 3]}, {"source": "research", "target": "systematic review", "depth": [1, 2]}, {"source": "research", "target": "trends in wearable", "depth": [1, 3]}, {"source": "research", "target": "wearable computing", "depth": [1, 3]}, {"source": "security", "target": "inflating cardinality estimate", "depth": [1, 3]}, {"source": "security", "target": "inflating cardinality", "depth": [1, 3]}, {"source": "security", "target": "cardinality estimate", "depth": [1, 3]}, {"source": "security", "target": "hll", "depth": [1, 3]}, {"source": "security", "target": "hyperloglog", "depth": [1, 3]}, {"source": "fast", "target": "fast auxiliary space", "depth": [1, 3]}, {"source": "fast", "target": "auxiliary space preconditioner", "depth": [1, 3]}, {"source": "fast", "target": "preconditioners on surface", "depth": [1, 3]}, {"source": "fast", "target": "auxiliary space", "depth": [1, 3]}, {"source": "fast", "target": "space preconditioner", "depth": [1, 3]}, {"source": "edge computing", "target": "edge computing applied", "depth": [1, 3]}, {"source": "edge computing", "target": "internet of vehicle", "depth": [1, 3]}, {"source": "edge computing", "target": "survey on blockchain", "depth": [1, 3]}, {"source": "edge computing", "target": "blockchain and edge", "depth": [1, 3]}, {"source": "edge computing", "target": "computing applied", "depth": [1, 3]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity recognition", "target": "multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity recognition", "target": "evaluation for named", "depth": [1, 3]}, {"source": "named entity recognition", "target": "interpretable multi-dataset", "depth": [1, 3]}, {"source": "intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 2]}, {"source": "intelligent surface", "target": "large intelligent surface", "depth": [1, 2]}, {"source": "intelligent surface", "target": "aided multi-user network", "depth": [1, 3]}, {"source": "intelligent surface", "target": "interplay between noma", "depth": [1, 3]}, {"source": "intelligent surface", "target": "aided multi-user", "depth": [1, 3]}, {"source": "recent advance", "target": "advance", "depth": [1, 2]}, {"source": "recent advance", "target": "selective image encryption", "depth": [1, 3]}, {"source": "recent advance", "target": "advances in selective", "depth": [1, 3]}, {"source": "recent advance", "target": "selective image", "depth": [1, 3]}, {"source": "recent advance", "target": "image encryption", "depth": [1, 3]}, {"source": "modeling", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "modeling", "target": "inference and control", "depth": [1, 3]}, {"source": "modeling", "target": "processes modeling", "depth": [1, 3]}, {"source": "modeling", "target": "hawkes process", "depth": [1, 2]}, {"source": "modeling", "target": "species diffusion", "depth": [1, 3]}, {"source": "environment", "target": "detection performance", "depth": [1, 2]}, {"source": "environment", "target": "controllable environment", "depth": [1, 3]}, {"source": "environment", "target": "performance of self-supervised", "depth": [1, 3]}, {"source": "environment", "target": "competitive environment", "depth": [1, 3]}, {"source": "environment", "target": "limitations of learning", "depth": [1, 3]}, {"source": "machine learning method", "target": "model for prediction", "depth": [1, 3]}, {"source": "machine learning method", "target": "prediction of power", "depth": [1, 3]}, {"source": "machine learning method", "target": "power output", "depth": [1, 3]}, {"source": "machine learning method", "target": "output of wave", "depth": [1, 3]}, {"source": "machine learning method", "target": "wave farm", "depth": [1, 3]}, {"source": "testing", "target": "charles can pen-test", "depth": [1, 3]}, {"source": "testing", "target": "vulnerability testing", "depth": [1, 3]}, {"source": "testing", "target": "evolutionary approach", "depth": [1, 3]}, {"source": "testing", "target": "approach to vulnerability", "depth": [1, 3]}, {"source": "testing", "target": "pen-test", "depth": [1, 3]}, {"source": "visual question", "target": "answering", "depth": [1, 2]}, {"source": "visual question", "target": "consistent visual question", "depth": [1, 3]}, {"source": "visual question", "target": "lexical perturbation", "depth": [1, 3]}, {"source": "visual question", "target": "perturbations for consistent", "depth": [1, 3]}, {"source": "visual question", "target": "incorporating pointing", "depth": [1, 3]}, {"source": "fading channel", "target": "fast fading channel", "depth": [1, 3]}, {"source": "fading channel", "target": "frequency domain equalization", "depth": [1, 3]}, {"source": "fading channel", "target": "low-complexity frequency domain", "depth": [1, 3]}, {"source": "fading channel", "target": "frequency domain", "depth": [1, 2]}, {"source": "fading channel", "target": "domain equalization", "depth": [1, 3]}, {"source": "principle", "target": "speed-up ramp-counter adc", "depth": [1, 3]}, {"source": "principle", "target": "locality principle", "depth": [1, 3]}, {"source": "principle", "target": "adc using locality", "depth": [1, 3]}, {"source": "principle", "target": "ramp-counter adc", "depth": [1, 3]}, {"source": "principle", "target": "speed-up ramp-counter", "depth": [1, 3]}, {"source": "exploring", "target": "data science tool", "depth": [1, 3]}, {"source": "exploring", "target": "exploring the political", "depth": [1, 3]}, {"source": "exploring", "target": "science tool", "depth": [1, 3]}, {"source": "exploring", "target": "political pulse", "depth": [1, 3]}, {"source": "exploring", "target": "country using datum", "depth": [1, 3]}, {"source": "learning technique", "target": "machine learning technique", "depth": [1, 2]}, {"source": "learning technique", "target": "low-cost nir spectrometer", "depth": [1, 3]}, {"source": "learning technique", "target": "egg storage time", "depth": [1, 3]}, {"source": "learning technique", "target": "low-cost nir", "depth": [1, 3]}, {"source": "learning technique", "target": "nir spectrometer", "depth": [1, 3]}, {"source": "transformer", "target": "multi-label image classification", "depth": [1, 3]}, {"source": "transformer", "target": "general multi-label image", "depth": [1, 3]}, {"source": "transformer", "target": "classification with transformer", "depth": [1, 3]}, {"source": "transformer", "target": "multi-label image", "depth": [1, 3]}, {"source": "transformer", "target": "general multi-label", "depth": [1, 3]}, {"source": "meta-learning", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "meta-learning", "target": "natural and artificial", "depth": [1, 3]}, {"source": "meta-learning", "target": "connecting context-specific adaptation", "depth": [1, 3]}, {"source": "meta-learning", "target": "humans to meta-learning", "depth": [1, 3]}, {"source": "meta-learning", "target": "context-specific adaptation", "depth": [1, 3]}, {"source": "finite element", "target": "element method", "depth": [1, 2]}, {"source": "finite element", "target": "bakhvalov-type mesh", "depth": [1, 3]}, {"source": "finite element", "target": "spectral finite element", "depth": [1, 3]}, {"source": "finite element", "target": "finite element approximation", "depth": [1, 3]}, {"source": "finite element", "target": "softfem", "depth": [1, 3]}, {"source": "robustnes", "target": "improves robustnes", "depth": [1, 3]}, {"source": "robustnes", "target": "uncertainty in deep", "depth": [1, 2]}, {"source": "robustnes", "target": "rethinking uncertainty", "depth": [1, 3]}, {"source": "robustnes", "target": "optimization under uncertainty", "depth": [1, 3]}, {"source": "robustnes", "target": "robustness concept", "depth": [1, 3]}, {"source": "scene graph", "target": "road scene graph", "depth": [1, 3]}, {"source": "scene graph", "target": "scene representation dataset", "depth": [1, 3]}, {"source": "scene graph", "target": "semantic graph-based scene", "depth": [1, 3]}, {"source": "scene graph", "target": "graph-based scene representation", "depth": [1, 3]}, {"source": "scene graph", "target": "intelligent vehicle", "depth": [1, 3]}, {"source": "domain", "target": "adaptation", "depth": [1, 1]}, {"source": "domain", "target": "heuristic domain adaptation", "depth": [1, 3]}, {"source": "domain", "target": "heuristic domain", "depth": [1, 3]}, {"source": "domain", "target": "robust dpg method", "depth": [1, 3]}, {"source": "domain", "target": "robust dpg", "depth": [1, 3]}, {"source": "feature", "target": "audio feature", "depth": [1, 3]}, {"source": "feature", "target": "movement generation", "depth": [1, 3]}, {"source": "feature", "target": "generation with audio", "depth": [1, 3]}, {"source": "feature", "target": "movement", "depth": [1, 2]}, {"source": "feature", "target": "audio", "depth": [1, 2]}, {"source": "property", "target": "parametric graph template", "depth": [1, 3]}, {"source": "property", "target": "properties and algorithm", "depth": [1, 3]}, {"source": "property", "target": "graph template", "depth": [1, 3]}, {"source": "property", "target": "parametric graph", "depth": [1, 3]}, {"source": "property", "target": "template", "depth": [1, 2]}, {"source": "perspective", "target": "deep learning perspective", "depth": [1, 3]}, {"source": "perspective", "target": "edge", "depth": [1, 2]}, {"source": "perspective", "target": "perspectives from teacher", "depth": [1, 3]}, {"source": "perspective", "target": "teachers and student", "depth": [1, 3]}, {"source": "perspective", "target": "rubrics for capstone", "depth": [1, 3]}, {"source": "mobile robot", "target": "mobile robot navigation", "depth": [1, 3]}, {"source": "mobile robot", "target": "control for mobile", "depth": [1, 3]}, {"source": "mobile robot", "target": "robot navigation", "depth": [1, 2]}, {"source": "mobile robot", "target": "navigation using machine", "depth": [1, 3]}, {"source": "mobile robot", "target": "motion control", "depth": [1, 2]}, {"source": "face", "target": "face generation", "depth": [1, 2]}, {"source": "face", "target": "lifting", "depth": [1, 3]}, {"source": "face", "target": "stylegan", "depth": [1, 3]}, {"source": "face", "target": "low-resolution face recognition", "depth": [1, 3]}, {"source": "face", "target": "low-resolution face", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge retention", "depth": [1, 3]}, {"source": "knowledge", "target": "retention through metric", "depth": [1, 3]}, {"source": "knowledge", "target": "retention", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge transfer", "depth": [1, 3]}, {"source": "knowledge", "target": "transfer in deep", "depth": [1, 3]}, {"source": "deep learning based", "target": "explaining deep learning", "depth": [1, 2]}, {"source": "deep learning based", "target": "computer-aided diagnosis system", "depth": [1, 3]}, {"source": "deep learning based", "target": "diagnosis system", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based computer-aided", "depth": [1, 3]}, {"source": "deep learning based", "target": "based computer-aided diagnosi", "depth": [1, 3]}, {"source": "language understanding", "target": "spoken language understanding", "depth": [1, 2]}, {"source": "language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "language understanding", "target": "understanding resource package", "depth": [1, 3]}, {"source": "language understanding", "target": "language understanding resource", "depth": [1, 3]}, {"source": "language understanding", "target": "resource package", "depth": [1, 3]}, {"source": "path planning", "target": "graph attention network", "depth": [1, 2]}, {"source": "path planning", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "path planning", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "path planning", "target": "large-scale multi-robot path", "depth": [1, 3]}, {"source": "path planning", "target": "graph attention", "depth": [1, 1]}, {"source": "uncertainty estimation", "target": "neural uncertainty estimation", "depth": [1, 3]}, {"source": "uncertainty estimation", "target": "target speaker extraction", "depth": [1, 3]}, {"source": "uncertainty estimation", "target": "improving rnn transducer", "depth": [1, 2]}, {"source": "uncertainty estimation", "target": "rnn transducer", "depth": [1, 2]}, {"source": "uncertainty estimation", "target": "transducer with target", "depth": [1, 3]}, {"source": "relation extraction", "target": "long-tail relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "learning relation prototype", "depth": [1, 3]}, {"source": "relation extraction", "target": "prototype from unlabeled", "depth": [1, 3]}, {"source": "relation extraction", "target": "texts for long-tail", "depth": [1, 3]}, {"source": "relation extraction", "target": "relation prototype", "depth": [1, 3]}, {"source": "galerkin method", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "galerkin method", "target": "matrix-free isogeometric galerkin", "depth": [1, 3]}, {"source": "galerkin method", "target": "isogeometric galerkin method", "depth": [1, 3]}, {"source": "galerkin method", "target": "interpolation based quadrature", "depth": [1, 3]}, {"source": "galerkin method", "target": "tensor product spline", "depth": [1, 3]}, {"source": "deep generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "deep generative model", "target": "volumetrized deep generative", "depth": [1, 3]}, {"source": "deep generative model", "target": "progressively volumetrized deep", "depth": [1, 3]}, {"source": "deep generative model", "target": "data-efficient contextual learning", "depth": [1, 3]}, {"source": "deep generative model", "target": "image recovery", "depth": [1, 3]}, {"source": "multi-view clustering", "target": "incomplete multi-view clustering", "depth": [1, 2]}, {"source": "multi-view clustering", "target": "incomplete multi-view", "depth": [1, 2]}, {"source": "multi-view clustering", "target": "unbalanced incomplete multi-view", "depth": [1, 3]}, {"source": "multi-view clustering", "target": "view evolution", "depth": [1, 3]}, {"source": "multi-view clustering", "target": "weak view", "depth": [1, 3]}, {"source": "strategy", "target": "deviation and adaptive", "depth": [1, 3]}, {"source": "strategy", "target": "adaptive strategy", "depth": [1, 3]}, {"source": "strategy", "target": "continuous blackjack", "depth": [1, 3]}, {"source": "strategy", "target": "equilibrium", "depth": [1, 3]}, {"source": "strategy", "target": "blackjack", "depth": [1, 3]}, {"source": "learning algorithm", "target": "model learning algorithm", "depth": [1, 3]}, {"source": "learning algorithm", "target": "accurate action model", "depth": [1, 3]}, {"source": "learning algorithm", "target": "action model learning", "depth": [1, 3]}, {"source": "learning algorithm", "target": "accurate action", "depth": [1, 3]}, {"source": "learning algorithm", "target": "action model", "depth": [1, 3]}, {"source": "boltzmann machine", "target": "restricted boltzmann machine", "depth": [1, 2]}, {"source": "boltzmann machine", "target": "restricted boltzmann", "depth": [1, 2]}, {"source": "boltzmann machine", "target": "multinary restricted boltzmann", "depth": [1, 3]}, {"source": "boltzmann machine", "target": "tractable loss function", "depth": [1, 3]}, {"source": "boltzmann machine", "target": "color image generation", "depth": [1, 3]}, {"source": "segmentation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "segmentation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "segmentation", "target": "channel-wise", "depth": [1, 3]}, {"source": "segmentation", "target": "text segmentation", "depth": [1, 3]}, {"source": "segmentation", "target": "rethinking text segmentation", "depth": [1, 3]}, {"source": "denoising", "target": "image denoising", "depth": [1, 2]}, {"source": "denoising", "target": "regularization by denoising", "depth": [1, 3]}, {"source": "denoising", "target": "reconstruction and calibration", "depth": [1, 3]}, {"source": "denoising", "target": "calibration using regularization", "depth": [1, 3]}, {"source": "denoising", "target": "joint reconstruction", "depth": [1, 3]}, {"source": "regularization", "target": "nonlinear ill-posed equation", "depth": [1, 3]}, {"source": "regularization", "target": "regularization of system", "depth": [1, 3]}, {"source": "regularization", "target": "ill-posed equation", "depth": [1, 3]}, {"source": "regularization", "target": "systems of nonlinear", "depth": [1, 3]}, {"source": "regularization", "target": "graph embedding", "depth": [1, 2]}, {"source": "reinforcement", "target": "transition state", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning of transition", "depth": [1, 3]}, {"source": "reinforcement", "target": "state", "depth": [1, 2]}, {"source": "reinforcement", "target": "offline reinforcement learning", "depth": [1, 3]}, {"source": "reinforcement", "target": "reinforcement learning hand-on", "depth": [1, 3]}, {"source": "word embedding", "target": "deconstructing word embedding", "depth": [1, 3]}, {"source": "word embedding", "target": "word embedding algorithm", "depth": [1, 3]}, {"source": "word embedding", "target": "deconstructing word", "depth": [1, 3]}, {"source": "word embedding", "target": "embedding algorithm", "depth": [1, 3]}, {"source": "word embedding", "target": "deconstructing", "depth": [1, 3]}, {"source": "augmented reality", "target": "manufacturing execution system", "depth": [1, 3]}, {"source": "augmented reality", "target": "integrating augmented reality", "depth": [1, 3]}, {"source": "augmented reality", "target": "level for industry", "depth": [1, 3]}, {"source": "augmented reality", "target": "execution system", "depth": [1, 3]}, {"source": "augmented reality", "target": "cognition level", "depth": [1, 3]}, {"source": "adaptation", "target": "heuristic domain adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "heuristic domain", "depth": [1, 3]}, {"source": "adaptation", "target": "visual emotion adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "emotion adaptation", "depth": [1, 3]}, {"source": "adaptation", "target": "visual emotion", "depth": [1, 3]}, {"source": "neural machine", "target": "soft lexical constraint", "depth": [1, 3]}, {"source": "neural machine", "target": "lexical constraint", "depth": [1, 3]}, {"source": "neural machine", "target": "transformer with repositioning", "depth": [1, 3]}, {"source": "neural machine", "target": "repositioning for neural", "depth": [1, 3]}, {"source": "neural machine", "target": "pure character-based neural", "depth": [1, 3]}, {"source": "inference attack", "target": "membership inference attack", "depth": [1, 2]}, {"source": "inference attack", "target": "membership inference", "depth": [1, 2]}, {"source": "inference attack", "target": "based privacy-preserving technique", "depth": [1, 2]}, {"source": "inference attack", "target": "technique against membership", "depth": [1, 3]}, {"source": "inference attack", "target": "adversarial example based", "depth": [1, 2]}, {"source": "person re-identification", "target": "unsupervised person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "networks via asymmetric", "depth": [1, 3]}, {"source": "person re-identification", "target": "unsupervised person", "depth": [1, 2]}, {"source": "person re-identification", "target": "enhancing diversity", "depth": [1, 3]}, {"source": "person re-identification", "target": "diversity in teacher-student", "depth": [1, 3]}, {"source": "distillation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "distillation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "distillation", "target": "channel-wise", "depth": [1, 3]}, {"source": "distillation", "target": "pruning and quantization", "depth": [1, 3]}, {"source": "distillation", "target": "kd-lib", "depth": [1, 3]}, {"source": "review", "target": "vietnamese review", "depth": [1, 3]}, {"source": "review", "target": "bert for sentiment", "depth": [1, 3]}, {"source": "review", "target": "analysis of vietnamese", "depth": [1, 3]}, {"source": "review", "target": "fine-tuning bert", "depth": [1, 3]}, {"source": "review", "target": "bert", "depth": [1, 2]}, {"source": "role", "target": "role of uncertainty", "depth": [1, 3]}, {"source": "role", "target": "anticipatory", "depth": [1, 3]}, {"source": "role", "target": "infodemic", "depth": [1, 3]}, {"source": "role", "target": "connectivity estimation", "depth": [1, 3]}, {"source": "role", "target": "role of spectral", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "approximations of stochastic", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "equations with unbounded", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "convergence of smooth", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "unbounded coefficient", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "score-based generative modeling", "depth": [1, 3]}, {"source": "diffusion", "target": "communication via diffusion", "depth": [1, 3]}, {"source": "diffusion", "target": "survey on modulation", "depth": [1, 3]}, {"source": "diffusion", "target": "modulation technique", "depth": [1, 3]}, {"source": "diffusion", "target": "techniques in molecular", "depth": [1, 3]}, {"source": "diffusion", "target": "molecular communication", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "sample pair generation", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "ultrasound video contrastive", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "video contrastive representation", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "effective sample pair", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "sample pair", "depth": [1, 3]}, {"source": "mobile device", "target": "object detection processing", "depth": [1, 3]}, {"source": "mobile device", "target": "detection processing pipeline", "depth": [1, 3]}, {"source": "mobile device", "target": "analysis and implication", "depth": [1, 3]}, {"source": "mobile device", "target": "detection processing", "depth": [1, 3]}, {"source": "mobile device", "target": "processing pipeline", "depth": [1, 2]}, {"source": "data analysi", "target": "functional data analysi", "depth": [1, 3]}, {"source": "data analysi", "target": "visual analytics approach", "depth": [1, 2]}, {"source": "data analysi", "target": "progressive functional datum", "depth": [1, 3]}, {"source": "data analysi", "target": "monitor time-series datum", "depth": [1, 3]}, {"source": "data analysi", "target": "analytics approach", "depth": [1, 2]}, {"source": "bayesian optimization", "target": "random mapping function", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "combinatorial bayesian optimization", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "convex polytope", "depth": [1, 2]}, {"source": "bayesian optimization", "target": "optimization with random", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "random mapping", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "frenet space", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "exploring grid topology", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "grid topology reconfiguration", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "simple deep reinforcement", "depth": [1, 3]}, {"source": "conversion", "target": "kernel using switchable", "depth": [1, 3]}, {"source": "conversion", "target": "continuous conversion", "depth": [1, 3]}, {"source": "conversion", "target": "switchable cyclegan", "depth": [1, 3]}, {"source": "conversion", "target": "cyclegan with adain", "depth": [1, 3]}, {"source": "conversion", "target": "lsat behavioral specification", "depth": [1, 3]}, {"source": "graph attention", "target": "graph attention network", "depth": [1, 2]}, {"source": "graph attention", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "graph attention", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "graph attention", "target": "large-scale multi-robot path", "depth": [1, 3]}, {"source": "graph attention", "target": "net length estimation", "depth": [1, 3]}, {"source": "blockchain", "target": "blockchain mechanism", "depth": [1, 3]}, {"source": "blockchain", "target": "characteristics of crypto", "depth": [1, 3]}, {"source": "blockchain", "target": "mechanism and distributional", "depth": [1, 3]}, {"source": "blockchain", "target": "crypto", "depth": [1, 3]}, {"source": "blockchain", "target": "mechanism", "depth": [1, 2]}, {"source": "construction", "target": "heap manipulation", "depth": [1, 3]}, {"source": "construction", "target": "symbiotic construction", "depth": [1, 3]}, {"source": "construction", "target": "construction for heap", "depth": [1, 3]}, {"source": "construction", "target": "manipulation", "depth": [1, 2]}, {"source": "construction", "target": "heap", "depth": [1, 3]}, {"source": "distributed", "target": "communication delay", "depth": [1, 3]}, {"source": "distributed", "target": "optimisation with communication", "depth": [1, 3]}, {"source": "distributed", "target": "distributed optimisation", "depth": [1, 3]}, {"source": "distributed", "target": "delay", "depth": [1, 3]}, {"source": "distributed", "target": "optimisation", "depth": [1, 3]}, {"source": "big datum", "target": "projective clustering approximation", "depth": [1, 3]}, {"source": "big datum", "target": "faster projective clustering", "depth": [1, 3]}, {"source": "big datum", "target": "projective clustering", "depth": [1, 3]}, {"source": "big datum", "target": "clustering approximation", "depth": [1, 3]}, {"source": "big datum", "target": "approximation of big", "depth": [1, 3]}, {"source": "trajectory planning", "target": "multiple autonomous underwater", "depth": [1, 3]}, {"source": "trajectory planning", "target": "autonomous underwater vehicle", "depth": [1, 3]}, {"source": "trajectory planning", "target": "safety guarantee", "depth": [1, 2]}, {"source": "trajectory planning", "target": "planning for multiple", "depth": [1, 3]}, {"source": "trajectory planning", "target": "multiple autonomou", "depth": [1, 3]}, {"source": "sequence labeling", "target": "sequence labeling based", "depth": [1, 3]}, {"source": "sequence labeling", "target": "deep active learning", "depth": [1, 2]}, {"source": "sequence labeling", "target": "uncertainty in gradient", "depth": [1, 3]}, {"source": "sequence labeling", "target": "learning for sequence", "depth": [1, 3]}, {"source": "sequence labeling", "target": "labeling based", "depth": [1, 3]}, {"source": "experimental study", "target": "isolated centrifugal fan", "depth": [1, 3]}, {"source": "experimental study", "target": "tonal noise source", "depth": [1, 3]}, {"source": "experimental study", "target": "numerical and experimental", "depth": [1, 3]}, {"source": "experimental study", "target": "centrifugal fan", "depth": [1, 3]}, {"source": "experimental study", "target": "study of tonal", "depth": [1, 3]}, {"source": "text classification", "target": "supervised text classification", "depth": [1, 3]}, {"source": "text classification", "target": "text search", "depth": [1, 3]}, {"source": "text classification", "target": "supervised text", "depth": [1, 3]}, {"source": "text classification", "target": "classification using text", "depth": [1, 3]}, {"source": "text classification", "target": "sequential targeting", "depth": [1, 3]}, {"source": "continual learning", "target": "deep artificial neuron", "depth": [1, 3]}, {"source": "continual learning", "target": "artificial neuron", "depth": [1, 2]}, {"source": "continual learning", "target": "learning with deep", "depth": [1, 3]}, {"source": "continual learning", "target": "deep artificial", "depth": [1, 3]}, {"source": "continual learning", "target": "neuron", "depth": [1, 2]}, {"source": "resource allocation", "target": "offloading and resource", "depth": [1, 3]}, {"source": "resource allocation", "target": "allocation in mobile", "depth": [1, 3]}, {"source": "resource allocation", "target": "energy-efficient resource allocation", "depth": [1, 3]}, {"source": "resource allocation", "target": "energy-efficient resource", "depth": [1, 3]}, {"source": "resource allocation", "target": "sequential task dependency", "depth": [1, 3]}, {"source": "design", "target": "compesation design", "depth": [1, 3]}, {"source": "design", "target": "narx model", "depth": [1, 3]}, {"source": "design", "target": "models for compesation", "depth": [1, 3]}, {"source": "design", "target": "identification of narx", "depth": [1, 3]}, {"source": "design", "target": "narx", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised object detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised object", "depth": [1, 3]}, {"source": "weakly supervised", "target": "cascade attentive dropout", "depth": [1, 3]}, {"source": "weakly supervised", "target": "attentive dropout", "depth": [1, 3]}, {"source": "weakly supervised", "target": "dropout for weakly", "depth": [1, 3]}, {"source": "action", "target": "action detection", "depth": [1, 2]}, {"source": "action", "target": "battery", "depth": [1, 3]}, {"source": "action", "target": "camera", "depth": [1, 2]}, {"source": "action", "target": "learning a semantic", "depth": [1, 3]}, {"source": "action", "target": "robot cinematography", "depth": [1, 3]}, {"source": "multi-task learning", "target": "incremental deep language", "depth": [1, 3]}, {"source": "multi-task learning", "target": "deep language model", "depth": [1, 3]}, {"source": "multi-task learning", "target": "re-framing incremental deep", "depth": [1, 3]}, {"source": "multi-task learning", "target": "incremental deep", "depth": [1, 3]}, {"source": "multi-task learning", "target": "deep language", "depth": [1, 3]}, {"source": "named entity", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity", "target": "multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity", "target": "evaluation for named", "depth": [1, 3]}, {"source": "named entity", "target": "interpretable multi-dataset", "depth": [1, 3]}, {"source": "named entity", "target": "features for named", "depth": [1, 3]}, {"source": "attention", "target": "scene graph classification", "depth": [1, 3]}, {"source": "attention", "target": "prior knowledge", "depth": [1, 3]}, {"source": "attention", "target": "graph classification", "depth": [1, 3]}, {"source": "attention", "target": "classification by attention", "depth": [1, 3]}, {"source": "attention", "target": "classification with prior", "depth": [1, 3]}, {"source": "learning to segment", "target": "partially labeled dataset", "depth": [1, 3]}, {"source": "learning to segment", "target": "multiple partially labeled", "depth": [1, 3]}, {"source": "learning to segment", "target": "dodnet", "depth": [1, 3]}, {"source": "learning to segment", "target": "labeled dataset", "depth": [1, 3]}, {"source": "learning to segment", "target": "segment multi-organ", "depth": [1, 3]}]}