{"node": [["neural network", "deep neural network", "convolutional neural network", "network", "learning", "reinforcement learning", "deep learning", "machine learning", "deep reinforcement learning", "system", "model", "detection", "object detection", "graph", "representation learning"], ["graph neural network", "recurrent neural network", "transfer learning", "federated learning", "learning to segment", "deep learning model", "learning model", "deep", "deep learning approach", "deep reinforcement", "reinforcement", "training", "machine learning method", "learning method", "machine", "learning approach", "reinforcement learning approach", "transfer", "anomaly detection", "object", "knowledge graph", "autonomous driving", "contrastive representation learning", "federated", "algorithm", "point cloud", "estimation", "problem", "classification", "survey", "datum", "approach", "recognition", "speech recognition", "action recognition", "speech", "image", "analysis", "semantic segmentation", "segmentation", "distillation", "language model", "generation", "face", "image classification", "control", "optimal control", "question answering", "visual question answering", "visual question", "optimization", "dataset", "domain adaptation", "model predictive control", "model predictive", "predictive control", "adaptation", "domain", "graph convolutional network", "communication", "prediction", "pose estimation", "human pose", "method", "embedding", "word embedding", "generative adversarial", "generative adversarial network", "adversarial network", "case study", "convolutional network", "graph convolutional", "information", "self-supervised learning", "code", "machine translation", "neural machine translation", "neural machine", "time", "flow", "learning framework", "task", "robot", "application", "theory", "blockchain", "translation", "differential equation", "stochastic differential equation", "semi-supervised learning", "artificial intelligence", "intelligence", "approximation", "reconstruction", "efficient", "computing", "face recognition", "variational autoencoder", "matching", "video", "instance segmentation", "framework", "finite element method", "finite element", "game", "active learning", "attack", "adversarial attack", "medical image", "neural architecture search", "neural architecture", "search", "architecture search", "robust", "knowledge distillation", "knowledge", "linear system", "natural language", "lower bound", "dynamical system", "challenge", "social medium", "representation", "sentiment analysis", "study", "synthesis", "language", "human", "performance", "environment", "bound", "text", "uncertainty", "robustness", "role", "state estimation", "time series", "motion planning", "attention network", "path planning", "gan", "depth estimation", "reconfigurable intelligent surface", "intelligent surface", "shape", "inference", "kernel", "pandemic", "data augmentation", "gaussian proces", "social network", "generative model", "deep generative model", "recommendation", "text classification", "logic", "entity recognition", "named entity recognition", "named entity", "linear", "image generation", "service", "metric learning", "adversarial training", "library", "meta-learning", "power system", "gaussian process", "interaction", "performance analysis", "fairness", "research", "security", "fast", "edge computing", "recent advance", "modeling", "testing", "fading channel", "principle", "exploring", "learning technique", "transformer", "scene graph", "feature", "property", "perspective", "mobile robot", "deep learning based", "language understanding", "uncertainty estimation", "relation extraction", "galerkin method", "multi-view clustering", "strategy", "learning algorithm", "boltzmann machine", "denoising", "regularization", "augmented reality", "inference attack", "person re-identification", "review", "diffusion", "mobile device", "data analysis", "bayesian optimization", "conversion", "graph attention", "construction", "distributed", "big datum", "trajectory planning", "sequence labeling", "experimental study", "continual learning", "resource allocation", "design", "weakly supervised", "action", "multi-task learning", "attention"], ["spiking neural network", "multi-objective reinforcement learning", "relu network", "machine learning approach", "network acceleration", "recommender system", "detection performance", "deep convolutional neural", "deep convolutional", "random graph", "random", "video object detection", "few-shot object detection", "unsupervised representation learning", "point", "drop estimation", "frenet space", "synthetic datum", "sequence datum", "ontology", "computational approach", "decomposition", "machine learning model", "explaining deep learning", "relevance propagation", "convergence analysis", "face generation", "image classification based", "answering", "driving", "unsupervised domain adaptation", "human action recognition", "human action", "skeleton-based action recognition", "dynamic graph", "motion prediction", "human pose estimation", "temporal convolutional network", "style transfer", "style", "contrastive self-supervised learning", "temporal information", "binary code", "linear time", "normalizing flow", "deep learning framework", "supervised graph", "autonomous learning", "multiple", "diversity", "deep learning method", "natural gradient", "efficient and scalable", "instance", "integrated approach", "element method", "weak galerkin finite", "galerkin finite element", "deep active learning", "backdoor attack", "medical image segmentation", "image segmentation", "streaming", "natural language generation", "language generation", "bounds for approximate", "performance bound", "nonlinear control", "distributed optimization", "control barrier function", "barrier function", "graph attention network", "multi-view depth estimation", "multi-view depth", "reconfigurable intelligent", "shape estimation", "pose and shape", "variational inference", "unsupervised learning", "augmentation", "deep generative", "disentanglement", "few-shot image", "deep metric learning", "process", "systematic review", "large intelligent surface", "advance", "frequency domain", "machine learning technique", "uncertainty in deep", "edge", "robot navigation", "spoken language understanding", "spoken language", "improving rnn transducer", "rnn transducer", "discontinuous galerkin method", "incomplete multi-view clustering", "incomplete multi-view", "restricted boltzmann machine", "restricted boltzmann", "image denoising", "state", "membership inference attack", "membership inference", "based privacy-preserving technique", "unsupervised person", "visual analytics approach", "convex polytope", "safety guarantee", "artificial neuron", "action detection", "camera"], ["enabled federated learning", "intelligent surface enabled", "surface enabled federated", "novo drug design", "approximating retrosynthesis", "drug design", "graph constraint logic", "constraint logic", "algorithms for graph", "low overlap", "clouds with low", "estimation with machine", "fast ir drop", "long-term short-term planning", "video quality problem", "quality problem", "video quality", "radio galaxy", "classification of radio", "data-efficient classification", "communication via diffusion", "survey on modulation", "modulation technique", "causal graph", "index direction", "main input", "direction with transfer", "on-shelf utility mining", "utility mining", "historical ontology", "multi-talker speech recognition", "intrinsic image decomposition", "decomposition using paradigm", "pathology-sensitive deep learning", "weakly labeled datum", "pathology-sensitive deep", "video capsule endoscopy", "layer-wise relevance propagation", "analysis of homotopy-sgd", "non-convex optimization", "homotopy-sgd for non-convex", "distillation for semantic", "channel-wise distillation", "language model performance", "model performance measure", "vocabulary size", "model performance", "lifting", "cancer image classification", "cancer image", "hawkes processes modeling", "inference and control", "processes modeling", "consistent visual question", "stream-based monitoring language", "monitoring language", "optimizations for stream-based", "autonomous driving framework", "short-term trajectory planning", "scan dataset", "supervision for classification", "targeted self supervision", "deep orthogonal linear", "orthogonal linear network", "deep orthogonal", "networks are shallow", "polyflow approximation", "accurate anomaly detection", "accurate anomaly", "detection in dynamic", "manifolds support multiplexed", "support multiplexed integration", "low-dimensional manifolds support", "manifolds support", "communication delay", "optimisation with communication", "distributed optimisation", "scene-compliant motion prediction", "ellipse loss", "loss for scene-compliant", "handling object symmetry", "cnn-based pose estimation", "liquid simulation method", "simulation method", "evaluation of liquid", "dense graph", "embedding in dense", "matching through embedding", "narrative knowledge graph", "clustering in narrative", "narrative knowledge", "controlled generative adversarial", "complexity controlled generative", "self-supervised object detection", "detection without imagenet", "self-emd", "retrieval in clutter", "urban twitter network", "networks and community", "microblogging in athen", "twitter network", "self-supervised models transfer", "models transfer", "binary code generation", "code generation", "predictive control update", "control update interval", "control update", "diversity in machine", "decoding and diversity", "researcher stating broader", "stating broader impact", "researcher stating", "modeling and analysis", "analysis of brain", "supervised graph learning", "graph learning framework", "context-dependent task", "learning of multiple", "controlled generative", "complexity controlled", "enabling the sense", "dual-arm robot", "sense", "enabling", "automatic specialization", "gaming application", "azp", "specialization", "parallelism in blockchain", "theory of transaction", "transaction parallelism", "approximations of stochastic", "equations with unbounded", "controllable environment", "model for prediction", "prediction of power", "tight hardness result", "results for training", "urinary tract infection", "connected health", "people with dementium", "meta-learning in natural", "natural and artificial", "natural gradient based", "eigenvalue-corrected natural gradient", "gradient based", "properties in optimal", "turnpike property", "continuous-time result", "overview of discrete-time", "curvelet frame", "reconstruction using sparsity", "sparsity in curvelet", "scalable neural vocoder", "vocoders for streaming", "aerial delivery network", "generation aerial delivery", "delivery network", "set-based face recognition", "joint clustering", "clustering and classification", "direct evolutionary optimization", "binary latent", "evolutionary optimization", "optimization of variational", "maximum matching", "patch-vq", "syntactic constituency path", "encoding syntactic constituency", "segmentation of overlapping", "overlapping object", "hci methodological framework", "methodological framework", "locally-aware constrained game", "games on network", "constrained game", "sequence labeling based", "uncertainty in gradient", "learning for sequence", "dnn", "universal trigger adversarial", "trigger adversarial attack", "detecting universal trigger", "attack with honeypot", "medical image translation", "multi-talker speech", "multi-talker", "multi-objective neural architecture", "robust instance segmentation", "robust instance", "dynamic convolution", "pseudoinverse-free randomized block", "inconsistent linear system", "randomized block iterative", "neighbor-augmented policy update", "approximate knowledge compilation", "knowledge compilation", "multiple faults estimation", "tractable design", "faults estimation", "framework and challenge", "federated crowdsensing", "crowdsensing", "social media network", "media network datum", "analysing social medium", "information geometric interpretation", "frame less visual", "geometric interpretation", "deep language-independent network", "deep language-independent", "language-independent network", "learnability in gan", "study of trait", "traits that affect", "conditionally-independent pixel synthesis", "pixel synthesis", "image generator", "generators with conditionally-independent", "stream-based monitoring", "complex event", "recognition in complex", "performance of self-supervised", "centralized learning", "federated and centralized", "hybrid federated", "adaptive nonlinear control", "causal bayesian network", "learning causal bayesian", "networks from text", "role of uncertainty", "anticipatory", "distributed optimization scheme", "norm-bounded uncertainty", "optimization scheme", "time series representation", "series representation learning", "self-supervised time series", "robust motion planning", "document understanding", "survey of deep", "approaches for ocr", "ocr and document", "message-aware graph attention", "multi-robot path planning", "structured latent manifold", "conditional gan", "geometrically structured latent", "latent manifold", "epipolar spatio-temporal network", "estimation using epipolar", "learning model predictive", "aided multi-user network", "multi-view transformation network", "shape recognition", "transformation network", "kernel using switchable", "continuous conversion", "switchable cyclegan", "economic risk evaluation", "learning for economic", "economic risk", "soft data augmentation", "learning by soft", "hybrid gaussian proces", "gaussian process model", "entity embedding vector", "hybrid gaussian", "online social network", "provable multi-objective reinforcement", "exploring global information", "session-based recommendation", "global information", "information for session-based", "supervised text classification", "text search", "supervised text", "modal intuitionistic logic", "intuitionistic logic", "theorems for modal", "interpretable multi-dataset evaluation", "graph convolutional adversarial", "convolutional adversarial network", "generate realistic dance", "linear symmetry-based disentanglement", "metric for linear", "symmetry-based disentanglement", "soft lexical constraint", "lexical constraint", "few-shot image generation", "unsupervised few-shot image", "autoencoders for unsupervised", "latency-sensitive service delivery", "service delivery", "latency-sensitive service", "knowledge retention", "retention through metric", "virtual adversarial training", "latent space virtual", "space virtual adversarial", "partially ordered hierarchical", "ordered hierarchical planner", "partially ordered", "lexical perturbation", "fourth industrial revolution", "power system testbed", "resilient power system", "cyber-physical resilient power", "system testbed", "deep gaussian process", "kinetic simulation", "plasma-material interaction", "parallel", "conventional deep learning", "empirical performance analysis", "analysis of conventional", "conventional deep", "minimax group fairness", "algorithms and experiment", "group fairness", "wearable computing research", "computing research", "inflating cardinality estimate", "inflating cardinality", "cardinality estimate", "fast auxiliary space", "auxiliary space preconditioner", "preconditioners on surface", "auxiliary space", "edge computing applied", "internet of vehicle", "survey on blockchain", "multi-dataset evaluation", "interplay between noma", "selective image encryption", "advances in selective", "selective image", "power output", "charles can pen-test", "vulnerability testing", "evolutionary approach", "perturbations for consistent", "fast fading channel", "frequency domain equalization", "low-complexity frequency domain", "speed-up ramp-counter adc", "locality principle", "adc using locality", "ramp-counter adc", "data science tool", "exploring the political", "science tool", "low-cost nir spectrometer", "egg storage time", "connecting context-specific adaptation", "humans to meta-learning", "bakhvalov-type mesh", "spectral finite element", "finite element approximation", "improves robustness", "rethinking uncertainty", "road scene graph", "scene representation dataset", "semantic graph-based scene", "graph-based scene representation", "audio feature", "movement generation", "generation with audio", "parametric graph template", "properties and algorithm", "graph template", "parametric graph", "mobile robot navigation", "control for mobile", "stylegan", "retention", "knowledge transfer", "computer-aided diagnosis system", "diagnosis system", "learning based computer-aided", "understanding resource package", "large-scale multi-robot path", "neural uncertainty estimation", "target speaker extraction", "long-tail relation extraction", "learning relation prototype", "prototype from unlabeled", "texts for long-tail", "matrix-free isogeometric galerkin", "isogeometric galerkin method", "interpolation based quadrature", "volumetrized deep generative", "progressively volumetrized deep", "data-efficient contextual learning", "unbalanced incomplete multi-view", "view evolution", "deviation and adaptive", "adaptive strategy", "continuous blackjack", "model learning algorithm", "accurate action model", "action model learning", "accurate action", "multinary restricted boltzmann", "tractable loss function", "channel-wise", "regularization by denoising", "reconstruction and calibration", "calibration using regularization", "nonlinear ill-posed equation", "ill-posed equation", "systems of nonlinear", "transition state", "learning of transition", "deconstructing word embedding", "word embedding algorithm", "deconstructing word", "embedding algorithm", "manufacturing execution system", "integrating augmented reality", "level for industry", "transformer with repositioning", "repositioning for neural", "technique against membership", "unsupervised person re-identification", "networks via asymmetric", "enhancing diversity", "vietnamese review", "bert for sentiment", "analysis of vietnamese", "fine-tuning bert", "convergence of smooth", "unbounded coefficient", "sample pair generation", "ultrasound video contrastive", "video contrastive representation", "object detection processing", "detection processing pipeline", "analysis and implication", "functional data analysis", "progressive functional datum", "monitor time-series datum", "random mapping function", "combinatorial bayesian optimization", "exploring grid topology", "grid topology reconfiguration", "blockchain mechanism", "characteristics of crypto", "mechanism and distributional", "heap manipulation", "symbiotic construction", "construction for heap", "delay", "projective clustering approximation", "faster projective clustering", "projective clustering", "clustering approximation", "multiple autonomous underwater", "autonomous underwater vehicle", "isolated centrifugal fan", "tonal noise source", "numerical and experimental", "centrifugal fan", "deep artificial neuron", "learning with deep", "deep artificial", "compesation design", "narx model", "models for compesation", "identification of narx", "supervised object detection", "weakly supervised object", "cascade attentive dropout", "attentive dropout", "battery", "learning a semantic", "incremental deep language", "deep language model", "re-framing incremental deep", "evaluation for named", "scene graph classification", "prior knowledge", "graph classification", "partially labeled dataset", "multiple partially labeled", "dodnet"]], "link": [{"source": "neural network", "target": "deep neural network", "depth": [0, 0]}, {"source": "neural network", "target": "graph neural network", "depth": [0, 1]}, {"source": "neural network", "target": "convolutional neural network", "depth": [0, 0]}, {"source": "neural network", "target": "network", "depth": [0, 0]}, {"source": "neural network", "target": "recurrent neural network", "depth": [0, 1]}, {"source": "neural network", "target": "spiking neural network", "depth": [0, 2]}, {"source": "learning", "target": "reinforcement learning", "depth": [0, 0]}, {"source": "learning", "target": "deep learning", "depth": [0, 0]}, {"source": "learning", "target": "machine learning", "depth": [0, 0]}, {"source": "learning", "target": "transfer learning", "depth": [0, 1]}, {"source": "learning", "target": "federated learning", "depth": [0, 1]}, {"source": "learning", "target": "learning to segment", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "learning model", "depth": [0, 1]}, {"source": "deep learning", "target": "deep", "depth": [0, 1]}, {"source": "deep learning", "target": "deep learning approach", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "deep reinforcement learning", "depth": [0, 0]}, {"source": "reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "reinforcement", "depth": [0, 1]}, {"source": "reinforcement learning", "target": "multi-objective reinforcement learning", "depth": [0, 2]}, {"source": "network", "target": "deep neural network", "depth": [0, 0]}, {"source": "network", "target": "graph neural network", "depth": [0, 1]}, {"source": "network", "target": "relu network", "depth": [0, 2]}, {"source": "network", "target": "training", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning method", "depth": [0, 1]}, {"source": "machine learning", "target": "learning method", "depth": [0, 1]}, {"source": "machine learning", "target": "machine", "depth": [0, 1]}, {"source": "machine learning", "target": "machine learning approach", "depth": [0, 2]}, {"source": "machine learning", "target": "learning approach", "depth": [0, 1]}, {"source": "deep neural network", "target": "network acceleration", "depth": [0, 2]}, {"source": "deep reinforcement learning", "target": "deep reinforcement", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "reinforcement learning approach", "depth": [0, 1]}, {"source": "deep reinforcement learning", "target": "learning approach", "depth": [0, 1]}, {"source": "system", "target": "recommender system", "depth": [0, 2]}, {"source": "model", "target": "transfer", "depth": [0, 1]}, {"source": "detection", "target": "object detection", "depth": [0, 0]}, {"source": "detection", "target": "anomaly detection", "depth": [0, 1]}, {"source": "detection", "target": "object", "depth": [0, 1]}, {"source": "detection", "target": "detection performance", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional neural", "depth": [0, 2]}, {"source": "convolutional neural network", "target": "deep convolutional", "depth": [0, 2]}, {"source": "graph", "target": "random graph", "depth": [0, 2]}, {"source": "graph", "target": "random", "depth": [0, 2]}, {"source": "graph", "target": "knowledge graph", "depth": [0, 1]}, {"source": "object detection", "target": "object", "depth": [0, 1]}, {"source": "object detection", "target": "video object detection", "depth": [0, 2]}, {"source": "object detection", "target": "few-shot object detection", "depth": [0, 2]}, {"source": "object detection", "target": "autonomous driving", "depth": [0, 1]}, {"source": "representation learning", "target": "contrastive representation learning", "depth": [0, 1]}, {"source": "representation learning", "target": "unsupervised representation learning", "depth": [0, 2]}, {"source": "federated learning", "target": "federated", "depth": [1, 1]}, {"source": "federated learning", "target": "enabled federated learning", "depth": [1, 3]}, {"source": "federated learning", "target": "intelligent surface enabled", "depth": [1, 3]}, {"source": "federated learning", "target": "surface enabled federated", "depth": [1, 3]}, {"source": "graph neural network", "target": "novo drug design", "depth": [1, 3]}, {"source": "graph neural network", "target": "approximating retrosynthesis", "depth": [1, 3]}, {"source": "graph neural network", "target": "drug design", "depth": [1, 3]}, {"source": "algorithm", "target": "graph constraint logic", "depth": [1, 3]}, {"source": "algorithm", "target": "constraint logic", "depth": [1, 3]}, {"source": "algorithm", "target": "algorithms for graph", "depth": [1, 3]}, {"source": "point cloud", "target": "point", "depth": [1, 2]}, {"source": "point cloud", "target": "low overlap", "depth": [1, 3]}, {"source": "point cloud", "target": "clouds with low", "depth": [1, 3]}, {"source": "estimation", "target": "drop estimation", "depth": [1, 2]}, {"source": "estimation", "target": "estimation with machine", "depth": [1, 3]}, {"source": "estimation", "target": "fast ir drop", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "deep reinforcement", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "deep reinforcement", "target": "frenet space", "depth": [1, 2]}, {"source": "problem", "target": "video quality problem", "depth": [1, 3]}, {"source": "problem", "target": "quality problem", "depth": [1, 3]}, {"source": "problem", "target": "video quality", "depth": [1, 3]}, {"source": "classification", "target": "radio galaxy", "depth": [1, 3]}, {"source": "classification", "target": "classification of radio", "depth": [1, 3]}, {"source": "classification", "target": "data-efficient classification", "depth": [1, 3]}, {"source": "survey", "target": "communication via diffusion", "depth": [1, 3]}, {"source": "survey", "target": "survey on modulation", "depth": [1, 3]}, {"source": "survey", "target": "modulation technique", "depth": [1, 3]}, {"source": "learning approach", "target": "deep learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "machine learning approach", "depth": [1, 2]}, {"source": "learning approach", "target": "reinforcement learning approach", "depth": [1, 1]}, {"source": "learning approach", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "transfer learning", "target": "causal graph", "depth": [1, 3]}, {"source": "transfer learning", "target": "index direction", "depth": [1, 3]}, {"source": "transfer learning", "target": "main input", "depth": [1, 3]}, {"source": "transfer learning", "target": "direction with transfer", "depth": [1, 3]}, {"source": "datum", "target": "synthetic datum", "depth": [1, 2]}, {"source": "datum", "target": "on-shelf utility mining", "depth": [1, 3]}, {"source": "datum", "target": "sequence datum", "depth": [1, 2]}, {"source": "datum", "target": "utility mining", "depth": [1, 3]}, {"source": "approach", "target": "ontology", "depth": [1, 2]}, {"source": "approach", "target": "historical ontology", "depth": [1, 3]}, {"source": "approach", "target": "computational approach", "depth": [1, 2]}, {"source": "recognition", "target": "speech recognition", "depth": [1, 1]}, {"source": "recognition", "target": "action recognition", "depth": [1, 1]}, {"source": "recognition", "target": "speech", "depth": [1, 1]}, {"source": "recognition", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "image", "target": "decomposition", "depth": [1, 2]}, {"source": "image", "target": "intrinsic image decomposition", "depth": [1, 3]}, {"source": "image", "target": "decomposition using paradigm", "depth": [1, 3]}, {"source": "deep learning model", "target": "pathology-sensitive deep learning", "depth": [1, 3]}, {"source": "deep learning model", "target": "weakly labeled datum", "depth": [1, 3]}, {"source": "deep learning model", "target": "pathology-sensitive deep", "depth": [1, 3]}, {"source": "deep learning model", "target": "video capsule endoscopy", "depth": [1, 3]}, {"source": "learning model", "target": "machine learning model", "depth": [1, 2]}, {"source": "learning model", "target": "explaining deep learning", "depth": [1, 2]}, {"source": "learning model", "target": "layer-wise relevance propagation", "depth": [1, 3]}, {"source": "learning model", "target": "relevance propagation", "depth": [1, 2]}, {"source": "analysis", "target": "convergence analysis", "depth": [1, 2]}, {"source": "analysis", "target": "analysis of homotopy-sgd", "depth": [1, 3]}, {"source": "analysis", "target": "non-convex optimization", "depth": [1, 3]}, {"source": "analysis", "target": "homotopy-sgd for non-convex", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "semantic segmentation", "target": "segmentation", "depth": [1, 1]}, {"source": "semantic segmentation", "target": "distillation", "depth": [1, 1]}, {"source": "language model", "target": "language model performance", "depth": [1, 3]}, {"source": "language model", "target": "model performance measure", "depth": [1, 3]}, {"source": "language model", "target": "vocabulary size", "depth": [1, 3]}, {"source": "language model", "target": "model performance", "depth": [1, 3]}, {"source": "generation", "target": "face generation", "depth": [1, 2]}, {"source": "generation", "target": "lifting", "depth": [1, 3]}, {"source": "generation", "target": "face", "depth": [1, 1]}, {"source": "image classification", "target": "image classification based", "depth": [1, 2]}, {"source": "image classification", "target": "cancer image classification", "depth": [1, 3]}, {"source": "image classification", "target": "cancer image", "depth": [1, 3]}, {"source": "control", "target": "optimal control", "depth": [1, 1]}, {"source": "control", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "control", "target": "inference and control", "depth": [1, 3]}, {"source": "control", "target": "processes modeling", "depth": [1, 3]}, {"source": "question answering", "target": "visual question answering", "depth": [1, 1]}, {"source": "question answering", "target": "visual question", "depth": [1, 1]}, {"source": "question answering", "target": "answering", "depth": [1, 2]}, {"source": "question answering", "target": "consistent visual question", "depth": [1, 3]}, {"source": "optimization", "target": "stream-based monitoring language", "depth": [1, 3]}, {"source": "optimization", "target": "monitoring language", "depth": [1, 3]}, {"source": "optimization", "target": "optimizations for stream-based", "depth": [1, 3]}, {"source": "autonomous driving", "target": "driving", "depth": [1, 2]}, {"source": "autonomous driving", "target": "autonomous driving framework", "depth": [1, 3]}, {"source": "autonomous driving", "target": "short-term trajectory planning", "depth": [1, 3]}, {"source": "autonomous driving", "target": "frenet space", "depth": [1, 2]}, {"source": "dataset", "target": "scan dataset", "depth": [1, 3]}, {"source": "dataset", "target": "supervision for classification", "depth": [1, 3]}, {"source": "dataset", "target": "targeted self supervision", "depth": [1, 3]}, {"source": "speech recognition", "target": "speech", "depth": [1, 1]}, {"source": "speech recognition", "target": "domain adaptation", "depth": [1, 1]}, {"source": "speech recognition", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "deep", "target": "deep orthogonal linear", "depth": [1, 3]}, {"source": "deep", "target": "orthogonal linear network", "depth": [1, 3]}, {"source": "deep", "target": "deep orthogonal", "depth": [1, 3]}, {"source": "deep", "target": "networks are shallow", "depth": [1, 3]}, {"source": "model predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "model predictive control", "target": "predictive control", "depth": [1, 1]}, {"source": "model predictive control", "target": "polyflow approximation", "depth": [1, 3]}, {"source": "domain adaptation", "target": "unsupervised domain adaptation", "depth": [1, 2]}, {"source": "domain adaptation", "target": "adaptation", "depth": [1, 1]}, {"source": "domain adaptation", "target": "domain", "depth": [1, 1]}, {"source": "action recognition", "target": "human action recognition", "depth": [1, 2]}, {"source": "action recognition", "target": "human action", "depth": [1, 2]}, {"source": "action recognition", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "action recognition", "target": "skeleton-based action recognition", "depth": [1, 2]}, {"source": "anomaly detection", "target": "accurate anomaly detection", "depth": [1, 3]}, {"source": "anomaly detection", "target": "accurate anomaly", "depth": [1, 3]}, {"source": "anomaly detection", "target": "detection in dynamic", "depth": [1, 3]}, {"source": "anomaly detection", "target": "dynamic graph", "depth": [1, 2]}, {"source": "recurrent neural network", "target": "manifolds support multiplexed", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "support multiplexed integration", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "low-dimensional manifolds support", "depth": [1, 3]}, {"source": "recurrent neural network", "target": "manifolds support", "depth": [1, 3]}, {"source": "communication", "target": "communication delay", "depth": [1, 3]}, {"source": "communication", "target": "optimisation with communication", "depth": [1, 3]}, {"source": "communication", "target": "distributed optimisation", "depth": [1, 3]}, {"source": "prediction", "target": "motion prediction", "depth": [1, 2]}, {"source": "prediction", "target": "scene-compliant motion prediction", "depth": [1, 3]}, {"source": "prediction", "target": "ellipse loss", "depth": [1, 3]}, {"source": "prediction", "target": "loss for scene-compliant", "depth": [1, 3]}, {"source": "pose estimation", "target": "human pose estimation", "depth": [1, 2]}, {"source": "pose estimation", "target": "human pose", "depth": [1, 1]}, {"source": "pose estimation", "target": "handling object symmetry", "depth": [1, 3]}, {"source": "pose estimation", "target": "cnn-based pose estimation", "depth": [1, 3]}, {"source": "method", "target": "liquid simulation method", "depth": [1, 3]}, {"source": "method", "target": "simulation method", "depth": [1, 3]}, {"source": "method", "target": "evaluation of liquid", "depth": [1, 3]}, {"source": "embedding", "target": "word embedding", "depth": [1, 1]}, {"source": "embedding", "target": "dense graph", "depth": [1, 3]}, {"source": "embedding", "target": "embedding in dense", "depth": [1, 3]}, {"source": "embedding", "target": "matching through embedding", "depth": [1, 3]}, {"source": "knowledge graph", "target": "narrative knowledge graph", "depth": [1, 3]}, {"source": "knowledge graph", "target": "clustering in narrative", "depth": [1, 3]}, {"source": "knowledge graph", "target": "narrative knowledge", "depth": [1, 3]}, {"source": "generative adversarial", "target": "generative adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "adversarial network", "depth": [1, 1]}, {"source": "generative adversarial", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "object", "target": "self-supervised object detection", "depth": [1, 3]}, {"source": "object", "target": "detection without imagenet", "depth": [1, 3]}, {"source": "object", "target": "self-emd", "depth": [1, 3]}, {"source": "object", "target": "retrieval in clutter", "depth": [1, 3]}, {"source": "case study", "target": "urban twitter network", "depth": [1, 3]}, {"source": "case study", "target": "networks and community", "depth": [1, 3]}, {"source": "case study", "target": "microblogging in athen", "depth": [1, 3]}, {"source": "case study", "target": "twitter network", "depth": [1, 3]}, {"source": "convolutional network", "target": "graph convolutional network", "depth": [1, 1]}, {"source": "convolutional network", "target": "temporal convolutional network", "depth": [1, 2]}, {"source": "convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "transfer", "target": "style transfer", "depth": [1, 2]}, {"source": "transfer", "target": "style", "depth": [1, 2]}, {"source": "transfer", "target": "self-supervised models transfer", "depth": [1, 3]}, {"source": "transfer", "target": "models transfer", "depth": [1, 3]}, {"source": "information", "target": "contrastive self-supervised learning", "depth": [1, 2]}, {"source": "information", "target": "temporal information", "depth": [1, 2]}, {"source": "information", "target": "self-supervised learning", "depth": [1, 1]}, {"source": "code", "target": "binary code generation", "depth": [1, 3]}, {"source": "code", "target": "binary code", "depth": [1, 2]}, {"source": "code", "target": "code generation", "depth": [1, 3]}, {"source": "predictive control", "target": "model predictive", "depth": [1, 1]}, {"source": "predictive control", "target": "predictive control update", "depth": [1, 3]}, {"source": "predictive control", "target": "control update interval", "depth": [1, 3]}, {"source": "predictive control", "target": "control update", "depth": [1, 3]}, {"source": "machine translation", "target": "neural machine translation", "depth": [1, 1]}, {"source": "machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "machine translation", "target": "diversity in machine", "depth": [1, 3]}, {"source": "machine translation", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "time", "target": "linear time", "depth": [1, 2]}, {"source": "time", "target": "researcher stating broader", "depth": [1, 3]}, {"source": "time", "target": "stating broader impact", "depth": [1, 3]}, {"source": "time", "target": "researcher stating", "depth": [1, 3]}, {"source": "flow", "target": "normalizing flow", "depth": [1, 2]}, {"source": "flow", "target": "modeling and analysis", "depth": [1, 3]}, {"source": "flow", "target": "analysis of brain", "depth": [1, 3]}, {"source": "learning framework", "target": "deep learning framework", "depth": [1, 2]}, {"source": "learning framework", "target": "supervised graph learning", "depth": [1, 3]}, {"source": "learning framework", "target": "graph learning framework", "depth": [1, 3]}, {"source": "learning framework", "target": "supervised graph", "depth": [1, 2]}, {"source": "task", "target": "context-dependent task", "depth": [1, 3]}, {"source": "task", "target": "autonomous learning", "depth": [1, 2]}, {"source": "task", "target": "learning of multiple", "depth": [1, 3]}, {"source": "task", "target": "multiple", "depth": [1, 2]}, {"source": "generative adversarial network", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "generative adversarial network", "target": "controlled generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "controlled generative adversarial", "depth": [1, 3]}, {"source": "adversarial network", "target": "complexity controlled generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "controlled generative", "depth": [1, 3]}, {"source": "adversarial network", "target": "complexity controlled", "depth": [1, 3]}, {"source": "robot", "target": "enabling the sense", "depth": [1, 3]}, {"source": "robot", "target": "dual-arm robot", "depth": [1, 3]}, {"source": "robot", "target": "sense", "depth": [1, 3]}, {"source": "robot", "target": "enabling", "depth": [1, 3]}, {"source": "application", "target": "automatic specialization", "depth": [1, 3]}, {"source": "application", "target": "gaming application", "depth": [1, 3]}, {"source": "application", "target": "azp", "depth": [1, 3]}, {"source": "application", "target": "specialization", "depth": [1, 3]}, {"source": "theory", "target": "parallelism in blockchain", "depth": [1, 3]}, {"source": "theory", "target": "theory of transaction", "depth": [1, 3]}, {"source": "theory", "target": "transaction parallelism", "depth": [1, 3]}, {"source": "theory", "target": "blockchain", "depth": [1, 1]}, {"source": "translation", "target": "diversity in machine", "depth": [1, 3]}, {"source": "translation", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "translation", "target": "diversity", "depth": [1, 2]}, {"source": "differential equation", "target": "stochastic differential equation", "depth": [1, 1]}, {"source": "differential equation", "target": "approximations of stochastic", "depth": [1, 3]}, {"source": "differential equation", "target": "equations with unbounded", "depth": [1, 3]}, {"source": "self-supervised learning", "target": "contrastive self-supervised learning", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "temporal information", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "detection performance", "depth": [1, 2]}, {"source": "self-supervised learning", "target": "controllable environment", "depth": [1, 3]}, {"source": "learning method", "target": "machine learning method", "depth": [1, 1]}, {"source": "learning method", "target": "deep learning method", "depth": [1, 2]}, {"source": "learning method", "target": "model for prediction", "depth": [1, 3]}, {"source": "learning method", "target": "prediction of power", "depth": [1, 3]}, {"source": "training", "target": "tight hardness result", "depth": [1, 3]}, {"source": "training", "target": "results for training", "depth": [1, 3]}, {"source": "training", "target": "relu network", "depth": [1, 2]}, {"source": "semi-supervised learning", "target": "urinary tract infection", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "connected health", "depth": [1, 3]}, {"source": "semi-supervised learning", "target": "people with dementium", "depth": [1, 3]}, {"source": "machine", "target": "diversity in machine", "depth": [1, 3]}, {"source": "machine", "target": "decoding and diversity", "depth": [1, 3]}, {"source": "machine", "target": "diversity", "depth": [1, 2]}, {"source": "artificial intelligence", "target": "intelligence", "depth": [1, 1]}, {"source": "artificial intelligence", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "artificial intelligence", "target": "natural and artificial", "depth": [1, 3]}, {"source": "approximation", "target": "natural gradient based", "depth": [1, 3]}, {"source": "approximation", "target": "eigenvalue-corrected natural gradient", "depth": [1, 3]}, {"source": "approximation", "target": "natural gradient", "depth": [1, 2]}, {"source": "approximation", "target": "gradient based", "depth": [1, 3]}, {"source": "optimal control", "target": "properties in optimal", "depth": [1, 3]}, {"source": "optimal control", "target": "turnpike property", "depth": [1, 3]}, {"source": "optimal control", "target": "continuous-time result", "depth": [1, 3]}, {"source": "optimal control", "target": "overview of discrete-time", "depth": [1, 3]}, {"source": "reconstruction", "target": "curvelet frame", "depth": [1, 3]}, {"source": "reconstruction", "target": "reconstruction using sparsity", "depth": [1, 3]}, {"source": "reconstruction", "target": "sparsity in curvelet", "depth": [1, 3]}, {"source": "efficient", "target": "scalable neural vocoder", "depth": [1, 3]}, {"source": "efficient", "target": "efficient and scalable", "depth": [1, 2]}, {"source": "efficient", "target": "vocoders for streaming", "depth": [1, 3]}, {"source": "computing", "target": "aerial delivery network", "depth": [1, 3]}, {"source": "computing", "target": "generation aerial delivery", "depth": [1, 3]}, {"source": "computing", "target": "delivery network", "depth": [1, 3]}, {"source": "face recognition", "target": "set-based face recognition", "depth": [1, 3]}, {"source": "face recognition", "target": "joint clustering", "depth": [1, 3]}, {"source": "face recognition", "target": "clustering and classification", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "direct evolutionary optimization", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "binary latent", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "evolutionary optimization", "depth": [1, 3]}, {"source": "variational autoencoder", "target": "optimization of variational", "depth": [1, 3]}, {"source": "matching", "target": "maximum matching", "depth": [1, 3]}, {"source": "matching", "target": "dense graph", "depth": [1, 3]}, {"source": "matching", "target": "embedding in dense", "depth": [1, 3]}, {"source": "matching", "target": "matching through embedding", "depth": [1, 3]}, {"source": "video", "target": "video quality problem", "depth": [1, 3]}, {"source": "video", "target": "quality problem", "depth": [1, 3]}, {"source": "video", "target": "video quality", "depth": [1, 3]}, {"source": "video", "target": "patch-vq", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "graph convolutional", "depth": [1, 1]}, {"source": "graph convolutional network", "target": "syntactic constituency path", "depth": [1, 3]}, {"source": "graph convolutional network", "target": "encoding syntactic constituency", "depth": [1, 3]}, {"source": "instance segmentation", "target": "instance", "depth": [1, 2]}, {"source": "instance segmentation", "target": "segmentation of overlapping", "depth": [1, 3]}, {"source": "instance segmentation", "target": "overlapping object", "depth": [1, 3]}, {"source": "framework", "target": "hci methodological framework", "depth": [1, 3]}, {"source": "framework", "target": "methodological framework", "depth": [1, 3]}, {"source": "framework", "target": "integrated approach", "depth": [1, 2]}, {"source": "finite element method", "target": "element method", "depth": [1, 2]}, {"source": "finite element method", "target": "weak galerkin finite", "depth": [1, 2]}, {"source": "finite element method", "target": "galerkin finite element", "depth": [1, 2]}, {"source": "finite element method", "target": "finite element", "depth": [1, 1]}, {"source": "game", "target": "locally-aware constrained game", "depth": [1, 3]}, {"source": "game", "target": "games on network", "depth": [1, 3]}, {"source": "game", "target": "constrained game", "depth": [1, 3]}, {"source": "active learning", "target": "deep active learning", "depth": [1, 2]}, {"source": "active learning", "target": "sequence labeling based", "depth": [1, 3]}, {"source": "active learning", "target": "uncertainty in gradient", "depth": [1, 3]}, {"source": "active learning", "target": "learning for sequence", "depth": [1, 3]}, {"source": "attack", "target": "dnn", "depth": [1, 3]}, {"source": "attack", "target": "backdoor attack", "depth": [1, 2]}, {"source": "adversarial attack", "target": "universal trigger adversarial", "depth": [1, 3]}, {"source": "adversarial attack", "target": "trigger adversarial attack", "depth": [1, 3]}, {"source": "adversarial attack", "target": "detecting universal trigger", "depth": [1, 3]}, {"source": "adversarial attack", "target": "attack with honeypot", "depth": [1, 3]}, {"source": "medical image", "target": "medical image segmentation", "depth": [1, 2]}, {"source": "medical image", "target": "image segmentation", "depth": [1, 2]}, {"source": "medical image", "target": "medical image translation", "depth": [1, 3]}, {"source": "speech", "target": "multi-talker speech recognition", "depth": [1, 3]}, {"source": "speech", "target": "streaming", "depth": [1, 2]}, {"source": "speech", "target": "multi-talker speech", "depth": [1, 3]}, {"source": "speech", "target": "multi-talker", "depth": [1, 3]}, {"source": "neural architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "neural architecture search", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "neural architecture search", "target": "search", "depth": [1, 1]}, {"source": "architecture search", "target": "neural architecture", "depth": [1, 1]}, {"source": "architecture search", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "architecture search", "target": "search", "depth": [1, 1]}, {"source": "robust", "target": "robust instance segmentation", "depth": [1, 3]}, {"source": "robust", "target": "robust instance", "depth": [1, 3]}, {"source": "robust", "target": "dynamic convolution", "depth": [1, 3]}, {"source": "knowledge distillation", "target": "distillation", "depth": [1, 1]}, {"source": "knowledge distillation", "target": "knowledge", "depth": [1, 1]}, {"source": "linear system", "target": "pseudoinverse-free randomized block", "depth": [1, 3]}, {"source": "linear system", "target": "inconsistent linear system", "depth": [1, 3]}, {"source": "linear system", "target": "randomized block iterative", "depth": [1, 3]}, {"source": "natural language", "target": "natural language generation", "depth": [1, 2]}, {"source": "natural language", "target": "language generation", "depth": [1, 2]}, {"source": "natural language", "target": "neighbor-augmented policy update", "depth": [1, 3]}, {"source": "lower bound", "target": "approximate knowledge compilation", "depth": [1, 3]}, {"source": "lower bound", "target": "knowledge compilation", "depth": [1, 3]}, {"source": "lower bound", "target": "bounds for approximate", "depth": [1, 2]}, {"source": "dynamical system", "target": "multiple faults estimation", "depth": [1, 3]}, {"source": "dynamical system", "target": "tractable design", "depth": [1, 3]}, {"source": "dynamical system", "target": "performance bound", "depth": [1, 2]}, {"source": "dynamical system", "target": "faults estimation", "depth": [1, 3]}, {"source": "challenge", "target": "framework and challenge", "depth": [1, 3]}, {"source": "challenge", "target": "federated crowdsensing", "depth": [1, 3]}, {"source": "challenge", "target": "crowdsensing", "depth": [1, 3]}, {"source": "social medium", "target": "social media network", "depth": [1, 3]}, {"source": "social medium", "target": "media network datum", "depth": [1, 3]}, {"source": "social medium", "target": "analysing social medium", "depth": [1, 3]}, {"source": "representation", "target": "information geometric interpretation", "depth": [1, 3]}, {"source": "representation", "target": "frame less visual", "depth": [1, 3]}, {"source": "representation", "target": "geometric interpretation", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "deep language-independent network", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "deep language-independent", "depth": [1, 3]}, {"source": "sentiment analysis", "target": "language-independent network", "depth": [1, 3]}, {"source": "study", "target": "learnability in gan", "depth": [1, 3]}, {"source": "study", "target": "study of trait", "depth": [1, 3]}, {"source": "study", "target": "traits that affect", "depth": [1, 3]}, {"source": "synthesis", "target": "conditionally-independent pixel synthesis", "depth": [1, 3]}, {"source": "synthesis", "target": "pixel synthesis", "depth": [1, 3]}, {"source": "synthesis", "target": "image generator", "depth": [1, 3]}, {"source": "synthesis", "target": "generators with conditionally-independent", "depth": [1, 3]}, {"source": "language", "target": "stream-based monitoring language", "depth": [1, 3]}, {"source": "language", "target": "monitoring language", "depth": [1, 3]}, {"source": "language", "target": "optimizations for stream-based", "depth": [1, 3]}, {"source": "language", "target": "stream-based monitoring", "depth": [1, 3]}, {"source": "neural architecture", "target": "multi-objective neural architecture", "depth": [1, 3]}, {"source": "neural architecture", "target": "search", "depth": [1, 1]}, {"source": "human", "target": "human action recognition", "depth": [1, 2]}, {"source": "human", "target": "human action", "depth": [1, 2]}, {"source": "human", "target": "complex event", "depth": [1, 3]}, {"source": "human", "target": "recognition in complex", "depth": [1, 3]}, {"source": "performance", "target": "detection performance", "depth": [1, 2]}, {"source": "performance", "target": "controllable environment", "depth": [1, 3]}, {"source": "performance", "target": "performance of self-supervised", "depth": [1, 3]}, {"source": "performance", "target": "environment", "depth": [1, 1]}, {"source": "federated", "target": "centralized learning", "depth": [1, 3]}, {"source": "federated", "target": "federated and centralized", "depth": [1, 3]}, {"source": "federated", "target": "hybrid federated", "depth": [1, 3]}, {"source": "bound", "target": "bounds for approximate", "depth": [1, 2]}, {"source": "bound", "target": "adaptive nonlinear control", "depth": [1, 3]}, {"source": "bound", "target": "nonlinear control", "depth": [1, 2]}, {"source": "text", "target": "causal bayesian network", "depth": [1, 3]}, {"source": "text", "target": "learning causal bayesian", "depth": [1, 3]}, {"source": "text", "target": "networks from text", "depth": [1, 3]}, {"source": "uncertainty", "target": "robustness", "depth": [1, 1]}, {"source": "uncertainty", "target": "role of uncertainty", "depth": [1, 3]}, {"source": "uncertainty", "target": "role", "depth": [1, 1]}, {"source": "uncertainty", "target": "anticipatory", "depth": [1, 3]}, {"source": "state estimation", "target": "distributed optimization scheme", "depth": [1, 3]}, {"source": "state estimation", "target": "norm-bounded uncertainty", "depth": [1, 3]}, {"source": "state estimation", "target": "distributed optimization", "depth": [1, 2]}, {"source": "state estimation", "target": "optimization scheme", "depth": [1, 3]}, {"source": "time series", "target": "time series representation", "depth": [1, 3]}, {"source": "time series", "target": "series representation learning", "depth": [1, 3]}, {"source": "time series", "target": "self-supervised time series", "depth": [1, 3]}, {"source": "motion planning", "target": "control barrier function", "depth": [1, 2]}, {"source": "motion planning", "target": "robust motion planning", "depth": [1, 3]}, {"source": "motion planning", "target": "barrier function", "depth": [1, 2]}, {"source": "deep learning approach", "target": "document understanding", "depth": [1, 3]}, {"source": "deep learning approach", "target": "survey of deep", "depth": [1, 3]}, {"source": "deep learning approach", "target": "approaches for ocr", "depth": [1, 3]}, {"source": "deep learning approach", "target": "ocr and document", "depth": [1, 3]}, {"source": "attention network", "target": "graph attention network", "depth": [1, 2]}, {"source": "attention network", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "attention network", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "attention network", "target": "path planning", "depth": [1, 1]}, {"source": "gan", "target": "structured latent manifold", "depth": [1, 3]}, {"source": "gan", "target": "conditional gan", "depth": [1, 3]}, {"source": "gan", "target": "geometrically structured latent", "depth": [1, 3]}, {"source": "gan", "target": "latent manifold", "depth": [1, 3]}, {"source": "depth estimation", "target": "multi-view depth estimation", "depth": [1, 2]}, {"source": "depth estimation", "target": "multi-view depth", "depth": [1, 2]}, {"source": "depth estimation", "target": "epipolar spatio-temporal network", "depth": [1, 3]}, {"source": "depth estimation", "target": "estimation using epipolar", "depth": [1, 3]}, {"source": "model predictive", "target": "predictive control update", "depth": [1, 3]}, {"source": "model predictive", "target": "control update interval", "depth": [1, 3]}, {"source": "model predictive", "target": "control update", "depth": [1, 3]}, {"source": "model predictive", "target": "learning model predictive", "depth": [1, 3]}, {"source": "reconfigurable intelligent surface", "target": "intelligent surface", "depth": [1, 1]}, {"source": "reconfigurable intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 2]}, {"source": "reconfigurable intelligent surface", "target": "aided multi-user network", "depth": [1, 3]}, {"source": "shape", "target": "multi-view transformation network", "depth": [1, 3]}, {"source": "shape", "target": "shape recognition", "depth": [1, 3]}, {"source": "shape", "target": "transformation network", "depth": [1, 3]}, {"source": "human pose", "target": "human pose estimation", "depth": [1, 2]}, {"source": "human pose", "target": "shape estimation", "depth": [1, 2]}, {"source": "human pose", "target": "pose and shape", "depth": [1, 2]}, {"source": "inference", "target": "variational inference", "depth": [1, 2]}, {"source": "inference", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "inference", "target": "inference and control", "depth": [1, 3]}, {"source": "inference", "target": "processes modeling", "depth": [1, 3]}, {"source": "kernel", "target": "kernel using switchable", "depth": [1, 3]}, {"source": "kernel", "target": "continuous conversion", "depth": [1, 3]}, {"source": "kernel", "target": "switchable cyclegan", "depth": [1, 3]}, {"source": "pandemic", "target": "economic risk evaluation", "depth": [1, 3]}, {"source": "pandemic", "target": "unsupervised learning", "depth": [1, 2]}, {"source": "pandemic", "target": "learning for economic", "depth": [1, 3]}, {"source": "pandemic", "target": "economic risk", "depth": [1, 3]}, {"source": "data augmentation", "target": "augmentation", "depth": [1, 2]}, {"source": "data augmentation", "target": "soft data augmentation", "depth": [1, 3]}, {"source": "data augmentation", "target": "learning by soft", "depth": [1, 3]}, {"source": "gaussian proces", "target": "hybrid gaussian proces", "depth": [1, 3]}, {"source": "gaussian proces", "target": "gaussian process model", "depth": [1, 3]}, {"source": "gaussian proces", "target": "entity embedding vector", "depth": [1, 3]}, {"source": "gaussian proces", "target": "hybrid gaussian", "depth": [1, 3]}, {"source": "social network", "target": "online social network", "depth": [1, 3]}, {"source": "generative model", "target": "deep generative model", "depth": [1, 1]}, {"source": "generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "generative model", "target": "multi-objective reinforcement learning", "depth": [1, 2]}, {"source": "generative model", "target": "provable multi-objective reinforcement", "depth": [1, 3]}, {"source": "recommendation", "target": "exploring global information", "depth": [1, 3]}, {"source": "recommendation", "target": "session-based recommendation", "depth": [1, 3]}, {"source": "recommendation", "target": "global information", "depth": [1, 3]}, {"source": "recommendation", "target": "information for session-based", "depth": [1, 3]}, {"source": "search", "target": "supervised text classification", "depth": [1, 3]}, {"source": "search", "target": "text search", "depth": [1, 3]}, {"source": "search", "target": "text classification", "depth": [1, 1]}, {"source": "search", "target": "supervised text", "depth": [1, 3]}, {"source": "logic", "target": "modal intuitionistic logic", "depth": [1, 3]}, {"source": "logic", "target": "intuitionistic logic", "depth": [1, 3]}, {"source": "logic", "target": "theorems for modal", "depth": [1, 3]}, {"source": "entity recognition", "target": "named entity recognition", "depth": [1, 1]}, {"source": "entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "entity recognition", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "graph convolutional", "target": "graph convolutional adversarial", "depth": [1, 3]}, {"source": "graph convolutional", "target": "convolutional adversarial network", "depth": [1, 3]}, {"source": "graph convolutional", "target": "generate realistic dance", "depth": [1, 3]}, {"source": "linear", "target": "linear symmetry-based disentanglement", "depth": [1, 3]}, {"source": "linear", "target": "metric for linear", "depth": [1, 3]}, {"source": "linear", "target": "symmetry-based disentanglement", "depth": [1, 3]}, {"source": "linear", "target": "disentanglement", "depth": [1, 2]}, {"source": "neural machine translation", "target": "neural machine", "depth": [1, 1]}, {"source": "neural machine translation", "target": "soft lexical constraint", "depth": [1, 3]}, {"source": "neural machine translation", "target": "lexical constraint", "depth": [1, 3]}, {"source": "image generation", "target": "few-shot image generation", "depth": [1, 3]}, {"source": "image generation", "target": "unsupervised few-shot image", "depth": [1, 3]}, {"source": "image generation", "target": "autoencoders for unsupervised", "depth": [1, 3]}, {"source": "image generation", "target": "few-shot image", "depth": [1, 2]}, {"source": "service", "target": "latency-sensitive service delivery", "depth": [1, 3]}, {"source": "service", "target": "service delivery", "depth": [1, 3]}, {"source": "service", "target": "latency-sensitive service", "depth": [1, 3]}, {"source": "metric learning", "target": "deep metric learning", "depth": [1, 2]}, {"source": "metric learning", "target": "knowledge retention", "depth": [1, 3]}, {"source": "metric learning", "target": "retention through metric", "depth": [1, 3]}, {"source": "metric learning", "target": "knowledge", "depth": [1, 1]}, {"source": "adversarial training", "target": "virtual adversarial training", "depth": [1, 3]}, {"source": "adversarial training", "target": "latent space virtual", "depth": [1, 3]}, {"source": "adversarial training", "target": "space virtual adversarial", "depth": [1, 3]}, {"source": "library", "target": "partially ordered hierarchical", "depth": [1, 3]}, {"source": "library", "target": "ordered hierarchical planner", "depth": [1, 3]}, {"source": "library", "target": "partially ordered", "depth": [1, 3]}, {"source": "visual question answering", "target": "visual question", "depth": [1, 1]}, {"source": "visual question answering", "target": "answering", "depth": [1, 2]}, {"source": "visual question answering", "target": "consistent visual question", "depth": [1, 3]}, {"source": "visual question answering", "target": "lexical perturbation", "depth": [1, 3]}, {"source": "intelligence", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "intelligence", "target": "natural and artificial", "depth": [1, 3]}, {"source": "intelligence", "target": "meta-learning", "depth": [1, 1]}, {"source": "intelligence", "target": "fourth industrial revolution", "depth": [1, 3]}, {"source": "power system", "target": "power system testbed", "depth": [1, 3]}, {"source": "power system", "target": "resilient power system", "depth": [1, 3]}, {"source": "power system", "target": "cyber-physical resilient power", "depth": [1, 3]}, {"source": "power system", "target": "system testbed", "depth": [1, 3]}, {"source": "gaussian process", "target": "process", "depth": [1, 2]}, {"source": "gaussian process", "target": "deep gaussian process", "depth": [1, 3]}, {"source": "interaction", "target": "kinetic simulation", "depth": [1, 3]}, {"source": "interaction", "target": "plasma-material interaction", "depth": [1, 3]}, {"source": "interaction", "target": "parallel", "depth": [1, 3]}, {"source": "performance analysis", "target": "conventional deep learning", "depth": [1, 3]}, {"source": "performance analysis", "target": "empirical performance analysis", "depth": [1, 3]}, {"source": "performance analysis", "target": "analysis of conventional", "depth": [1, 3]}, {"source": "performance analysis", "target": "conventional deep", "depth": [1, 3]}, {"source": "fairness", "target": "minimax group fairness", "depth": [1, 3]}, {"source": "fairness", "target": "algorithms and experiment", "depth": [1, 3]}, {"source": "fairness", "target": "group fairness", "depth": [1, 3]}, {"source": "research", "target": "wearable computing research", "depth": [1, 3]}, {"source": "research", "target": "computing research", "depth": [1, 3]}, {"source": "research", "target": "systematic review", "depth": [1, 2]}, {"source": "security", "target": "inflating cardinality estimate", "depth": [1, 3]}, {"source": "security", "target": "inflating cardinality", "depth": [1, 3]}, {"source": "security", "target": "cardinality estimate", "depth": [1, 3]}, {"source": "fast", "target": "fast auxiliary space", "depth": [1, 3]}, {"source": "fast", "target": "auxiliary space preconditioner", "depth": [1, 3]}, {"source": "fast", "target": "preconditioners on surface", "depth": [1, 3]}, {"source": "fast", "target": "auxiliary space", "depth": [1, 3]}, {"source": "edge computing", "target": "edge computing applied", "depth": [1, 3]}, {"source": "edge computing", "target": "internet of vehicle", "depth": [1, 3]}, {"source": "edge computing", "target": "survey on blockchain", "depth": [1, 3]}, {"source": "named entity recognition", "target": "named entity", "depth": [1, 1]}, {"source": "named entity recognition", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity recognition", "target": "multi-dataset evaluation", "depth": [1, 3]}, {"source": "intelligent surface", "target": "reconfigurable intelligent", "depth": [1, 2]}, {"source": "intelligent surface", "target": "large intelligent surface", "depth": [1, 2]}, {"source": "intelligent surface", "target": "aided multi-user network", "depth": [1, 3]}, {"source": "intelligent surface", "target": "interplay between noma", "depth": [1, 3]}, {"source": "recent advance", "target": "advance", "depth": [1, 2]}, {"source": "recent advance", "target": "selective image encryption", "depth": [1, 3]}, {"source": "recent advance", "target": "advances in selective", "depth": [1, 3]}, {"source": "recent advance", "target": "selective image", "depth": [1, 3]}, {"source": "modeling", "target": "hawkes processes modeling", "depth": [1, 3]}, {"source": "modeling", "target": "inference and control", "depth": [1, 3]}, {"source": "modeling", "target": "processes modeling", "depth": [1, 3]}, {"source": "environment", "target": "detection performance", "depth": [1, 2]}, {"source": "environment", "target": "controllable environment", "depth": [1, 3]}, {"source": "environment", "target": "performance of self-supervised", "depth": [1, 3]}, {"source": "machine learning method", "target": "model for prediction", "depth": [1, 3]}, {"source": "machine learning method", "target": "prediction of power", "depth": [1, 3]}, {"source": "machine learning method", "target": "power output", "depth": [1, 3]}, {"source": "testing", "target": "charles can pen-test", "depth": [1, 3]}, {"source": "testing", "target": "vulnerability testing", "depth": [1, 3]}, {"source": "testing", "target": "evolutionary approach", "depth": [1, 3]}, {"source": "visual question", "target": "answering", "depth": [1, 2]}, {"source": "visual question", "target": "consistent visual question", "depth": [1, 3]}, {"source": "visual question", "target": "lexical perturbation", "depth": [1, 3]}, {"source": "visual question", "target": "perturbations for consistent", "depth": [1, 3]}, {"source": "fading channel", "target": "fast fading channel", "depth": [1, 3]}, {"source": "fading channel", "target": "frequency domain equalization", "depth": [1, 3]}, {"source": "fading channel", "target": "low-complexity frequency domain", "depth": [1, 3]}, {"source": "fading channel", "target": "frequency domain", "depth": [1, 2]}, {"source": "principle", "target": "speed-up ramp-counter adc", "depth": [1, 3]}, {"source": "principle", "target": "locality principle", "depth": [1, 3]}, {"source": "principle", "target": "adc using locality", "depth": [1, 3]}, {"source": "principle", "target": "ramp-counter adc", "depth": [1, 3]}, {"source": "exploring", "target": "data science tool", "depth": [1, 3]}, {"source": "exploring", "target": "exploring the political", "depth": [1, 3]}, {"source": "exploring", "target": "science tool", "depth": [1, 3]}, {"source": "learning technique", "target": "machine learning technique", "depth": [1, 2]}, {"source": "learning technique", "target": "low-cost nir spectrometer", "depth": [1, 3]}, {"source": "learning technique", "target": "egg storage time", "depth": [1, 3]}, {"source": "meta-learning", "target": "meta-learning in natural", "depth": [1, 3]}, {"source": "meta-learning", "target": "natural and artificial", "depth": [1, 3]}, {"source": "meta-learning", "target": "connecting context-specific adaptation", "depth": [1, 3]}, {"source": "meta-learning", "target": "humans to meta-learning", "depth": [1, 3]}, {"source": "finite element", "target": "element method", "depth": [1, 2]}, {"source": "finite element", "target": "bakhvalov-type mesh", "depth": [1, 3]}, {"source": "finite element", "target": "spectral finite element", "depth": [1, 3]}, {"source": "finite element", "target": "finite element approximation", "depth": [1, 3]}, {"source": "robustness", "target": "improves robustness", "depth": [1, 3]}, {"source": "robustness", "target": "uncertainty in deep", "depth": [1, 2]}, {"source": "robustness", "target": "rethinking uncertainty", "depth": [1, 3]}, {"source": "scene graph", "target": "road scene graph", "depth": [1, 3]}, {"source": "scene graph", "target": "scene representation dataset", "depth": [1, 3]}, {"source": "scene graph", "target": "semantic graph-based scene", "depth": [1, 3]}, {"source": "scene graph", "target": "graph-based scene representation", "depth": [1, 3]}, {"source": "domain", "target": "adaptation", "depth": [1, 1]}, {"source": "feature", "target": "audio feature", "depth": [1, 3]}, {"source": "feature", "target": "movement generation", "depth": [1, 3]}, {"source": "feature", "target": "generation with audio", "depth": [1, 3]}, {"source": "property", "target": "parametric graph template", "depth": [1, 3]}, {"source": "property", "target": "properties and algorithm", "depth": [1, 3]}, {"source": "property", "target": "graph template", "depth": [1, 3]}, {"source": "property", "target": "parametric graph", "depth": [1, 3]}, {"source": "perspective", "target": "edge", "depth": [1, 2]}, {"source": "mobile robot", "target": "mobile robot navigation", "depth": [1, 3]}, {"source": "mobile robot", "target": "control for mobile", "depth": [1, 3]}, {"source": "mobile robot", "target": "robot navigation", "depth": [1, 2]}, {"source": "face", "target": "face generation", "depth": [1, 2]}, {"source": "face", "target": "lifting", "depth": [1, 3]}, {"source": "face", "target": "stylegan", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge retention", "depth": [1, 3]}, {"source": "knowledge", "target": "retention through metric", "depth": [1, 3]}, {"source": "knowledge", "target": "retention", "depth": [1, 3]}, {"source": "knowledge", "target": "knowledge transfer", "depth": [1, 3]}, {"source": "deep learning based", "target": "explaining deep learning", "depth": [1, 2]}, {"source": "deep learning based", "target": "computer-aided diagnosis system", "depth": [1, 3]}, {"source": "deep learning based", "target": "diagnosis system", "depth": [1, 3]}, {"source": "deep learning based", "target": "learning based computer-aided", "depth": [1, 3]}, {"source": "language understanding", "target": "spoken language understanding", "depth": [1, 2]}, {"source": "language understanding", "target": "spoken language", "depth": [1, 2]}, {"source": "language understanding", "target": "understanding resource package", "depth": [1, 3]}, {"source": "path planning", "target": "graph attention network", "depth": [1, 2]}, {"source": "path planning", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "path planning", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "path planning", "target": "large-scale multi-robot path", "depth": [1, 3]}, {"source": "uncertainty estimation", "target": "neural uncertainty estimation", "depth": [1, 3]}, {"source": "uncertainty estimation", "target": "target speaker extraction", "depth": [1, 3]}, {"source": "uncertainty estimation", "target": "improving rnn transducer", "depth": [1, 2]}, {"source": "uncertainty estimation", "target": "rnn transducer", "depth": [1, 2]}, {"source": "relation extraction", "target": "long-tail relation extraction", "depth": [1, 3]}, {"source": "relation extraction", "target": "learning relation prototype", "depth": [1, 3]}, {"source": "relation extraction", "target": "prototype from unlabeled", "depth": [1, 3]}, {"source": "relation extraction", "target": "texts for long-tail", "depth": [1, 3]}, {"source": "galerkin method", "target": "discontinuous galerkin method", "depth": [1, 2]}, {"source": "galerkin method", "target": "matrix-free isogeometric galerkin", "depth": [1, 3]}, {"source": "galerkin method", "target": "isogeometric galerkin method", "depth": [1, 3]}, {"source": "galerkin method", "target": "interpolation based quadrature", "depth": [1, 3]}, {"source": "deep generative model", "target": "deep generative", "depth": [1, 2]}, {"source": "deep generative model", "target": "volumetrized deep generative", "depth": [1, 3]}, {"source": "deep generative model", "target": "progressively volumetrized deep", "depth": [1, 3]}, {"source": "deep generative model", "target": "data-efficient contextual learning", "depth": [1, 3]}, {"source": "multi-view clustering", "target": "incomplete multi-view clustering", "depth": [1, 2]}, {"source": "multi-view clustering", "target": "incomplete multi-view", "depth": [1, 2]}, {"source": "multi-view clustering", "target": "unbalanced incomplete multi-view", "depth": [1, 3]}, {"source": "multi-view clustering", "target": "view evolution", "depth": [1, 3]}, {"source": "strategy", "target": "deviation and adaptive", "depth": [1, 3]}, {"source": "strategy", "target": "adaptive strategy", "depth": [1, 3]}, {"source": "strategy", "target": "continuous blackjack", "depth": [1, 3]}, {"source": "learning algorithm", "target": "model learning algorithm", "depth": [1, 3]}, {"source": "learning algorithm", "target": "accurate action model", "depth": [1, 3]}, {"source": "learning algorithm", "target": "action model learning", "depth": [1, 3]}, {"source": "learning algorithm", "target": "accurate action", "depth": [1, 3]}, {"source": "boltzmann machine", "target": "restricted boltzmann machine", "depth": [1, 2]}, {"source": "boltzmann machine", "target": "restricted boltzmann", "depth": [1, 2]}, {"source": "boltzmann machine", "target": "multinary restricted boltzmann", "depth": [1, 3]}, {"source": "boltzmann machine", "target": "tractable loss function", "depth": [1, 3]}, {"source": "segmentation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "segmentation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "segmentation", "target": "channel-wise", "depth": [1, 3]}, {"source": "denoising", "target": "image denoising", "depth": [1, 2]}, {"source": "denoising", "target": "regularization by denoising", "depth": [1, 3]}, {"source": "denoising", "target": "reconstruction and calibration", "depth": [1, 3]}, {"source": "denoising", "target": "calibration using regularization", "depth": [1, 3]}, {"source": "regularization", "target": "nonlinear ill-posed equation", "depth": [1, 3]}, {"source": "regularization", "target": "ill-posed equation", "depth": [1, 3]}, {"source": "regularization", "target": "systems of nonlinear", "depth": [1, 3]}, {"source": "reinforcement", "target": "transition state", "depth": [1, 3]}, {"source": "reinforcement", "target": "learning of transition", "depth": [1, 3]}, {"source": "reinforcement", "target": "state", "depth": [1, 2]}, {"source": "word embedding", "target": "deconstructing word embedding", "depth": [1, 3]}, {"source": "word embedding", "target": "word embedding algorithm", "depth": [1, 3]}, {"source": "word embedding", "target": "deconstructing word", "depth": [1, 3]}, {"source": "word embedding", "target": "embedding algorithm", "depth": [1, 3]}, {"source": "augmented reality", "target": "manufacturing execution system", "depth": [1, 3]}, {"source": "augmented reality", "target": "integrating augmented reality", "depth": [1, 3]}, {"source": "augmented reality", "target": "level for industry", "depth": [1, 3]}, {"source": "neural machine", "target": "soft lexical constraint", "depth": [1, 3]}, {"source": "neural machine", "target": "lexical constraint", "depth": [1, 3]}, {"source": "neural machine", "target": "transformer with repositioning", "depth": [1, 3]}, {"source": "neural machine", "target": "repositioning for neural", "depth": [1, 3]}, {"source": "inference attack", "target": "membership inference attack", "depth": [1, 2]}, {"source": "inference attack", "target": "membership inference", "depth": [1, 2]}, {"source": "inference attack", "target": "based privacy-preserving technique", "depth": [1, 2]}, {"source": "inference attack", "target": "technique against membership", "depth": [1, 3]}, {"source": "person re-identification", "target": "unsupervised person re-identification", "depth": [1, 3]}, {"source": "person re-identification", "target": "networks via asymmetric", "depth": [1, 3]}, {"source": "person re-identification", "target": "unsupervised person", "depth": [1, 2]}, {"source": "person re-identification", "target": "enhancing diversity", "depth": [1, 3]}, {"source": "distillation", "target": "distillation for semantic", "depth": [1, 3]}, {"source": "distillation", "target": "channel-wise distillation", "depth": [1, 3]}, {"source": "distillation", "target": "channel-wise", "depth": [1, 3]}, {"source": "review", "target": "vietnamese review", "depth": [1, 3]}, {"source": "review", "target": "bert for sentiment", "depth": [1, 3]}, {"source": "review", "target": "analysis of vietnamese", "depth": [1, 3]}, {"source": "review", "target": "fine-tuning bert", "depth": [1, 3]}, {"source": "role", "target": "role of uncertainty", "depth": [1, 3]}, {"source": "role", "target": "anticipatory", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "approximations of stochastic", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "equations with unbounded", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "convergence of smooth", "depth": [1, 3]}, {"source": "stochastic differential equation", "target": "unbounded coefficient", "depth": [1, 3]}, {"source": "diffusion", "target": "communication via diffusion", "depth": [1, 3]}, {"source": "diffusion", "target": "survey on modulation", "depth": [1, 3]}, {"source": "diffusion", "target": "modulation technique", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "sample pair generation", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "ultrasound video contrastive", "depth": [1, 3]}, {"source": "contrastive representation learning", "target": "video contrastive representation", "depth": [1, 3]}, {"source": "mobile device", "target": "object detection processing", "depth": [1, 3]}, {"source": "mobile device", "target": "detection processing pipeline", "depth": [1, 3]}, {"source": "mobile device", "target": "analysis and implication", "depth": [1, 3]}, {"source": "data analysis", "target": "functional data analysis", "depth": [1, 3]}, {"source": "data analysis", "target": "visual analytics approach", "depth": [1, 2]}, {"source": "data analysis", "target": "progressive functional datum", "depth": [1, 3]}, {"source": "data analysis", "target": "monitor time-series datum", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "random mapping function", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "combinatorial bayesian optimization", "depth": [1, 3]}, {"source": "bayesian optimization", "target": "convex polytope", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "long-term short-term planning", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "frenet space", "depth": [1, 2]}, {"source": "reinforcement learning approach", "target": "exploring grid topology", "depth": [1, 3]}, {"source": "reinforcement learning approach", "target": "grid topology reconfiguration", "depth": [1, 3]}, {"source": "conversion", "target": "kernel using switchable", "depth": [1, 3]}, {"source": "conversion", "target": "continuous conversion", "depth": [1, 3]}, {"source": "conversion", "target": "switchable cyclegan", "depth": [1, 3]}, {"source": "graph attention", "target": "graph attention network", "depth": [1, 2]}, {"source": "graph attention", "target": "message-aware graph attention", "depth": [1, 3]}, {"source": "graph attention", "target": "multi-robot path planning", "depth": [1, 3]}, {"source": "graph attention", "target": "large-scale multi-robot path", "depth": [1, 3]}, {"source": "blockchain", "target": "blockchain mechanism", "depth": [1, 3]}, {"source": "blockchain", "target": "characteristics of crypto", "depth": [1, 3]}, {"source": "blockchain", "target": "mechanism and distributional", "depth": [1, 3]}, {"source": "construction", "target": "heap manipulation", "depth": [1, 3]}, {"source": "construction", "target": "symbiotic construction", "depth": [1, 3]}, {"source": "construction", "target": "construction for heap", "depth": [1, 3]}, {"source": "distributed", "target": "communication delay", "depth": [1, 3]}, {"source": "distributed", "target": "optimisation with communication", "depth": [1, 3]}, {"source": "distributed", "target": "distributed optimisation", "depth": [1, 3]}, {"source": "distributed", "target": "delay", "depth": [1, 3]}, {"source": "big datum", "target": "projective clustering approximation", "depth": [1, 3]}, {"source": "big datum", "target": "faster projective clustering", "depth": [1, 3]}, {"source": "big datum", "target": "projective clustering", "depth": [1, 3]}, {"source": "big datum", "target": "clustering approximation", "depth": [1, 3]}, {"source": "trajectory planning", "target": "multiple autonomous underwater", "depth": [1, 3]}, {"source": "trajectory planning", "target": "autonomous underwater vehicle", "depth": [1, 3]}, {"source": "trajectory planning", "target": "safety guarantee", "depth": [1, 2]}, {"source": "sequence labeling", "target": "sequence labeling based", "depth": [1, 3]}, {"source": "sequence labeling", "target": "deep active learning", "depth": [1, 2]}, {"source": "sequence labeling", "target": "uncertainty in gradient", "depth": [1, 3]}, {"source": "sequence labeling", "target": "learning for sequence", "depth": [1, 3]}, {"source": "experimental study", "target": "isolated centrifugal fan", "depth": [1, 3]}, {"source": "experimental study", "target": "tonal noise source", "depth": [1, 3]}, {"source": "experimental study", "target": "numerical and experimental", "depth": [1, 3]}, {"source": "experimental study", "target": "centrifugal fan", "depth": [1, 3]}, {"source": "text classification", "target": "supervised text classification", "depth": [1, 3]}, {"source": "text classification", "target": "text search", "depth": [1, 3]}, {"source": "text classification", "target": "supervised text", "depth": [1, 3]}, {"source": "continual learning", "target": "deep artificial neuron", "depth": [1, 3]}, {"source": "continual learning", "target": "artificial neuron", "depth": [1, 2]}, {"source": "continual learning", "target": "learning with deep", "depth": [1, 3]}, {"source": "continual learning", "target": "deep artificial", "depth": [1, 3]}, {"source": "design", "target": "compesation design", "depth": [1, 3]}, {"source": "design", "target": "narx model", "depth": [1, 3]}, {"source": "design", "target": "models for compesation", "depth": [1, 3]}, {"source": "design", "target": "identification of narx", "depth": [1, 3]}, {"source": "weakly supervised", "target": "supervised object detection", "depth": [1, 3]}, {"source": "weakly supervised", "target": "weakly supervised object", "depth": [1, 3]}, {"source": "weakly supervised", "target": "cascade attentive dropout", "depth": [1, 3]}, {"source": "weakly supervised", "target": "attentive dropout", "depth": [1, 3]}, {"source": "action", "target": "action detection", "depth": [1, 2]}, {"source": "action", "target": "battery", "depth": [1, 3]}, {"source": "action", "target": "camera", "depth": [1, 2]}, {"source": "action", "target": "learning a semantic", "depth": [1, 3]}, {"source": "multi-task learning", "target": "incremental deep language", "depth": [1, 3]}, {"source": "multi-task learning", "target": "deep language model", "depth": [1, 3]}, {"source": "multi-task learning", "target": "re-framing incremental deep", "depth": [1, 3]}, {"source": "named entity", "target": "interpretable multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity", "target": "multi-dataset evaluation", "depth": [1, 3]}, {"source": "named entity", "target": "evaluation for named", "depth": [1, 3]}, {"source": "attention", "target": "scene graph classification", "depth": [1, 3]}, {"source": "attention", "target": "prior knowledge", "depth": [1, 3]}, {"source": "attention", "target": "graph classification", "depth": [1, 3]}, {"source": "learning to segment", "target": "partially labeled dataset", "depth": [1, 3]}, {"source": "learning to segment", "target": "multiple partially labeled", "depth": [1, 3]}, {"source": "learning to segment", "target": "dodnet", "depth": [1, 3]}]}